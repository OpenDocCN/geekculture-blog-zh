<html>
<head>
<title>Creating New Humans With Generative Adversarial Networks and Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用生成对抗网络和深度学习创造新人类</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/creating-new-humans-with-generative-adversarial-networks-and-deep-learning-e1312ddec544?source=collection_archive---------7-----------------------#2021-02-04">https://medium.com/geekculture/creating-new-humans-with-generative-adversarial-networks-and-deep-learning-e1312ddec544?source=collection_archive---------7-----------------------#2021-02-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="3ec1" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">你认识这里的人吗？</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/3d18f17d88523efea5cecdd19bb49ce7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oJcrB64tX4FE_YjL.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Photo from <a class="ae jt" href="https://github.com/NVlabs/stylegan" rel="noopener ugc nofollow" target="_blank">NVlabs</a></figcaption></figure><h1 id="8416" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">你玩过这个电子游戏吗？</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ju"><img src="../Images/b9e1932751a0cfa3431343ceeef86ebf.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/0*9mnQIc2DxOXQ60g3.gif"/></div><figcaption class="jp jq et er es jr js bd b be z dx">Pacman from <a class="ae jt" href="https://nv-tlabs.github.io/gameGAN/" rel="noopener ugc nofollow" target="_blank">Nv-tlabs</a></figcaption></figure><p id="7e65" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">也许你两个都答应了，或者只答应了第二个。毕竟，这是吃豆人，我们一生中至少玩过一次的游戏。</p><p id="e327" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated"><strong class="jx hj">对吗？</strong></p><p id="0486" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">事实上，无论是人还是游戏都不是真实的。它们都是使用人工智能生成的，更具体地说，是一个<strong class="jx hj">生成对抗网络。</strong></p></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h1 id="8d4a" class="if ig hi bd ih ii la ik il im lb io ip iq lc is it iu ld iw ix iy le ja jb jc bi translated">什么是GAN，它是如何工作的？</h1><p id="7497" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">GAN或生成式对抗网络是一种深度学习框架，擅长于<strong class="jx hj">生成</strong>与真实数据点无法区分的虚假数据点。这就意味着GANs能够生成栩栩如生的面孔，甚至可以再造视频游戏。</p><h2 id="028f" class="lk ig hi bd ih ll lm ln il lo lp lq ip kg lr ls it kk lt lu ix ko lv lw jb lx bi translated">它们是如何工作的？</h2><p id="dbb0" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">顾名思义，生成性<strong class="jx hj">对抗性</strong>网络由两个相互竞争的网络组成。冲突被利用来创建期望的输出。</p><p id="bc42" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">GAN的第一个神经网络称为生成器。给定一个随机输入，生成器尽最大努力生成一个似是而非的输出。</p><p id="b0c1" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">第二个网络是鉴别器。鉴别器的工作就是看发电机的输出，确定是真的还是假的。</p><p id="a1f4" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">两个网络一起训练，玩零和游戏。生成器生成样本。这些样本连同来自数据集中的示例一起被提供给鉴别器。鉴别器将每幅图像分类为真或假。这种分类用于改进两个网络。对鉴别器进行了调整，以更好地对图像进行分类，并识别由生成器生成的图像。更新生成器以创建更好的图像来欺骗鉴别器。</p><p id="6087" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">随着他们的训练和改进，生成器在生成数据方面变得更好，直到最终，生成的结果与真实的结果无法区分。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/f77eb2881b4563739f3d8257cdd64ee5.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/0*F5QJT8dRPwDL61JJ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx">The loss of a GAN during training. The networks compete, which is shown by the losses. If one network has a decrease in loss, the other one will have an increase and vice versa | image from <a class="ae jt" href="https://stats.stackexchange.com/questions/332991/how-to-interpret-the-following-gan-training-losses" rel="noopener ugc nofollow" target="_blank">StackExchange</a></figcaption></figure><p id="738a" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">发生器可以被认为是试图制造假币的伪造者，而鉴别器是试图检测假币的警察。鉴别器将假币与真币进行比较，从而更好地检测假币。因此，生产者必须更加努力地工作，制造更有说服力的赝品。鉴别者和制造者相互竞争，改进他们的方法，直到制造者能够制造出与真币几乎无法区分的伪钞。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lz"><img src="../Images/2caf7a3738600c30601b3392c324daa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LegfOLsNEsSqj_0Me0ZKeg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">The structure of a GAN</figcaption></figure><h2 id="0c48" class="lk ig hi bd ih ll lm ln il lo lp lq ip kg lr ls it kk lt lu ix ko lv lw jb lx bi translated">事实真相</h2><p id="c9b9" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">为了改善网络，这两个网络必须以价值最大化为目标。因此，我们训练鉴别器将正确的标签分配给生成的图像和真实样本。<em class="ma"> D(x) </em>表示<em class="ma"> x </em>来自真实数据集而非生成器的概率。<em class="ma"> D(x) </em>产生值1，意味着鉴别器100%确信样本是真实图像。为了最大化鉴别器将正确标签分配给生成样本和真实样本的概率，鉴别器试图最大化</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mb"><img src="../Images/b3e64486d8248e21107e3eaea523d126.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*uGkPqNxoXvo4SGFZBp0IBw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx">The discriminator maximizes its accuracy at classifying images. To do this D(x) of a real image should be close to 1, and D(G(z)) (the discriminator’s prediction on an image generated from the generator) should be close to 0.</figcaption></figure><p id="d62b" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">同时，发电机被训练为最大化<em class="ma"> log( D( G(z))，</em>其中z是输入噪声。<em class="ma"> log( D( G(z ) ) </em>表示鉴别器对发电机输出的分类。数字越大，鉴别器越认为发电机的输出是真实的，因此发电机的性能越好。</p><h1 id="72bb" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">GANs是如何如此擅长生成图像的？</h1><p id="74d8" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated"><strong class="jx hj">卷积层</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mc"><img src="../Images/2dde59d5440f1cbf91c21483aa100dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WXfDIw7mnzlSuQZJ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">structure of CNN | photo from <a class="ae jt" href="https://commons.wikimedia.org/wiki/File:Typical_cnn.png" rel="noopener ugc nofollow" target="_blank">wikipedia</a></figcaption></figure><p id="7c9a" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">卷积层通常存在于卷积神经网络中，擅长处理图像。这些网络从图像中识别形状和图案。</p><p id="5ba2" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">鉴别器利用这种能力来更好地对图像进行分类，生成器利用这种能力来创建与真实图像具有相同形状和图案的更真实的图像。</p><p id="61c1" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">卷积层和GAN结构一起创建了一种GAN类型，称为深度卷积生成对抗网络或DCGAN。</p></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h1 id="1eeb" class="if ig hi bd ih ii la ik il im lb io ip iq lc is it iu ld iw ix iy le ja jb jc bi translated">让我们创建自己的GAN来生成逼真的人眼</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es md"><img src="../Images/7d777d04d9816ab207b13c54716721aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5b1Lt-D5tB0Z7Z7f"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Photo by <a class="ae jt" href="https://unsplash.com/@victorfreitas?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Victor Freitas</a> on <a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="b75e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">数据收集</h1><p id="0cb6" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">像所有的机器学习模型一样，要取得好的结果，需要高质量和丰富的数据集。</p><p id="6bce" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">我们将图像加载到RGB的3个通道中，然后将它们的大小调整为128x128。我发现这个分辨率是低计算时间和高分辨率之间的一个很好的折衷。当图像被载入时，每个像素的值是一个从0到255的浮点数。因为我们的生成器的激活函数将是tanh，像素的值必须映射到-1到1之间的值来匹配。</p><p id="65c4" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">使用的数据集是使用此i <a class="ae jt" href="https://github.com/ostrolucky/Bulk-Bing-Image-downloader" rel="noopener ugc nofollow" target="_blank">图像下载脚本</a>和另一个眼睛数据集找到的图像的组合。这产生了大约1000张特写眼睛的图像。这可能已经足够了，但我决定通过水平翻转每个图像来增加数据，以创建总共2000个图像。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="a082" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">在加载和扩充图像后，我们在第23行创建了一个TensorFlow数据集，将图像混洗并将其分成几批。我用64的批处理大小来训练模型，因为这是我的GPU可以处理的最大值。数据集中的最终图像如下所示。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mg"><img src="../Images/8454cfab88e71e2f55781eae3411f81f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*x0LTzrX-Aeai9qRr1Vy7GQ.png"/></div></figure><h1 id="e332" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">构建模型</h1><h2 id="ea1b" class="lk ig hi bd ih ll lm ln il lo lp lq ip kg lr ls it kk lt lu ix ko lv lw jb lx bi translated">鉴别器</h2><p id="1123" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">鉴别器只是一个简单的CNN。增加了一个sigmoid激活函数，以保持输出值在0和1之间。CNN输出1意味着100%确信输入图像是来自数据集的真实眼睛。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="me mf l"/></div></figure><h2 id="b109" class="lk ig hi bd ih ll lm ln il lo lp lq ip kg lr ls it kk lt lu ix ko lv lw jb lx bi translated">发电机</h2><p id="43b4" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">发电机稍微复杂一点</p><p id="bc0a" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">它几乎就像一个反向的CNN。它接受随机噪声的张量，并应用过滤器将其放大为128x128的图像。随着它的训练，过滤器的权重将提高，以创建更好的图像。</p><p id="3af4" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">因此，生成器的输入是大小为100的随机张量。</p><p id="abec" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">形状100的张量连接到大小为16*16*256的致密层。这是为了使层的大小可以调整到16，16，256。换句话说，随机噪声被转换成具有256个通道的16x16图像。Conv2DTranspose层会减少通道，同时增加输出的大小，直到发生器最终输出一个128x128的3通道图像。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="me mf l"/></div></figure><h2 id="f715" class="lk ig hi bd ih ll lm ln il lo lp lq ip kg lr ls it kk lt lu ix ko lv lw jb lx bi translated">失败</h2><p id="62b6" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">损失函数是GAN和任何神经网络的关键部分。对于GANs，我们对鉴频器和发生器使用两个独立的损耗函数来优化二者。</p><h2 id="3169" class="lk ig hi bd ih ll lm ln il lo lp lq ip kg lr ls it kk lt lu ix ko lv lw jb lx bi translated">发电机损耗</h2><p id="9614" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">生成器正在进行优化，以创建一个输出，鉴别器会将类似于训练数据的图像分类为1。为了对此进行优化，我们使用二进制交叉熵损失，当在当前训练步骤中给定来自生成器的图像时，<em class="ma"> y_true </em>为1，<em class="ma"> y_pred </em>为鉴别器的输出。这捕获了生成的图像与真实图像的接近程度。</p><h2 id="8568" class="lk ig hi bd ih ll lm ln il lo lp lq ip kg lr ls it kk lt lu ix ko lv lw jb lx bi translated">鉴频器损耗</h2><p id="0970" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">与生成器不同，鉴别器每一步都在两个方面进行了优化。它的准确性在于将真实的训练数据匹配到标签1，将生成的输出匹配到标签0。因此，鉴频器损耗由两个独立的损耗相加而成。像发电机损耗一样，使用二进制交叉熵。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="me mf l"/></div></figure><h1 id="66b8" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">培养</h1><p id="e9a5" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">运行模型训练的主训练循环。在每个训练步骤中，为生成器生成噪声。然后，发生器的输出图像被输入鉴别器。同样，一批真实的眼睛被送入鉴别器。将鉴别器的两个预测放入损失函数，然后计算梯度。最后，Adam优化器将梯度应用于两个模型。在每个时期之后，生成一幅图像，其中包含生成器所生成内容的示例。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="me mf l"/></div></figure><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="me mf l"/></div></figure><h1 id="a7c2" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结果</h1><h2 id="6ba4" class="lk ig hi bd ih ll lm ln il lo lp lq ip kg lr ls it kk lt lu ix ko lv lw jb lx bi translated">400个时代</h2><p id="7832" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">运行GAN 400个周期，得到如下结果。生成器已经从数据集中学习了皮肤颜色，并对眼窝和瞳孔的样子有了大致的了解。然而，生成的图像仍然是模糊的，并且具有许多伪像</p><div class="je jf jg jh fd ab cb"><figure class="mh ji mi mj mk ml mm paragraph-image"><img src="../Images/5445112bd26b1aa0af604c9087f3cd09.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*UAZBGcL1AyIx_iS2T0V-UQ.gif"/></figure><figure class="mh ji mi mj mk ml mm paragraph-image"><img src="../Images/737fa175dee59600ccdc210df00ffe12.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*sptUd7aMFMGJKD-cmrx_ag.png"/><figcaption class="jp jq et er es jr js bd b be z dx mn di mo mp">Eyes after 400 epochs</figcaption></figure></div><h2 id="5ce2" class="lk ig hi bd ih ll lm ln il lo lp lq ip kg lr ls it kk lt lu ix ko lv lw jb lx bi translated">另外400个时代(总共800个时代)</h2><p id="aa09" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">在运行GAN另外400个周期后，生成器对皮肤的纹理和颜色有了更好的了解。它开始生成具有良好瞳孔形状和颜色的合适的眼睛。图像的分辨率也有所提高。</p><div class="je jf jg jh fd ab cb"><figure class="mh ji mi mj mk ml mm paragraph-image"><img src="../Images/198eeb14db1678af02b3f8d3cf74c425.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*lS-Ch8jnihi3LHi1SmjQRg.gif"/></figure><figure class="mh ji mi mj mk ml mm paragraph-image"><img src="../Images/ea4847c65b27c1f6f439933d0050d11e.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*l5_bXsAMoYwpQQu_cv7Rsw.png"/><figcaption class="jp jq et er es jr js bd b be z dx mn di mo mp">GAN after 800 epochs</figcaption></figure></div><h2 id="81c6" class="lk ig hi bd ih ll lm ln il lo lp lq ip kg lr ls it kk lt lu ix ko lv lw jb lx bi translated">又是400个时代(总共1200个时代)</h2><p id="48b5" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">经过总共1200个周期后，GAN能够产生更精细的图像。生成器现在能够生成睫毛，并且眼睛周围有更多的清晰度。</p><div class="je jf jg jh fd ab cb"><figure class="mh ji mi mj mk ml mm paragraph-image"><img src="../Images/f0c1d5bf6d287d3f4dd87dd3fc0ad487.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*1kCLhuk1gDKfaKfBGgWr3Q.gif"/></figure><figure class="mh ji mi mj mk ml mm paragraph-image"><img src="../Images/bed364e59daa1970acd94287e9ddb39e.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*sffXK0Jixxj_uHylY2E72A.png"/><figcaption class="jp jq et er es jr js bd b be z dx mn di mo mp">GAN after 1200 epochs</figcaption></figure></div><h2 id="b746" class="lk ig hi bd ih ll lm ln il lo lp lq ip kg lr ls it kk lt lu ix ko lv lw jb lx bi translated">最后400个时代(总共1600个时代)</h2><p id="8f12" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">最后，在1600个纪元后，生成器大多能够生成具有较小伪影的高质量眼睛。发生器并不完美，如具有蓝色皮肤的图像、没有实际眼睛的图像以及具有红色而不是眼睛的图像所示。同时，生成器能够生成几乎逼真的眼睛。特别是第三列的第四只眼睛。</p><div class="je jf jg jh fd ab cb"><figure class="mh ji mi mj mk ml mm paragraph-image"><img src="../Images/88d5e9c31705fd352d41a161b4419df7.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*JyBLsI3m7iPgWu61J7Kptg.gif"/></figure><figure class="mh ji mi mj mk ml mm paragraph-image"><img src="../Images/709ab85f873221cb42e34f3469485ebd.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*_xLZy_4GZ9NzKAIa7yhWXg.png"/><figcaption class="jp jq et er es jr js bd b be z dx mn di mo mp">GAN after 1600 epochs</figcaption></figure></div><p id="2f55" class="pw-post-body-paragraph jv jw hi jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated"><strong class="jx hj">完整代码，以及训练数据，可以在</strong> <a class="ae jt" href="https://github.com/williamjchen/eyeGAN" rel="noopener ugc nofollow" target="_blank"> <strong class="jx hj"> Github </strong> </a>上找到</p><h1 id="98cd" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结论</h1><p id="6640" class="pw-post-body-paragraph jv jw hi jx b jy lf ka kb kc lg ke kf kg lh ki kj kk li km kn ko lj kq kr ks hb bi translated">即使是简单的架构，GANs也非常强大。它们能够生成与真实眼睛无法区分的眼睛。有了更复杂的架构和更深入的网络，GANs能够创造出<a class="ae jt" href="https://github.com/NVlabs/stylegan" rel="noopener ugc nofollow" target="_blank">栩栩如生的</a>面孔、<a class="ae jt" href="https://nv-tlabs.github.io/gameGAN/" rel="noopener ugc nofollow" target="_blank">再造视频游戏</a>、<a class="ae jt" href="https://github.com/jantic/DeOldify#about-deoldify" rel="noopener ugc nofollow" target="_blank">给图像和电影着色</a>，把人变成<a class="ae jt" href="https://github.com/justinpinkney/toonify" rel="noopener ugc nofollow" target="_blank">卡通</a>等等。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mq"><img src="../Images/10513be99fc1853b4d5ca3202286cc20.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*d1TkUmYE3G-r_XpPpBExoA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx">styleGAN architecture | image from <a class="ae jt" href="https://arxiv.org/pdf/1812.04948.pdf" rel="noopener ugc nofollow" target="_blank">styleGANpaper</a></figcaption></figure></div></div>    
</body>
</html>