<html>
<head>
<title>Cluster Data using K-means Algorithm in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的K-means算法聚类数据</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/cluster-data-using-k-means-algorithm-in-machine-learning-299304301a0c?source=collection_archive---------27-----------------------#2021-08-18">https://medium.com/geekculture/cluster-data-using-k-means-algorithm-in-machine-learning-299304301a0c?source=collection_archive---------27-----------------------#2021-08-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="236b" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">什么是k-means算法？K均值算法示例</h2></div><p id="368a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">ML爱好者们你们好..！！</p><p id="1f75" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们直接跳到使用K-means算法进行聚类的主题。因为k-means算法是无监督机器学习中最流行的聚类算法之一。在无监督机器学习中，我们处理未标记的数据。在我们看代码和解释之前。让我们看看什么是k-means，它是如何工作的。喝杯咖啡，开始忙碌吧。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es jt"><img src="../Images/bdd3eec25cc5528d0c68f2bd415b8f59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l_qh5SsHf904QEe48ai7SA.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">K-Mean Clustering Algorithm</figcaption></figure><h1 id="659d" class="kj kk hi bd kl km kn ko kp kq kr ks kt io ku ip kv ir kw is kx iu ky iv kz la bi translated">什么是K-means算法？</h1><p id="77ed" class="pw-post-body-paragraph ix iy hi iz b ja lb ij jc jd lc im jf jg ld ji jj jk le jm jn jo lf jq jr js hb bi translated">K-means是由James MacQueen在1967年开发的，他设计了它来根据对象的属性将对象分组为k个分区。这是最流行的聚类算法之一。在该算法的帮助下，我们使用数据的各种属性将输入数据分成k个子组。</p><p id="6fca" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">K-Means形成了一个向量空间，因为它假设对象的属性可以用向量来表示。k-means聚类中的每个聚类都由质心来标识。主要目标是最小化总的组内方差。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es jt"><img src="../Images/ec4800b38485f54438ba120da8e99b96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yMam4njyN8nXxWx34gpMoQ.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">K-means algorithm in unsupervised machine learning</figcaption></figure><p id="badd" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用优化技术实现这些数据点的分组。在该技术中，我们试图最小化数据点和相应的聚类质心之间的距离的平方和。正如你在上面的图片中看到的。</p><p id="a2a3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该算法遵循迭代过程，如下所示:</p><ul class=""><li id="3ef3" class="lg lh hi iz b ja jb jd je jg li jk lj jo lk js ll lm ln lo bi translated">选择k个簇的数量</li><li id="757a" class="lg lh hi iz b ja lp jd lq jg lr jk ls jo lt js ll lm ln lo bi translated">最初，创建k个分区，并随机或通过使用一些启发式信息来分配每个条目分区</li><li id="b427" class="lg lh hi iz b ja lp jd lq jg lr jk ls jo lt js ll lm ln lo bi translated">计算每组的质心</li><li id="5a4c" class="lg lh hi iz b ja lp jd lq jg lr jk ls jo lt js ll lm ln lo bi translated">计算每个观测值和每个聚类质心之间的距离</li><li id="5fb9" class="lg lh hi iz b ja lp jd lq jg lr jk ls jo lt js ll lm ln lo bi translated">然后，通过将每个入口点与质心更靠近它的聚类相关联来构建新的分区</li><li id="116d" class="lg lh hi iz b ja lp jd lq jg lr jk ls jo lt js ll lm ln lo bi translated">重新计算新群的质心</li><li id="182e" class="lg lh hi iz b ja lp jd lq jg lr jk ls jo lt js ll lm ln lo bi translated">重复步骤4到6，直到算法收敛</li></ul><p id="e4ca" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于质心的不同位置导致不同的结果，因此，每个质心的位置特别重要。该算法的目的是定位k个质心，每个聚类一个。最好的选择是把它们放在彼此尽可能远的地方。</p><p id="2e5d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们举一个例子，在这个例子中，我们将使用k-means算法将数据分组到由相对质心识别的四个聚类中。我们还将能够追踪边界，以确定彼此相关的领域。</p><h1 id="116c" class="kj kk hi bd kl km kn ko kp kq kr ks kt io ku ip kv ir kw is kx iu ky iv kz la bi translated">K均值聚类算法的示例代码</h1><p id="c4ba" class="pw-post-body-paragraph ix iy hi iz b ja lb ij jc jd lc im jf jg ld ji jj jk le jm jn jo lf jq jr js hb bi translated">您可以使用Jupyter Notebook或Google Colab来执行这个示例，或者您可以简单地创建一个python文件。数据集将在本文末尾提供。</p><ul class=""><li id="c465" class="lg lh hi iz b ja jb jd je jg li jk lj jo lk js ll lm ln lo bi translated">导入所需的库</li></ul><pre class="ju jv jw jx fd lu lv lw lx aw ly bi"><span id="59a5" class="lz kk hi lv b fi ma mb l mc md">import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.cluster import KMeans</span></pre><ul class=""><li id="6d0e" class="lg lh hi iz b ja jb jd je jg li jk lj jo lk js ll lm ln lo bi translated">加载输入数据并根据属性定义聚类的数量。</li></ul><pre class="ju jv jw jx fd lu lv lw lx aw ly bi"><span id="65b9" class="lz kk hi lv b fi ma mb l mc md">input_file = ('data_multivar.txt') #dataset<br/># Load data<br/>x = []<br/>with open(input_file, 'r') as f:<br/>    for line in f.readlines():<br/>        data = [float(i) for i in line.split(',')]<br/>        x.append(data)<br/>data = np.array(x)<br/>num_clusters = 4</span></pre><ul class=""><li id="82d8" class="lg lh hi iz b ja jb jd je jg li jk lj jo lk js ll lm ln lo bi translated">现在用下面的代码看看我们的数据。</li></ul><pre class="ju jv jw jx fd lu lv lw lx aw ly bi"><span id="526a" class="lz kk hi lv b fi ma mb l mc md">plt.figure()<br/>plt.scatter(data[:,0], data[:,1], marker='o', facecolors='none', edgecolors='k', s=30)<br/>x_min, x_max = min(data[:, 0]) - 1, max(data[:, 0]) + 1<br/>y_min, y_max = min(data[:, 1]) - 1, max(data[:, 1]) + 1<br/>plt.title('Input data')<br/>plt.xlim(x_min, x_max)<br/>plt.ylim(y_min, y_max)<br/>plt.xticks(())<br/>plt.yticks(())</span></pre><p id="3cc6" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当您运行该单元时，您会看到类似这样的内容:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es me"><img src="../Images/4b230de0688e1ac44a6b510730c160e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*jwdzsbtzScR9WPT2eDv_vg.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">Clustering using k-means algorithm</figcaption></figure><ul class=""><li id="7884" class="lg lh hi iz b ja jb jd je jg li jk lj jo lk js ll lm ln lo bi translated">现在让我们训练我们的数据模型</li></ul><pre class="ju jv jw jx fd lu lv lw lx aw ly bi"><span id="4344" class="lz kk hi lv b fi ma mb l mc md">kmeans = KMeans(init='k-means++', n_clusters=num_clusters, n_init=10)<br/>kmeans.fit(data)</span></pre><ul class=""><li id="4706" class="lg lh hi iz b ja jb jd je jg li jk lj jo lk js ll lm ln lo bi translated">现在我们的数据被训练，我们需要可视化的边界。</li></ul><pre class="ju jv jw jx fd lu lv lw lx aw ly bi"><span id="28c0" class="lz kk hi lv b fi ma mb l mc md"># Step size of the mesh<br/>step_size = 0.01</span><span id="e696" class="lz kk hi lv b fi mf mb l mc md"># Plot the boundaries<br/>x_min, x_max = min(data[:, 0]) - 1, max(data[:, 0]) + 1<br/>y_min, y_max = min(data[:, 1]) - 1, max(data[:, 1]) + 1<br/>x_values, y_values = np.meshgrid(np.arange(x_min, x_max,<br/>step_size), np.arange(y_min, y_max, step_size))</span><span id="fa53" class="lz kk hi lv b fi mf mb l mc md"># Predict labels for all points in the mesh<br/>predicted_labels = kmeans.predict(np.c_[x_values.ravel(),<br/>y_values.ravel()])</span></pre><ul class=""><li id="da3d" class="lg lh hi iz b ja jb jd je jg li jk lj jo lk js ll lm ln lo bi translated">现在，让我们绘制结果来查看边界。</li></ul><pre class="ju jv jw jx fd lu lv lw lx aw ly bi"><span id="1598" class="lz kk hi lv b fi ma mb l mc md"># Plot the results<br/>predicted_labels = predicted_labels.reshape(x_values.shape)<br/>plt.figure()<br/>plt.clf()<br/>plt.imshow(predicted_labels, interpolation='nearest', extent=(x_values.min(), x_values.max(), y_values.min(), y_values.max()), cmap=plt.cm.Paired, aspect='auto', origin='lower')<br/>plt.scatter(data[:,0], data[:,1], marker='o', facecolors='none', edgecolors='k', s=30)</span></pre><p id="143e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">结果将是这样的:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mg"><img src="../Images/f83417792723fbe05555d2cb20bcf864.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*CSwNiyloxx7fOCsL55oyhA.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">clustering using k-means algorithm</figcaption></figure><ul class=""><li id="2c07" class="lg lh hi iz b ja jb jd je jg li jk lj jo lk js ll lm ln lo bi translated">如果我们看一下质心</li></ul><pre class="ju jv jw jx fd lu lv lw lx aw ly bi"><span id="fedb" class="lz kk hi lv b fi ma mb l mc md">centroids = kmeans.cluster_centers_<br/>plt.scatter(centroids[:,0], centroids[:,1], marker='o', s=200, linewidths=3, color='k', zorder=10, facecolors='black')<br/>x_min, x_max = min(data[:, 0]) - 1, max(data[:, 0]) + 1<br/>y_min, y_max = min(data[:, 1]) - 1, max(data[:, 1]) + 1<br/>plt.title('Centoids and boundaries obtained using KMeans')<br/>plt.xlim(x_min, x_max)<br/>plt.ylim(y_min, y_max)<br/>plt.xticks(())<br/>plt.yticks(())<br/>plt.show()</span></pre><p id="2606" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mh"><img src="../Images/f39acc84d13351c71aab3e042c2b5c14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*ChVggmNPI91LawIedZ0nLg.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Centroids in clustering</figcaption></figure><p id="aca7" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">嗯，刚果..！！你做了这个。</p><p id="bf0c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">代码和数据集是</strong> <a class="ae mi" href="https://github.com/imrohit007/K-means-Example" rel="noopener ugc nofollow" target="_blank"> <strong class="iz hj">这里是</strong> </a></p><p id="5dde" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">嗯，就是这样。感谢您的阅读。如果这篇文章内容丰富，那么一定要鼓掌并与你的社区分享。</p><p id="d293" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">快乐学习..！！</p></div></div>    
</body>
</html>