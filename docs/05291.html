<html>
<head>
<title>Linear Regression using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python进行线性回归</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/linear-regression-using-python-7ce93ba8ff2a?source=collection_archive---------14-----------------------#2021-07-17">https://medium.com/geekculture/linear-regression-using-python-7ce93ba8ff2a?source=collection_archive---------14-----------------------#2021-07-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="98b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇博客中，你将全面了解什么是线性回归，它的应用，以及这种算法是如何工作的。在实现中，我们将看到如何从头开始在模型中应用线性回归，以及如何使用Scikit-learn python包。那么，让我们开始吧。</p><p id="1f89" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">线性回归</strong></p><p id="772e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归通常是第一个也是最容易实现的机器学习算法之一。该回归模型使用直线显示因变量和一个或多个自变量之间的线性关系，其中两个变量都应该是定量的。</p><p id="918c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回归线的方程表示为:<strong class="ih hj"> h(x_i)=b_0+b_1*(x_i) </strong>，其中h(x_i)表示第I次观测预测的响应值，b_0表示y截距，b_1表示回归线的斜率。B0和B1都是回归系数。</p><p id="2e06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">寻找最佳拟合回归线</strong></p><p id="7cef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了找到最佳拟合回归线，我们使用<strong class="ih hj">最小二乘法</strong>。</p><p id="da4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最小二乘法用于通过最小化数据点和回归线之间距离的平方和来找到最佳拟合线。最佳回归直线是具有最小值的直线。</p><p id="5bcf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们考虑一下</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/d7b9f98ac23f1f85deb08c6904e41952.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*8695KVWeziKLLTSG6el7lQ.png"/></div></figure><p id="a599" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，E0是剩余误差</p><p id="109f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，平方误差函数(J)定义为</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jl"><img src="../Images/fa24840fb928f3ef5d9f1efd42dbf603.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*nHRUotXH_82r8D1n2XlLwA.png"/></div></figure><p id="b028" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如前所述，最佳回归直线是具有最小值的直线。因此，我们必须使残差最小，并找到J最小的B0和B1的值。<br/>经过详细的数学计算，我们有了这些结论:<br/> SS_xy是x和y的交叉偏差之和。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jm"><img src="../Images/6b4567745c9b9e46b93226d345321038.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*YNd9T9jNwOIw5qGc288BFg.png"/></div></figure><p id="b447" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SS_xx是x的离差平方和。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jn"><img src="../Images/d6cef4ef77653c54e679a1a85ed123da.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*djEk_46DKV4fIwYTp9NPfQ.png"/></div></figure><p id="3f0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，B0和B1的值为:</p><p id="092f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">B1 = SS _ xy/SS _ xx</p><p id="e93d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">b_0 = ȳ- (b_1)* x̅</p><p id="3129" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> R分数</strong></p><p id="f9b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">r分数用于评估回归线的拟合程度，即实际数据与拟合回归线的接近程度。这个分数并不能说明这条线是否合适。低R值表示回归线与数据拟合不佳，而高R值表示模型良好，回归线拟合良好。</p><p id="a27b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">R = 1- (SS_r / SS_t)其中，</p><p id="82bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SS_r是残差的平方和。</p><p id="4a10" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SS_t是误差的总和。</p><p id="0c32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设R = 0.72，我们可以说</p><p id="1d3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可以参考的是，该模型解释了因变量的72%的变化，而剩余的28%的变化仍未被解释。</p><p id="a537" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">现在让我们看看实现:</strong></p><p id="bddb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们将计算回归系数</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jo"><img src="../Images/3036dfe51a5ab87c987c71f071afa887.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*bQ-gMoSGgD_V9fewj00iUw.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jp"><img src="../Images/75c6026ef7e298b843a673659f06eec0.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*E1ozLBeeY6t0kvqGjqMFAg.png"/></div></figure><p id="7df4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将找到h(x_i)(预测响应值)并绘制回归线</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jq"><img src="../Images/316b73eeefb5757c8df38ba1cab0bc0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*IB5BQUF5VasOovn66KkRIg.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/f3596691246f57b31afb7d68b939f675.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*9n0ykGZxPVeyFfRQNAbN3A.png"/></div></figure><p id="daa4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们终于可以找到R分数了</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es js"><img src="../Images/ce1210e9cf0b2d2fd1379b8d71690906.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*n45syyE_YkGC4krLuc8-OQ.png"/></div></figure><p id="342a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们可以看到R值为0.64(约为0.64)。)表明模型是好的，可以解释因变量72%的变异。</p><p id="59cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">使用Scikit-learn实现一个机器学习库应用的线性回归</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jt"><img src="../Images/68ac26c9b1e9ed7bc0ddf610c021155e.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*YL6lnHyBI0Bj2amyEJw54g.png"/></div></figure><p id="c402" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">线性回归的应用</strong></p><ul class=""><li id="1772" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">它提供了对消费者行为的洞察，并分析了定价的影响。</li><li id="8d3f" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">它有助于分析趋势和理解影响盈利能力的因素。</li><li id="e648" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">它有助于检查业务中的风险。</li><li id="bc0b" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">它有助于根据该地区的降雨量预测作物产量，根据多年的经验预测一个人的工资。</li></ul><p id="46e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望这篇博客能帮助你理解什么是线性回归，它的应用，如何从头开始实现它，以及如何使用Scikit学习库。</p><p id="8221" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢大家！</p></div></div>    
</body>
</html>