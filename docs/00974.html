<html>
<head>
<title>Natural Language Processing(NLP) Using Classification Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用分类模型的自然语言处理</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/natural-learning-processing-nlp-using-classification-model-a0d59ae09d48?source=collection_archive---------16-----------------------#2021-03-22">https://medium.com/geekculture/natural-learning-processing-nlp-using-classification-model-a0d59ae09d48?source=collection_archive---------16-----------------------#2021-03-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/41314e993637de3f832fa41e9dda4072.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y6mSYJgtnp9L6odYyQ1IDA.png"/></div></div></figure><p id="78d5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">什么是自然语言处理或NLP？首先要解释的是，我们人类能够阅读、理解和收集语言的含义。然而，为了让机器执行所有这些动作，它需要“NLP”来让计算机像我们一样理解语言。</p><p id="9d27" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">NLP有许多应用程序，例如为听力有困难的人提供的语音到文本服务，我们每天在消息中使用的文本到语音服务，我们讨厌交流的聊天机器人，除非它能解决我们的问题，以及翻译服务。</p><p id="71ec" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了让机器发挥NLP的魔力，我们需要对数据进行预处理。记号化是一种方法，我们可以用它来删除所有的空格或特殊字符，以及许多其他使用正则表达式的东西。</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="bccf" class="jx jy hi jt b fi jz ka l kb kc">tokenizer = RegexpTokenizer(r'\w+')</span></pre><p id="3180" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上面的代码是一个正则表达式的例子，它将挑选出字母数字字符序列作为标记，并丢弃其他所有内容。预处理的下一部分是词汇化/词干化。这个过程会缩短单词，这样我们就可以组合同一个单词的相似形式。简单来说，它将返回单词的基本/字典形式。</p><figure class="jo jp jq jr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kd"><img src="../Images/dc1d9519a562667832f0d4bdba59897e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tzexjf1MlVncIGmrAnlbwA.jpeg"/></div></div></figure><p id="7087" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">另一个预处理步骤是删除所有常见的英语单词，如“我”、“我”、“我们”等。我们可以把停用词定义为几乎没有任何意义的词。以下是英语停用词列表:</p><figure class="jo jp jq jr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ke"><img src="../Images/437960a2e96ab092234fee4a45b6dc15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R1NmayfziRv8QKKUw4dt_w.png"/></div></div></figure><p id="a77d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了练习和展示我从NLP中学到的新技能，我有一个项目是使用分类模型预测帖子来自哪个子目录。该项目预测帖子来自哪个子编辑，我选择了滑雪和滑雪板子编辑，以查看该模型如何在两个类似的子编辑主题之间进行预测:</p><p id="023a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">使用自然语言处理预测子网格:</strong></p><p id="50df" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我的项目的问题陈述是:</p><p id="3f78" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">“一家滑雪场希望使用分类模型找出帖子来自哪个子编辑区，并查看每个子编辑区中频繁使用的是什么类型的单词。”</p><p id="8de9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据是从Reddit上收集的，我是用来自https://api.pushshift.io/reddit/search/submission<a class="ae kf" href="https://api.pushshift.io/reddit/search/submission" rel="noopener ugc nofollow" target="_blank">的pushshift的API收集的。之后，我使用请求库，它允许我从不同的子编辑中提取帖子。然后，我用。json将数据格式化到字典中，并将其转换成用于建模的数据框架。</a></p><p id="1ccd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> EDA和数据清洗:</strong>在这个数据集中，有很多我不需要的不必要的列。因此，我将这些列过滤为三列“subreddit<strong class="is hj">”</strong>:告诉我们它来自哪个subred dit，“self text<strong class="is hj">”</strong>:文章的文本，“title<strong class="is hj">”</strong>:文章标题。之后，我删除了所有来自API的重复帖子，并将selftext和title合并到一个列中，以便模型更好地预测。然后，我将滑雪和滑雪板子编辑列转换为二进制列。</p><p id="fa9e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">预处理</strong>:正如我之前解释的，为了在模型中获得更好的结果，我们需要预处理文本。我使用RegExp Tokenizer: ('[a-z]\w+'):它只返回小写字母，没有任何标点符号或特殊字母。我还对文本进行了词汇化，以便使文本规范化，不包含任何派生单词。下面的图片展示了预处理步骤将如何删除所有的空白和一些出现在文本中该行之前的特殊字符。</p><figure class="jo jp jq jr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kg"><img src="../Images/ba35ad660e40ce4dec5218c5df219ec3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bVnI4jmN2N5TFBD_7QofUw.png"/></div></div></figure><p id="e2d6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">建模</strong>:在对数据进行预处理后，我决定使用带有CountVectorizer的逻辑回归和带有TfidfVectorizer的随机森林模型来预测帖子来自哪个子编辑。</p><p id="1bea" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">CountVectorizer:将文本转换为在整个文本中出现的每个单词的计数的向量。</p><p id="b9a8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">TfidfVectorizer: Tfidf代表词频逆文档频率，它将文本转换为特征向量，旨在更好地定义一个单词对文档的重要性，同时还考虑到与同一语料库中其他文档的关系。</p><p id="3b2c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">逻辑回归:对通过/失败、赢/输或滑雪/滑雪板的某个类别或事件的概率进行建模。</p><p id="b6c3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">随机森林:它在数据集的各种自举子样本上拟合多个决策树分类器，并使用投票来提高预测精度和控制过拟合。</p><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es kh"><img src="../Images/94d3ff4b3956a2dca64e0a3e011b3d4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*jF44V3tFxL6dLXAYQAbDeA.png"/></div></figure><p id="8379" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">训练分数:模型如何符合训练数据</p><p id="b0d9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">测试分数:模型如何推广到新数据</p><p id="5bbc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">交叉价值分数:评估模型的有效性</p><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es ki"><img src="../Images/7f4aedfe111035b9a600925b559f3de9.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*kYj_-p8EWXo_oGD92kKJzw.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx">Confusion Matrix for the Model</figcaption></figure><p id="7c15" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们能够准确预测100个滑雪板柱子中的67个和250个滑雪板柱子中的242个。该模型能够比滑雪板柱子更好地预测滑雪板柱子，因为其灵敏度约为89%,因为其最小化了假阴性，而精度约为67%,因为其最小化了假阳性。</p><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es kn"><img src="../Images/b64b4ff653402fe0841c24e6aaf0e3ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*lgWXUmHd02kJgDcjSd70Iw.png"/></div></figure><p id="b16e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如你所看到的，所有预测滑雪帖子的热门词汇都与滑雪有关，其中一些非常有趣。因为pas是滑雪巡逻队中医疗专业人员的专用词。瑞士以在野外滑雪而闻名。Hackerone是一个奇怪的词，因为它是一家公司，其首席执行官是一个狂热的滑雪爱好者。</p><figure class="jo jp jq jr fd ij er es paragraph-image"><div class="er es ko"><img src="../Images/1cf3af37b0c1390ede7ebd6e472dd4b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*gZ87oRwBG6n541S9HJsE5Q.png"/></div></figure><p id="e0bc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于滑雪板，伯顿是一个词，因为杰克伯顿刚刚去世，因为他做了这么多的滑雪板，使之成为奥运会批准的运动。日本有滑雪板爱好者喜爱的最好的地形公园和度假村之一。</p><p id="081f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该模型能够准确预测88%的帖子。为了改进模型，我可以更深入地研究更多的特征工程，并使数据更加平衡。另一种方法是删除所有的词，如滑雪，滑雪板，滑雪。然而，这可能会使精确度下降很多。</p><p id="8515" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你想看看这个项目，下面是Github的链接。</p><p id="8d0e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae kf" href="https://github.com/tw1270/Web-APIs-and-Predicting-Subreddit" rel="noopener ugc nofollow" target="_blank">https://github.com/tw1270/Web-APIs-and-Predicting-Subreddit</a></p><div class="kp kq ez fb kr ks"><a href="https://www.linkedin.com/in/tenzin-wangdu/" rel="noopener  ugc nofollow" target="_blank"><div class="kt ab dw"><div class="ku ab kv cl cj kw"><h2 class="bd hj fi z dy kx ea eb ky ed ef hh bi translated">丹津·王度-大会数据科学研究员| LinkedIn</h2><div class="kz l"><h3 class="bd b fi z dy kx ea eb ky ed ef dx translated">我是一名数据科学家，拥有数学学士学位。我有使用Python、SQL和Tableau的项目工作经验…</h3></div><div class="la l"><p class="bd b fp z dy kx ea eb ky ed ef dx translated">www.linkedin.com</p></div></div><div class="lb l"><div class="lc l ld le lf lb lg io ks"/></div></div></a></div></div></div>    
</body>
</html>