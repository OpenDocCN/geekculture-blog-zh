<html>
<head>
<title>Deploying Multi-Node Hadoop Cluster on AWS Using Ansible Automation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Ansible Automation在AWS上部署多节点Hadoop集群</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/deploying-multi-node-hadoop-cluster-on-aws-using-ansible-automation-f16edb5d183a?source=collection_archive---------15-----------------------#2021-04-30">https://medium.com/geekculture/deploying-multi-node-hadoop-cluster-on-aws-using-ansible-automation-f16edb5d183a?source=collection_archive---------15-----------------------#2021-04-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/f657235040a10b62f17a787dc361483d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*KNuKM-xKiLNuxYxwep4SCw.gif"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Created by Raktim</figcaption></figure><div class=""/><div class=""><h2 id="caff" class="pw-subtitle-paragraph iu hw hx bd b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl dx translated">在当今世界，所有大公司都有数百万用户&amp;他们数十亿的数据。但是，请想一想，这些公司每天是如何存储这些海量数据的。让我们看看他们在使用什么工具&amp;我们如何也能自己设置这些工具…</h2></div><h1 id="d4c5" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">大数据:</h1><figure class="kf kg kh ki fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ke"><img src="../Images/a846e44c41cc297db652430246861634.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Rr9ckAQgeGPOn9cJ.jpg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Source : Google</figcaption></figure><p id="4bb6" class="pw-post-body-paragraph kj kk hx kl b km kn iy ko kp kq jb kr ks kt ku kv kw kx ky kz la lb lc ld le hb bi translated">我们都知道每天有数百万人在使用互联网，其中大多数人使用社交媒体平台，如T2脸书、Instagram、YouTube T3等。如果我们再想一想<strong class="kl hy">我们没有向这些社交媒体平台支付任何费用</strong>，那么这些公司是如何开展业务的。<strong class="kl hy">答案很简单……</strong></p><blockquote class="lf"><p id="5f31" class="lg lh hx bd li lj lk ll lm ln lo le dx translated">“如果你不为产品付费，那么你就是产品”</p></blockquote><p id="8992" class="pw-post-body-paragraph kj kk hx kl b km lp iy ko kp lq jb kr ks lr ku kv kw ls ky kz la lt lc ld le hb bi translated"><strong class="kl hy">这些公司拥有数十亿的用户数据&amp;利用这些数据，他们可以开展业务。</strong>现在最大的挑战是— <strong class="kl hy">他们如何能够存储如此大量的数据</strong>。此外，他们还需要有效地存储这些数据，以便将来可以快速读取它们。<strong class="kl hy">分布式存储集群的好戏来了。</strong></p><blockquote class="lu lv lw"><p id="32ce" class="kj kk lx kl b km kn iy ko kp kq jb kr ly kt ku kv lz kx ky kz ma lb lc ld le hb bi translated"><strong class="kl hy">几天前，我写了一篇博客，讨论了分布式存储集群如何解决大数据的挑战。</strong>为了便于参考，我附上了下面的链接…</p></blockquote><div class="hh hi ez fb hj mb"><a href="https://raktimmidya.medium.com/data-is-business-but-big-data-is-problem-ecda244ec620" rel="noopener follow" target="_blank"><div class="mc ab dw"><div class="md ab me cl cj mf"><h2 class="bd hy fi z dy mg ea eb mh ed ef hw bi translated">数据是业务:)但大数据是问题:(</h2><div class="mi l"><h3 class="bd b fi z dy mg ea eb mh ed ef dx translated">你有没有想象过流行的社交媒体平台有数十亿用户，他们是如何存储这些庞大的数据的…</h3></div><div class="mj l"><p class="bd b fp z dy mg ea eb mh ed ef dx translated">raktimmidya.medium.com</p></div></div><div class="mk l"><div class="ml l mm mn mo mk mp hp mb"/></div></div></a></div><h1 id="cf3e" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">Hadoop:</h1><figure class="kf kg kh ki fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mq"><img src="../Images/2e2c2a824959e98cd93379443623ad90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4hX6qjrKG4VxtL81.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Hadoop Logo</figcaption></figure><ul class=""><li id="d3a8" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">在我上面提到的博客中，我提到过<strong class="kl hy">要实现分布式存储集群，有很多技术工具可用</strong>。其中最流行的工具是<strong class="kl hy"> Hadoop </strong>在这种背景下。</li></ul><p id="a44b" class="pw-post-body-paragraph kj kk hx kl b km kn iy ko kp kq jb kr ks kt ku kv kw kx ky kz la lb lc ld le hb bi translated">Hadoop是一个允许我们在分布式环境中存储大数据的程序，因此，我们可以并行处理它。Hadoop中基本上有两个组件——<strong class="kl hy">HDFS&amp;纱</strong>。</p><p id="9217" class="pw-post-body-paragraph kj kk hx kl b km kn iy ko kp kq jb kr ks kt ku kv kw kx ky kz la lb lc ld le hb bi translated"><strong class="kl hy"> HDFS (Hadoop分布式文件系统)帮助我们在集群中存储各种格式的数据。YARN用于Hadoop中的资源管理。它允许对存储在HDFS各地的数据进行并行处理。</strong></p><blockquote class="lu lv lw"><p id="e83f" class="kj kk lx kl b km kn iy ko kp kq jb kr ly kt ku kv lz kx ky kz ma lb lc ld le hb bi translated">在这篇博客中，我不想深入Hadoop，但是我想展示如何创建可行的角色来在AWS EC2实例上设置Hadoop分布式存储集群。但是如果你想了解更多关于Hadoop的知识，你可以参考这个链接——<a class="ae na" href="https://www.tutorialspoint.com/hadoop/index.htm" rel="noopener ugc nofollow" target="_blank">https://www.tutorialspoint.com/hadoop/index.htm</a></p></blockquote><h1 id="d82b" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">让我们看看问题陈述:</h1><ol class=""><li id="ed0c" class="mr ms hx kl b km nb kp nc ks nd kw ne la nf le ng mx my mz bi translated">创建可启动4个AWS EC2实例的角色。</li><li id="381d" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le ng mx my mz bi translated">动态获取IP并创建清单，以便在这些实例上运行进一步的角色。</li><li id="760c" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le ng mx my mz bi translated">创建角色以配置Hadoop名称节点(主节点)、数据节点(工作节点)和客户端节点。</li><li id="e009" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le ng mx my mz bi translated">最后，将第一个和第二个实例配置为名称节点和客户端节点，并将其他两个系统配置为数据节点。</li></ol><h1 id="a132" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">先决条件:</h1><p id="3aaa" class="pw-post-body-paragraph kj kk hx kl b km nb iy ko kp nc jb kr ks nm ku kv kw nn ky kz la no lc ld le hb bi translated">显然，通过查看问题陈述，<strong class="kl hy">它可能看起来非常小&amp;简单，但是我们需要注意许多组件来实现这个设置。</strong>但是不要担心，因为我会一如既往地讨论每个&amp;小问题，这样在博客的结尾，你会觉得很舒服。</p><h2 id="b6fc" class="np jn hx bd jo nq nr ns js nt nu nv jw ks nw nx jy kw ny nz ka la oa ob kc oc bi translated">理解这一点有几个先决条件:</h2><ul class=""><li id="047c" class="mr ms hx kl b km nb kp nc ks nd kw ne la nf le mw mx my mz bi translated"><strong class="kl hy">虽然我将展示如何编写代码来完成这一实用，但你绝对需要AWS EC2实例&amp; Ansible角色的基本知识。如果你没有这些知识，那么你可以参考下面提到的博客… </strong></li></ul><div class="hh hi ez fb hj mb"><a rel="noopener follow" target="_blank" href="/swlh/getting-started-with-ansible-ee31be8c6a75"><div class="mc ab dw"><div class="md ab me cl cj mf"><h2 class="bd hy fi z dy mg ea eb mh ed ef hw bi translated">Ansible入门</h2><div class="mi l"><h3 class="bd b fi z dy mg ea eb mh ed ef dx translated">让我们学习Ansible的基础知识以及一个实用工具——使用Ansible进行docker环境供应。</h3></div><div class="mj l"><p class="bd b fp z dy mg ea eb mh ed ef dx translated">medium.com</p></div></div><div class="mk l"><div class="od l mm mn mo mk mp hp mb"/></div></div></a></div><div class="hh hi ez fb hj mb"><a href="https://raktimmidya.medium.com/getting-started-with-aws-terraform-293e9125dff" rel="noopener follow" target="_blank"><div class="mc ab dw"><div class="md ab me cl cj mf"><h2 class="bd hy fi z dy mg ea eb mh ed ef hw bi translated">AWS &amp; Terraform入门。</h2><div class="mi l"><h3 class="bd b fi z dy mg ea eb mh ed ef dx translated">如何入门使用Terraform在AWS中构建基础设施？</h3></div><div class="mj l"><p class="bd b fp z dy mg ea eb mh ed ef dx translated">raktimmidya.medium.com</p></div></div><div class="mk l"><div class="oe l mm mn mo mk mp hp mb"/></div></div></a></div><ul class=""><li id="3942" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">我使用我的本地Windows机器&amp;在那里我使用Oracle VM box来运行Linux操作系统。在我的虚拟机中，我安装了Ansible版本2.10.4。同样为了使事情更容易，我通过SSH将我的RHEL8虚拟机与我的Windows系统的VS代码连接起来。</li><li id="459b" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le mw mx my mz bi translated">最后<strong class="kl hy">我们需要一个AWS帐户&amp;在那里使用IAM我们需要创建AWS访问密钥&amp;秘密密钥</strong>，以便Ansible可以登录到我们的AWS帐户来启动实例。</li></ul><h2 id="ca09" class="np jn hx bd jo nq nr ns js nt nu nv jw ks nw nx jy kw ny nz ka la oa ob kc oc bi translated">让我们开始运行命令和编写代码…</h2><h1 id="86c2" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">创建四个角色:</h1><p id="3953" class="pw-post-body-paragraph kj kk hx kl b km nb iy ko kp nc jb kr ks nm ku kv kw nn ky kz la no lc ld le hb bi translated">我将在GitHub上上传我的职责&amp;代码——链接在本博客的末尾。在这篇博客中，我将讨论这些代码的每一点，所以要学习它们，请继续阅读。</p><ul class=""><li id="3374" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated"><strong class="kl hy">创建一个工作空间，比如说“hadoop-ws”。进入这个工作区&amp;创建一个名为“角色”的文件夹。现在进入这个文件夹&amp;运行下面提到的三个命令…</strong></li></ul><pre class="kf kg kh ki fd of og oh oi aw oj bi"><span id="a8ee" class="np jn hx og b fi ok ol l om on">ansible-galaxy init ec2<br/>ansible-galaxy init hadoop_master<br/>ansible-galaxy init hadoop_slave<br/>ansible-galaxy init hadoop_client</span></pre><ul class=""><li id="1530" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">记住一件事，它将在<strong class="kl hy"> "hadoop-ws/roles/" </strong>文件夹&amp;中创建四个角色，你可以给你的角色取任何你想要的名字，但是<strong class="kl hy">我建议取一些逻辑名字。</strong></li></ul><h1 id="8a44" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">设置可行的配置文件:</h1><p id="1371" class="pw-post-body-paragraph kj kk hx kl b km nb iy ko kp nc jb kr ks nm ku kv kw nn ky kz la no lc ld le hb bi translated"><strong class="kl hy">现在，在“hadoop-ws”工作区中，我们将创建一个本地配置文件。</strong>将来无论我们要使用什么ansible命令，它都将在这个工作空间内运行——“Hadoop-ws”，这样ansible就可以读取这个本地配置文件&amp;并相应地工作。</p><h2 id="85f3" class="np jn hx bd jo nq nr ns js nt nu nv jw ks nw nx jy kw ny nz ka la oa ob kc oc bi translated">因此，在“hadoop-ws”文件夹中创建一个名为“ansible.cfg”的文件，并将下面提到的内容放入其中…</h2><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><ul class=""><li id="203b" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">这里我们可以看到一些常见的关键字，如<strong class="kl hy">、【主机密钥检查】、【命令警告】</strong>等。因为我已经问过，要理解这个实用的东西需要基本的Ansible知识，所以我相信你知道这些关键词。</li><li id="e185" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le mw mx my mz bi translated">让我告诉一些新的关键字，如<strong class="kl hy">“私有密钥文件”</strong>，它表示aws密钥对。<strong class="kl hy">当Ansible通过SSH登录AWS实例来设置K8s时，它需要私有密钥文件</strong>。另外<strong class="kl hy">EC2实例的默认远程用户是“ec2-user”。</strong></li></ul><h1 id="62e7" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">创建AWS密钥对并将其放入工作区:</h1><p id="1db1" class="pw-post-body-paragraph kj kk hx kl b km nb iy ko kp nc jb kr ks nm ku kv kw nn ky kz la no lc ld le hb bi translated"><strong class="kl hy">转到AWS = &gt; EC2 = &gt; Key-pair &amp;在那里创建一个密钥对，比如说“hadoop_instance.pem”。</strong>然后在你的VM工作区下载密匙——“Hadoop-ws”。最后运行…</p><pre class="kf kg kh ki fd of og oh oi aw oj bi"><span id="744b" class="np jn hx og b fi ok ol l om on">chmod 400 hadoop_instance.pem</span></pre><h2 id="3a5d" class="np jn hx bd jo nq nr ns js nt nu nv jw ks nw nx jy kw ny nz ka la oa ob kc oc bi translated">创建一个用于存储AWS凭据的安全存储库:</h2><p id="dfb1" class="pw-post-body-paragraph kj kk hx kl b km nb iy ko kp nc jb kr ks nm ku kv kw nn ky kz la no lc ld le hb bi translated"><strong class="kl hy">最后，在您的工作区运行… </strong></p><pre class="kf kg kh ki fd of og oh oi aw oj bi"><span id="8e26" class="np jn hx og b fi ok ol l om on">ansible-vault create cred.yml</span></pre><ul class=""><li id="dcb8" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">它将要求提供一个保险库密码&amp;然后它将打开Linux上的VI编辑器，在这个文件中创建两个变量&amp;将您的AWS访问密钥和秘密密钥作为值。比如说…</li></ul><pre class="kf kg kh ki fd of og oh oi aw oj bi"><span id="6a3c" class="np jn hx og b fi ok ol l om on">access_key: ABCDEFGHIJK<br/>secret_key: abcdefghijk12345</span></pre><ul class=""><li id="1654" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">保存文件。现在你终于准备好编写可完成的角色了。</li></ul><h2 id="f301" class="np jn hx bd jo nq nr ns js nt nu nv jw ks nw nx jy kw ny nz ka la oa ob kc oc bi translated">仅供参考，运行下面提到的命令，观察下面截图中的输出…</h2><figure class="kf kg kh ki fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es oq"><img src="../Images/1088b6133fd7d7f13d779687a30ee63b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DlOvpnNCxNi5tqpc27J4TQ.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Screenshot of terminal</figcaption></figure><h1 id="478d" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">为ec2角色编写代码:</h1><figure class="kf kg kh ki fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es or"><img src="../Images/d99819f83414c413be29c1ef4a1165cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cvVLhTFBTFOQgPraVpvP0g.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Self made on Canva</figcaption></figure><h2 id="31e7" class="np jn hx bd jo nq nr ns js nt nu nv jw ks nw nx jy kw ny nz ka la oa ob kc oc bi translated">任务YML文件:</h2><p id="2e5a" class="pw-post-body-paragraph kj kk hx kl b km nb iy ko kp nc jb kr ks nm ku kv kw nn ky kz la no lc ld le hb bi translated"><strong class="kl hy">进入“hadoop-ws/roles/ec2/tasks/”文件夹&amp;开始编辑“main.yml”文件。在这个文件中写下下面提到的代码…</strong></p><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><ul class=""><li id="907a" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated"><strong class="kl hy">该文件帮助Ansible转到AWS &amp;以在那里启动4个实例&amp; 1个安全组。</strong>让我们试着一个一个地理解，这个文件中发生了什么。</li></ul><blockquote class="lu lv lw"><p id="690c" class="kj kk lx kl b km kn iy ko kp kq jb kr ly kt ku kv lz kx ky kz ma lb lc ld le hb bi translated">记住一件事<strong class="kl hy">我将在我的本地主机上运行这个文件&amp; Ansible将联系AWS API </strong>发送提示。现在<strong class="kl hy"> Ansible是在Python语言&amp;之上编写的，Ansible需要Boto &amp; Boto3 Python库来联系AWS API。</strong>这就是为什么使用pip模块，我们首先在本地主机上安装这两个库。这里我使用了<strong class="kl hy">“python _ pkgs”</strong>变量&amp;值存储在变量文件中，我将在后面展示。</p></blockquote><ul class=""><li id="5711" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">接下来，我们将使用<strong class="kl hy">“ec2 _ group”</strong>模块来创建AWS安全组。<strong class="kl hy">这里为了使事情简单，我只允许所有的港口都有入站&amp;出站的规则。但是在现实情况中，我们总是配置最好的证券。这里我使用了两个变量叫做<strong class="kl hy">“SG _ name”，“region_name”。</strong>这些变量的值我们将放在变量文件中。</strong></li><li id="889d" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le mw mx my mz bi translated">接下来，我们将使用<strong class="kl hy">“ec2”</strong>模块来启动ec2实例。这里我用loop用不同的标签多次调用这个模块。我们可以再次看到我使用了一些变量，&amp;那些变量&amp;它们的值在变量文件中被提及。</li><li id="49fb" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le mw mx my mz bi translated"><strong class="kl hy">这里需要注意的非常重要的一点是，我使用“register”将元数据存储在一个名为“ec2”</strong>的变量中，以便将来我可以从该元数据中检索重要信息。有一点我想提一下，如果你了解AWS的基础知识，那么你肯定知道我们为什么在ec2模块下使用这些选项。最后，我们将<strong class="kl hy">“wait”</strong>设为true，因为我希望ansible在实例成功启动后转到下一步。</li><li id="7c84" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le mw mx my mz bi translated"><strong class="kl hy">接下来，我将使用能够创建动态主机组的“添加主机”模块。</strong>请记住，我还没有在系统中创建任何<strong class="kl hy">“inventory”</strong>文件，因为我希望这个“add_host”模块创建该信息。我们看不到“add_host”在做什么，但您可以认为它在创建变量，这些变量包含我们将用作清单的IP地址。如果您想查看“添加主机”正在创建什么，那么您可以使用“调试”模块&amp;打印“主机组”。</li><li id="7e31" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le mw mx my mz bi translated">最后，我们对元数据进行JSON解析，以找到每个实例的公共ip &amp;然后我们将这些IP添加到我们的动态主机组中。最后，我们将在这里创建3个主机组，称为“namenode”、“datanode”和“clientnode”。Namenode包含一个实例IP，datanode包含两个实例IP，最后clientnode包含一个实例IP。</li><li id="33fa" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le mw mx my mz bi translated">最后，我使用<strong class="kl hy">“wait _ for”</strong>模块来确保SSH服务已经启动&amp;可用于连接。</li></ul><h2 id="47fd" class="np jn hx bd jo nq nr ns js nt nu nv jw ks nw nx jy kw ny nz ka la oa ob kc oc bi translated">变量YML文件:</h2><p id="4512" class="pw-post-body-paragraph kj kk hx kl b km nb iy ko kp nc jb kr ks nm ku kv kw nn ky kz la no lc ld le hb bi translated"><strong class="kl hy">打开“Hadoop-ws/roles/ec2/vars/main . yml”文件&amp;存储我们在“task/main.yml”文件中提到的所有变量及其各自的值。</strong>作为参考，我附上了文件…</p><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><h1 id="efba" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">为hadoop_master角色编写代码:</h1><figure class="kf kg kh ki fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es or"><img src="../Images/635bc36dbd2e2b9460bea2f9207c6bb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_wJpOfnMec4lS61iv3StLA.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Self made using Canva</figcaption></figure><h2 id="9baa" class="np jn hx bd jo nq nr ns js nt nu nv jw ks nw nx jy kw ny nz ka la oa ob kc oc bi translated">任务YML文件:</h2><p id="9ec7" class="pw-post-body-paragraph kj kk hx kl b km nb iy ko kp nc jb kr ks nm ku kv kw nn ky kz la no lc ld le hb bi translated"><strong class="kl hy">类似地，像上次一样打开“Hadoop-ws/roles/Hadoop _ master/tasks/main . yml”文件&amp; </strong>将下面提到的代码放在那里…</p><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><ul class=""><li id="5250" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated"><strong class="kl hy">整个文件能够设置Hadoop Namenode(主节点)。</strong>让我们一个一个的去理解这个文件里写的模块…</li><li id="6165" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le mw mx my mz bi translated">首先，我使用<strong class="kl hy">“get _ URL”</strong>模块下载hadoop &amp; java软件&amp;，然后使用<strong class="kl hy">“command”</strong>模块安装这些下载的软件。变量<strong class="kl hy">“pkgs _ name”</strong>存储在<strong class="kl hy">“vars/main . yml”</strong>文件中，后面我会展示。</li></ul><blockquote class="lu lv lw"><p id="ae24" class="kj kk lx kl b km kn iy ko kp kq jb kr ly kt ku kv lz kx ky kz ma lb lc ld le hb bi translated"><strong class="kl hy">接下来，我们需要配置Hadoop Namenode &amp;，因为我们需要在“/etc/hadoop/core-site.xml”文件&amp;”/etc/Hadoop/HDFS-site . XML”文件中写入一些数据。</strong></p></blockquote><ul class=""><li id="686a" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated"><strong class="kl hy">现在，在“core-site.xml”文件中，我们需要提到一些关键字&amp;需要说明当前系统是我们的Namenode。</strong>我使用复制模块将文件“Hadoop-ws/roles/Hadoop _ master/files/core-site . XML”复制到文件“/etc/hadoop/core-site.xml”中的Namenode。因为hadoop是从文件夹“/etc/hadoop/”中读取配置的。作为参考，我提到了下面的文件…</li></ul><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><ul class=""><li id="bf69" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated"><strong class="kl hy">接下来，我使用模板模块复制Namenode中的“hdfs-site.xml.j2”文件。</strong>现在，模板模块一步完成三件事——首先，它从“Hadoop-ws/roles/Hadoop _ master/templates”文件夹中选择“hdfs-site.xml.j2”文件&amp;在这个文件中，我提到了一个变量。其次，模板模块用值更新变量。最后，它将文件复制到namenode &amp;中，将其重命名为“hdfs-site.xml”。作为参考，我提到了下面的文件…</li></ul><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><ul class=""><li id="662d" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">接下来，我们的代码将在namenode中创建一个目录，该目录将存储集群的元数据。为此我使用了<strong class="kl hy">【文件】</strong>模块。</li><li id="5897" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le mw mx my mz bi translated">最后，在最后3个步骤中，我们只是格式化namenode &amp;，然后启动namenode服务。为了使服务永久化，我们将服务启动命令放在“/etc/rc.d/rc.local”文件中。</li></ul><h2 id="222f" class="np jn hx bd jo nq nr ns js nt nu nv jw ks nw nx jy kw ny nz ka la oa ob kc oc bi translated">变量YML文件:</h2><p id="69da" class="pw-post-body-paragraph kj kk hx kl b km nb iy ko kp nc jb kr ks nm ku kv kw nn ky kz la no lc ld le hb bi translated"><strong class="kl hy">打开“Hadoop-ws/roles/Hadoop _ master/vars/main . yml”文件&amp;存储变量。为了便于参考，我附上了文件…</strong></p><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><h1 id="99c6" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">为hadoop_slave角色编写代码:</h1><figure class="kf kg kh ki fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es or"><img src="../Images/8cd907ca869c194df30e66b01d1ecddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FApes09p4bo7KbomBETRGQ.png"/></div></div></figure><h2 id="2d52" class="np jn hx bd jo nq nr ns js nt nu nv jw ks nw nx jy kw ny nz ka la oa ob kc oc bi translated">任务YML文件:</h2><p id="02cf" class="pw-post-body-paragraph kj kk hx kl b km nb iy ko kp nc jb kr ks nm ku kv kw nn ky kz la no lc ld le hb bi translated"><strong class="kl hy">同样像上次一样打开“Hadoop-ws/roles/Hadoop _ slave/tasks/main . yml”文件&amp; </strong>把下面提到的代码放在那里…</p><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><ul class=""><li id="4e63" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">这里的前三个步骤与前面的namenode任务文件完全相同。之后再来理解吧…</li></ul><blockquote class="lu lv lw"><p id="2e88" class="kj kk lx kl b km kn iy ko kp kq jb kr ly kt ku kv lz kx ky kz ma lb lc ld le hb bi translated"><strong class="kl hy">我们使用“模板”模块两次将“core-site . XML . J2”&amp;“HDFS-site . XML . J2”文件复制到datanode。我已经在前面的代码中讨论了模板模块的作用。但是在这里，这两个模板文件有细微的变化。让我们来了解他们…</strong></p></blockquote><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><ul class=""><li id="6578" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">在这个<strong class="kl hy"> "core-site.xml" </strong>文件中，我们需要告诉我们的namenode在哪里，以便datanode可以连接到它。这就是为什么我们需要告诉datanode IP地址和端口号namenode服务在哪个端口上工作。这里我使用了<strong class="kl hy">“host vars”</strong>关键字，它能够进入主机组&amp;获取通过收集事实收集的所有元数据。</li><li id="9352" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le mw mx my mz bi translated">现在有多个主机组&amp;主机，但是这里我们需要从<strong class="kl hy">“NameNode”</strong>主机组获取信息。这就是为什么我们使用<strong class="kl hy">【群体】</strong>关键字的原因。接下来，我们将使用<strong class="kl hy">“[组[' NameNode '][0]]”</strong>关键字从主机组<strong class="kl hy">“NameNode”</strong>中过滤第一台主机。现在<strong class="kl hy">“hostvars”</strong>知道从哪个主机，它需要获取元数据。</li><li id="8c8f" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le mw mx my mz bi translated">接下来是过滤元数据和搜索IP的时候了。为此，我们使用<strong class="kl hy">“ansi ble _ all _ IP v4 _ addresses”</strong>事实。所以这个可能的事实包含了主机名节点的所有私有IP。接下来，我使用<strong class="kl hy">“[0]”</strong>从列表中选择第一个私有IP。<strong class="kl hy">这是使用可转换事实的动态配置方法。</strong></li></ul><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><ul class=""><li id="7907" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">下一个<strong class="kl hy">“hdfs-site.xml . J2”</strong>文件使用了与之前来自“hadoop_master”角色的“HDFS-site . XML”文件相同的概念，唯一的区别是这里我告诉我当前的节点是datanode。</li><li id="e51d" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le mw mx my mz bi translated"><strong class="kl hy">然后在主代码中，我使用“文件”模块来创建文件夹，我们将使用该文件夹来存储datanode中的数据。在datanode中，我们不需要格式化它。我们只需要启动datanode服务。然后我就像上次一样让服务永久化。</strong></li></ul><h2 id="f2d5" class="np jn hx bd jo nq nr ns js nt nu nv jw ks nw nx jy kw ny nz ka la oa ob kc oc bi translated">变量YML文件:</h2><p id="7803" class="pw-post-body-paragraph kj kk hx kl b km nb iy ko kp nc jb kr ks nm ku kv kw nn ky kz la no lc ld le hb bi translated"><strong class="kl hy">打开“Hadoop-ws/roles/Hadoop _ slave/vars/main . yml”文件&amp;存储变量。</strong>作为参考，我附上了文件…</p><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><h1 id="7c5d" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">为hadoop_client角色编写代码:</h1><figure class="kf kg kh ki fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es or"><img src="../Images/b7d6ee88667b8248a4b375a5cb3423d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Js3fDyvWYSd3MFdVWLzvYQ.png"/></div></div></figure><h2 id="22f3" class="np jn hx bd jo nq nr ns js nt nu nv jw ks nw nx jy kw ny nz ka la oa ob kc oc bi translated">任务YML文件:</h2><p id="f087" class="pw-post-body-paragraph kj kk hx kl b km nb iy ko kp nc jb kr ks nm ku kv kw nn ky kz la no lc ld le hb bi translated"><strong class="kl hy">类似地，像上次一样打开“Hadoop-ws/roles/Hadoop _ client/tasks/main . yml”文件&amp; </strong>将下面提到的代码放在那里…</p><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><ul class=""><li id="22b1" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">在客户端系统中，我们再次下载并安装hadoop和java软件，就像之前我们在主从系统中所做的那样。</li><li id="5b72" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le mw mx my mz bi translated"><strong class="kl hy">接下来，在客户端系统中，我们只需设置“core-site.xml”文件，以便客户端知道namenode的位置。我再次使用模板模块&amp;应用我在奴隶角色中使用的相同概念。作为参考，我在下面附上了文件…</strong></li></ul><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><h2 id="359f" class="np jn hx bd jo nq nr ns js nt nu nv jw ks nw nx jy kw ny nz ka la oa ob kc oc bi translated">变量YML文件:</h2><p id="e1f6" class="pw-post-body-paragraph kj kk hx kl b km nb iy ko kp nc jb kr ks nm ku kv kw nn ky kz la no lc ld le hb bi translated"><strong class="kl hy">打开“Hadoop-ws/roles/Hadoop _ client/vars/main . yml”文件&amp;存储变量。为了便于参考，我附上了文件…</strong></p><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><h1 id="2ba2" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">最后，创建安装文件:</h1><ul class=""><li id="e8b1" class="mr ms hx kl b km nb kp nc ks nd kw ne la nf le mw mx my mz bi translated">现在终于到了创建<strong class="kl hy"> "setup.yml" </strong>文件的时候了，我们将运行该文件在AWS上创建整个基础设施。<strong class="kl hy">记住一件事，我们需要在文件夹“hadoop-ws”中创建这个文件。为了便于参考，我附上了下面的文件…</strong></li></ul><figure class="kf kg kh ki fd hk"><div class="bz dy l di"><div class="oo op l"/></div></figure><ul class=""><li id="5a2e" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">如您所见，我们正在本地主机上运行第一个<strong class="kl hy">“ec2”</strong>角色，因为<strong class="kl hy">将从本地主机联系AWS API。</strong>同样使用<strong class="kl hy">“vars _ files”</strong>我在这个任务中包含了<strong class="kl hy">“cred . yml”</strong>文件，以便“ec2”角色可以访问它。</li><li id="2308" class="mr ms hx kl b km nh kp ni ks nj kw nk la nl le mw mx my mz bi translated"><strong class="kl hy">在接下来的三个步骤中，我们分别在“namenode”、“datanode”&amp;“clientnode”动态主机组上运行“hadoop_master”、“Hadoop _ slave”&amp;“Hadoop _ client”角色。</strong></li></ul><h2 id="9358" class="np jn hx bd jo nq nr ns js nt nu nv jw ks nw nx jy kw ny nz ka la oa ob kc oc bi translated">GitHub参考库:</h2><div class="hh hi ez fb hj mb"><a href="https://github.com/raktim00/Hadoop-AWS-Ansible" rel="noopener  ugc nofollow" target="_blank"><div class="mc ab dw"><div class="md ab me cl cj mf"><h2 class="bd hy fi z dy mg ea eb mh ed ef hw bi translated">raktim00/Hadoop-AWS-Ansible</h2><div class="mi l"><h3 class="bd b fi z dy mg ea eb mh ed ef dx translated">使用Ansible在AWS EC2实例上设置Hadoop多节点集群…</h3></div><div class="mj l"><p class="bd b fp z dy mg ea eb mh ed ef dx translated">github.com</p></div></div><div class="mk l"><div class="os l mm mn mo mk mp hp mb"/></div></div></a></div><blockquote class="lu lv lw"><p id="e265" class="kj kk lx kl b km kn iy ko kp kq jb kr ly kt ku kv lz kx ky kz ma lb lc ld le hb bi translated"><strong class="kl hy"> <em class="hx">编码部分到此为止。现在是运行剧本的时候了。为此，在“hadoop-ws”文件夹中运行下面提到的命令。</em>T13】</strong></p></blockquote><pre class="kf kg kh ki fd of og oh oi aw oj bi"><span id="0dd3" class="np jn hx og b fi ok ol l om on">ansible-playbook setup.yml --ask-vault-pass</span></pre><ul class=""><li id="9246" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">接下来，它将提示您传递您的Ansible Vault (cred.yml文件)的密码，提供密码&amp;然后<strong class="kl hy">您将看到自动化的力量……</strong></li></ul><figure class="kf kg kh ki fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ot"><img src="../Images/226c04a7931a3cf831261280035e31bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*DVM6bXgnq_PAVnXFsgOJRg.gif"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Ansible Playbook Workflow</figcaption></figure><h1 id="3c28" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">检查您的集群:</h1><p id="b266" class="pw-post-body-paragraph kj kk hx kl b km nb iy ko kp nc jb kr ks nm ku kv kw nn ky kz la no lc ld le hb bi translated">只需登录到客户端节点，运行下面提到的hadoop命令，检查您的集群是否工作正常。作为参考，我在下面分享了该命令的输出…</p><pre class="kf kg kh ki fd of og oh oi aw oj bi"><span id="ef7e" class="np jn hx og b fi ok ol l om on">hadoop dfsadmin -report</span></pre><figure class="kf kg kh ki fd hk er es paragraph-image"><div class="er es ou"><img src="../Images/db6f241f8bcf07818b1b36fefc67021a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*uN7LqgExQwhKHsKmOeznKQ.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx">Client node terminal screenshot</figcaption></figure><h1 id="0090" class="jm jn hx bd jo jp jq jr js jt ju jv jw jd jx je jy jg jz jh ka jj kb jk kc kd bi translated">最后的话:</h1><ul class=""><li id="85ff" class="mr ms hx kl b km nb kp nc ks nd kw ne la nf le mw mx my mz bi translated"><strong class="kl hy">学习Ansible，AWS &amp; Hadoop有无限的未来可能。这只是一个简单的Ansible角色演示，但是如果你愿意，你可以通过添加更多的模块来创建更多更大的基础设施。我们可以使用Ansible实现的每一种配置。</strong></li></ul><blockquote class="lu lv lw"><p id="2ff7" class="kj kk lx kl b km kn iy ko kp kq jb kr ly kt ku kv lz kx ky kz ma lb lc ld le hb bi translated"><strong class="kl hy">注意:这是本练习的第一部分。在下一篇博客中，我们将扩展这一实践，并添加Hadoop Map Reduce集群(Compute Cluster)设置，使用Ansible角色。虽然我已经发布了整个视频，所以如果你想你可以看看下面提到的视频。</strong></p></blockquote><div class="hh hi ez fb hj mb"><a href="https://www.linkedin.com/posts/raktimmidya_hadoop-ansible-ansibleautomates-activity-6790914935430885376-Qcx3" rel="noopener  ugc nofollow" target="_blank"><div class="mc ab dw"><div class="md ab me cl cj mf"><h2 class="bd hy fi z dy mg ea eb mh ed ef hw bi translated">LinkedIn上的rak Tim Midya:# Hadoop # ansi ble # AWS | 15条评论</h2><div class="mi l"><h3 class="bd b fi z dy mg ea eb mh ed ef dx translated">嘿，大家好...😊了解如何创建一个可行的角色来在AWS上设置Hadoop HDFS和MR集群…</h3></div><div class="mj l"><p class="bd b fp z dy mg ea eb mh ed ef dx translated">www.linkedin.com</p></div></div><div class="mk l"><div class="ov l mm mn mo mk mp hp mb"/></div></div></a></div><ul class=""><li id="ef91" class="mr ms hx kl b km kn kp kq ks mt kw mu la mv le mw mx my mz bi translated">我试图让它尽可能简单。希望你从这里学到了一些东西。我一直在写关于机器学习、DevOps自动化、云计算、大数据分析等方面的博客。所以，如果你想看我以后的博客，请在Medium上关注我。您也可以在LinkedIn上ping我，在下面查看我的LinkedIn个人资料…</li></ul><div class="hh hi ez fb hj mb"><a href="https://www.linkedin.com/in/raktimmidya/" rel="noopener  ugc nofollow" target="_blank"><div class="mc ab dw"><div class="md ab me cl cj mf"><h2 class="bd hy fi z dy mg ea eb mh ed ef hw bi translated">Raktim Midya -微软学生学习大使(测试版)-微软| LinkedIn</h2><div class="mi l"><h3 class="bd b fi z dy mg ea eb mh ed ef dx translated">★我是一名技术爱好者，致力于更好地理解不同热门技术领域背后的核心概念…</h3></div><div class="mj l"><p class="bd b fp z dy mg ea eb mh ed ef dx translated">www.linkedin.com</p></div></div><div class="mk l"><div class="ow l mm mn mo mk mp hp mb"/></div></div></a></div><p id="f8d3" class="pw-post-body-paragraph kj kk hx kl b km kn iy ko kp kq jb kr ks kt ku kv kw kx ky kz la lb lc ld le hb bi translated"><strong class="kl hy">感谢大家阅读。就这样…结束…😊</strong></p><figure class="kf kg kh ki fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ox"><img src="../Images/5a7a34d0698d7f08687d261649b384d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r5VeD2fV04iDy8xfmaauHA.png"/></div></div></figure></div></div>    
</body>
</html>