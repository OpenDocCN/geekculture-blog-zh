<html>
<head>
<title>How to build a simple Web scraper using Beautifulsoup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Beautifulsoup构建一个简单的Web刮刀</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/how-to-build-a-simple-web-scraper-using-beautifulsoup-2f2f0f97dc47?source=collection_archive---------15-----------------------#2021-11-16">https://medium.com/geekculture/how-to-build-a-simple-web-scraper-using-beautifulsoup-2f2f0f97dc47?source=collection_archive---------15-----------------------#2021-11-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="67e1" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用Beautifulsoup和Python构建web scraper的分步指南。</h2></div><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es iy"><img src="../Images/089476206f12f800f093f6546dafb5ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LmI_3tyeHycq0Q97"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx">Photo by <a class="ae jo" href="https://unsplash.com/@ilyapavlov?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Ilya Pavlov</a> on <a class="ae jo" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="6961" class="jp jq hi bd jr js jt ju jv jw jx jy jz io ka ip kb ir kc is kd iu ke iv kf kg bi translated">介绍</h1><p id="9ccd" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">数据收集是数据科学项目中定义和分析问题之后的主要步骤之一。虽然有多种收集数据的方法，但在本文中，我们将重点关注web抓取技术，以便为我们的数据科学项目收集数据。</p><p id="d024" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">构建一个通用的web刮刀既不可行也不可取。每一个网页刮刀都应该为特定的情况而制造，并且应该根据要刮的网页的变化而修改。</p><p id="042f" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">在本文中，我们将重点介绍如何使用Beautifulsoup和Requests库创建一个简单的web scraper类，它可以抓取任何静态网页(默认情况下是链接和图像)。当然，我们也将尝试抓取静态网页。</p><h1 id="1167" class="jp jq hi bd jr js jt ju jv jw jx jy jz io ka ip kb ir kc is kd iu ke iv kf kg bi translated">定义步骤</h1><p id="4af9" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">我们将利用面向对象的python从头开始创建这个刮刀。</p><p id="9606" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">让我们列出构建这个刮刀所需的功能</p><p id="621a" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated"><strong class="kj hj"> 1。解析URL的方法</strong></p><p id="c1ed" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">此方法应该创建一个自定义对象，该对象可用于访问给定页面上的任何web元素。</p><p id="16a1" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated"><strong class="kj hj"> 2。一种从网页中获取所有链接的方法</strong></p><p id="8a2e" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated"><strong class="kj hj"> 3。一种从网页中获取所有图片链接的方法</strong></p><p id="b921" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated"><strong class="kj hj"> 4。一种从图像链接下载图像到当前目录的方法。</strong></p><p id="6f21" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">现在我们已经列出了这个刮刀的核心功能，让我们一步一步地构建刮刀。</p><h1 id="e72e" class="jp jq hi bd jr js jt ju jv jw jx jy jz io ka ip kb ir kc is kd iu ke iv kf kg bi translated">建造铲运机</h1><p id="539c" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">让我们创建scraper类并定义我们的方法。我们将把这个刮刀命名为“静态刮刀”。</p><pre class="iz ja jb jc fd li lj lk ll aw lm bi"><span id="a0e4" class="ln jq hi lj b fi lo lp l lq lr"><strong class="lj hj">class</strong> <strong class="lj hj">StaticSiteScraper</strong>:<br/>    <strong class="lj hj">def</strong> <strong class="lj hj">__init__</strong>(self):<br/>        <strong class="lj hj">pass</strong><br/><br/>    <em class="ls"># A method for parsing the url</em><br/>    <strong class="lj hj">def</strong> <strong class="lj hj">url_parse</strong>(self):<br/>        <strong class="lj hj">pass</strong><br/><br/>    <em class="ls"># A method for fetching all links from the webpage</em><br/>    <strong class="lj hj">def</strong> <strong class="lj hj">get_all_links</strong>(self):<br/>        <strong class="lj hj">pass</strong><br/><br/>    <em class="ls"># A method for fetching all image links from the webpage</em><br/>    <strong class="lj hj">def</strong> <strong class="lj hj">get_all_image_links</strong>(self):<br/>        <strong class="lj hj">pass</strong><br/><br/>    <em class="ls"># A method for downloading images from the image links</em><br/>    <strong class="lj hj">def</strong> <strong class="lj hj">download_images</strong>(self):<br/>        <strong class="lj hj">pass</strong></span></pre><h1 id="7b3f" class="jp jq hi bd jr js jt ju jv jw jx jy jz io ka ip kb ir kc is kd iu ke iv kf kg bi translated">1.获取HTML页面内容</h1><p id="5cbf" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">让我们定义获取HTML页面的函数。</p><p id="b6c8" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">我们将使用请求库从URL获取HTML内容，并将其存储在一个名为data的变量中。</p><pre class="iz ja jb jc fd li lj lk ll aw lm bi"><span id="8fd2" class="ln jq hi lj b fi lo lp l lq lr">data <strong class="lj hj">=</strong> requests.get(url).text</span></pre><p id="a122" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">然后，我们将创建一个soup对象，将这个HTML内容解析成可读的文本格式。</p><pre class="iz ja jb jc fd li lj lk ll aw lm bi"><span id="856d" class="ln jq hi lj b fi lo lp l lq lr">soup <strong class="lj hj">=</strong> bs(data, parser)</span></pre><p id="ad97" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">最后我们的函数将返回这个soup对象。</p><p id="2c03" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">综上所述，我们有:</p><pre class="iz ja jb jc fd li lj lk ll aw lm bi"><span id="8c59" class="ln jq hi lj b fi lo lp l lq lr"><strong class="lj hj">def</strong> <strong class="lj hj">url_parse</strong>():<br/>    <strong class="lj hj">data</strong> <strong class="lj hj">=</strong> requests.<strong class="lj hj">get</strong>(url).text<br/>    soup <strong class="lj hj">=</strong> bs(<strong class="lj hj">data</strong>, parser)<br/>    <strong class="lj hj">return</strong> soup</span></pre><p id="062b" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">创建的soup对象可以用来访问解析后的HTML内容中的任何元素。</p><p id="226e" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">例如，我们可以使用以下内容访问网页的标题文本:</p><pre class="iz ja jb jc fd li lj lk ll aw lm bi"><span id="759a" class="ln jq hi lj b fi lo lp l lq lr"><strong class="lj hj">soup</strong>.title.text</span></pre><p id="0927" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">类似地，您可以使用soup对象来访问您需要的任何元素。</p><p id="30b7" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">现在我们有了soup对象，我们可以使用这个对象来创建从解析的HTML内容中获取所有链接和图像的方法。</p><h1 id="741b" class="jp jq hi bd jr js jt ju jv jw jx jy jz io ka ip kb ir kc is kd iu ke iv kf kg bi translated">2.获取所有链接</h1><p id="4deb" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">让我们首先定义一个列表，用于存储我们使用方法收集的所有链接。这个列表将是我们方法的输出。</p><p id="3f02" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">我们知道链接存储在HTML页面的<a>标签中。</a></p><p id="e5f2" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">因此，要访问链接，我们需要首先访问<a>标记，可以使用:</a></p><pre class="iz ja jb jc fd li lj lk ll aw lm bi"><span id="7fa5" class="ln jq hi lj b fi lo lp l lq lr"><strong class="lj hj">soup</strong>.find_all('a')</span></pre><p id="39e3" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">这将获取解析后的HTML内容中所有<a>标签的列表。</a></p><p id="bf4b" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">现在，我们必须遍历列表中的每个元素，并从“href”属性中提取链接。然后，我们将把收集到的链接存储在我们之前定义的列表中。</p><pre class="iz ja jb jc fd li lj lk ll aw lm bi"><span id="c45e" class="ln jq hi lj b fi lo lp l lq lr"><strong class="lj hj">for</strong> tag <strong class="lj hj">in</strong> a_tags:<br/>    items <strong class="lj hj">=</strong> str(tag).<strong class="lj hj">split</strong>(" ")<br/><br/>    <strong class="lj hj">for</strong> item <strong class="lj hj">in</strong> items:<br/>        <strong class="lj hj">if</strong> 'href' <strong class="lj hj">in</strong> item:<br/>            link_item <strong class="lj hj">=</strong> item.<strong class="lj hj">split</strong>("=")[1].<strong class="lj hj">split</strong>("\"")[1]<br/>            <strong class="lj hj">if</strong> 'http' <strong class="lj hj">in</strong> link_item <strong class="lj hj">or</strong> 'www' <strong class="lj hj">in</strong> link_item:<br/>                links.append(link_item)</span></pre><p id="b86b" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">综上所述，我们有:</p><pre class="iz ja jb jc fd li lj lk ll aw lm bi"><span id="1ea3" class="ln jq hi lj b fi lo lp l lq lr"><strong class="lj hj">def</strong> <strong class="lj hj">get_all_links</strong>():<br/>    links<strong class="lj hj">=</strong>[]<br/><br/>    a_tags <strong class="lj hj">=</strong> soup.find_all('a')<br/><br/>    <strong class="lj hj">for</strong> tag <strong class="lj hj">in</strong> a_tags:<br/>        items <strong class="lj hj">=</strong> str(tag).<strong class="lj hj">split</strong>(" ")<br/>        <strong class="lj hj">for</strong> item <strong class="lj hj">in</strong> items:<br/>            <strong class="lj hj">if</strong> 'href' <strong class="lj hj">in</strong> item:<br/>                link_item <strong class="lj hj">=</strong> item.<strong class="lj hj">split</strong>("=")[1].<strong class="lj hj">split</strong>("\"")[1]<br/>                <strong class="lj hj">if</strong> 'http' <strong class="lj hj">in</strong> link_item <strong class="lj hj">or</strong> 'www' <strong class="lj hj">in</strong> link_item:<br/>                    links.append(link_item)<br/>    <strong class="lj hj">return</strong> links</span></pre><h1 id="ee19" class="jp jq hi bd jr js jt ju jv jw jx jy jz io ka ip kb ir kc is kd iu ke iv kf kg bi translated">3.获取所有图像链接</h1><p id="a1ca" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">这一步与上一步完全相似，在上一步中，我们从解析的内容中收集了所有链接。</p><p id="3712" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">这里唯一的区别是，我们在这里使用了<img/>标签，而不是<a>标签。此外，我们使用“src”属性而不是“href”来访问图像链接。</a></p><pre class="iz ja jb jc fd li lj lk ll aw lm bi"><span id="3ded" class="ln jq hi lj b fi lo lp l lq lr"><strong class="lj hj">def</strong> <strong class="lj hj">get_all_image_links</strong>():<br/>    img_links<strong class="lj hj">=</strong>[]<br/><br/>    img_tags <strong class="lj hj">=</strong> soup.find_all('img')<br/>    <strong class="lj hj">for</strong> tag <strong class="lj hj">in</strong> img_tags:<br/>        items <strong class="lj hj">=</strong> str(tag).<strong class="lj hj">split</strong>(" ")<br/>        <strong class="lj hj">for</strong> item <strong class="lj hj">in</strong> items:<br/>            <strong class="lj hj">if</strong> 'src' <strong class="lj hj">in</strong> item:<br/>                link_item <strong class="lj hj">=</strong> item.<strong class="lj hj">split</strong>("=")[1].<strong class="lj hj">split</strong>("\"")[1]<br/>                <strong class="lj hj">if</strong> 'http' <strong class="lj hj">in</strong> link_item <strong class="lj hj">or</strong> 'www' <strong class="lj hj">in</strong> link_item:<br/>                    img_links.append(link_item)<br/>    <strong class="lj hj">return</strong> img_links</span></pre><h1 id="0c7e" class="jp jq hi bd jr js jt ju jv jw jx jy jz io ka ip kb ir kc is kd iu ke iv kf kg bi translated">4.下载图像</h1><p id="187a" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">现在，我们已经有了所有的图片链接，我们现在将从这些链接下载所有的图片，并将它们存储在我们的本地目录中。为此，我们将把图像列表作为参数传递给这个方法。</p><p id="ead2" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">我们将首先创建一个date_变量，以“dd-mm-yyyy”格式存储当前日期。</p><pre class="iz ja jb jc fd li lj lk ll aw lm bi"><span id="bbbc" class="ln jq hi lj b fi lo lp l lq lr"><strong class="lj hj">day</strong> <strong class="lj hj">=</strong> datetime.date.today().<strong class="lj hj">day</strong><br/><strong class="lj hj">month</strong> <strong class="lj hj">=</strong> datetime.date.today().<strong class="lj hj">month</strong><br/><strong class="lj hj">year</strong> <strong class="lj hj">=</strong> datetime.date.today().<strong class="lj hj">year</strong><br/><br/>date_ <strong class="lj hj">=</strong> str(<strong class="lj hj">day</strong>)<strong class="lj hj">+</strong>"-"<strong class="lj hj">+</strong>str(<strong class="lj hj">month</strong>)<strong class="lj hj">+</strong>"-"<strong class="lj hj">+</strong>str(<strong class="lj hj">year</strong>)<strong class="lj hj">+</strong>"_"</span></pre><p id="1f11" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">在创建存储图像的新目录之前，我们将检查当前工作目录中是否存在“images”目录。</p><p id="59ee" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">如果没有找到，我们将创建一个新的“图像”目录。在“images”目录中，我们将创建一个以当前日期为名称的新目录来存储图像。</p><pre class="iz ja jb jc fd li lj lk ll aw lm bi"><span id="28e9" class="ln jq hi lj b fi lo lp l lq lr"><strong class="lj hj">if</strong> 'images' <strong class="lj hj">not</strong> <strong class="lj hj">in</strong> os.listdir():<br/>        os.mkdir("images")<br/>        os.chdir("images")<br/><br/>    os.mkdir(date_)<br/>    os.chdir(date_)</span></pre><p id="055a" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">现在，我们将初始化一个图像编号变量来命名图像。我们可以访问<alt>标签来从URL中获取图像名称，但是有时候，图像没有别名。因此，为了保持图像名称的统一，我们将对图像进行编号。</alt></p><pre class="iz ja jb jc fd li lj lk ll aw lm bi"><span id="c228" class="ln jq hi lj b fi lo lp l lq lr">img_no <strong class="lj hj">=</strong> 1</span></pre><p id="1b32" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">接下来，我们将遍历图像链接，获取图像并将它们存储在本地目录中。</p><pre class="iz ja jb jc fd li lj lk ll aw lm bi"><span id="e55a" class="ln jq hi lj b fi lo lp l lq lr"><strong class="lj hj">for</strong> <strong class="lj hj">link</strong> <strong class="lj hj">in</strong> image_list:<br/>    img_response <strong class="lj hj">=</strong> requests.<strong class="lj hj">get</strong>(<strong class="lj hj">link</strong>)<br/><br/>    img_format <strong class="lj hj">=</strong> link.<strong class="lj hj">split</strong>(".")[<strong class="lj hj">-</strong>1]<br/><br/>    filename <strong class="lj hj">=</strong> "img" <strong class="lj hj">+</strong> str(img_no) <strong class="lj hj">+</strong> "." <strong class="lj hj">+</strong> img_format<br/><br/>    <strong class="lj hj">with</strong> <strong class="lj hj">open</strong>(filename, "wb+") <strong class="lj hj">as</strong> f:<br/>        f.<strong class="lj hj">write</strong>(img_response.content)<br/>    img_no <strong class="lj hj">+=</strong> 1</span></pre><p id="01b0" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">综上所述，我们有:</p><pre class="iz ja jb jc fd li lj lk ll aw lm bi"><span id="689b" class="ln jq hi lj b fi lo lp l lq lr"><strong class="lj hj">def</strong> <strong class="lj hj">download_images</strong>(image_list):<br/>    <strong class="lj hj">day</strong> <strong class="lj hj">=</strong> datetime.date.today().<strong class="lj hj">day</strong><br/>    <strong class="lj hj">month</strong> <strong class="lj hj">=</strong> datetime.date.today().<strong class="lj hj">month</strong><br/>    <strong class="lj hj">year</strong> <strong class="lj hj">=</strong> datetime.date.today().<strong class="lj hj">year</strong><br/><br/>    date_ <strong class="lj hj">=</strong> str(<strong class="lj hj">day</strong>)<strong class="lj hj">+</strong>"-"<strong class="lj hj">+</strong>str(<strong class="lj hj">month</strong>)<strong class="lj hj">+</strong>"-"<strong class="lj hj">+</strong>str(<strong class="lj hj">year</strong>)<strong class="lj hj">+</strong>"_"<br/><br/>    <strong class="lj hj">if</strong> 'images' <strong class="lj hj">not</strong> <strong class="lj hj">in</strong> os.listdir():<br/>        os.mkdir("images")<br/>        os.chdir("images")<br/><br/>    os.mkdir(date_)<br/>    os.chdir(date_)<br/><br/>    img_no <strong class="lj hj">=</strong> 1<br/><br/>    <strong class="lj hj">for</strong> link <strong class="lj hj">in</strong> image_list:<br/>        img_response <strong class="lj hj">=</strong> requests.get(link)<br/><br/>        img_format <strong class="lj hj">=</strong> link.split(".")[<strong class="lj hj">-</strong>1]<br/><br/>        filename <strong class="lj hj">=</strong> "img" <strong class="lj hj">+</strong> str(img_no) <strong class="lj hj">+</strong> "." <strong class="lj hj">+</strong> img_format<br/><br/>        <strong class="lj hj">with</strong> <strong class="lj hj">open</strong>(filename, "wb+") <strong class="lj hj">as</strong> f:<br/>            f.write(img_response.content)<br/>        img_no <strong class="lj hj">+=</strong> 1</span></pre><p id="bc77" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">现在，我们已经定义了所有的方法，我们将把它们放在一起创建我们的StaticSiteScraper类。我不打算在这里深究，因为这是不言自明的。</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="8a57" class="jp jq hi bd jr js ma ju jv jw mb jy jz io mc ip kb ir md is kd iu me iv kf kg bi translated">实现我们的静态刮刀</h1><p id="96b2" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">最后，我们创建了scraper类。</p><p id="1227" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">现在是时候测试我们的StaticSiteScraper了。为此，我现在转到craigslist.org的纽约房地产页面。</p><p id="454b" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">从页面获取URL</p><p id="6242" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">URL = " https://new York . craigslist . org/d/real-estate/search/rea "</p><p id="a143" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">使用我们的StaticSiteScraper创建一个<strong class="kj hj"> craig </strong>对象</p><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es mf"><img src="../Images/86ecd051380f797a3827f3bd76b3a084.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*PzO3rZHNH3MsQ0Vw3l5iOA.png"/></div></figure><p id="8922" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">创建一个<strong class="kj hj">页面对象</strong>，如果需要的话，它可以用来访问这个页面中的任何其他HTML元素。</p><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es mg"><img src="../Images/3550a891cb7f7f0e00f15191d2089e5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/1*fENJ2V-LnzPnZoqHzgtjHA.png"/></div></figure><p id="db71" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">现在，我们将访问该网页中的所有链接。</p><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es mh"><img src="../Images/0ede83ef855296d478531578580a45e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*5TuuGhJni7QLZEsChncQgA.png"/></div></figure><p id="129b" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">类似地，我们现在将获取网页上所有图片的链接。</p><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es mi"><img src="../Images/e969acde69051df4aa2f1ce5996ad97c.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*--tIBFGVF058EpQg_nG15w.png"/></div></figure><p id="aea7" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">我们的输出是:</p><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es mj"><img src="../Images/27980a38faf476ec34f7e05549918e01.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*p5XdIeEoXVS5326hMc0U3Q.png"/></div></div></figure><p id="a210" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">在开始下载所有图像之前，请确保检查以下内容:</p><p id="a90e" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated"><strong class="kj hj"> 1。如果我们能够获取图像链接</strong></p><p id="6f02" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">我这么说的原因是因为几乎所有的网站都在一个<div>标签中发布它们的图片，也许在<div>标签中的更多标签中。因此，很难一次获取所有图像。</div></div></p><p id="781c" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">这里，您将不得不使用我们之前创建的<strong class="kj hj">页面对象</strong>来更深入地挖掘您可以找到图像链接的标签。从那里，你必须获取每张图片并把它存储到一个列表中。</p><p id="b4f2" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated"><strong class="kj hj"> 2。如果图像链接格式正确</strong></p><p id="e55c" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">大多数情况下，图像链接的格式可能不正确，在将它们传递给函数之前，我们可能需要以正确的格式重新排列它们。</p><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es mk"><img src="../Images/325533247fecd0dc8421882e6d24c92e.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*ZuPyoYapl3gMMvA6zpGVLQ.png"/></div></figure><p id="bb62" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">现在我们的输出看起来像这样:</p><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es ml"><img src="../Images/c81f20a4a32f926674482506d561e7ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*kGC1ec7rvV3BOUZvb4zWhg.png"/></div></figure><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es mm"><img src="../Images/b7d742b6bacbb9ebafcd6d9423ec89c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*VAzFySgKls1Z56awq9Revw.png"/></div></figure><p id="7457" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">至此，我们已经创建了一个web scraper，它可以获取给定URL的所有静态内容。</p><p id="8c1c" class="pw-post-body-paragraph kh ki hi kj b kk ld ij km kn le im kp kq lf ks kt ku lg kw kx ky lh la lb lc hb bi translated">最后，我希望你喜欢它。关注我以获取更多可操作的内容，并随时发布您的宝贵反馈和建议。</p><div class="mn mo ez fb mp mq"><a rel="noopener follow" target="_blank" href="/@retinpkumar"><div class="mr ab dw"><div class="ms ab mt cl cj mu"><h2 class="bd hj fi z dy mv ea eb mw ed ef hh bi translated">Retin P Kumar培养基</h2><div class="mx l"><h3 class="bd b fi z dy mv ea eb mw ed ef dx translated">阅读Retin P Kumar在媒体上的文章。我是一名来自印度的有抱负的数据科学家和机器学习爱好者…</h3></div><div class="my l"><p class="bd b fp z dy mv ea eb mw ed ef dx translated">medium.com</p></div></div><div class="mz l"><div class="na l nb nc nd mz ne ji mq"/></div></div></a></div></div></div>    
</body>
</html>