<html>
<head>
<title>Explainable Defect Detection Using Convolutional Neural Networks: Case Study</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用卷积神经网络的可解释缺陷检测:案例研究</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/explainable-defect-detection-using-convolutional-neural-networks-case-study-2b58bc17c8b1?source=collection_archive---------1-----------------------#2022-01-14">https://medium.com/geekculture/explainable-defect-detection-using-convolutional-neural-networks-case-study-2b58bc17c8b1?source=collection_archive---------1-----------------------#2022-01-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="ed9b" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">没有任何包围盒标签的训练对象检测模型。这篇文章展示了可解释人工智能的力量。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/0daf8c01e80ebfa76631dd1f504f2f2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_YxJpwTByr3CY3PWig-dbQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image by Author</figcaption></figure><p id="8ff9" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">尽管神经网络非常精确，但在需要预测解释能力的领域，如医学、银行、教育等，它并没有得到广泛应用。</p><p id="2e2a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在本教程中，我将向您展示如何克服卷积神经网络的这种可解释性限制。的确如此——通过探索、检查、处理和可视化由深度神经网络层产生的特征图。我们将详细介绍这种方法，并讨论如何将它应用到现实世界的任务中——缺陷检测。</p><p id="dc68" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我为这个项目创建了一个<a class="ae kj" href="https://github.com/OlgaChernytska/Visual-Inspection" rel="noopener ugc nofollow" target="_blank"> Github库</a>，在这里你可以找到所有的数据准备、模型、训练和评估脚本。</p><p id="b7f6" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">内容<br/> </strong> —任务<br/> —训练管道<br/> —推理管道<br/> —评估<br/> —结论</p><h1 id="a025" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">工作</h1><p id="0af3" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">给你一个400个图像的数据集，其中包含好的项目(标记为“好”类)和有缺陷的项目(标记为“异常”类)的图像。数据集不平衡，好的图像样本比有缺陷的图像样本多。图片中的物品可以是任何类型和复杂程度的——瓶子、电缆、药丸、瓷砖、皮革、拉链等。下面是数据集的一个示例。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lh"><img src="../Images/75f2b3ec70f9f9a26336ece3fa77120e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ofIkVT_nN1mFpInLv34xHw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 1. Subset “Pill” from <a class="ae kj" href="https://www.mvtec.com/company/research/datasets/mvtec-ad" rel="noopener ugc nofollow" target="_blank">MVTEC Anomaly Detection Dataset</a>. Image by Author</figcaption></figure><p id="146a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">你的任务是建立一个模型，将图像分类为“良好”/“异常”类，如果图像被分类为“异常”，则返回缺陷的边界框。尽管这个任务看起来很简单，就像一个典型的对象检测任务，但有一个问题——我们没有边界框的标签。</p><p id="8842" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">幸运的是，这个任务是可以解决的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es li"><img src="../Images/bf0428dec3db306a7d1014c12964ab51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pfxpZO1eyj4EwZ3-96Nw6w.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 2. Model is expected to predict class ‘Good’ / ‘Anomaly’ and localize a defect region for an ‘Anomaly’ class. No bounding boxes are provided during training, only class labels. Image by Author</figcaption></figure><h1 id="be97" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">培训渠道</h1><p id="abf4" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated"><em class="lj">披露:我不是在分享我的真实商业项目，而是展示如何解释分类模型预测，因此这可能会用于许多领域和任务——不仅是制造业，还有医学。我还应该说，在这里不要期望高精度，因为这是我最喜欢的项目。但是你可以自由地使用我的结果作为你的项目的起点，投入更多的时间并达到你需要的精确度:)</em></p><h2 id="e326" class="lk kl hi bd km ll lm ln kq lo lp lq ku jw lr ls kw ka lt lu ky ke lv lw la lx bi translated">数据准备</h2><p id="b626" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">对于我的所有实验，我都使用了<a class="ae kj" href="https://www.mvtec.com/company/research/datasets/mvtec-ad" rel="noopener ugc nofollow" target="_blank"> MVTEC异常检测数据集</a>(注意，它是在<a class="ae kj" href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener ugc nofollow" target="_blank">知识共享署名-非商业-共享4.0国际</a>许可下分发的，这意味着它不能用于商业目的)。</p><p id="4940" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">该数据集包括不同项目类型的15个子集，如瓶子、电缆、药丸、皮革、瓷砖等；每个子集总共有300-400幅图像，每幅图像都被标记为“良好”/“异常”。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ly"><img src="../Images/a777411e106b4e14b10cf1d44ce9e504.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ofni3mJdCWwULzdqX7SHRg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 3. Samples from <a class="ae kj" href="https://www.mvtec.com/company/research/datasets/mvtec-ad" rel="noopener ugc nofollow" target="_blank">MVTEC Anomaly Detection Dataset</a>:<br/>upper row — good images, lower row — images with the defective items. <a class="ae kj" href="https://www.mvtec.com/company/research/datasets/mvtec-ad" rel="noopener ugc nofollow" target="_blank">Image Source</a></figcaption></figure><p id="cec3" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">作为数据预处理步骤，<strong class="jp hj">将图像调整为224×224像素，以加快训练速度。</strong>大多数子集中的图像尺寸为1024×1024，但由于缺陷尺寸也很大，我们可以在不牺牲模型精度的情况下将图像尺寸调整为较低的分辨率。</p><p id="a8f3" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">考虑使用数据增强。</strong>一般来说，适当的数据扩充总是有益于你的模型(顺便说一句，查看<a class="ae kj" href="https://towardsdatascience.com/complete-guide-to-data-augmentation-for-computer-vision-1abe4063ad07" rel="noopener" target="_blank">我关于数据扩充的帖子</a>了解更多)。</p><p id="244e" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">但是让我们假设，当部署到生产中时，我们的模型将“看到”与我们现在拥有的数据集中格式完全相同的数据。因此，如果图像被居中、缩放和旋转(如在胶囊和电缆子集中)，我们可能根本不使用任何数据增强，因为测试图像也被期望居中、缩放和旋转。但是，如果不旋转(而只是居中和缩放)mages，如在螺钉和金属螺母子集中，将旋转作为预处理步骤添加到训练管道将有助于模型更好地学习。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lz"><img src="../Images/cbccb8d0a46ac26432d0922453662a02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w46NAJzdBxaEmraZHqVT2g.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 4. Examples of subsets with preprocessed (centered, scaled, and rotated) and not preprocessed (not rotated) images. Visualizing the mean image helps understand whether images in the subset are preprocessed or not. Image by Author</figcaption></figure><p id="97cf" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">将数据分成训练/测试部分</strong>。理想情况下，我们希望拥有训练、验证和测试部分——分别用于训练模型、调整超参数和评估模型准确性。但是我们只有300–400张图像，所以让我们将80%的图像放入训练集，20%放入测试集。对于小数据集，我们可以执行5重交叉验证，以确保评估结果是稳健的。</p><p id="0d0c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">当处理不平衡数据集时，训练/测试分割应该以分层的方式执行，因此训练和测试部分将包含两个类别的相同份额——“良好”/“异常”。此外，如果您有缺陷类型的信息(如划痕、裂纹等)，最好也根据缺陷类型进行分层分割，这样训练和测试零件将包含相同份额的有划痕/裂纹的项目。</p><h2 id="2c79" class="lk kl hi bd km ll lm ln kq lo lp lq ku jw lr ls kw ka lt lu ky ke lv lw la lx bi translated">模型</h2><p id="0c2b" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">我们就拿ImageNet上预训练的<a class="ae kj" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank"> VGG16 </a>来说，改变它的分类头——用全局平均池和单个密集层代替扁平化和密集层。我将在“推理管道”一节中解释为什么我们需要这些特定的层。</p><p id="13c6" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">(这种方法我已经在论文<a class="ae kj" href="https://arxiv.org/abs/1512.04150" rel="noopener ugc nofollow" target="_blank">中找到了，学习深度特征进行鉴别定位</a>。在这篇文章中，我将介绍文中描述的所有重要步骤。)</p><p id="a5d8" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们将该模型训练为典型的2类分类模型。该模型输出一个二维向量，其中包含分类“好”和“异常”的概率(对于一维输出，该方法也应该可行，请随意尝试)。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/093eec9bf897e0fe3f8d661eca3789f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t6Hv5CCi0zBBO9Z34bBG2w.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 5. Original VGG-16 architecture VS custom one. Image by Author</figcaption></figure><p id="4b47" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在训练期间，前10个卷积层被冻结，我们只训练分类头和后3个卷积层。这是因为我们的数据集太小，无法微调整个模型。损失是交叉熵；优化器是Adam，学习率为0.0001。</p><p id="b9dc" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我试验了不同的MVTEC异常检测数据集子集。我用batch_size=10对模型进行了最多10个时期的训练，并在训练集准确率达到98%时提前停止。为了处理不平衡数据集，我们可以应用损失加权:对“异常”类图像使用较高的权重，对“良好”类图像使用较低的权重。</p><h1 id="7640" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">推理管道</h1><p id="7d29" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">在推断过程中，我们不仅要将图像分类为“好的”/“异常的”类别，而且要在图像被分类为“异常”的情况下获得缺陷的边界框。</p><p id="7f79" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">由于这个原因，我们使模型处于推理模式，以输出类别概率以及热图，这些稍后将被处理到边界框中。热图是根据深层要素图创建的。</p><p id="b4ed" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">第一步。【ReLU激活后，从con V5–3层获取所有特征地图。对于单个输入，将有512个大小为14×14的特征地图(大小为224×224的输入图像通过4个池层每次缩减采样两次)。</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mb"><img src="../Images/69196ae944f0f40918f3ecdbdbd85b44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qBrUEpNQeh3BASY1zmLx7Q.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 6. Feature Maps from Layer Conv5–3 (after ReLU activation).<br/>There are 512 feature maps total, each of size 14×14; visualized only some of them. Image by Author</figcaption></figure><p id="92f9" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">第二步</strong>。对con V5–3层的所有512个要素图求和，每个要素图乘以影响“异常”类得分计算的密集层中的权重。仔细看图7和图8，理解这个步骤。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mc"><img src="../Images/cfc0894a9c050ba5c1fec11e80a32032.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kWTfpm5BEaByjetkUBgsJg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 7. Detailed architecture of the last model layers (classification head). Image by Author</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es md"><img src="../Images/ed84685e86d15740f4a5620aee63917d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kfM_k3AzFNyCESDNSQOmYQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 8. The final heatmap is calculated as the sum of Conv5–3 layer heatmaps each multiplied by the weight in the Dense layer that affected the ‘Anomaly’ class score. Image by Author</figcaption></figure><p id="1734" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">为什么会这样？</strong>现在你会明白为什么分类头要有一个全局平均池层和一个密集层。这种架构使得有可能跟踪什么特征图(以及多少)影响最终预测并使其成为“异常”类。</p><p id="1070" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">每个特征图(层con V5–3的输出；参见图6)突出显示了输入图像中的一些区域。全局平均池图层将每个要素地图表示为一个数字(我们可以将其视为一维嵌入)。密集层通过将每个嵌入乘以相应的权重来计算分类“好”和“异常”的分数(和概率)。该流程如图7所示。</p><p id="24e1" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">因此，密集图层权重表示每个要素地图对“良好”和“异常”类分数的影响程度(我们只对“异常”类分数感兴趣)。将con V5–3图层的特征地图相加，每个地图乘以密集图层的相应权重，这样做很有意义。</p><p id="7e18" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">有趣的是，使用全局平均池而不是全局最大池对于使模型找到整个对象是至关重要的。下面是原始论文<a class="ae kj" href="https://arxiv.org/abs/1512.04150" rel="noopener ugc nofollow" target="_blank">学习深度特征进行鉴别定位</a>所说的:</p><blockquote class="me mf mg"><p id="6f66" class="jn jo lj jp b jq jr ij js jt ju im jv mh jx jy jz mi kb kc kd mj kf kg kh ki hb bi translated">“我们相信，与鼓励网络仅识别一个区别部分的全局最大汇集相比，全局平均汇集损失鼓励网络识别对象的范围。这是因为，当进行贴图的平均时，可以通过找到对象的所有有区别的部分来最大化值，因为所有低激活会减少特定贴图的输出。另一方面，对于全局最大值池，除了最有区别的图像区域之外，所有图像区域的低分数不会影响分数，因为您只是执行最大值。”</p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mk"><img src="../Images/f5ce0207d2b4914bc5eaa978a08c04f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pQnjZ12s92ZmBfHeJEPp0g.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 9. The final heatmap is calculated by summing feature maps multiplied by the weight in the Dense layer that affected the ‘Anomaly’ class score. We may guess that feature maps, such as 139 and 181, have large positive weights during summation, feature map 172 has a large negative weight and feature map 127 probably has a weight close to 0, so it doesn’t affect how the final heatmap look. Image by Author</figcaption></figure><p id="f40e" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">第三步</strong>。下一步是对热图进行上采样，以匹配输入图像的大小——224×224。双线性上采样是可以的，就像任何其他上采样方法一样。</p><p id="e963" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">回到模型输出<strong class="jp hj">。</strong>该模型返回“良好”和“异常”类别的概率，以及显示在计算“异常”分数时哪些像素是重要的热图。模型总是返回热图，不管它将图像分类为“好”还是“异常”；当课程“好”的时候，我们只是忽略了热图。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ml"><img src="../Images/66ca5128f3a911b5af9a1b06252dc457.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cjBjF1zvr6IqpfdNYBTqzQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 10. Model in the inference mode should output ‘Anomaly’ class heatmap. Image by Author</figcaption></figure><p id="9169" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">热图看起来很好(见图11)，并解释了是哪个区域使模型决定该图像属于“异常”类。我们可以就此打住，或者(如我所承诺的)将热图处理成一个边界框。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/79fe8a43300df5b50facd9dd07c15fd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V-CkWSHspFPQH5fI0_UISQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 11. Heatmaps for some ‘Anomaly’ class images. Image by Author</figcaption></figure><p id="771c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">从热图到包围盒。这里你可能会想到几种方法。我给你看一个最简单的。在大多数情况下，它工作得很好。</p><p id="0859" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">1.首先，标准化热图，使所有值都在范围[0，1]内。</p><p id="a48f" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">2.选择一个阈值。将其应用于热图，以便所有大于阈值的值都转换为1，小于阈值的值都转换为0。阈值越大，边界框就越小。我喜欢阈值在[0.7，0.9]范围内时的结果。</p><p id="0ba9" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">3.我们假设，1s的区域是一个单一的致密区域。然后，通过在高度和宽度维度中查找argmin和argmax，围绕该区域绘制一个边界框。</p><p id="6836" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">但是，注意这种方法只能返回一个边界框(根据定义)，所以如果图像有多个缺陷区域，它就会失败。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mn"><img src="../Images/6fca854b7783b525e24fdf1eca0c4a81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*otUXs8dPBkQopKL5O6hajQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 12. How to process heatmap into the bounding box. Image by Author</figcaption></figure><h1 id="88d8" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">估价</h1><p id="fae1" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">让我们在MVTEC异常检测数据集的5个子集上评估该方法——榛子、皮革、电缆、牙刷和药丸。</p><p id="fd8d" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">对于每个子集，我都训练了一个独立的模型；选择20%的图像作为测试集——以随机和分层的方式。没有使用数据增强。我在损失函数中应用了类别权重——1代表“良好”类别，3代表“异常”,因为在大多数子集中，良好图像比异常图像多3倍。该模型最多被训练10个时期，如果训练集精度达到98%，则提前停止。这是我的笔记本，上面有培训脚本。</p><p id="8df9" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">以下是评测结果。子集的训练集大小为80–400幅图像。平衡精度在81.7%到95.5%之间。有些子集，比如榛子和皮革，对模特来说比较容易学，而药丸是相对比较难的子集。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mo"><img src="../Images/7fd1f1993492657ac8aae7418cf5f332.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o5LPU5Ynfbx7luB9Tj8Ylw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 13. Evaluation results for 5 subsets from <a class="ae kj" href="https://www.mvtec.com/company/research/datasets/mvtec-ad" rel="noopener ugc nofollow" target="_blank">MVTEC Anomaly Detection Dataset</a>. Image by Author</figcaption></figure><p id="f4a4" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">数字就是这样，现在让我们看看预测是什么样的。在大多数情况下，如果类别是“异常”，模型产生正确的类别预测和精确的边界框。然而，存在一些错误:它们或者是不正确的类预测，或者是当类被正确预测为“异常”时错误的边界框位置。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mp"><img src="../Images/563dfd1afe83f8eb5e6e816e0915ea41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B4pk0nNO-8wU7UTZk8HBuA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 14. Hazelnut subset: Predictions on the Test Set. Image by Author</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/6ba478ccf491ef94918aff4d88e42a7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WrLyH41k_5lSa2Bwl_WO9g.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 15. Leather subset: Predictions on the Test Set. Image by Author</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mr"><img src="../Images/de1bc2cba21a098726b95236c5a1ebbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GCjvdooiyhL_K6RljGaNUw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 16. Cable subset: Predictions on the Test Set. Image by Author</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ms"><img src="../Images/5164507601e183356a8049211c0ca385.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2osI457VxnDsDGK13YTYUQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 17. Toothbrush subset: Predictions on the Test Set. Image by Author</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mp"><img src="../Images/1844948cffca6772c4a103006c4d8d3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YMWn-vzpFh1ZsB44OnzsBQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image 18. Pill subset: Predictions on the Test Set.</figcaption></figure><h1 id="42a4" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">结论</h1><p id="7dc4" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">在这篇文章中，我想告诉你，神经网络并不像有些人认为的那样是黑盒算法，但是当你知道去哪里找时，它是很容易解释的:)这里描述的方法是解释你的模型预测的许多方法之一。</p><p id="622b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">当然，模型不是那么准确，主要是因为它是我的快速宠物项目。但是如果你要做类似的工作，请随意以我的结果为起点，投入更多的时间，获得你需要的精确度。</p><p id="f100" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我正在开源这个项目的代码到<a class="ae kj" href="https://github.com/OlgaChernytska/Visual-Inspection" rel="noopener ugc nofollow" target="_blank">这个Github库</a>。请随意使用我的结果作为您项目的起点:)</p><h1 id="78c5" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">下一步是什么？</h1><p id="5c65" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">如果您想提高这种异常检测模型的准确性，添加数据扩充—是开始的地方。我推荐你阅读我的帖子——<a class="ae kj" href="https://towardsdatascience.com/complete-guide-to-data-augmentation-for-computer-vision-1abe4063ad07" rel="noopener" target="_blank">计算机视觉数据增强完全指南</a>。在那里，您将发现如何使用数据扩充来使您的模型受益，而不是有害:)</p><p id="0959" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">如果你对案例研究感兴趣，可以查看我的教程—<a class="ae kj" href="https://towardsdatascience.com/gentle-introduction-to-2d-hand-pose-estimation-approach-explained-4348d6d79b11" rel="noopener" target="_blank">2D手部姿态估计简介:方法讲解</a>。</p></div><div class="ab cl mt mu gp mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="hb hc hd he hf"><h1 id="5203" class="kk kl hi bd km kn na kp kq kr nb kt ku io nc ip kw ir nd is ky iu ne iv la lb bi translated">参考</h1><p id="be0a" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">[1]周、、Aditya Khosla、Agata Lapedriza、Aude Oliva和Antonio Torralba:学习用于区别性定位的深度特征；载于:2016年IEEE计算机视觉和模式识别会议论文集。<a class="ae kj" href="https://arxiv.org/pdf/1512.04150.pdf" rel="noopener ugc nofollow" target="_blank"> pdf </a></p><p id="0d9c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">[2]保罗·博格曼、基利安·巴茨纳、迈克尔·福瑟、大卫·萨特勒格、卡斯滕·斯特格:MVTec异常检测数据集:用于无监督异常检测的综合真实世界数据集；发表于:国际计算机视觉杂志，2021年1月。<a class="ae kj" href="https://link.springer.com/content/pdf/10.1007/s11263-020-01400-4.pdf" rel="noopener ugc nofollow" target="_blank"> pdf </a></p><p id="c99e" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">[3]保罗·博格曼、迈克尔·福瑟、大卫·萨特勒格、卡斯滕·斯特格:mv tec AD——用于无监督异常检测的综合真实数据集；参加:IEEE计算机视觉和模式识别大会(CVPR)，2019年6月。<a class="ae kj" href="https://www.mvtec.com/fileadmin/Redaktion/mvtec.com/company/research/datasets/mvtec_ad.pdf" rel="noopener ugc nofollow" target="_blank"> pdf </a></p></div></div>    
</body>
</html>