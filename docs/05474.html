<html>
<head>
<title>Time Series Forecast Using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习的时间序列预测</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/time-series-forecast-using-deep-learning-adef5753ec85?source=collection_archive---------0-----------------------#2021-07-22">https://medium.com/geekculture/time-series-forecast-using-deep-learning-adef5753ec85?source=collection_archive---------0-----------------------#2021-07-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="294e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Keras循环神经网络和LSTM的练习</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/3299c54a14fc3180469bcd3a934e1c5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qSbngV0UEcZGDg2l"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Photo by <a class="ae jt" href="https://unsplash.com/@markuswinkler?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Markus Winkler</a> on <a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="c0fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<a class="ae jt" rel="noopener" href="/geekculture/time-series-forecast-in-python-5c4c61e1c2c2">之前的博客</a>中，我解释了一个用Python进行时间序列预测的例子，使用了像SARIMA这样的经典时间序列分析方法。在这篇博客中，我举了一个训练深度神经网络的例子，比如Keras的RNN / LSTM，用于预测时间序列。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="8072" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">介绍</h1><p id="5f98" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">时间序列通常被定义为一个或多个变量在连续时间段内的一系列值。例如，连续几年的销售量、一个城市几个月的平均温度等。如果该序列只涉及一个变量，则称为单变量时间序列。如果该序列列出了多个变量在不同时间点的值，则称为多元时间序列。在这个博客的例子中，我们将处理一个单变量时间序列。</p><p id="d3c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">连续的时间点称为时间步长。例如，每个时间步长可以是1到12个月或1到31天或一系列年份等。</p><p id="db0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于时间序列成分和经典预测方法的更多基本细节，请参考我之前的<a class="ae jt" rel="noopener" href="/geekculture/time-series-forecast-in-python-5c4c61e1c2c2">博客。</a> <br/>在这篇博客中，我们将重点讨论使用深度神经网络(递归神经网络)进行时间序列预测。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="acbe" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">基于深度神经网络的时间序列预测</h1><p id="9f6d" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">在深度学习神经网络，尤其是递归神经网络流行之前，有许多经典的分析方法/算法用于时间序列预测- <strong class="ih hj"> AR、MA、ARMA、ARIMA、SARIMA等。由于其有效性以及在大量数据不可用的情况下(这些数据对于训练rnn至关重要),它们甚至在今天仍被使用。</strong></p><h2 id="8919" class="le kc hi bd kd lf lg lh kh li lj lk kl iq ll lm kp iu ln lo kt iy lp lq kx lr bi translated">深度学习与经典时间序列预测方法的比较</h2><ul class=""><li id="0b9e" class="ls lt hi ih b ii kz im la iq lu iu lv iy lw jc lx ly lz ma bi translated">在上述经典方法中，我们必须对时间序列数据进行预处理，如分析和去除趋势、季节性等。没有这个时间序列，像ARIMA这样的算法就无法工作。但深度神经网络是“神奇的”，因为它们可以学习不同时间序列中的内在模式，并提出一个合理的模型，而无需我们费心打破时间序列数据中存在的趋势和季节性模式。</li><li id="c2b8" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc lx ly lz ma bi translated">但神经网络的缺点是，你需要大量的数据来训练一个模型，不像经典方法那样不需要大量的数据。此外，神经网络还涉及到超参数的配置和学习率等问题。，这并不简单，需要一些迭代和微调。深度学习网络的训练也很耗时，并且需要GPU来提高速度。</li></ul><p id="e20a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，深度网络(递归神经网络)在预测时间序列方面是有效的，我们将在下面讨论的例子中看到这一点。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="d75b" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">递归神经网络</h1><p id="96f6" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">递归神经网络(RNNs)专门设计用于处理<strong class="ih hj">序列数据。</strong> RNNs已经能够在<strong class="ih hj">自然语言处理、</strong>计算机视觉、<strong class="ih hj">时间序列分析等领域产生最先进的结果。</strong>在RNNs中，神经网络的每个隐藏层将其输出(前馈)提供给下一层，并在时间步“t”提供给自己输出，同时在下一个时间步“t+1”训练数据。也就是说，RNN试图学习一系列数据，而不是普通神经网络学习的独立数据。由于这种序列学习能力，rnn具有学习语言(单词/句子的序列)、视频、时间序列等的能力。</p><h2 id="373f" class="le kc hi bd kd lf lg lh kh li lj lk kl iq ll lm kp iu ln lo kt iy lp lq kx lr bi translated">LSTM ( L <strong class="ak"> ong，短期记忆网络)</strong></h2><p id="e7e3" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">LSTM是RNNs的流行变体，它解决了常规RNNs中的问题，如非常深的RNNs中的“消失梯度问题”,当误差梯度通过具有许多隐藏层的RNNs中的时间反向传播(BPTT)传递时，该问题阻碍了初始层中的学习过程。LSTMs还解决了当训练序列变得太长(例如，一段很长的文本)时，正常rnn面临的记忆丢失问题。LSTM变得如此受欢迎，以至于它们几乎取代了rnn，当人们提到rnn时，他们大多指的是LSTM。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="08bd" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">使用RNN / LSTM进行单变量时间序列分析的分步示例</h1><p id="24c2" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">现在让我们直接进入本博客的主题…一步一步的例子，如何训练时间序列数据和未来预测值的RNN和LSTM模型..</p><h1 id="b236" class="kb kc hi bd kd ke mg kg kh ki mh kk kl km mi ko kp kq mj ks kt ku mk kw kx ky bi translated">问题</h1><p id="8c7a" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated"><strong class="ih hj">预测维基百科文章的未来浏览量。</strong>我们将在70K个时间序列样本的训练集上训练和拟合时间序列模型，每个样本都包含一些跨多个月的维基百科文章的每日查看计数。然后，我们将使用模型来预测任何给定样本在未来一天或多天的未来视图计数。</p><p id="b47c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将探索RNN(递归神经网络)，特别是LSTM(长短期记忆)的RNN变种来训练和预测。</p><h1 id="89f0" class="kb kc hi bd kd ke mg kg kh ki mh kk kl km mi ko kp kq mj ks kt ku mk kw kx ky bi translated">数据集</h1><p id="3b78" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">数据集取自Kaggle上的<a class="ae jt" href="https://www.kaggle.com/c/web-traffic-time-series-forecasting/" rel="noopener ugc nofollow" target="_blank">网络流量时间序列预测竞赛</a>。</p><p id="2123" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练数据集由大约145k个时间序列组成。从2015年7月1日到2016年12月31日，这些时间序列中的每一个都代表了不同维基百科文章的日浏览量。</p><h1 id="aa34" class="kb kc hi bd kd ke mg kg kh ki mh kk kl km mi ko kp kq mj ks kt ku mk kw kx ky bi translated">密码</h1><p id="42f9" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">这个练习的完整笔记本代码可以从我的<a class="ae jt" href="https://github.com/raja-surya/Time-Series-RNN" rel="noopener ugc nofollow" target="_blank"> github链接</a>下载。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="b66b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从加载数据的第一步开始练习..</p><h1 id="f669" class="kb kc hi bd kd ke mg kg kh ki mh kk kl km mi ko kp kq mj ks kt ku mk kw kx ky bi translated"><strong class="ak"> 1。读取数据</strong></h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ml"><img src="../Images/15176cdc2fe3472b07b8d17f1a45f314.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gop0DybNkXzwEj8adr33JQ.png"/></div></div></figure><p id="6e95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们看到数据集包含近145K行和551列。每一行都是一个独特的时间序列。对于每个时间序列，您将获得相应文章的名称以及该时间序列所代表的流量类型(全部、移动、桌面、蜘蛛)。这些列是从2015年7月1日到2016年12月31日的每日日期。因此每个时间序列的长度为550天。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="2029" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated"><strong class="ak"> 2。数据清理</strong></h1><p id="818e" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">我们在数据集中看到许多缺失(NaN)值。不幸的是，该数据集的数据源并不区分零流量值和缺失值。缺少值可能意味着流量为零，或者当天的数据不可用。<br/>由于缺少关于丢失值的清晰度，我们可以安全地忽略那些具有空值的时间序列，因为数据集对于时间序列建模来说是足够大的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mm"><img src="../Images/d81967cee8a255791d790251629e9fe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*x7vsr92RezweRRBT49NuiQ.png"/></div></figure><p id="fc58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们删除不必要的“页面”列，并将列名从日期改为时间步长，这将有助于我们稍后操作数据。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="ab fe cl mn"><img src="../Images/6111ee6ec4c0b39fba2c0157b41d6f8e.png" data-original-src="https://miro.medium.com/v2/format:webp/1*hzcKbQiS6kmCq_iEHMvnkw.png"/></div></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="56eb" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">3.数据准备和可视化</h1><p id="2a13" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">让我们将最大时间步长设为160 ( 160天)。rnn要求数据以三维形式输入— [批量大小、时间步长、单个时间步长中的元素数量]。所以我们首先把所有的数据转换成三维数组。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mo"><img src="../Images/01183e15b797c74aeb6ad730bf9f028c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4nrg1_hBjq0L64mh3QycWQ.png"/></div></div></figure><h2 id="d789" class="le kc hi bd kd lf lg lh kh li lj lk kl iq ll lm kp iu ln lo kt iy lp lq kx lr bi translated"><strong class="ak"> 3.1检查并移除异常值</strong></h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mp"><img src="../Images/5c25d481fbbf6abdeef95a3305d1c94e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0__FxLTtxaPbbspO_qBZZQ.png"/></div></div></figure><p id="3e51" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们看到在我们的时间序列中有极高的值，如上面看到的最大值。第99百分位的值只有9883。因此，显然存在一些异常值，它们在99%以上。让我们只取第99个百分点进行分析。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ml"><img src="../Images/dc7eea7a2cf46d532321a3c135427650.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qIlGlSDerVLjBh2gd5-dZw.png"/></div></div></figure><p id="488b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们有102220个剔除异常值后的时间序列样本。</p><p id="ddf8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将绘制一个时间序列样本。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mq"><img src="../Images/49b69cc6886e3640cf37842d0ed0264e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6aCQNnH3rpWP2oOX62ZErg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Time Series Sample</figcaption></figure><p id="c329" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在上面的时间序列中看到一个高范围的值。因此，需要对数据集进行缩放。</p><h2 id="6f9a" class="le kc hi bd kd lf lg lh kh li lj lk kl iq ll lm kp iu ln lo kt iy lp lq kx lr bi translated"><strong class="ak"> 3.2时间序列数据的缩放</strong></h2><p id="2374" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">我们将首先对整个数据进行对数转换。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mr"><img src="../Images/96b4ec9163ea8cce6490729fa8a09a48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fM3G58wqgq7TJuw93ko3eA.png"/></div></div></figure><p id="8dd5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将进一步规范化数据集，使其值介于0和1之间(最小最大缩放)。</p><p id="8b68" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在此之前，我们将把数据分成训练集、测试集和验证集。首先，我们将在150个时间步长上进行训练，并预测第151个时间步长的值。<br/>训练集= 70K时间序列<br/>有效集= 20K时间序列<br/>测试集= 10K时间序列</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ms"><img src="../Images/4acef780c715865b7cc82a15b97412b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RrFY_U4-CFgMw7nX4dPCIQ.png"/></div></div></figure><p id="a67d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们了解一下X_train和y_train的尺寸</p><p id="c281" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">X _ train:</strong><br/>70000——单个时间序列数(总批量)。<br/> 150-在70K训练数据的每一个中，用于训练的连续天数(时间步长)。<br/> 1-值的数量(此处为单变量，只有一个变量，即特定日期的查看次数)。</p><p id="a573" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> y_train: <br/> </strong> 70000-单个时间序列的数量(总批量)<br/> 1-每个时间序列的目标值的数量(我们预测第151天的值)</p><p id="51a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">最小最大归一化</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mt"><img src="../Images/3569abd069beaa2d8f07ca8f2482d9c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*ZloqDtq99XYcBY7x-7FThw.png"/></div></figure><p id="40ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对数变换训练数据集的最小值为0，最大值约为9。我们将在这个经过对数变换的训练数据集上安装一个最小最大缩放器，以进一步缩小0-1范围内的所有数据点。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mu"><img src="../Images/7566a31ab0f6bf2f7009f4b181163b8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RHONSQpAlbvAv2x4ytSemg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mv"><img src="../Images/07c8783e454ed84cc91426370768c524.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*BT26yWth1wJf-eC7qU6lZQ.png"/></div></figure><p id="6467" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们看到数值在0-1范围内变化。</p><p id="7539" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们有了训练数据、有效数据等。准备好了，我们现在准备好为时间序列建立模型了。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="2bfc" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">4.建模和预测(单日)</h1><p id="b188" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">我们将从创建一个简单的基线模型开始建模，这将有助于我们稍后评估高级模型的性能。</p><h2 id="6a0e" class="le kc hi bd kd lf lg lh kh li lj lk kl iq ll lm kp iu ln lo kt iy lp lq kx lr bi translated">4.1基准模型</h2><p id="7369" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated"><strong class="ih hj"> 4.1.1天真的预测</strong></p><p id="9211" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在简单预测中，我们只预测最后一个观察值，即预测时间步长t+1的值与前一个时间步长t的值相同</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mw"><img src="../Images/857f4e24bfe9d5977b731a8f417e9b54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mSItM6ZGhlEHrX6Ga5CIGg.png"/></div></div></figure><p id="7da3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们得到基线均方误差为0.0029608。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mx"><img src="../Images/0501b4a4e7312ffeff8bb6ef6568a586.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PvDAt3LRWkvfPbWxHKJUMw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Naive forecast for a sample</figcaption></figure><p id="7988" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您在第151天的样本图上看到<strong class="ih hj">(图上的150，因为它从0开始)，</strong>预测值与前一时间步的值相同。与实际值相差甚远(红圈)。</p><p id="3081" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4.1.2线性回归模型</strong></p><p id="abf1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将使用keras构建一个线性回归模型。<br/>我们使用平坦层和密集输出层来实现线性回归模型。</p><p id="50a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回想一下，输入维度= batch_size，n_steps，1。平坦层使由n个步骤(在我们的例子中是150个时间步骤)组成的输入平坦化，并将这150个元素馈送到具有一个神经元的密集层。因此涉及150个前馈权重+一个偏差，这相当于一个回归方程</p><p id="aeed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">y = (W0 * t0) + (W1 * t1) +……。(W149 * t149) + b</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es my"><img src="../Images/ed4a4515097aa1e13aa31224b89e7340.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mQFnzn_WP0HmO-ernJ2Q9Q.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mz"><img src="../Images/51fbc4a4be399cd0d8326d20b98639d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vtq1y6Tvc0V7kQTOTCAS9g.png"/></div></div></figure><p id="3cf9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们从线性模型得到0.0017274的均方误差，这优于0.0029608的原始预测。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es na"><img src="../Images/4f76d0690d7d9d118c5f02d874ad3c82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GqOJ6qBM9am0eW39Nel9ag.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Linear Regression model forecast for a sample</figcaption></figure><p id="6af1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，由keras NN建立的线性模型给出了比简单预测模型更好的更接近的预测。</p><p id="7d41" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们将尝试高级模型，我们将从简单的RNN架构开始。</p><h2 id="7ad2" class="le kc hi bd kd lf lg lh kh li lj lk kl iq ll lm kp iu ln lo kt iy lp lq kx lr bi translated">4.2简单的RNN</h2><p id="5b7a" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">我们将尝试最简单的只有一层和一个神经元的RNN。<br/>注意<strong class="ih hj">如果确认损失在多个连续时期内没有改善(减少)，我们使用Keras </strong>提供的提前停止回调 <strong class="ih hj">来停止训练过程。</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nb"><img src="../Images/afa3433f1c0e584938a75fab5de52d8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*97KFBlbZAuk5tdO9IB9p_A.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nc"><img src="../Images/a11fe4662c07fc5a1fe02c03c6eee07f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dm6ZJWjCzP1Xpy1lcPELzg.png"/></div></div></figure><p id="19c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在验证集上对模型进行评估，得到简单RNN模型的均方误差为0.0037434，比线性模型的均方误差0.0017274差。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es na"><img src="../Images/2a0b3738e8242dfadb5d78fd3148332d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uyuBzB_xE_BWffD2PzuXKw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Simple RNN forecast for a sample</figcaption></figure><p id="2b31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简单RNN对样本50的预测不如线性回归模型好..</p><h2 id="06f0" class="le kc hi bd kd lf lg lh kh li lj lk kl iq ll lm kp iu ln lo kt iy lp lq kx lr bi translated">4.3深度RNN</h2><p id="e940" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">让我们尝试一个稍微深一点的RNN(增加一个RNN层)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nd"><img src="../Images/23bc3027e3ceff16b2b1e343d52e15be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q3MKc3b0kZ8pvgt6uZia0w.png"/></div></div></figure><p id="8935" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">除了提前停止，<strong class="ih hj">我们还使用Keras的ModelCheckpoint回调来保存跨运行时期的最佳模型。</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ne"><img src="../Images/882ce2c9f0c9942863d954a8485d0756.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JNHs5YA9p_bXq3t-mJNwEw.png"/></div></div></figure><p id="7002" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们从深RNN模型得到的均方误差为0.0016934，比简单的RNN要好。</p><p id="8dd8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们对验证集进行预测，然后对一些时间序列样本绘制简单RNN和深度RNN预测与原始值的关系图。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nf"><img src="../Images/552b7c03fe657482055d7060d8ac1f22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FDr7dVRCanW7khmLyjZWoA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Comparison of Deep RNN forecast with Actuals</figcaption></figure><p id="a51c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在验证集中为40个不同的时间序列绘制了第151天的预测。我们看到，深度RNN预报几乎紧跟原始计数，总体上比简单的RNN要好。</p><p id="d3bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以rnn在预测方面做得非常好。</p><p id="e22e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看深RNN对某一特定样本的预测图。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ng"><img src="../Images/c4b6df8346ca07c5a25b9dadf4c13837.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LZ_Dq39CnNBwj0aQ08oItg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Deep RNN forecast for a sample</figcaption></figure><p id="105a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">样本50的预测比简单RNN好得多，更接近原始值。</p><h2 id="5927" class="le kc hi bd kd lf lg lh kh li lj lk kl iq ll lm kp iu ln lo kt iy lp lq kx lr bi translated">4.4 LSTM模式</h2><p id="7f2e" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">现在让我们去找一个LSTM模型。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nh"><img src="../Images/dcd80c3b3e90f083ddb759aa0bfbcec8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iEdgBeMXLOG46_mjmXNuYg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ni"><img src="../Images/d0efcea7f036ae41916c17c9428e370d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UVIG0JzoAEjDJnqSakAjsQ.png"/></div></div></figure><p id="f4ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们对验证集进行了评估，LSTM的MSE为0.0016625，看起来略好于深度RNN。</p><p id="8d09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们对验证集进行预测，并绘制一些时间序列样本的LSTM预测值与原始值的关系图。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nj"><img src="../Images/4266bf123d19e499306f1007478625e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q2b-38iAB0QFLBnL5kr-IQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Comparison of LSTM forecast with Actuals</figcaption></figure><p id="fd58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述原始值与预测值的图表显示，LSTM在预测不同时间序列样本的第151天的值方面做得非常好。</p><p id="595d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们来看看LSTM对某一特定时间序列的预测。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nk"><img src="../Images/943e8e41ca2161480e4b770d4b3140a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-KB7msjxQO6SSh0jX12EsA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">LSTM forecast for a sample</figcaption></figure><p id="adec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">与我们目前尝试的所有模型相比，LSTM对样本50的预测最接近实际值！</strong></p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="9f4b" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">5.提前几个时间步(天)的预测</h1><p id="9e9d" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">让我们做一些更有趣的事情..<br/>我们现在将预测多个天数(一次k天),即n+1天，n+2天…通过在前n天的数据上训练n+k。</p><h2 id="0565" class="le kc hi bd kd lf lg lh kh li lj lk kl iq ll lm kp iu ln lo kt iy lp lq kx lr bi translated">5.1将“n”天的值作为一个整体进行训练，并对第n+1、n+2天进行预测…..n+k</h2><p id="28d2" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">在这一部分中，我们像以前一样训练前n天的时间序列值，但目标将是多个预测，即未来3天，而不是我们在前面章节中看到的1天预测。</p><p id="0a25" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于目标现在是3天，我们必须为训练、测试和验证数据准备一组新的目标(每个时间序列有3个值)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nl"><img src="../Images/1d65b818ba47d71e11eeeb2400ae1bb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F0kcGRfaVAjmGs1OuRwQtQ.png"/></div></div></figure><p id="6301" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如上所述，我们将预测3天——第151天、第152天、第153天。因此，每个时间序列将有3个值作为目标。</p><p id="e346" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们对新形成的目标进行必要的最小最大比例变换，然后训练一个LSTM模型。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nm"><img src="../Images/e13460415dbfbb897ad99e9bfc9250a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d0g-PlYZ6pE0xz_xcJDPzw.png"/></div></div></figure><p id="4d55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意，LSTM模型的输出数量=预测天数。</strong></p><p id="13b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们对验证集进行预测，并检查其中一个样本。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nn"><img src="../Images/13e24c150937f8d1fd55efc2890b86d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FE9K8V669dGr6xvJmM_JpQ.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es no"><img src="../Images/93abaae32e5411fc0370406e0dc2af9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J-Lla8mYMVF1BLjyxJB43w.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Three days forecast of LSTM</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es np"><img src="../Images/dbe070b558bb212c851b9a4851a7580f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QjUW5V2fgCzgo362F6XIxw.png"/></div></div></figure><p id="86e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">我们看到LSTM在预测值接近实际值方面做得很好！</strong></p><h2 id="f959" class="le kc hi bd kd lf lg lh kh li lj lk kl iq ll lm kp iu ln lo kt iy lp lq kx lr bi translated">5.2序列对序列模型</h2><p id="10fc" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated"><strong class="ih hj">训练“n”天的值，预测每个时间步/天的下一个k值。</strong></p><p id="344d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们将以下列方式训练LSTM。</p><ol class=""><li id="feda" class="ls lt hi ih b ii ij im in iq nq iu nr iy ns jc nt ly lz ma bi translated">对于从t=0开始的每个时间步长t，将值传递给LSTM，并预测接下来3个时间步长的值。即t+1，t+2，t+3。</li><li id="bd30" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc nt ly lz ma bi translated">对时间步长做(1)直到时间步长150。在时间步长0，模型将输出包含时间步长1到3的预测的向量，然后在时间步长1，模型将预测时间步长2到4，依此类推。</li><li id="a5bc" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc nt ly lz ma bi translated">定型模型后，使用模型预测第151、152和153天的值。</li></ol><p id="c16a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种模型架构将不同于以前的模型。我们不是训练模型只在最后一个时间步预测接下来的3个值，而是训练它在每个时间步预测接下来的3个值。</p><p id="5c38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">因此，前面的模型是序列到向量RNNs，而这将是序列到序列RNN。</strong></p><p id="9ce4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种技术的优点是，损失将包含每个时间步的输出项，而不仅仅是最后一个时间步的输出项。因此，将有更多误差梯度流经模型。它们也将从每个时间步长的输出中流出。这可以稳定训练过程。</p><p id="3fc8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种方法中，训练集中的每个目标(我们在训练集中有70K个时间序列，所以70K个目标)必须是与输入序列长度相同的序列(即150)，在每一步包含一个三维向量。</p><p id="5494" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们相应地准备目标并检查尺寸。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nu"><img src="../Images/4f62a1dcc9ce3a2f8790adb56641c874.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_apBk84iBHPqJvbE0bWvKQ.png"/></div></div></figure><p id="2138" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要将模型转换为序列到序列模型，我们必须在所有递归层(包括最后一层)中设置return_sequence=True，并且我们必须在每个时间步应用最后一层(输出)。因此我们使用Keras时间分布层来实现这个目的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nv"><img src="../Images/2967434c14a3b4ba1eb57cd475f3fc9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZKJLIdz-hXuLCglfssa4OQ.png"/></div></div></figure><p id="27d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们对验证集进行预测，并检查其中一个样本。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nw"><img src="../Images/1b856880e4515e058891415a59d761c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OQdio1S7baqpQkLXuRY-sQ.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nx"><img src="../Images/78b40318ecc8b1192d7ab09dad204478.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DQebWOCVHYhmtsm8tbebmA.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ny"><img src="../Images/9bd09bf211b4d3377e8763123f44545c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SXm69peWb37C6wFAQOIlTA.png"/></div></div></figure><p id="ac4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">我们看到，这一次，LSTM也做得很好，预测值接近实际值！</strong></p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="22b7" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">结论</h1><p id="c6c6" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">我们成功地使用RNNs训练了数千个时间序列样本，并预测了未来单个和多个时间步长的值。我们不必担心时间序列的组成部分，如趋势、季节性、噪音等。，因为RNNs逼近任意序列的能力使我们很容易进行时间序列预测。</p></div></div>    
</body>
</html>