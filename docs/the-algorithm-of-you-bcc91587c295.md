# 你的算法:人工智能如何编程人类行为

> 原文：<https://medium.com/geekculture/the-algorithm-of-you-bcc91587c295?source=collection_archive---------1----------------------->

![](img/601e27a234ff2db77834a6f480f66b2c.png)

你知道脸书比你自己还了解你吗？

这是事实。如果你和大多数用户一样，这些年来给了很多“赞”不是吗？多少？几千？坏消息。**你把你的自由意志交给了算法行为修正的魔鬼。**

> 在我们看到的每一条内容背后，都是一个试图以某种方式修改我们行为的人工智能算法。

## 你的算法可以为任何结果设计你的行为。

一项关于脸书喜欢的预测能力的研究发现,“喜欢”足以准确预测用户可能宁愿保守秘密的极其敏感的个人信息:性取向、种族、宗教和政治观点、性格特征、智力、幸福、成瘾、父母离异、年龄和性别。

这怎么可能呢？通过在 feeds 中放置免费调查(每个人都对自己很好奇！)，研究人员让用户完成详细的性格评估，并提供他们的人口统计数据:基本上，什么是真实的。此外，用户的朋友和家人也提供了关于他们性格的见解。这些数据成为了测试该算法是否可以仅从喜欢的数据中准确预测相同的社会和心理特征的基准。

你猜怎么着。

*   如果你给 EN 150 点赞，FACEBOOK 比你最好的朋友更了解你。
*   如果你有 GIVEN 250 喜欢的人，FACEBOOK 比你母亲更了解你。
*   *如果你给了超过 300 个赞，FACEBOOK 比你自己还了解你。*

研究人员表示，在数百万用户不知情的情况下，使用从他们那里轻易获得的如此深刻的心理洞察来影响用户的行为是非常不道德的。

然而，这正是社交媒体背后的商业模式的描述。

> 我们在屏幕上看到的反馈不是随机的或中性的:这是一个有针对性的攻击计划，带有定制的个性化内容，以推动特定的人做出特定的行为。

由平台的真实客户订购——无论是广告商还是恐怖分子招募者。你不是顾客。你就是产品。

任何脸书的付费用户都可以做，而且不贵。根据人道技术中心的说法，一辆二手车的价格可以赢得整个国家的关注。

人类总是试图相互影响。如果我想向你借钱，或者说服你加入家庭教师协会，我可以微笑着对你示好。不过，我不确定这是否可行。我说服你的能力**受到我对你的了解的几个变量**的限制:我对你性格的了解，我们以前关系的历史，我猜测你是否心情好。有些甚至不是准确的事实，而是我对你形成的偏见和成见。

此外，我也有自己的人际问题——我今天可能会感到特别不安全，也许我昨晚睡得不好，我内向害羞，我选择了错误的服装，用了错误的语气，或者弄乱了我的妆容——一千件其他的事情会让我变得无效。

> 最终，你的决定取决于你自己。你保持你的自由意志。

我只能猜测是什么促使你行动。我无法准确估计我影响你的机会。

> 但是人工智能可以。AI 没有我们人类的局限性。

## 你的算法用数千个——也许是数百万个——它收集的关于你的变量进行运算。

您曾经使用过的所有应用程序和设备的整个数字足迹的变量。这些数据被汇总到一个巨大的数据库中，其中包含了所有关于你的信息。你在网上做的越多，你的数字足迹就越大。

此外，你的数字历史可以追溯到几年前——时间越长，人工智能对你的了解就越多。正如信用历史可以预测你的金融行为一样， ***你的数字历史可以预测任何行为。***

如果数据中有缺口，AI 会用和你一样的人的信息来填充它们。这是一个简单的任务:它知道谁是你的社交媒体朋友。

> 您的数字档案包含您的确切压力点。如果在正确的时间以正确的方式施压，想要的行为结果几乎是不可避免的。

不是猜的五五开。是 90/10 的确定性。

你没有意识到这些压力点是什么。机器为你建立了一个功能，精确地修改结果——你的行为。你不假思索地服从了。

这不是广告。**这是精神控制。**

# 行为矫正:你的功能

让我们考虑一个假设的例子，看看行为矫正的功能是什么样子的。比方说，一个社交媒体平台的客户是一个广告商，他想让你买一件珠宝。你在社交媒体订阅源中看到的内容会按下你在数字足迹中找到的心理按钮，并经过精确计算:

## 行为矫正的⨍unction =

## 0.X *不安全感+

## 0.X *中年危机(看起来更年轻！) +

## 0.X *羡慕更好看的社交媒体朋友+

## 0.X * FOMO(这些大家都买，你还等什么！) +

## 0.X *拒绝购买朋友推荐的商品的内疚感+

## 0.X *对老公的愤怒(我让他看看！) +

## 0.X *潜意识信息(佩戴珠宝的名人照片)+

## 0.X *政治统一(产品广告显示在您同意的政治内容旁边)

## 0.X *紧急购买(出售！) +

## 0.X *储蓄欲望(优惠券！) +

## 0.X *稀缺性(物资快用完了！) +

## 0.X *社会压力(你的朋友喜欢这个产品！) +

## 0.X *慈善(我们捐款是为了一个美好的事业！) +

## 0.X *自恋(你活该！) +

## 0.X *购买提示被设定在一个疲软的时刻+

## 一百万个其他变量…=

## =行为结果:用户购买了一件珠宝

这个过程可以重复 ***来给任何人编程，用他们独有的公式实现任何行为结果。***

# 构建你的算法

不是个人特质 A 导致行为 b .**T5【大脑神经生物学和机器智能交汇处发生的事情复杂得令人难以置信。**

AI 发现了你众多变量、 ***特质和你不知道自己有*** *的不安全感之间错综复杂的关系。*人类分析师，即使是直接处理数据的人，也可能不会注意到这些联系——它们不明显或不直观。有些没有意义。但是算法会找到有效的相关性。

甚至算法的创造者也不清楚这是如何发生的。机器在数据中发现的一些相关性甚至不能被人类程序员定义为逻辑变量。 [Youtube 的创造者感到惊讶的是，他们的算法以某种方式将人们推向黑暗内容和阴谋论](https://algotransparency.org/en/press.html?candidat=Benoit%20Hamon&file=ytrecos-presidentielle-2017-06-10)——这一切都是为了“参与”。

## 注意力工程师可能不知道它为什么工作，但机器知道。

也许是看了 YouTube 上的某个视频，导致你最近在亚马逊购物。也许看到某些名人八卦旁边的保险广告可以预测你的投票行为——但前提是你是中年白人女性。它可以是任何东西。机器运行了数百万个“T0”对比测试，以发现如果广告或政治活动以粉色对蓝色的背景呈现，你是否更有可能点击。你没有意识到你潜意识中的这些奇怪的怪癖——但 AI 知道它们是真实的。

> 算法比你更懂你。它已经爬遍了你的潜意识——由你的数据揭示。

你的算法从不睡觉，它从不疲倦。它没有感情。它与同情和怜悯无关。**它不会犹豫其说服策略是对是错，是善是恶——只要它们能有效实现目标。**

换句话说，**T5 没有任何内置于的伦理参数。**不是人类。你的算法只针对结果进行优化——**行为修正:**

*   *让你买。*
*   *让你投票。*
*   *让你为某项事业捐款。*
*   *让你变成游戏迷。*
*   *让你去参与暴动。*
*   *让你变成恐怖分子。*
*   让你在人类生存的每个领域放弃你的自由意志。
*   *让你放弃更多的数据来进一步优化算法。*

# 你的算法是神经病。

当出价最高的人为以任何方式改变你的行为出价时，这是可以做到的。有时准确率超过 90%——根据情况，人工智能可以确信你会完全按照它希望你的方式行事。

这是按下你大脑中正确的心理按钮的问题。在你脆弱的时候给你正确的信息。让你感到愤怒或沮丧——并把你推向你的功能设定的行为结果。

还记得《社会困境》纪录片中主角被带回毁灭性的数字成瘾陷阱的场景吗？操纵型人工智能算法利用角色最大的弱点定制了一个通知。“吸引”用户所要做的就是向他展示:**“*你的前女友开始了新的恋情！***

![](img/d0b684b3d9678f75b1a5533e117fb5d1.png)

这一切都发生在我们的意识水平之下。你认为你在做你自己的选择，而事实上你被精确地操纵着。

你的幸福不是你的功能的程序化结果。 只有用户参与度和平台盈利能力。这是一个古老的故事——跟着钱走就行了。

# 行为修正功能的编程

![](img/9d64c63d5b3d0caa56e003806fa1710c.png)

你的功能被编程在机器学习黑匣子里面。该算法被输入了两个东西:来自你的数字足迹的 ***数据*** 和在人类中实现期望的行为 ***输出*** 的任务。然后它提出最佳的 ***函数*** 来实现结果。

***You 的功能实时动态调整，用潜意识信息轰炸用户*** 直到达到想要的结果，行为的改变。该算法是自我优化的。这意味着随着时间的推移，随着它获得更多关于你的数据，它在校准你的行为方面变得更好。

> 通过向平台提供我们日常数字活动过程中的数据，我们正在训练算法(免费！)如何更高效地操纵我们。这叫做机器学习，因为，嗯…它会学习。

不是虚构，是现实。同样的过程被用于训练谷歌翻译——不同语言的大量文本被输入机器，算法找出语言中的复杂模式，使人类翻译几乎过时。没有语言学家参与其中。

[杰伦·拉尼尔](http://www.jaronlanier.com/)在他的书 [*中提出了立即删除你的社交媒体账户的十个理由*](http://www.jaronlanier.com/tenarguments.html) 称之为用有针对性的内容影响用户的过程**算法行为修正**，以及从事这一过程的公司**BUMMER machine:*用户的行为被修正，并制成一个出租帝国。***

我们在网上与朋友交谈，分享我们的观点，点击一些链接——在这样做的过程中，我们不知不觉地给了算法行为修正机器工具来操纵我们。

人工智能将我们独特的数据与对所有人都一样的进化认知偏差集结合起来。

> 由此产生的公式是用来对付我们的心理武器。我们不是为了这个而报名的。

对这种商业模式的明显的道德异议是，为了未知第三方的利益而控制人类的精神是危险的。它正在摧毁人类的尊严、自由意志和我们社会的基本结构。

# 一条出路

人性和文明话语的崩溃也不是邪恶的天才策划的。算法没有良心:发生的是附带损害。**副作用** —就像药物上的细则，只是意想不到和未披露的。

但与药物治疗不同， ***数码产品可以被重新设计和调整，以尽量减少技术的负面副作用。***

应该做些什么来解决这个问题？对于技术开发人员来说，这是一个商机: ***使用机器学习来开发一种过滤算法，为用户的利益和福祉优化所有输入的内容。*** 这可以通过给 AI 一个不同的优化结果来实现:

> 用户快乐而不是用户参与度。

然后，人工智能将调整你的函数中的参数，从效率和盈利能力以及最大化屏幕时间转向用户更可持续的使用。毕竟谁是最宝贵的资源。

*   **广告被屏蔽**——除非它们与用户的健康相关。
*   身份政治的回音室里的政治洗脑被来自不同领域的平衡新闻所取代。
*   **社交媒体供稿是为积极性而优化的，**不是嫉妒和比较。
*   但是等等——所有这些难道不会让用户对改进的数字饮食更加上瘾吗？也许吧。自然停止点将成为界面的一部分，提醒人们休息一下，关注现实世界。

用户会更开心，不再紧张，更加信任平台，也许不会删除他们的脸书和 Instagram 账户。

## 世界也不会像今天这样疯狂。

[TechDetox 妈妈](https://www.techdetoxbox.com/mission-screentime-children-wellbeing/)在上瘾技术的[接收端发现了自己的孩子，决定反击。](https://www.techdetoxbox.com/screen-time-problems/)

她对技术和心理之间关系的研究试图揭示数字行为操纵是如何影响人类福祉的。

她在她的博客[TechDetoxBox.com](https://www.techdetoxbox.com/)上写道，要找到[解决方案](https://www.techdetoxbox.com/digital-wellbeing/)来保护我们的家庭，恢复我们的人性。