<html>
<head>
<title>Classifying spiders of Kentucky with fastAi. Part II</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用fastAi分类肯塔基蜘蛛。第二部分</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/building-a-state-of-the-art-fastai-app-to-identify-the-strange-and-dangerous-spiders-of-kentucky-50c0995b20c3?source=collection_archive---------30-----------------------#2021-08-01">https://medium.com/geekculture/building-a-state-of-the-art-fastai-app-to-identify-the-strange-and-dangerous-spiders-of-kentucky-50c0995b20c3?source=collection_archive---------30-----------------------#2021-08-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/57618ff8d4258fb670d928f6ba4a5ca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-FhMgBXsiUIx17Po5b4BMA.jpeg"/></div></div></figure><h1 id="1da0" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">第二部分:获取基线</h1><p id="65f6" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">当构建像我们目前正在构建的深度学习应用程序时，我们会想要构建一个基线模型。基线模型将在我们构建改进模型时用作比较模型。因此，我们的目标是建立这个简单的模型，并看看通过使用不同的迁移学习模型、添加层和调整我们的超参数，我们可以取得多大的改善。要查看代码，请点击这里查看github库<a class="ae km" href="https://github.com/chris-kehl/Spider_Classifier" rel="noopener ugc nofollow" target="_blank">。</a>如果你还没有收集数据文件，请查看<a class="ae km" rel="noopener" href="/@chris.kehl/building-a-state-of-the-art-fastai-app-to-identify-the-strange-and-dangerous-spiders-of-kentucky-4817183ef604">第一部分</a>。</p><p id="4c9d" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">当我们继续使用我们的模型时，我们开始实现我们的数据加载器。<strong class="jq hj">数据加载器</strong>是一个内置的PyTorch对象，它从数据集中抓取一批要素，并将数据转换为张量。通过将数据转换成张量，我们可以确保模型尽可能高效地工作。张量能够与GPU一起工作，并允许多个工人处理张量，从而允许并行加载多个批次。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="4448" class="lb ir hi kx b fi lc ld l le lf">class DataLoaders(GetAttr):<br/>def __init(self, *loaders): self.loaders = loaders<br/>def __getitem__(self, i): return self.loaders[i]<br/>train, valid = add_props(lambda i,self: self[i])</span></pre><p id="3ce2" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">现在，我们已经创建了数据加载器并运行了代码块，是时候将我们的数据拆分到我们的spider文件夹中，以允许80%的数据用于我们的训练集，20%的数据用于测试集。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="a729" class="lb ir hi kx b fi lc ld l le lf">spiders = DataBlock(<br/>    blocks=(ImageBlock, CategoryBlock),<br/>    get_items=get_image_files,<br/>    splitter=RandomSplitter(valid_pct=0.2, seed=42),<br/>    get_y=parent_label,<br/>    item_tfms=Resize(128))</span></pre><p id="911f" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">让我们为数据加载器设置路径，并用一行显示4个图像。我们将数据加载器命名为dls，并将其指向数据加载器可以访问图像的路径。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="f27f" class="lb ir hi kx b fi lc ld l le lf">dls = spiders.dataloaders(path)<br/>dls.valid.show_batch(max_n=4, nrows=1)</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lg"><img src="../Images/f3313d75a8733e934f63a67d24ef7d63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UU0S0LiJz2cxU9UqJVa8SQ.png"/></div></div></figure><p id="fca5" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">现在我们已经有了图像，并且对我们的数据加载器实际上正在工作有了很好的感觉，我们将希望确保我们的图像是正方形128 x 128。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="faa0" class="lb ir hi kx b fi lc ld l le lf"># resize the images to make them square (128)</span><span id="572a" class="lb ir hi kx b fi lh ld l le lf">spiders = spiders.new(item_tfms=Resize(128, ResizeMethod.Pad, pad_mode='zeros'))<br/>dls = spiders.dataloaders(path)<br/>dls.valid.show_batch(max_n=4, nrows=1)</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/d01de4aa3eedb0bf0b16b0682be62b97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XQFcA-mmUuPb6UYIshw50g.png"/></div></div></figure><p id="becb" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">我们注意到，当我们对图像进行方形处理时，我们为一些照片提供了一些填充。我们希望将数据扩充应用于训练集。这将允许我们的150个图像物种获得更多的数据来训练。我们从不同角度翻转数据，模糊照片，裁剪照片，并应用其他技术来帮助训练我们的数据。首先我们将裁剪我们的图像。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="9d28" class="lb ir hi kx b fi lc ld l le lf">spiders = spiders.new(item_tfms=RandomResizedCrop(128, min_scale=0.3))<br/>dls = spiders.dataloaders(path)<br/>dls.train.show_batch(max_n=8, nrows=2, unique=True)</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lj"><img src="../Images/6a9cf2256c1e0ce78374ada861a7cc5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M6n0BqmgRw5xMJmiZGAlOQ.png"/></div></div></figure><p id="76e0" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">呀，你可以看到出现的不是一只蜘蛛，而是一个棕色的咬伤。一会儿我们将看看如何清理我们的数据。当然，为了正确识别我们的物种，我们不想添加这些照片。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="27a0" class="lb ir hi kx b fi lc ld l le lf">spiders = spiders.new(item_tfms=RandomResizedCrop(224, min_scale=0.5),<br/>batch_tfms=aug_transforms())<br/>dls = spiders.dataloaders(path)</span></pre><p id="8602" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">上面的代码应用了我们在上面的照片中讨论的数据扩充。我们的下一步是训练模型，我们可以看到我们的初始基线在哪里。我们要训练5个纪元。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="66cf" class="lb ir hi kx b fi lc ld l le lf">learn = cnn_learner(dls, models.vgg19_bn, metrics=error_rate)<br/>learn.fine_tune(5)<br/>warnings.filterwarnings('ignore')</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/b88dc2d07adeb6158ae91846848b3c06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sFL7xuIHb0j2j9dRd3uLEQ.png"/></div></div></figure><p id="3e14" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">因此，我们看到错误率为0.482。目前情况不太好。让我们来看一个混淆矩阵，看看我们的图像是如何表现的。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="fc37" class="lb ir hi kx b fi lc ld l le lf"># implement a confusion matrix<br/>interp = ClassificationInterpretation.from_learner(learn)<br/>interp.plot_confusion_matrix(figsize=(12,12), dpi=60)</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/0da58b3e1b6e29969ce79d0b416b0310.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KMGnSXhwZI10623NNHIIKw.png"/></div></div></figure><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="7783" class="lb ir hi kx b fi lc ld l le lf">interp.most_confused(min_val=8)</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lm"><img src="../Images/c9feeb4adddfd820aeb5e3243a877bc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PpjGTFIbUzpdoAx31O703Q.png"/></div></div></figure><p id="4101" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">这是我们在前面的代码中所做的。我们对我们的模型进行了5个时期的训练，并查看了我们的错误率。然后，我们绘制了一个混淆矩阵，以查看我们的模型识别哪些图像有问题。然后我们打印出哪些图像错过了他们的目标识别8。因此，如果我们的模型错过了8个或更多的图像识别，我们会在上面的打印结果中列出。从这一点，我们可以看到我们的黑寡妇北部和黑寡妇南部是我们最大的错误。现在我不是蜘蛛专家，所以我该如何解决这个问题。我推荐谷歌，我们用谷歌搜索两种蜘蛛的区别。FastAi实现了一个名为imageClassifierCleaner()的工具。这使我们能够检查每一个训练和测试图像，并选择哪些图像要删除或放入另一个类别。我承认，在Google Colab上这么做很费时间，过一会儿你的记忆可能会停滞不前。我的建议是仔细检查这些图片，然后用下面的清洁剂清理它们，或者一张一张地检查每张图片。我去试试吸尘器。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="48be" class="lb ir hi kx b fi lc ld l le lf"># Add the cleaner to clean up images that don't belong<br/>cleaner = ImageClassifierCleaner(learn)<br/>cleaner</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/bb5f1ca4914b0e78f9bcf45268b6f3e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f2_x9aCrM93VBXu-MncOPA.png"/></div></div></figure><p id="57d7" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">好吧，我知道棕色隐士长什么样了。我用吸尘器清除了狼蛛的照片和咬伤的照片。我会谷歌一下南北黑寡妇的区别，看看我是否能通过清理我们的图像来改善我们的基线。我在谷歌上搜索了北方和南方黑寡妇的区别，北方黑寡妇有明显的沙漏图案，但已经破碎，而南方黑寡妇的沙漏是完整的。所以，我会用清洁剂，看看能不能发现一些出入。如果我发现任何不一致的地方，我不想删除它们，我只会把它们移到适当的类别。很难说，但我确实清理了一些不属于我的照片。试图修复黑暗捕鱼蜘蛛和条纹捕鱼蜘蛛可能是一个挑战。谷歌照片对我来说看起来是一样的，所以我想只要它是一个钓鱼蜘蛛，我们就会有这个想法。对于虎尾兰和虎尾兰也是一样，我们需要一个主题专家(SME)来协助这项任务。这是一个很好的观点，要建立严肃的模型，你需要确保你与SME合作，以确保你对正确的图像进行分类。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="2c2a" class="lb ir hi kx b fi lc ld l le lf">for idx in cleaner.delete():<br/>cleaner.fns[idx].unlink()</span></pre><p id="204a" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">上面的代码是在我们完成清洁器之后运行的。我们现在将再次运行我们的模型，看看我们是否有任何改进。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="7c80" class="lb ir hi kx b fi lc ld l le lf">learn = cnn_learner(dls, models.vgg19_bn, metrics=error_rate)<br/>learn.fine_tune(5)<br/>warnings.filterwarnings('ignore')</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/d897403f0f471d00b13c37627850e187.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HH4mRsiFzZsv_7-IB8TrzQ.png"/></div></div></figure><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/161f750e50c8c50486ad7d751b9a103c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DUg-XKfi8_aW6zXCn4g30g.png"/></div></div></figure><p id="4cb8" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">这个模型并没有让我们做得更好。让我们用resnet34代替vgg_19来尝试一下我们的迁移学习。我们正在寻找最低的错误率。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="40e7" class="lb ir hi kx b fi lc ld l le lf">learn = cnn_learner(dls, resnet34, metrics=error_rate)<br/>learn.fine_tune(2)</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/a4546f156b3672e72fccb2f610f715d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-jrU06pZypPfqiljaMuPOQ.png"/></div></div></figure><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="6881" class="lb ir hi kx b fi lc ld l le lf">learn.recorder.plot_loss()</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/2c0e41cd02efff7072091239e572da29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*Dw72-y0dZ1u5XQgWAhvR2A.png"/></div></figure><p id="a986" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">我们的resnet34型号性能大致相同。我们将声明我们已经完成了基线模型。我们的目标是提高模型的基线分数，误差率为0.484。我们将在第三部分改进我们的模型。</p><p id="dd64" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">@ckehl_chris</p><p id="04f0" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">@linked-in_ <a class="ae km" href="https://www.linkedin.com/in/chris-kehl-552017109/" rel="noopener ugc nofollow" target="_blank"> chriskehl </a></p><p id="5ac6" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">感谢预览，我希望你会喜欢所有即将到来的职位。</p><p id="ddf4" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">参考:</p><p id="1986" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">蜘蛛图片:<a class="ae km" href="https://www.pexels.com/search/spider/" rel="noopener ugc nofollow" target="_blank">https://www.pexels.com/search/spider/</a></p><p id="7a9d" class="pw-post-body-paragraph jo jp hi jq b jr kn jt ju jv ko jx jy jz kp kb kc kd kq kf kg kh kr kj kk kl hb bi translated">霍华德，杰里米；古格，西尔万。利用fastai和PyTorch为编码人员提供深度学习。奥莱利媒体。Kindle版。</p></div></div>    
</body>
</html>