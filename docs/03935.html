<html>
<head>
<title>Getting started with Pytorch: 5 Interesting functions for Tensor operations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pytorch入门:张量运算的5个有趣函数</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/getting-started-with-pytorch-5-interesting-functions-for-tensor-operations-1cb3f6d99958?source=collection_archive---------45-----------------------#2021-06-17">https://medium.com/geekculture/getting-started-with-pytorch-5-interesting-functions-for-tensor-operations-1cb3f6d99958?source=collection_archive---------45-----------------------#2021-06-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/fc16b8232b6f558b37d89dcb1aff7263.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3G90f7g9YfnJl0Haif-s5w.png"/></div></div></figure><p id="2544" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Pytorch是由脸书人工智能研究实验室开发的开源机器学习库，用于深度学习、自然语言处理和计算机视觉等各种应用。</p><p id="e051" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">基于PyTorch的深度学习软件包括Tesla Autopilot、优步的Pyro、HuggingFace的Transformers、PyTorch Lightning和Catalyst。</p><p id="8a9a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">PyTorch有两个高级特性:</p><ol class=""><li id="62b8" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">张量计算(类似于NumPy ),由图形处理单元(GPU)提供大量加速</li><li id="51fb" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">用于建立和训练深度神经网络的自动微分。</li></ol><p id="df48" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">PyTorch Tensor在概念上类似于NumPy，但具有GPU功能来加速数值运算。此外，Pytorch还提供了自动计算导数的附加功能，这是使用深度学习算法时必须具备的。</p><p id="098c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇文章中，我们将研究5个简单的火炬。张量函数，它们的应用和它们的局限性。</p><ul class=""><li id="bf74" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn kc ju jv jw bi translated"><strong class="is hj">创作</strong>:火炬。常态</li><li id="1ffa" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated"><strong class="is hj">转换</strong>:火炬。FROM_NUMPY</li><li id="ff04" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated"><strong class="is hj">劈</strong>:火炬。使分离</li><li id="a306" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated"><strong class="is hj">变径</strong>:火炬。ARGMAX</li><li id="3254" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated"><strong class="is hj">数学</strong>:火炬。马特穆尔</li></ul><p id="59b8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在开始之前，让我们安装并导入PyTorch。</p></div><div class="ab cl kd ke gp kf" role="separator"><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki"/></div><div class="hb hc hd he hf"><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><h1 id="8fda" class="kq kr hi bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">1.火炬。常态</h1><p id="e474" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">这个函数返回从独立的正态分布中抽取的随机数的张量，这些分布的平均值和标准偏差是给定的。</p><p id="7111" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">参数:</strong></p><ul class=""><li id="364e" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn kc ju jv jw bi translated">均值(张量/浮点):每个元素均值的张量/所有分布的均值</li><li id="1b0e" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">std(Tensor/float):每个元素标准偏差的张量/所有分布的标准偏差</li><li id="f707" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">大小(整数..):定义输出张量形状的整数序列。</li><li id="58e1" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">发电机(火炬。发生器，可选)—用于采样的伪随机数发生器</li><li id="4185" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">out(张量，可选)-输出张量。</li></ul><p id="81d6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">mean和std的形状不需要匹配，但是每个张量的元素总数需要相同。</p><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="e201" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面使用参数均值的例子中，我们给出了一个预定义的张量，其均值将决定输出张量正态分布的均值。</p><p id="568f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用参数std，我们给出了一个预定义的张量，其标准偏差将遵循输出张量的正态分布。</p><p id="29a3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建了一个正态分布张量，其平均值与张量(100)相同。,110.)并且具有从张量(1，0，-0.1)导出的标准偏差</p><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="9c58" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的例子中，我们得到一个大小为2行4列的正态分布张量，平均值为50，标准差为5。</p><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="966e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">均值=0的正态函数仅适用于大于0.0的标准差，因此它不会采用负标准差。</p><p id="4bbe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">总结</strong></p><p id="92ab" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">torch的正态函数可用于各种统计分析，其中需要正态分布张量来测试各种假设。</p><h1 id="3371" class="kq kr hi bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">2.火炬。FROM_NUMPY</h1><p id="52a3" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">Torch.from_numpy是用于将numpy数组转换为张量的函数。当使用机器或深度学习算法时，我们大多使用Numpy数组格式的数据，这就是为什么在使用真实数据集时，该函数非常重要。</p><p id="a262" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要注意的是，由于返回的张量和ndarray共享相同的存储器，对张量的任何修改都将反映在ndarray中，反之亦然。返回的张量不可调整大小。</p><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="ff87" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的例子中，我们获取了一个int64数据类型的大小为(2，3)的数组，并使用torch.from_numpy函数将其更改为张量。</p><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="16f4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的例子中，我们创建了两个NumPy数组，分别表示两种产品的价格和相应价格产生的销售额，然后将它们都转换成两个张量。</p><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="1bfc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">From_numpy目前接受dtypes为<strong class="is hj"> numpy.float64、numpy.float32、numpy.float16、numpy.complex64、numpy.complex128、numpy.int64、numpy.int32、numpy.int16、numpy.int8、numpy.uint8和numpy.bool </strong>的ndarray。因此，任何其他数据类型(如string)都不可能被转换为tensor，如上面的例子所示。</p><p id="8d09" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">总结</strong></p><p id="1229" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在数据科学项目中，NumPy数组是数据类型的首选，这个函数非常有用。</p><h1 id="3061" class="kq kr hi bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">3.火炬。使分离</h1><p id="ebb4" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">将张量分割成块，每个块是原始张量的一个视图。</p><p id="f4d2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">参数:</strong></p><ul class=""><li id="36ac" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn kc ju jv jw bi translated">张量(Tensor)-要分割的张量。</li><li id="5633" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">split _ size _ or _ sections(int)/(list(int))—单个块的大小或每个块的大小列表</li><li id="8549" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">dim(int)-沿其分割张量的维度。</li></ul><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="28d8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果split_size_or_sections是整数类型，那么张量将被分割成相等大小的块(如果可能的话),并且如果沿着给定维度dim的张量大小不能被split_size整除，则最后一个块将更小。</p><p id="e4c0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的例子中，我们使用值为2的split_size_or_section，即每个块的大小为2，将我们的原始(5，2)张量分成3个大小为2的张量块，除了最后一个，由于缺少相等数量的元素，它只占用1个数组。</p><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="66a2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果split_size_or_sections是一个列表，那么张量将根据split_size_or_sections拆分成len(split_size_or_sections)个大小为dim的块。</p><p id="cab0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的例子中，我们将形状(3，4)的张量分成大小为2 (len[1，2])的张量块，第一个块的大小为1，第二个块的大小为2。</p><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="a680" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上述示例给出了一个错误，因为我们试图将形状3行元素和4列元素的张量分别拆分为块大小为1和3的2个张量，这是不可能的，因为我们只有3个元素。</p><p id="53b6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">总结</strong></p><p id="9ee6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当处理需要在张量的不同部分执行不同功能的函数和模块时，Torch.split是一个非常有用的函数。</p><h1 id="0f15" class="kq kr hi bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">4.火炬。ARGMAX</h1><p id="f0f7" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">返回输入张量中所有元素的最大值的索引。</p><p id="603b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">参数:</strong></p><ul class=""><li id="b079" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn kc ju jv jw bi translated">输入(张量)-输入张量。</li><li id="2744" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">dim(int)-要减少的尺寸。如果没有，则返回展平输入的argmax。</li><li id="af59" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">keep dim(bool)-输出张量是否保留dim。如果dim=None，则忽略。</li></ul><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="5ad0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的例子中，我们创建了一个shape (3，3)的随机张量，然后使用armax()找到具有最大值的元素的索引值。</p><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="6286" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的例子中，我们创建了一个3d张量，然后找到了张量中最大元素的索引以及每个维度/元素。</p><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="cb2f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的例子中，我们使用torch的randn函数创建了一个随机的2维张量，然后我们试图获得3维中最大元素的索引位置，这是不可能的，这就是为什么我们得到了“尺寸超出范围错误”</p><p id="ba39" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">总结</strong></p><p id="11bf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">argmax函数是一个非常有用的函数，我们可以在处理大型张量数据，需要执行函数或者只需要元素最大值的索引位置时使用。</p><h1 id="9050" class="kq kr hi bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">5 .火炬。马特穆尔</h1><p id="53eb" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">它的功能是执行2个张量相乘的数学运算，从而给出2个张量的矩阵乘积的输出。</p><p id="0f34" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">参数:</strong></p><ul class=""><li id="7cf9" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn kc ju jv jw bi translated">输入(张量)-要相乘的第一个张量</li><li id="e51d" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">other(Tensor)-要相乘的第二个张量。</li></ul><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="b04c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上述示例中，我们创建了2个1维张量，每个张量有3个元素/列，然后使用matmul函数计算其乘积，并将其存储在1维张量t3中。</p><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="138b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的例子中，我们创建了形状为[(3，2)]的1个张量矩阵t1和形状为[(2)]的另一个张量矩阵t2，因此t1和t2的乘积产生了形状为[(3)]的第三个张量t3。</p><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="52db" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的例子中，我们得到了一个错误，因为我们试图用一个形状矩阵[(1，3)]乘以一个形状矩阵[(2，2)]，这是不可能的。</p><p id="bd8a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">总结</strong></p><p id="66a3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">根据张量的维数，我们可以在不同的用例中使用matmul函数，如下所示:</p><ul class=""><li id="6e9d" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn kc ju jv jw bi translated">如果两个张量都是一维的，则返回点积(标量)。</li><li id="4900" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">如果两个参数都是二维的，则返回矩阵-矩阵乘积。</li><li id="c6eb" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">如果第一个参数是一维的，而第二个参数是二维的，则为了矩阵乘法的目的，会在它的维数前加上1。矩阵相乘后，移除预先考虑的维度。</li><li id="560b" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">如果第一个参数是二维的，第二个参数是一维的，则返回矩阵矢量积。</li><li id="5ec5" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">如果两个参数都至少是一维的，并且至少有一个参数是N维的(其中N &gt; 2)，则返回成批矩阵乘法。如果第一个参数是一维的，则在它的维度前面加上1，以便进行批量矩阵乘法，并在之后移除。如果第二个参数是一维的，则为了批量矩阵乘法的目的，会将1附加到它的维度上，并在之后移除。广播非矩阵(即批量)维度(因此必须是可广播的)。例如，如果输入是(j×1×n×n)张量，另一个是(k×n×n)张量，则out将是(j×k×n×n)张量。</li></ul><h1 id="1efc" class="kq kr hi bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">结论</h1><p id="5165" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">在这本笔记本中，我们看了5个有趣的随机选择的张量。可用于创建、转换、切片、归约和数学运算的Torch函数。每个函数都用工作和错误实例来说明。有关所有可用函数的完整列表，请参见tensors上的PyTorch官方文档。</p><p id="aefc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Jupyter笔记本链接:<a class="ae lt" href="https://jovian.ai/rupshakr/01-tensor-operations" rel="noopener ugc nofollow" target="_blank">https://jovian.ai/rupshakr/01-tensor-operations</a></p><h1 id="8897" class="kq kr hi bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">参考链接</h1><p id="29b3" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">提供你的参考资料和其他关于张量的有趣文章的链接</p><ul class=""><li id="4d99" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn kc ju jv jw bi translated">张量运算的官方文档:【https://pytorch.org/docs/stable/torch.html T2】</li><li id="682f" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">用PyTorch深度学习:Zero to GANs by jovian . ai:<a class="ae lt" href="https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans" rel="noopener ugc nofollow" target="_blank">https://jovian . ai/learn/deep-Learning-with-py torch-Zero to GANs</a></li><li id="beca" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn kc ju jv jw bi translated">py torch:<a class="ae lt" href="https://jovian.ai/outlink?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPyTorch" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/PyTorch</a></li></ul></div></div>    
</body>
</html>