<html>
<head>
<title>K-Means Clustering Simplified</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简化的k-均值聚类</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/k-means-clustering-simplified-f49cfb34388f?source=collection_archive---------43-----------------------#2021-06-28">https://medium.com/geekculture/k-means-clustering-simplified-f49cfb34388f?source=collection_archive---------43-----------------------#2021-06-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/4ddbc48be727359c86f51605c63ea7e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jd3Vld80IvpU21ZSKhDCkw.png"/></div></div></figure><p id="c9a8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是机器学习中非常常见的技术，你只需尝试获取一堆数据，并根据数据本身的属性找到有趣的聚类。</p><p id="04c6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">听起来很奇特，但实际上很简单。我们在K均值聚类中所做的就是试图<strong class="is hj">将我们的数据分成K个组</strong>，这就是K的来源:它是你试图将你的数据分成多少个不同的组。</p><h2 id="3b05" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">定义</h2><p id="72d2" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">一种无人监督的学习技术，你有<em class="ko">一堆东西，你想把它们</em>组合成不同的<strong class="is hj">簇</strong>。也许是电影类型或者人口统计学；仅仅基于数据本身的属性。</p><h2 id="ffba" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">说明</h2><p id="5a65" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">K-mean算法通过寻找K个质心来创建聚类。所以基本上，一个给定的数据点属于哪一组是由散点图中它最接近的质心点来定义的。</p><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kp"><img src="../Images/a0a971ba7588def7e610280aa03d3eed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G-xUr9GyZon49JiHA8c45A.png"/></div></div></figure><p id="29d8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以看到，这里显示的是一个K均值聚类的示例，其中的<strong class="is hj"> K为<em class="ko">三(3) </em> </strong>，正方形代表散点图中的数据点。</p><p id="2d17" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="ko">圆圈</em> </strong> <em class="ko">代表K-means聚类算法得出的质心</em>，每个点根据其最接近的质心被分配一个聚类。</p><p id="be29" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以基本上，一个给定的数据点属于哪一组是由散点图中它最接近的质心点来定义的。</p><h2 id="38df" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">k均值算法步骤</h2><ol class=""><li id="0203" class="ku kv hi is b it kj ix kk jb kw jf kx jj ky jn kz la lb lc bi translated">选择聚类数k。</li><li id="df17" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">从数据中随机选择k个点作为质心。</li><li id="50d5" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">将所有点分配给最近的聚类质心。</li><li id="3a6c" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">重新计算了新形成的星团的质心。</li><li id="ea60" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">如果质心位置改变，重复步骤3和4。</li></ol><h2 id="25b8" class="jo jp hi bd jq jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki bi translated">何时使用K均值聚类</h2><ul class=""><li id="a66a" class="ku kv hi is b it kj ix kk jb kw jf kx jj ky jn li la lb lc bi translated">当数据集是不同的或者以线性方式彼此分离时。</li><li id="9dd2" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn li la lb lc bi translated">当聚类中心的数量由于数据中明确定义的类型列表而被指定时。</li></ul><h1 id="38bd" class="lj jp hi bd jq lk ll lm ju ln lo lp jy lq lr ls kb lt lu lv ke lw lx ly kh lz bi translated">k均值优势:</h1><ol class=""><li id="cf21" class="ku kv hi is b it kj ix kk jb kw jf kx jj ky jn kz la lb lc bi translated"><strong class="is hj">简单</strong>:很容易实现 k-means，从复杂的数据集中识别未知的数据组。</li><li id="da17" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated"><strong class="is hj">灵活</strong>:如果有任何问题，调整集群段将允许在算法上容易地发生变化。</li><li id="a1b0" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated"><strong class="is hj">准确性</strong> : K-means分析提高了聚类的准确性，并确保关于特定问题域的信息是可用的。</li><li id="2a79" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated"><strong class="is hj">适用于大型数据集</strong> : K-means适用于大量数据集，其计算速度比小型数据集快得多。</li><li id="70cc" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated"><strong class="is hj">时间复杂度</strong> : K-means分段在数据对象数量上是线性的，因此增加了执行时间。</li><li id="1660" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated"><strong class="is hj">更少的计算成本</strong>:与使用其他聚类方法相比，k-means聚类技术是快速有效的。</li></ol><h1 id="5215" class="lj jp hi bd jq lk ll lm ju ln lo lp jy lq lr ls kb lt lu lv ke lw lx ly kh lz bi translated">k-均值缺点:</h1><ol class=""><li id="354a" class="ku kv hi is b it kj ix kk jb kw jf kx jj ky jn kz la lb lc bi translated"><strong class="is hj">用户定义的聚类</strong> : K-means不允许开发一组最优的聚类，为了获得有效的结果，您应该先决定聚类。</li><li id="24bd" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated"><strong class="is hj">值的顺序影响结果</strong>:构建算法时数据的排序方式影响数据集的最终结果。</li><li id="ed95" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated"><strong class="is hj">处理大数据集时崩溃</strong>:创建树状图技术会因为大量的计算负载而导致计算机崩溃。</li><li id="e85f" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated"><strong class="is hj">限于数值型数据</strong> : K-means算法只能在数值型数据中执行。</li><li id="781e" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated"><strong class="is hj">假设球形聚类</strong> : K-means聚类技术假设我们处理的是球形聚类，每个聚类都有相同数量的观测值。</li><li id="3c29" class="ku kv hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated"><strong class="is hj">预测问题</strong>:很难预测k值或聚类数。也很难比较产生的簇的质量。</li></ol><h1 id="271e" class="lj jp hi bd jq lk ll lm ju ln lo lp jy lq lr ls kb lt lu lv ke lw lx ly kh lz bi translated">Python中K均值的示例</h1><p id="f458" class="pw-post-body-paragraph iq ir hi is b it kj iv iw ix kk iz ja jb kl jd je jf km jh ji jj kn jl jm jn hb bi translated">让我们创建一些随机数据来尝试和集群。我们在python中输入这个小的创建集群数据函数，它从一个一致的随机种子开始，所以你每次都会得到相同的结果。</p><pre class="kq kr ks kt fd ma mb mc md aw me bi"><span id="b617" class="jo jp hi mb b fi mf mg l mh mi">from numpy import random, array</span><span id="5989" class="jo jp hi mb b fi mj mg l mh mi">#Create fake income/age clusters for N people in k clusters</span><span id="f953" class="jo jp hi mb b fi mj mg l mh mi">def createClusteredData(N, k):<br/>    random.seed(10)<br/>    pointsPerCluster = float(N)/k</span><span id="df65" class="jo jp hi mb b fi mj mg l mh mi">    X = []</span><span id="3b09" class="jo jp hi mb b fi mj mg l mh mi">    for i in range (k):<br/>        incomeCentroid = random.uniform(20000.0, 200000.0)<br/>        ageCentroid = random.uniform(20.0, 70.0)</span><span id="e687" class="jo jp hi mb b fi mj mg l mh mi">        for j in range(int(pointsPerCluster)):<br/>            X.append([random.normal(incomeCentroid, 10000.0),random.normal(ageCentroid, 2.0)])</span><span id="c5d6" class="jo jp hi mb b fi mj mg l mh mi"><br/>    X = array(X)</span><span id="9462" class="jo jp hi mb b fi mj mg l mh mi">    return X</span></pre><p id="eafc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它需要N，我想在K个集群中创建N个人的集群，所以它先计算出每个集群有多少个点，然后建立这个列表X，从空开始。</p><blockquote class="mk ml mm"><p id="8b58" class="iq ir ko is b it iu iv iw ix iy iz ja mn jc jd je mo jg jh ji mp jk jl jm jn hb bi translated">我们将使用k-means在无监督学习中重新发现这些聚类:</p></blockquote><pre class="kq kr ks kt fd ma mb mc md aw me bi"><span id="a5b0" class="jo jp hi mb b fi mf mg l mh mi">%matplotlib inline</span><span id="f378" class="jo jp hi mb b fi mj mg l mh mi">from sklearn.cluster import KMeans<br/>import matplotlib.pyplot as plt<br/>from sklearn.preprocessing import scale<br/>from numpy import random, float<br/></span><span id="cdeb" class="jo jp hi mb b fi mj mg l mh mi">data = createClusteredData(100, 5)<br/>model = KMeans(n_clusters=5)<br/></span><span id="d7c5" class="jo jp hi mb b fi mj mg l mh mi"># Note I'm scaling the data to normalize it! Important for good results.</span><span id="d215" class="jo jp hi mb b fi mj mg l mh mi">model = model.fit(scale(data))<br/></span><span id="c97a" class="jo jp hi mb b fi mj mg l mh mi"># We can look at the clusters each data point was assigned to</span><span id="b264" class="jo jp hi mb b fi mj mg l mh mi">print(model.labels_)<br/></span><span id="6ab4" class="jo jp hi mb b fi mj mg l mh mi"># And we'll visualize it:</span><span id="c0db" class="jo jp hi mb b fi mj mg l mh mi">plt.figure(figsize=(8, 6))<br/>plt.scatter(data[:,0], data[:,1], c=model.labels_.astype(float))<br/>plt.show()</span></pre><p id="f694" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="ko">输出:</em></p><pre class="kq kr ks kt fd ma mb mc md aw me bi"><span id="a07f" class="jo jp hi mb b fi mf mg l mh mi">[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3  3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]</span></pre><figure class="kq kr ks kt fd ij er es paragraph-image"><div class="er es mq"><img src="../Images/295b78b3a239da0d5a26dd9c9cdef029.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*5sn9-Vs-QQZYOUmye0Tmyg.png"/></div></figure><p id="901d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这就是K均值聚类的全部内容，就是这么简单。你可以从集群中学习<em class="ko">sci kit-learn K-Means</em>。</p><p id="a344" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在此之前，确保您<em class="ko">缩放并标准化数据</em>。你要确保你使用的K-Means的东西是可以互相比较的，尺度函数会帮你做到这一点。这就是K均值聚类的主要内容。</p><p id="dce0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，如果您有未分类的数据，并且您事先确实没有正确的答案，那么尝试自然地找到您的数据的有趣分组是一个好方法，这可能会让您对这些数据有所了解。</p></div><div class="ab cl mr ms gp mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="hb hc hd he hf"><p id="52ae" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">感谢你阅读这篇文章，我希望你喜欢并且今天学到了一些新的东西。如果您有任何问题，请随时通过我的博客联系我，我将非常乐意帮助您。</p><p id="62fb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">保持安全和愉快的学习！</p></div></div>    
</body>
</html>