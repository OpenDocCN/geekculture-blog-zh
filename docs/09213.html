<html>
<head>
<title>Diabetes Prediction using Machine Learning — Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习Python进行糖尿病预测</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/diabetes-prediction-using-machine-learning-python-23fc98125d8?source=collection_archive---------3-----------------------#2021-12-01">https://medium.com/geekculture/diabetes-prediction-using-machine-learning-python-23fc98125d8?source=collection_archive---------3-----------------------#2021-12-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/cc6538d7e8ab33356508034e655abb0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J5kpt-BBZdv5YAFzziHUfg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Photo by <a class="ae iu" href="https://unsplash.com/@cdc?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">CDC</a> on <a class="ae iu" href="https://unsplash.com/s/photos/doctor-with-patient?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="1c53" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated"><strong class="ak">表格内容</strong></h1><ol class=""><li id="80a0" class="jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</li><li id="f2cf" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">安装库</li><li id="7ed6" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">导入数据</li><li id="4055" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">缺失值分析</li><li id="7920" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">探索性数据分析</li><li id="c15e" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">特征工程</li><li id="5929" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">建模</li><li id="db28" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">预言；预测；预告</li><li id="851a" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">结论</li></ol></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><h1 id="b6d6" class="iv iw hi bd ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js bi translated"><strong class="ak">简介</strong></h1><p id="a1cd" class="pw-post-body-paragraph lc ld hi jv b jw jx le lf jy jz lg lh ka li lj lk kc ll lm ln ke lo lp lq kg hb bi translated">糖尿病是一种影响身体将食物转化为能量的健康状况。你吃的大部分食物被分解成糖(也称为葡萄糖)并释放到你的血液中。当你的血糖升高时，它会向你的胰腺发出释放胰岛素的信号。</p><p id="3ee8" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">如果没有持续、仔细的管理，糖尿病会导致血液中糖分的积累，从而增加危险并发症的风险，包括中风和心脏病。所以我决定用Python来预测机器学习。</p><h2 id="bcc9" class="lw iw hi bd ix lx ly lz jb ma mb mc jf ka md me jj kc mf mg jn ke mh mi jr mj bi translated"><strong class="ak">目标</strong></h2><ol class=""><li id="181a" class="jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">预测该人是否是糖尿病患者</li><li id="2ffe" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">找到糖尿病最有代表性的特征</li><li id="f269" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">尝试不同的分类方法，找到最高的准确性</li></ol></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><h1 id="24d2" class="iv iw hi bd ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js bi translated">安装库</h1><p id="f352" class="pw-post-body-paragraph lc ld hi jv b jw jx le lf jy jz lg lh ka li lj lk kc ll lm ln ke lo lp lq kg hb bi translated">在第一步中，我已经导入了python中用于机器学习的最常见的库，如Pandas、Seaborn、Matplitlib等。</p><p id="eab3" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">我使用Python是因为它是我用过的非常灵活和有效的编程语言。我也在软件开发领域使用Python。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="86ca" class="lw iw hi mp b fi mt mu l mv mw"># Import libraries<br/>import numpy as np <em class="mx"># linear algebra</em><br/>import pandas as pd <em class="mx"># data processing, CSV file I/O (e.g. pd.read_csv)</em><br/>import seaborn as sns <em class="mx"># for data visualization</em><br/>import matplotlib.pyplot as plt <em class="mx"># to plot charts</em><br/>from collections import Counter<br/>import os<br/><br/><em class="mx"># Modeling Libraries</em><br/>from sklearn.preprocessing import QuantileTransformer<br/>from sklearn.metrics import confusion_matrix, accuracy_score, precision_score<br/>from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.svm import SVC<br/>from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, train_test_split</span></pre><p id="322b" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">sklearn库非常通用和方便，并且服务于真实世界的目的。它提供了广泛的ML算法和模型。</p><blockquote class="my mz na"><p id="92f3" class="lc ld mx jv b jw lr le lf jy ls lg lh nb lt lj lk nc lu lm ln nd lv lp lq kg hb bi translated"><a class="ae iu" href="https://www.kaggle.com/gopalj/diabetes-prediction-using-python" rel="noopener ugc nofollow" target="_blank">阅读完整笔记本<strong class="jv hj">糖尿病预测使用Python </strong>上Kaggle </a></p></blockquote></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><h1 id="5ece" class="iv iw hi bd ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js bi translated">导入数据</h1><p id="64cf" class="pw-post-body-paragraph lc ld hi jv b jw jx le lf jy jz lg lh ka li lj lk kc ll lm ln ke lo lp lq kg hb bi translated">在这个项目中，我使用了来自<a class="ae iu" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的<a class="ae iu" href="https://www.kaggle.com/gopalj/diabetes-prediction-using-python/data" rel="noopener ugc nofollow" target="_blank">皮马印第安人糖尿病数据库</a>。这个数据集最初来自国家糖尿病、消化和肾脏疾病研究所。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="5d64" class="lw iw hi mp b fi mt mu l mv mw"># Import dataset<br/>df = pd.read_csv("../input/pima-indians-diabetes-database/diabetes.csv")</span><span id="fadd" class="lw iw hi mp b fi ne mu l mv mw"><em class="mx"># Get familier with dataset structure</em><br/>df.info()</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nf"><img src="../Images/648034d200267447c660b32a5b72d269.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_-gZJMtGlchXehcNja7RSA.png"/></div></div></figure><p id="2f9e" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">除身体质量指数和糖尿病外，所有列都是整数。结果是包含1和0值的标签。1表示该人患有糖尿病，0表示该人没有糖尿病。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="8709" class="lw iw hi mp b fi mt mu l mv mw"><em class="mx"># Show top 5 rows</em><br/>df.head()</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ng"><img src="../Images/7a3e97d3e39555a7bee80588a07a01fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6_HRQnLn7ysB3QnMlJIrxA.png"/></div></div></figure></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><h1 id="0989" class="iv iw hi bd ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js bi translated">缺失值分析</h1><p id="620b" class="pw-post-body-paragraph lc ld hi jv b jw jx le lf jy jz lg lh ka li lj lk kc ll lm ln ke lo lp lq kg hb bi translated">接下来，我将清理数据集，这是数据科学的重要组成部分。在建模和预测过程中，缺失数据会导致错误的统计数据。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="8704" class="lw iw hi mp b fi mt mu l mv mw"><em class="mx"># Explore missing values</em></span><span id="bb4f" class="lw iw hi mp b fi ne mu l mv mw">df.isnull().sum()</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nh"><img src="../Images/c51e0c410b8a0b80c894e6ca9dfac1ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e1qJb4bf8UmBrZb0VECNBA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Missing Value Analysis</figcaption></figure><p id="20e9" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">我观察到数据集中没有缺失值，但是葡萄糖、血压、胰岛素、皮肤厚度等特征的值为0，这是不可能的。我们必须用特定列的平均值或中值替换0值。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="0759" class="lw iw hi mp b fi mt mu l mv mw">df['Glucose'] = df['Glucose'].replace(0, df['Glucose'].mean())</span><span id="18bd" class="lw iw hi mp b fi ne mu l mv mw"><em class="mx"># Correcting missing values in blood pressure</em><br/>df['BloodPressure'] = df['BloodPressure'].replace(0, df['BloodPressure'].mean()) # There are 35 records with 0 BloodPressure in dataset</span><span id="cdcd" class="lw iw hi mp b fi ne mu l mv mw"><em class="mx"># Correcting missing values in BMI</em><br/>df['BMI'] = df['BMI'].replace(0, df['BMI'].median())</span><span id="10a1" class="lw iw hi mp b fi ne mu l mv mw"><em class="mx"># Correct missing values in Insulin and SkinThickness</em><br/><br/>df['SkinThickness'] = df['SkinThickness'].replace(0, df['SkinThickness'].median())<br/>df['Insulin'] = df['Insulin'].replace(0, df['Insulin'].median())</span></pre><p id="a0eb" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">现在，让我们回顾一下数据集统计数据</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="d88f" class="lw iw hi mp b fi mt mu l mv mw"><em class="mx"># Review dataset statistics</em><br/>df.describe()</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ni"><img src="../Images/f3dea58bcf64f7a30ed40686b6ed0e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tgoPtuPt7rfguvUCC0yayg.png"/></div></div></figure><p id="b8f1" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">现在我有了一个干净的数据集，特征中没有丢失值，这很好。</p></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><h1 id="ddab" class="iv iw hi bd ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js bi translated">探索性数据分析</h1><p id="9430" class="pw-post-body-paragraph lc ld hi jv b jw jx le lf jy jz lg lh ka li lj lk kc ll lm ln ke lo lp lq kg hb bi translated">在这一步，我使用GUI展示了使用<a class="ae iu" href="https://seaborn.pydata.org/" rel="noopener ugc nofollow" target="_blank"> Seaborn </a>的分析。</p><p id="ef58" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated"><strong class="jv hj">相关性</strong></p><p id="00a5" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">相关性是<strong class="jv hj">一个或多个变量彼此相关</strong>。这也有助于在我开始建模之前发现特征的重要性并清理数据集</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="8009" class="lw iw hi mp b fi mt mu l mv mw">plt.figure(figsize=(13,10))<br/>sns.heatmap(df.corr(),annot=True, fmt = ".2f", cmap = "coolwarm")</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nj"><img src="../Images/955ed9c250bffbc6e588a2c47a289ca4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RPkiWhzEHnyZmo74.png"/></div></div></figure><p id="b714" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">根据观察，怀孕、血糖、身体质量指数和年龄等特征与结果更相关。在接下来的步骤中，我展示了这些特性的细节表现。</p><p id="caa5" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated"><strong class="jv hj">怀孕</strong></p><p id="04c5" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">患有糖尿病的女性能够并且确实拥有健康的妊娠和健康的婴儿。管理糖尿病有助于降低并发症的风险。未经治疗的糖尿病会增加妊娠并发症的风险，如高血压、抑郁症、早产、出生缺陷和流产。</p><blockquote class="my mz na"><p id="1f7f" class="lc ld mx jv b jw lr le lf jy ls lg lh nb lt lj lk nc lu lm ln nd lv lp lq kg hb bi translated"><a class="ae iu" href="https://www.marchofdimes.org/complications/preexisting-diabetes.aspx" rel="noopener ugc nofollow" target="_blank">https://www . marchofdimes . org/complications/pre existing-diabetes . aspx</a></p></blockquote><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="7f08" class="lw iw hi mp b fi mt mu l mv mw"><em class="mx"># Explore </em>Pregnancies<em class="mx"> vs Outcome</em></span><span id="52dd" class="lw iw hi mp b fi ne mu l mv mw">plt.figure(figsize=(13,6))<br/>g = sns.kdeplot(df["Pregnancies"][df["Outcome"] == 1], <br/>     color="Red", shade = True)<br/>g = sns.kdeplot(df["Pregnancies"][df["Outcome"] == 0], <br/>     ax =g, color="Green", shade= True)</span><span id="f979" class="lw iw hi mp b fi ne mu l mv mw">g.set_xlabel("Pregnancies")<br/>g.set_ylabel("Frequency")<br/>g.legend(["Positive","Negative"])</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nk"><img src="../Images/bed87fd298482609bb433f769f67f03b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*r6mvarEM2TJ1mqgm.png"/></div></div></figure><p id="a93d" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated"><strong class="jv hj">结果</strong></p><p id="b3e8" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">结果有1和0值，其中1表示此人有糖尿病，0表示此人没有糖尿病。这是我在数据集中的标签列。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="f250" class="lw iw hi mp b fi mt mu l mv mw">sns.countplot('Outcome', data = df)</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div class="er es nl"><img src="../Images/0a470929e5924cfda2344e233ebc0724.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/0*uV59w2-aSntjl-Ti.png"/></div></figure><p id="b5e9" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">这表明，在数据集中有更多的人没有患糖尿病，大约是65%，而35%的人患有糖尿病。</p><p id="7950" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated"><strong class="jv hj">葡萄糖</strong></p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="b92f" class="lw iw hi mp b fi mt mu l mv mw"># Explore Gluecose vs Outcome</span><span id="97e8" class="lw iw hi mp b fi ne mu l mv mw">plt.figure(figsize=(10,6))<br/>sns.violinplot(data=df, x="Outcome", y="Glucose",<br/>               split=True, inner="quart", linewidth=1)</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div class="er es nm"><img src="../Images/2459b919925ad87fa9a03e601c2d67c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/0*RhkikjXIoMPgI5qh.png"/></div></figure><p id="84bd" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">随着血糖水平的升高，患糖尿病的几率逐渐增加。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="0ad4" class="lw iw hi mp b fi mt mu l mv mw"><em class="mx"># Explore Glucose vs Outcome</em><br/><br/>plt.figure(figsize=(13,6))<br/>g = sns.kdeplot(df["Glucose"][df["Outcome"] == 1], color="Red", shade = True)<br/>g = sns.kdeplot(df["Glucose"][df["Outcome"] == 0], ax =g, color="Green", shade= True)<br/>g.set_xlabel("Glucose")<br/>g.set_ylabel("Frequency")<br/>g.legend(["Positive","Negative"])</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nk"><img src="../Images/b6566a375c89ded7381c39bd8780154b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iB3ZbW9uYvLbfkiB.png"/></div></div></figure><p id="ede5" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated"><strong class="jv hj">探索葡萄糖vs身体质量指数vs年龄</strong></p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="c7c1" class="lw iw hi mp b fi mt mu l mv mw"><em class="mx"># Glucose vs BMI vs Age</em><br/><br/>plt.figure(figsize=(20,10))<br/>sns.scatterplot(data=df, x="Glucose", y="BMI", hue="Age", size="Age")</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nn"><img src="../Images/b69f2d9f9be097eac535d0c542ed37ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-DuvzOOGUIuJm-Pf.png"/></div></div></figure><p id="ae4d" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">根据观察，特征中有一些异常值。我们需要去除特征工程中的异常值。</p></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><h1 id="7163" class="iv iw hi bd ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js bi translated">特征工程</h1><p id="440a" class="pw-post-body-paragraph lc ld hi jv b jw jx le lf jy jz lg lh ka li lj lk kc ll lm ln ke lo lp lq kg hb bi translated">到目前为止，我研究了数据集，做了缺失值校正和数据可视化。接下来，我开始了特征工程。特征工程对于提高机器学习算法的性能是有用的，并且通常被认为是应用机器学习。</p><p id="1446" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">选择重要的特征并减少特征集的大小使得机器学习和数据分析算法中的计算更加可行。</p><p id="acf4" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated"><strong class="jv hj">异常值检测</strong></p><p id="b892" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">在这一部分中，我删除了dataset中列出的所有记录。离群值会影响模型的准确性。我使用<em class="mx"> Tukey方法</em>用于异常值检测。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="b926" class="lw iw hi mp b fi mt mu l mv mw">def detect_outliers(df,n,features):<br/>    outlier_indices = []<br/>    <em class="mx">"""</em><br/><em class="mx">    Detect outliers from given list of features. It returns a list of the indices</em><br/><em class="mx">    according to the observations containing more than n outliers according</em><br/><em class="mx">    to the Tukey method</em><br/><em class="mx">    """</em><br/>    <em class="mx"># iterate over features(columns)</em><br/>    for col <strong class="mp hj">in</strong> features:<br/>        Q1 = np.percentile(df[col], 25)<br/>        Q3 = np.percentile(df[col],75)<br/>        IQR = Q3 - Q1<br/>        <br/>        <em class="mx"># outlier step</em><br/>        outlier_step = 1.5 * IQR<br/>        <br/>        <em class="mx"># Determine a list of indices of outliers for feature col</em><br/>        outlier_list_col = df[(df[col] &lt; Q1 - outlier_step) | (df[col] &gt; Q3 + outlier_step )].index<br/>        <br/>        <em class="mx"># append the found outlier indices for col to the list of outlier indices </em><br/>        outlier_indices.extend(outlier_list_col)<br/>        <br/>    <em class="mx"># select observations containing more than 2 outliers</em><br/>    outlier_indices = Counter(outlier_indices)<br/>    multiple_outliers = list( k for k, v <strong class="mp hj">in</strong> outlier_indices.items() if v &gt; n )<br/>    <br/>    return multiple_outliers   <br/><br/><em class="mx"># detect outliers from numeric features</em><br/>outliers_to_drop = detect_outliers(df, 2 ,["Pregnancies", 'Glucose', 'BloodPressure', 'BMI', 'DiabetesPedigreeFunction', 'SkinThickness', 'Insulin', 'Age'])</span></pre><p id="e16d" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">在这里，我发现了所有特征的异常值，如怀孕、血糖、血压、身体质量指数、糖尿病、胰岛素、皮肤厚度和年龄。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="f246" class="lw iw hi mp b fi mt mu l mv mw">df.drop(df.loc[outliers_to_drop].index, inplace=True)</span></pre><p id="768f" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">我现在已经成功地从数据集中移除了所有异常值。下一步是在训练和测试中分割数据集，并进行建模。</p></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><h1 id="5840" class="iv iw hi bd ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js bi translated">建模</h1><p id="3741" class="pw-post-body-paragraph lc ld hi jv b jw jx le lf jy jz lg lh ka li lj lk kc ll lm ln ke lo lp lq kg hb bi translated">在这一部分中，我尝试了不同的模型，并比较了每个模型的准确性。然后，我对具有高精度的模型执行超参数调整。</p><p id="950a" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">在分割数据集之前，我需要使用<code class="du no np nq mp b">sklearn.preprocessing</code>将数据转换成分位数。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="9359" class="lw iw hi mp b fi mt mu l mv mw"># Data Transformation<br/>q  = QuantileTransformer()<br/>X = q.fit_transform(df)<br/>transformedDF = q.transform(X)<br/>transformedDF = pd.DataFrame(X)<br/>transformedDF.columns =['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']</span><span id="b92c" class="lw iw hi mp b fi ne mu l mv mw"># Show top 5 rows<br/>transformedDF.head()</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nr"><img src="../Images/c747b6b34338b6328676e36f432ab49f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*thdR1QwMiWPCXlaAU6Ngng.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Data Transformation</figcaption></figure><p id="1d57" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated"><strong class="jv hj">数据拆分</strong></p><p id="380a" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">接下来，我在测试和训练数据集中拆分数据。训练数据集将用于模型训练和评估，测试数据集将用于预测。在预测测试数据之前，我对各种模型进行了交叉验证。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="ce4d" class="lw iw hi mp b fi mt mu l mv mw">features = df.drop(["Outcome"], axis=1)<br/>labels = df["Outcome"]</span><span id="5676" class="lw iw hi mp b fi ne mu l mv mw">x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.30, random_state=7)</span></pre><p id="5c9e" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">上面的代码将数据集分为训练(70%)和测试(30%)数据集。</p><p id="5ecd" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated"><strong class="jv hj">交叉验证模型</strong></p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="e8cb" class="lw iw hi mp b fi mt mu l mv mw">def evaluate_model(models):<br/>    <em class="mx">"""</em><br/><em class="mx">    Takes a list of models and returns chart of cross validation scores using mean accuracy</em><br/><em class="mx">    """</em><br/>    <br/>    <em class="mx"># Cross validate model with Kfold stratified cross val</em><br/>    kfold = StratifiedKFold(n_splits = 10)<br/>    <br/>    result = []<br/>    for model <strong class="mp hj">in</strong> models :<br/>        result.append(cross_val_score(estimator = model, X = x_train, y = y_train, scoring = "accuracy", cv = kfold, n_jobs=4))<br/><br/>    cv_means = []<br/>    cv_std = []<br/>    for cv_result <strong class="mp hj">in</strong> result:<br/>        cv_means.append(cv_result.mean())<br/>        cv_std.append(cv_result.std())<br/><br/>    result_df = pd.DataFrame({<br/>        "CrossValMeans":cv_means,<br/>        "CrossValerrors": cv_std,<br/>        "Models":[<br/>            "LogisticRegression",<br/>            "DecisionTreeClassifier",<br/>            "AdaBoostClassifier",<br/>            "SVC",<br/>            "RandomForestClassifier",<br/>            "GradientBoostingClassifier",<br/>            "KNeighborsClassifier"<br/>        ]<br/>    })<br/><br/>    <em class="mx"># Generate chart</em><br/>    bar = sns.barplot(x = "CrossValMeans", y = "Models", data = result_df, orient = "h")<br/>    bar.set_xlabel("Mean Accuracy")<br/>    bar.set_title("Cross validation scores")<br/>    return result_df</span></pre><p id="dc24" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated"><em class="mx">方法“evaluate_model”采用模型列表，并使用平均准确度返回交叉验证分数图表。</em></p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="f869" class="lw iw hi mp b fi mt mu l mv mw"><em class="mx"># Modeling step Test differents algorithms </em><br/>random_state = 30<br/>models = [<br/>    LogisticRegression(random_state = random_state, solver='liblinear'),<br/>    DecisionTreeClassifier(random_state = random_state),<br/>    AdaBoostClassifier(DecisionTreeClassifier(random_state = random_state), random_state = random_state, learning_rate = 0.2),<br/>    SVC(random_state = random_state),<br/>    RandomForestClassifier(random_state = random_state),<br/>    GradientBoostingClassifier(random_state = random_state),<br/>    KNeighborsClassifier(),<br/>]<br/>evaluate_model(models)</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div class="er es ns"><img src="../Images/519a7dc2d53880b6cb07fd35c804e77d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/0*4BtML3KGa0oy1Zg9.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">Cross Validate Models</figcaption></figure><p id="b430" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">根据以上观察，我发现SVC、RandomForestClassifier和LogisticRegression模型更准确。接下来，我将对三个模型进行超参数调整。</p><p id="823e" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated"><strong class="jv hj">超参数调谐</strong></p><p id="2f4d" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">超参数调整是为学习算法选择一组最佳超参数。超参数是一个模型参数，其值在学习过程开始之前就已设定。机器学习算法的关键是超参数调整。</p><p id="c788" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">我对SVC、RandomForestClassifier和LogisticRegression模型逐一进行了调优。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="6f38" class="lw iw hi mp b fi mt mu l mv mw"># Import libraries<br/>from sklearn.model_selection import GridSearchCV<br/>from sklearn.metrics import classification_report</span><span id="5ed1" class="lw iw hi mp b fi ne mu l mv mw">def analyze_grid_result(grid_result):<br/>    '''<br/>    Analysis of GridCV result and predicting with test dataset<br/>    Show classification report at last<br/>    '''</span><span id="9df3" class="lw iw hi mp b fi ne mu l mv mw">    # Best parameters and accuracy<br/>    print("Tuned hyperparameters: (best parameters) ", grid_result.best_params_)<br/>    print("Accuracy :", grid_result.best_score_)<br/>    <br/>    means = grid_result.cv_results_["mean_test_score"]<br/>    stds = grid_result.cv_results_["std_test_score"]<br/>    for mean, std, params in zip(means, stds, grid_result.cv_results_["params"]):<br/>        print("%0.3f (+/-%0.03f) for %r" % (mean, std * 2, params))<br/>    print()</span><span id="bdae" class="lw iw hi mp b fi ne mu l mv mw">    print("Detailed classification report:")<br/>    y_true, y_pred = y_test, grid_result.predict(x_test)<br/>    print(classification_report(y_true, y_pred))<br/>    print()</span></pre><p id="be10" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">首先我已经从sklearn库导入了GridSearchCV和classification_report。然后，我定义了显示预测结果的“analyze_grid_result”方法。我为SearchCV中使用的每个模型调用了这个方法。在下一步中，我将对每个模型进行调优。</p><p id="027c" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated"><strong class="jv hj">物流回归</strong></p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="3c34" class="lw iw hi mp b fi mt mu l mv mw"># Define models and parameters for LogisticRegression<br/>model = LogisticRegression(solver='liblinear')<br/>solvers = ['newton-cg', 'liblinear']<br/>penalty = ['l2']<br/>c_values = [100, 10, 1.0, 0.1, 0.01]</span><span id="7a0e" class="lw iw hi mp b fi ne mu l mv mw"># Define grid search<br/>grid = dict(solver = solvers, penalty = penalty, C = c_values)<br/>cv = StratifiedKFold(n_splits = 50, random_state = 1, shuffle = True)<br/>grid_search = GridSearchCV(estimator = model, param_grid = grid, cv = cv, scoring = 'accuracy', error_score = 0)<br/>logi_result = grid_search.fit(x_train, y_train)</span><span id="4886" class="lw iw hi mp b fi ne mu l mv mw"># Logistic Regression Hyperparameter Result<br/>analyze_grid_result(logi_result)</span></pre><p id="54e3" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">输出:</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="4ee2" class="lw iw hi mp b fi mt mu l mv mw">Tuned hyperparameters: (best parameters)  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}<br/>Accuracy : 0.7883636363636363<br/>Detailed classification report:<br/><br/>              precision    recall  f1-score   support<br/><br/>           0       0.78      0.84      0.81       147<br/>           1       0.68      0.58      0.62        83<br/><br/>    accuracy                           0.75       230<br/>   macro avg       0.73      0.71      0.72       230<br/>weighted avg       0.74      0.75      0.74       230</span></pre><p id="883f" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">根据我的观察，在LogisticRegression中，它使用`<em class="mx"> {'C': 10，' penalty': 'l2 '，' solver ':' liblinear ' }【T10]`参数返回了最佳得分0.78。接下来，我将对其他模型进行调优。</em></p><p id="5185" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated"><strong class="jv hj"> SVC </strong></p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="4a65" class="lw iw hi mp b fi mt mu l mv mw"># Define models and parameters for LogisticRegression<br/>model = SVC()</span><span id="c4dc" class="lw iw hi mp b fi ne mu l mv mw"># Define grid search<br/>tuned_parameters = [<br/>    {"kernel": ["rbf"], "gamma": [1e-3, 1e-4], "C": [1, 10, 100, 1000]},<br/>    {"kernel": ["linear"], "C": [1, 10, 100, 1000]},<br/>]<br/>cv = StratifiedKFold(n_splits = 2, random_state = 1, shuffle = True)<br/>grid_search = GridSearchCV(estimator = model, param_grid = tuned_parameters, cv = cv, scoring = 'accuracy', error_score = 0)<br/>scv_result = grid_search.fit(x_train, y_train)</span><span id="ea34" class="lw iw hi mp b fi ne mu l mv mw"># SVC Hyperparameter Result<br/>analyze_grid_result(scv_result)</span></pre><p id="eb6e" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">输出:</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="3042" class="lw iw hi mp b fi mt mu l mv mw">Tuned hyperparameters: (best parameters)  {'C': 10, 'kernel': 'linear'}<br/>Accuracy : 0.7775797976410084<br/>Detailed classification report:<br/><br/>              precision    recall  f1-score   support<br/><br/>           0       0.78      0.84      0.81       147<br/>           1       0.67      0.57      0.61        83<br/><br/>    accuracy                           0.74       230<br/>   macro avg       0.72      0.70      0.71       230<br/>weighted avg       0.74      0.74      0.74       230</span></pre><p id="2422" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">SVC模型给出的最大精度为0.77，略低于逻辑回归。我不会再用这个型号了。</p><p id="30c0" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated"><strong class="jv hj"> RandomForestClassifier </strong></p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="84a4" class="lw iw hi mp b fi mt mu l mv mw"># Define models and parameters for LogisticRegression<br/>model = RandomForestClassifier(random_state=42)</span><span id="116b" class="lw iw hi mp b fi ne mu l mv mw"># Define grid search<br/>tuned_parameters = { <br/>    'n_estimators': [200, 500],<br/>    'max_features': ['auto', 'sqrt', 'log2'],<br/>    'max_depth' : [4,5,6,7,8],<br/>    'criterion' :['gini', 'entropy']<br/>}<br/>cv = StratifiedKFold(n_splits = 2, random_state = 1, shuffle = True)<br/>grid_search = GridSearchCV(estimator = model, param_grid = tuned_parameters, cv = cv, scoring = 'accuracy', error_score = 0)<br/>grid_result = grid_search.fit(x_train, y_train)</span><span id="a461" class="lw iw hi mp b fi ne mu l mv mw"># SVC Hyperparameter Result<br/>analyze_grid_result(grid_result)</span></pre><p id="270e" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">输出:</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="22c8" class="lw iw hi mp b fi mt mu l mv mw">Tuned hyperparameters: (best parameters)  {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 200}<br/>Accuracy : 0.7663648051875454<br/>Detailed classification report:<br/><br/>              precision    recall  f1-score   support<br/><br/>           0       0.78      0.83      0.80       147<br/>           1       0.66      0.58      0.62        83<br/><br/>    accuracy                           0.74       230<br/>   macro avg       0.72      0.70      0.71       230<br/>weighted avg       0.73      0.74      0.74       230</span></pre><p id="f67d" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">Randomforest模型给出了最大0.76%的精确度，与其他模型相比不是最好的。所以我决定用LogisticRegression模型进行预测。</p></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><h1 id="657e" class="iv iw hi bd ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js bi translated">预言；预测；预告</h1><p id="e42e" class="pw-post-body-paragraph lc ld hi jv b jw jx le lf jy jz lg lh ka li lj lk kc ll lm ln ke lo lp lq kg hb bi translated">到目前为止，我致力于EDA、特征工程、模型交叉验证和超参数调整，并为我的数据集找到最佳工作模型。接下来，我从测试数据集进行预测，并将结果存储在CSV中。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="6aa4" class="lw iw hi mp b fi mt mu l mv mw"># Test predictions<br/>y_pred = logi_result.predict(x_test)<br/>print(classification_report(y_test, y_pred))<br/></span><span id="aa37" class="lw iw hi mp b fi ne mu l mv mw"># output<br/>              precision    recall  f1-score   support<br/><br/>           0       0.78      0.84      0.81       147<br/>           1       0.68      0.58      0.62        83<br/><br/>    accuracy                           0.75       230<br/>   macro avg       0.73      0.71      0.72       230<br/>weighted avg       0.74      0.75      0.74       230</span></pre><p id="f80b" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">最后，在名为<code class="du no np nq mp b">Prediction</code>的测试数据集中追加新的特性列，并打印数据集。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="a23c" class="lw iw hi mp b fi mt mu l mv mw">x_test['pred'] = y_pred<br/>print(x_test)</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nt"><img src="../Images/0ec2ec5c4b15e88c5c1a7d52a9577fc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ufh6ZexIZKjnofKt8UwTZQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Diabetes Predictions</figcaption></figure><p id="7ae3" class="pw-post-body-paragraph lc ld hi jv b jw lr le lf jy ls lg lh ka lt lj lk kc lu lm ln ke lv lp lq kg hb bi translated">为了更好地理解特性在建模后的影响，我将在另一篇文章中阐述特性的重要性。</p><blockquote class="my mz na"><p id="2e74" class="lc ld mx jv b jw lr le lf jy ls lg lh nb lt lj lk nc lu lm ln nd lv lp lq kg hb bi translated"><a class="ae iu" href="https://www.kaggle.com/gopalj/diabetes-prediction-using-python" rel="noopener ugc nofollow" target="_blank">阅读完整笔记本<strong class="jv hj">在Kaggle上使用Python </strong>进行糖尿病预测</a></p></blockquote></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><h1 id="8321" class="iv iw hi bd ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js bi translated">结论</h1><ol class=""><li id="bca1" class="jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">糖尿病是怀孕期间的症状之一。必须进行治疗以避免并发症。</li><li id="4f2f" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">身体质量指数指数可以帮助避免糖尿病并发症的前一种方式</li><li id="5c7e" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">糖尿病在35-40岁开始出现，并随着年龄的增长而增加。</li></ol></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><h1 id="f1ac" class="iv iw hi bd ix iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js bi translated">感谢阅读！</h1><p id="b990" class="pw-post-body-paragraph lc ld hi jv b jw jx le lf jy jz lg lh ka li lj lk kc ll lm ln ke lo lp lq kg hb bi translated">如果你喜欢我的工作并想支持我，我会非常感谢你在我的社交媒体频道上关注我:</p><ol class=""><li id="0948" class="jt ju hi jv b jw lr jy ls ka nu kc nv ke nw kg kh ki kj kk bi translated">支持我的最好方式就是在<strong class="jv hj">媒体</strong>T21【这里上关注我。</li><li id="cb48" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">在<strong class="jv hj">推特</strong>T2【这里关注我。</li><li id="cb28" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">在<strong class="jv hj"> LinkedIn </strong> <a class="ae iu" href="https://www.linkedin.com/in/gopal-joshi-971b9865/" rel="noopener ugc nofollow" target="_blank">这里</a>关注我。</li><li id="0216" class="jt ju hi jv b jw kl jy km ka kn kc ko ke kp kg kh ki kj kk bi translated">跟着我上<strong class="jv hj">Kaggle</strong>T10】这里。</li></ol></div></div>    
</body>
</html>