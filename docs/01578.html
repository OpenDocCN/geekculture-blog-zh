<html>
<head>
<title>MultiClass Image Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多类图像分类</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/multiclass-image-classification-dcf9585f2ff9?source=collection_archive---------8-----------------------#2021-04-16">https://medium.com/geekculture/multiclass-image-classification-dcf9585f2ff9?source=collection_archive---------8-----------------------#2021-04-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="d6a7" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">多类机器学习模型的评价指标综述</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ix"><img src="../Images/074d3fe4cd37af38187fd149c77700cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*eIs08V-8tmdEW-tHOo2IFg.jpeg"/></div></figure><p id="e07f" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">不管是拼多类还是拼多类，科学都是一样的。多类图像分类是计算机视觉中的一项常见任务，我们将图像分为三类或更多类。</p><p id="b2dc" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们听说过机器学习中的分类和回归技术。我们知道这两种技术分别对离散和连续数据使用不同的算法。在本文中，我们将了解更多关于分类的知识。</p><h1 id="e852" class="kb kc hi bd kd ke kf kg kh ki kj kk kl io km ip kn ir ko is kp iu kq iv kr ks bi translated">工作流程:</h1><ul class=""><li id="7235" class="kt ku hi jh b ji kv jl kw jo kx js ky jw kz ka la lb lc ld bi translated">从谷歌上抓取图片</li><li id="1851" class="kt ku hi jh b ji le jl lf jo lg js lh jw li ka la lb lc ld bi translated">移除重复的图像</li><li id="c0d2" class="kt ku hi jh b ji le jl lf jo lg js lh jw li ka la lb lc ld bi translated">主导背景颜色</li><li id="2f61" class="kt ku hi jh b ji le jl lf jo lg js lh jw li ka la lb lc ld bi translated">训练模型</li><li id="a6fd" class="kt ku hi jh b ji le jl lf jo lg js lh jw li ka la lb lc ld bi translated">预测图像类别</li></ul><blockquote class="lj lk ll"><p id="2984" class="jf jg lm jh b ji jj ij jk jl jm im jn ln jp jq jr lo jt ju jv lp jx jy jz ka hb bi translated">当我们可以将一幅图像分为多个类别时，这就是所谓的多标签图像分类问题。</p></blockquote><h1 id="ede5" class="kb kc hi bd kd ke kf kg kh ki kj kk kl io km ip kn ir ko is kp iu kq iv kr ks bi translated">初始启动:</h1><pre class="iy iz ja jb fd lq lr ls lt aw lu bi"><span id="e1bb" class="lv kc hi lr b fi lw lx l ly lz">import os<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import cv2<br/>import csv<br/>import glob<br/>import pickle<br/>import time<br/>from simple_image_download import simple_image_download<br/>from sklearn.cluster import KMeans<br/>from PIL import Image, ImageStat<br/>from keras.preprocessing import image<br/>from keras.preprocessing.image import img_to_array, load_img,   ImageDataGenerator<br/>from sklearn.model_selection import train_test_split<br/>from keras.applications.inception_v3 import InceptionV3<br/>from keras.layers import Dense, GlobalAveragePooling2D<br/>from keras.models import Model<br/>from keras.optimizers import Adam<br/><br/>import warnings<br/>warnings.filterwarnings(<strong class="lr hj">'ignore'</strong>)</span></pre><p id="9b5c" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为要下载的类别创建一个CSV文件，并将其存储在项目目录中。我们将在这个项目中使用16个类别。</p><p id="27a5" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jh hj">第一步:从谷歌获取图片</strong></p><pre class="iy iz ja jb fd lq lr ls lt aw lu bi"><span id="995a" class="lv kc hi lr b fi lw lx l ly lz">def images_scrapped_from_google():<br/>    number_of_images_download = 100<br/>    response = simple_image_download.simple_image_download<br/><br/>    with open(load_queries_from_file) as file:<br/>        queries = list(x[0] for x in csv.reader(file))<br/>       <em class="lm"><br/>    </em>for query in queries:<br/>        response().download(query,number_of_images_download)</span></pre><p id="b0aa" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">simple_image_download是一个开源的python库，在从互联网下载图像和生成模型训练数据集方面非常方便。</p><p id="97e6" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jh hj">第二步:从文件夹中移除重复图像</strong></p><pre class="iy iz ja jb fd lq lr ls lt aw lu bi"><span id="a4a3" class="lv kc hi lr b fi lw lx l ly lz">folders = glob.glob(os.path.join(os.getcwd(), <strong class="lr hj">'simple_images/*'</strong>))<br/><br/>images_storing = []<br/>duplicated_files = []<br/><br/>for folder in folders:<br/>    for image in glob.glob(folder + <strong class="lr hj">'/*'</strong>):<br/>        if not image in duplicated_files:<br/>            img_org = Image.open(image)<br/>            pixel_mean1 = ImageStat.Stat(img_org).mean<br/><br/>            for image_2 in glob.glob(folder + <strong class="lr hj">'/*'</strong>):<br/>                if image != image_2:<br/>                    img_check = Image.open(image_2)<br/>                    pixel_mean2 = ImageStat.Stat(img_check).mean<br/><br/>                    if pixel_mean1 == pixel_mean2:<br/>                        duplicated_files.append(image)<br/>                        duplicated_files.append(image_2)<br/><br/>                        try:<br/>                            os.remove(image_2)<br/>                        except:<br/>                            pass<br/><br/>                        if not image in images_storing:<br/>                            images_storing.append(image)<br/>                else:<br/>                    if not image in images_storing:<br/>                        images_storing.append(image)<br/><em class="lm"><br/></em>return images_storing</span></pre><p id="3d85" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jh hj">什么是glob.glob？</strong></p><p id="278a" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">因此，它会让你抓取所有的文件或文件夹从目录中使用正则表达式。举个例子，</p><pre class="iy iz ja jb fd lq lr ls lt aw lu bi"><span id="85f5" class="lv kc hi lr b fi lw lx l ly lz">folders = glob.glob(“simple_images/*”)<br/>print(folders)<br/>------------------------------------------------------------------<br/>['simple_images/baseball bat', 'simple_images/cricket bat', 'simple_images/volleyball', 'simple_images/basketball', 'simple_images/drum', 'simple_images/piano']</span></pre><p id="86cc" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jh hj">第三步:寻找主要背景色</strong></p><pre class="iy iz ja jb fd lq lr ls lt aw lu bi"><span id="f027" class="lv kc hi lr b fi lw lx l ly lz">def getting_percentage_of_dominant_colors(cluster, centroids):<br/>    labels = np.arange(0, len(np.unique(cluster.labels_)) + 1)<br/>    (hist, _) = np.histogram(cluster.labels_, bins=labels)<br/>    hist = hist.astype(<strong class="lr hj">"float"</strong>)<br/>    hist /= hist.sum()<br/><br/>    <em class="lm"># iterate through each cluster's color and percentage<br/>    </em>colors = sorted([(percent, color) for (percent, color) in zip(hist, centroids)])<br/>    for (percent, color) in colors:<br/>        try:<br/>            if percent &gt; 0.50:<br/>                print(color, <strong class="lr hj">"{:0.2f}%"</strong>.format(percent * 100))<br/>                return True<br/>        except Exception as e:<br/>            print(str(e))<br/>    return False</span></pre><p id="c1b8" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">函数将检查图像的主色背景是否大于0.50，然后图像将被存储，否则删除它。背后的原因是，当你有一个多颜色的背景，该对象不会被模型准确地检测到。</p><pre class="iy iz ja jb fd lq lr ls lt aw lu bi"><span id="a10d" class="lv kc hi lr b fi lw lx l ly lz"><em class="lm"># Load images and convert to a list of pixels<br/></em>load_images = images_scrapped_from_google()<br/><br/>images_for_model_train = []<br/>count = 0<br/>for img in load_images:<br/>    try:<br/>        count += 1<br/>        print(count)<br/>        try:<br/>            image = cv2.imread(img)<br/>        except Exception:<br/>            pass<br/>        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)<br/>        reshape = image.reshape((image.shape[0] * image.shape[1], 3))<br/><br/>        <em class="lm"># Find and display most dominant colors<br/>        </em>kmeans = KMeans(n_clusters=5).fit(reshape)<br/>        visualize = getting_percentage_of_dominant_colors(kmeans, kmeans.cluster_centers_)<br/>        if visualize is True:<br/>            images_for_model_train.append(img)<br/>            with open(<strong class="lr hj">"labels_list_of_single_images.csv"</strong>, <strong class="lr hj">"w"</strong>, newline=<strong class="lr hj">""</strong>) as f:<br/>                columns = [<strong class="lr hj">'image_path'</strong>, <strong class="lr hj">'category'</strong>]<br/>                writer = csv.writer(f)<br/>                writer.writerow(columns)<br/>                for img_to_csv in images_for_model_train:<br/>                    writer.writerow([img_to_csv, img_to_csv.split(<strong class="lr hj">"</strong>\\<strong class="lr hj">"</strong>)[-2]])<br/>        else:<br/>            try:<br/>                os.remove(img)<br/>            except:<br/>                pass<br/><br/>    except:<br/>        print(<strong class="lr hj">"Unrecognized Input of an Image"</strong>)<br/>        os.remove(img)</span></pre><p id="aff1" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">写一个CSV文件与类别，给模型的路径，从那里采取的形象，并得到它的训练。</p><p id="bb5b" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jh hj">步骤4:加载训练模型</strong></p><p id="5a0f" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">现在我们都准备好开始为我们的模型训练编码了。我们将使用预训练模型<a class="ae ma" href="https://keras.io/api/applications/inceptionv3/" rel="noopener ugc nofollow" target="_blank"> InceptionV3 </a>，该模型已经在具有1000个类别的图像数据上进行了训练。</p><p id="28d9" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为什么要用预先训练好的CNN模型？CNN的初始层仅训练低级和中级特征，例如边缘、线条、边界等。各种图像都包含这些特征。预先训练的CNN的这些特征使得它非常可重复使用。因此，使用这种已经在大量数据上训练过的预训练模型是有意义的，许多公司为此投入了大量资金。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mb"><img src="../Images/f56db7eda0bd042cdc862d88294b7708.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ALaEVO__JSC6SKMQVNMn8Q.png"/></div></div><figcaption class="mg mh et er es mi mj bd b be z dx">InceptionV3 Model Architecture</figcaption></figure><pre class="iy iz ja jb fd lq lr ls lt aw lu bi"><span id="3388" class="lv kc hi lr b fi lw lx l ly lz">try:<br/>    df = pd.read_csv(os.path.join(os.getcwd(), <strong class="lr hj">"labels_list_of_single_images.csv"</strong>))<br/>    top_categories = sorted(list(df[<strong class="lr hj">'category'</strong>].value_counts().index))<br/>    target_labels = df[<strong class="lr hj">'category'</strong>]<br/>    train_data = np.array(<br/>        [img_to_array(load_img(train_img, target_size=(299, 299))) for train_img in df[<strong class="lr hj">'image_path'</strong>].values.tolist()]) \<br/>        .astype(<strong class="lr hj">'float32'</strong>)<br/>    x_train, x_validation, y_train, y_validation = train_test_split(train_data, target_labels, test_size=0.2,<br/>                                                                    random_state=100)<br/><br/>    print(<strong class="lr hj">"x_train samples: "</strong>, x_train.shape)<br/>    print(<strong class="lr hj">"x_validation samples: "</strong>, x_validation.shape)<br/><br/>    y_train = pd.get_dummies(y_train.reset_index(drop=True)).values<br/>    y_validation = pd.get_dummies(y_validation.reset_index(drop=True)).values<br/><br/>    <em class="lm"># Train Generator<br/>    </em>train_datagen = ImageDataGenerator(rescale=1. / 255,<br/>                                       rotation_range=30,<br/>                                       width_shift_range=0.2,<br/>                                       height_shift_range=0.2,<br/>                                       horizontal_flip=<strong class="lr hj">'true'</strong>)<br/><br/>    train_generator = train_datagen.flow(x_train, y_train, shuffle=False, batch_size=40, seed=42)<br/><br/>    <em class="lm"># Validation Generator<br/>    </em>val_datagen = ImageDataGenerator(rescale=1. / 255)<br/><br/>    val_generator = val_datagen.flow(x_validation, y_validation, shuffle=False, batch_size=40, seed=42)<br/><br/><br/><em class="lm"># Model Intialize<br/>    </em>base_model = InceptionV3(weights=<strong class="lr hj">'imagenet'</strong>, include_top=False, input_shape=(299, 299, 3))<br/><br/>    x = base_model.output<br/>    x = GlobalAveragePooling2D()(x)<br/><br/>    <em class="lm"># Add a fully-connected layer<br/>    </em>x = Dense(512, activation=<strong class="lr hj">'relu'</strong>)(x)<br/>    predictions = Dense(16, activation=<strong class="lr hj">'sigmoid'</strong>)(x)<br/><br/>    model = Model(inputs=base_model.input, outputs=predictions)<br/><br/>    model.compile(Adam(lr=.0001), loss= <strong class="lr hj">'categorical_crossentropy'</strong>, metrics=[<strong class="lr hj">'accuracy'</strong>])<br/><br/>    <em class="lm"># Train the model<br/>    </em>start = time.time()<br/>    model.fit_generator(train_generator,<br/>                        steps_per_epoch=len(x_train) // 40,<br/>                        validation_data=val_generator,<br/>                        validation_steps=len(x_validation) // 40,<br/>                        epochs=5,<br/>                        verbose=2)<br/>    end = time.time()<br/>    print(<strong class="lr hj">"</strong>\n<strong class="lr hj">Total Time Taken:"</strong>, round((end - start) / 60, 2), <strong class="lr hj">"Minutes"</strong>)<br/><br/>    try:<br/>        file = open(<strong class="lr hj">"multi_class_model.pkl"</strong>, <strong class="lr hj">"wb"</strong>)<br/>        pickle.dump(model, file)<br/>        print(<strong class="lr hj">"Model Saved..!!"</strong>)<br/>       <em class="lm"><br/>    </em>except Exception as e:<br/>        print(str(e))<br/><br/>except Exception as e:<br/>    print(str(e))</span></pre><p id="c7f8" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jh hj">迁移学习:</strong></p><p id="7856" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">要使用预训练模型，我们需要保持所有之前的层不变，只根据我们的用例更改最后一层。InceptionV3已经在1000个图像类上进行了训练。我们的问题只有16种不同的图像类别。因此，我们将把InceptionV3的最后一层修改为16个类。迁移学习节省了工程师大量的培训时间和开发精力。</p><p id="b6ec" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">ImageDataGenerator用于增强图像。我们可以为数据扩充做更多的预处理。神经网络在处理大量数据时效果更好。<a class="ae ma" href="https://lionbridge.ai/articles/data-augmentation-with-machine-learning-an-overview/" rel="noopener ugc nofollow" target="_blank">数据扩充</a>是我们在训练时用来增加数据量的一种策略。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mk"><img src="../Images/f3d1cabaafb2f591faa70fa61ab29cac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8OAo8d9ODiv7Jyv2UxBLqA.png"/></div></div></figure><p id="04f1" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jh hj">步骤5:预测图像类别</strong></p><pre class="iy iz ja jb fd lq lr ls lt aw lu bi"><span id="ecb1" class="lv kc hi lr b fi lw lx l ly lz"><em class="lm"># For Prediction<br/></em>def predict_from_image(img_path):<br/>    model_classes = pickle.load(open(<strong class="lr hj">"multi_class_model.pkl"</strong>, <strong class="lr hj">"rb"</strong>))<br/>    print(model_classes.summary())<br/>    img = image.load_img(img_path, target_size=(299, 299))<br/>    img_tensor = image.img_to_array(img)  <em class="lm"># (height, width, channels)<br/>    </em>img_tensor = np.expand_dims(img_tensor,<br/>                                axis=0)  <em class="lm"># (1, height, width, channels),<br/>                  #add a dimension because the model expects this shape: (batch_size, height, width, channels)<br/>    </em>img_tensor /= 255.<br/><br/>    pred = model_classes.predict(img_tensor)<br/>    sorted_category_list = sorted(top_categories)<br/>    predicted_class = sorted_category_list[np.argmax(pred)]<br/><br/>    return predicted_class, max(pred)<br/><br/><br/>img_path = os.path.join(os.getcwd(), <strong class="lr hj">"</strong>baseball bat_3.jpg<strong class="lr hj">"</strong>)<br/>classes, prob = predict_from_image(img_path)<br/>print(<strong class="lr hj">f"</strong>\n{classes}\n{prob[top_categories.index(classes)]}<strong class="lr hj">"</strong>)</span></pre><p id="7250" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jh hj">模型预测:</strong></p><pre class="iy iz ja jb fd lq lr ls lt aw lu bi"><span id="907d" class="lv kc hi lr b fi lw lx l ly lz">baseball_bat<br/>0.9999959468841553</span></pre><p id="b258" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们现在已经使用迁移学习成功地建立了一个CNN模型。使用这种方法，任何多类图像分类问题都可以在短时间内以良好的精度得到解决。</p><p id="1aac" class="pw-post-body-paragraph jf jg hi jh b ji jj ij jk jl jm im jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">快乐学习…！！！</p></div></div>    
</body>
</html>