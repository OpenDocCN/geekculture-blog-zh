<html>
<head>
<title>File Processing in Big Data Systems: Which is Quicker? Which is better?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">大数据系统中的文件处理:哪个更快？哪个更好？</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/file-processing-a-comparative-analytics-study-e21b4693b70c?source=collection_archive---------3-----------------------#2021-02-06">https://medium.com/geekculture/file-processing-a-comparative-analytics-study-e21b4693b70c?source=collection_archive---------3-----------------------#2021-02-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="a775" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">比较分析研究基准流行的编程语言和执行引擎。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/71932dc4fe0b4fc3d4381d2535584fb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JAlaohX-4tbRGmg8"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@sumo?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">PAUL SMITH</a> on <a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="85d6" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">介绍</h1><p id="9170" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">你有没有想过哪些编程语言和执行引擎在处理文件时是最快的还是最慢的？您是否陷入了困境，不知道应该使用哪种编程语言来有效地解决您的业务问题？不用再看了，这就是你的答案。</p><p id="3882" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">我们看看流行的语言，如<strong class="ki hj"> <em class="lh"> Python、Java、</em> </strong>和<strong class="ki hj"> <em class="lh"> Scala </em> </strong>和执行引擎，如<strong class="ki hj"> <em class="lh"> Hadoop </em> </strong>和<strong class="ki hj"> <em class="lh"> Spark </em> </strong>，看看它们在处理文件和基准测试方面表现如何。</p></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><h1 id="2978" class="jo jp hi bd jq jr lp jt ju jv lq jx jy io lr ip ka ir ls is kc iu lt iv ke kf bi translated">方法学</h1><p id="b5d0" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">我们探索并进行数据分析&amp;比较在各种编程语言和执行引擎中计算输入文本文件字数所需的执行时间，输入文本文件的大小从极小到极大不等。</p><p id="3f9e" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">我们编写示例字数统计程序来处理这些文件并执行它们。然后，我们计算单独处理文件所需的时间，并收集结果。此外，我们收集我们的样本发现和观察结果，并进行比较。从单个分析中得到的所有发现都被收集并组合在一个<a class="ae jn" href="https://github.com/Thomas-George-T/File-Processing-Comparative-Analytics/blob/master/Data-Analysis.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ki hj"> Google Colab </strong> </a>笔记本中，然后我们使用<em class="lh"> matplotlib </em>绘制图表，并根据我们的发现得出结论。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/740bd8ef38997684ffeeda0063ce1b31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VdBjOs_0-IbrX6rZ"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@wesleyphotography?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Wesley Tingey</a> on <a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="00df" class="lu jp hi bd jq lv lw lx ju ly lz ma jy kp mb mc ka kt md me kc kx mf mg ke mh bi translated">文件</h2><p id="86ee" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">对于这个实验，我们需要两种文件。一个仅输入文本的大文件和一个小文本文件，同时记住它们应该是适当的大小，以便它们不会扭曲我们正在进行的性能测试。</p><p id="ac76" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">考虑到这些限制，我们正在运行一个数据科学实验<em class="lh">(各种各样的)。</em>我们挑选了一些相关的东西，对于大型文本文件，我们选择了<a class="ae jn" href="https://norvig.com/big.txt" rel="noopener ugc nofollow" target="_blank"> big.txt </a>，如果你不熟悉的话，这是来自《美丽数据》一书<em class="lh">(sega ran和Hammerbacher，2009) </em>来自《自然语言语料库数据》一章<em class="lh"/>他们在那里谈到运行拼写纠正。多么贴切！</p><p id="9220" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">对于这个小文件，我们使用从Apache Hadoop Wikipedia页面中收集的数据，这是我们在实验中进行基准测试的另一个执行引擎。</p></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><h1 id="da6b" class="jo jp hi bd jq jr lp jt ju jv lq jx jy io lr ip ka ir ls is kc iu lt iv ke kf bi translated">数据分析</h1><p id="1aa0" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">说得够多了，让我们开始看看编程语言和执行引擎，以及如何对它们进行基准测试。</p><h2 id="f36d" class="lu jp hi bd jq lv lw lx ju ly lz ma jy kp mb mc ka kt md me kc kx mf mg ke mh bi translated">编程语言</h2><p id="07e5" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">我们采用的方法是用各自的语言编写字数统计程序，并解析我们选择的大小文件。因为我们对Python、Scala和Python重复了相同的步骤，所以我们以Python为例进行演示:</p><h2 id="c2d6" class="lu jp hi bd jq lv lw lx ju ly lz ma jy kp mb mc ka kt md me kc kx mf mg ke mh bi translated">计算机编程语言</h2><p id="f60e" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">我们用Python开始我们的程序，第一步是读取文件。我们使用这个小文本文件作为例子:</p><pre class="iy iz ja jb fd mi mj mk ml aw mm bi"><span id="94d8" class="lu jp hi mj b fi mn mo l mp mq"># Reading file</span><span id="7d91" class="lu jp hi mj b fi mr mo l mp mq">file=open("../Input-Files/apache-hadoop-wiki.txt","r",encoding="utf-8")</span></pre><p id="48b0" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">现在对于我们实际的字数统计，我们使用内置的结构<em class="lh">字典</em>:</p><pre class="iy iz ja jb fd mi mj mk ml aw mm bi"><span id="08f3" class="lu jp hi mj b fi mn mo l mp mq"># Initializing Dictionary<br/>dict = {}</span><span id="8410" class="lu jp hi mj b fi mr mo l mp mq"># counting number of times each word comes up in list of words (in dictionary)for word in file.read().split():<br/>    dict[word] = dict.get(word, 0) + 1</span><span id="0187" class="lu jp hi mj b fi mr mo l mp mq">file.close()</span></pre><p id="c02c" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">我们写下刚刚计算的结果:</p><pre class="iy iz ja jb fd mi mj mk ml aw mm bi"><span id="809b" class="lu jp hi mj b fi mn mo l mp mq">#write the file<br/>fw = open("small-result-python.txt","w",encoding="utf-8")<br/>fw.write(str(dict))<br/>fw.close()</span></pre><p id="9a6c" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">我们计算字数结果的一小段:</p><pre class="iy iz ja jb fd mi mj mk ml aw mm bi"><span id="7b19" class="lu jp hi mj b fi mn mo l mp mq">{'Apache': 79, 'Hadoop': 201, 'From': 3, 'Wikipedia,': 1, 'the': 211, 'free': 1, 'encyclopedia': 1, 'Jump': 2, 'to': 122 }</span></pre><p id="866e" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">现在，为了对我们的程序进行基准测试，我们导入了<em class="lh">时间</em>包，并在适当的时候插入了钩子。</p><p id="b3ac" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">所以我们的完整程序看起来是这样的:</p><pre class="iy iz ja jb fd mi mj mk ml aw mm bi"><span id="d006" class="lu jp hi mj b fi mn mo l mp mq">import time</span><span id="b717" class="lu jp hi mj b fi mr mo l mp mq">start = time.time()</span><span id="31a4" class="lu jp hi mj b fi mr mo l mp mq"># Reading filefile=open("../Input-Files/apache-hadoop-wiki.txt","r",encoding="utf-8")</span><span id="d9bc" class="lu jp hi mj b fi mr mo l mp mq"># Initializing Dictionary<br/>dict = {}</span><span id="f071" class="lu jp hi mj b fi mr mo l mp mq"># counting number of times each word comes up in list of words (in dictionary)<br/>for word in file.read().split():<br/>     dict[word] = dict.get(word, 0) + 1</span><span id="8197" class="lu jp hi mj b fi mr mo l mp mq">file.close()</span><span id="e6c1" class="lu jp hi mj b fi mr mo l mp mq">#write the file<br/>fw = open("small-result-python.txt","w",encoding="utf-8")<br/>fw.write(str(dict))<br/>fw.close()</span><span id="eb03" class="lu jp hi mj b fi mr mo l mp mq">end = time.time() print("Execution time :", end - start)</span></pre><p id="ed71" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">类似地，我们收集小文件和大文件的结果，并分别为所有语言绘制图表:</p><div class="iy iz ja jb fd ab cb"><figure class="ms jc mt mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/62eb23235efdec3cabd406058f7b73d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/1*6hy2tODqHA9TU12CyURaVw.png"/></div></figure><figure class="ms jc my mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/51b984ef8fdefce63d9d29b73379ed22.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*wpAVZEjrDMiQ0_1Rb7MFlQ.png"/></div></figure><figure class="ms jc mz mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/14332acca4c7345a24d68b7c3733e13b.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*luLJF-PZQs6MGFSmnBnhIA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx na di nb nc">(Left) Bar chart depicting processing times for Python | (Middle) Bar chart depicting processing times for Java | (Right) Bar chart depicting processing times for Scala | Images by Author.</figcaption></figure></div><h2 id="e1e8" class="lu jp hi bd jq lv lw lx ju ly lz ma jy kp mb mc ka kt md me kc kx mf mg ke mh bi translated">执行引擎</h2><p id="7892" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">我们认为Hadoop和Spark是我们的执行引擎。我们将在实验中使用独立模式/集群。</p><p id="a9c7" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">我们重复对编程语言采取的相同步骤，结果如下所示:</p><div class="iy iz ja jb fd ab cb"><figure class="ms jc nd mu mv mw mx paragraph-image"><img src="../Images/ea5bb1f0737bb24b706d1592be40f954.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*mb-qHf0ZrUx9lc4_za_W8w.png"/></figure><figure class="ms jc ne mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/d9d47ffb3723a133429172d1ce96acc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*CRboVvnXCFFWbmSkxlx09A.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx nf di ng nc">(left) Graph depicting processing time taken by Hadoop | (right) Graph depicting processing time taken by Spark | Images by Author</figcaption></figure></div></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><h1 id="a0dc" class="jo jp hi bd jq jr lp jt ju jv lq jx jy io lr ip ka ir ls is kc iu lt iv ke kf bi translated">比较分析</h1><p id="91c2" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">现在我们有了编程语言和执行引擎的所有单独结果。让我们比较一下，得出有用的见解。</p><p id="a3e5" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">我们使用Google Colab来绘制python中的基准图:</p><p id="4880" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">我们首先导入所需的库:<em class="lh">熊猫</em>和<em class="lh"> matlplotlib </em></p><pre class="iy iz ja jb fd mi mj mk ml aw mm bi"><span id="f82c" class="lu jp hi mj b fi mn mo l mp mq"><strong class="mj hj">import</strong> <strong class="mj hj">pandas</strong> <strong class="mj hj">as</strong> <strong class="mj hj">pd</strong><br/><strong class="mj hj">import</strong> <strong class="mj hj">matplotlib</strong> <strong class="mj hj">as</strong> <strong class="mj hj">mpl</strong><br/><strong class="mj hj">import</strong> <strong class="mj hj">matplotlib.pyplot</strong> <strong class="mj hj">as</strong> <strong class="mj hj">plt</strong><br/>mpl.style.use('ggplot')</span></pre><p id="60b8" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">准备我们的语言数据集</p><pre class="iy iz ja jb fd mi mj mk ml aw mm bi"><span id="0927" class="lu jp hi mj b fi mn mo l mp mq"><em class="lh"># initialize list of languages </em><br/>data_lan = [['java', 0.123, 1.179 ], ['scala', 10.172, 3.528]] <br/>  <br/><em class="lh"># Create the pandas DataFrame </em><br/>df_languages = pd.DataFrame(data_lan, columns = ['languages', 'small','big']) <br/>  <br/><em class="lh"># print dataframe. </em><br/>df_languages</span></pre><p id="3b26" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">因为这是一个不断发展的实验，将来我们可以用更多的语言和执行引擎进行基准测试，所以我们使用这种方法:</p><pre class="iy iz ja jb fd mi mj mk ml aw mm bi"><span id="81b5" class="lu jp hi mj b fi mn mo l mp mq"><em class="lh"># Appending Data, Use this method in the future when trying to add more languages</em></span><span id="0082" class="lu jp hi mj b fi mr mo l mp mq">df_languages = df_languages.append({'languages':'python','small':0.006, 'big':1.154}, ignore_index=<strong class="mj hj">True</strong>)<br/>df_languages</span><span id="5b94" class="lu jp hi mj b fi mr mo l mp mq"><em class="lh"># Set the languages as index for our x axis</em><br/>df_languages.set_index('languages', inplace=<strong class="mj hj">True</strong>)<br/>df_languages</span></pre><p id="f9ab" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">准备绘图的结果数据:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nh"><img src="../Images/02dd9216874c7810272abfa630d6e2f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*rOqTKZbYH8lVIHnxsJ-f3A.jpeg"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Dataset with clear X &amp; Y axis demarcations | Image by Author</figcaption></figure><p id="2748" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">绘制我们的数据:</p><pre class="iy iz ja jb fd mi mj mk ml aw mm bi"><span id="060f" class="lu jp hi mj b fi mn mo l mp mq">ax = df_languages.plot(kind='bar',<br/>                      figsize = (10,10)<br/>                      )</span><span id="f1b3" class="lu jp hi mj b fi mr mo l mp mq">plt.xlabel('Languages')<br/>plt.title('Execution times for each language for both small and large files')</span><span id="eafc" class="lu jp hi mj b fi mr mo l mp mq">ax.set_facecolor('white')<br/>ax.tick_params(axis='x', colors='black', labelsize=14)<br/>ax.axhline(0, color='black')<br/>ax.legend(facecolor='white',fontsize=14)<br/>ax.tick_params(top=<strong class="mj hj">False</strong>, left=<strong class="mj hj">False</strong>, right=<strong class="mj hj">False</strong>, labelleft=<strong class="mj hj">False</strong>)</span><span id="ed33" class="lu jp hi mj b fi mr mo l mp mq"><strong class="mj hj">for</strong> p <strong class="mj hj">in</strong> ax.patches:   <em class="lh">#display the percentages above the bars</em><br/>    width, height = p.get_width(), p.get_height()<br/>    x, y = p.get_xy() <br/>    ax.annotate('<strong class="mj hj">{}</strong> s'.format(height), (x, y + height + 0.1),fontsize=14)</span><span id="0899" class="lu jp hi mj b fi mr mo l mp mq">plt.show()</span></pre></div><div class="ab cl li lj gp lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="hb hc hd he hf"><h1 id="80d9" class="jo jp hi bd jq jr lp jt ju jv lq jx jy io lr ip ka ir ls is kc iu lt iv ke kf bi translated">结论</h1><div class="iy iz ja jb fd ab cb"><figure class="ms jc ni mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/7ad040f0c2217002e09c21dcbb0ea35a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*F0MXItV4FAoX-wHOUzAxRg.png"/></div></figure><figure class="ms jc nj mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/61af4d615b48d6501bc0bb56d211e2cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*EuEDyyX_c76odQn-oIe1HQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx nk di nl nc">(left) Graph comparing &amp; benchmarking the file processing time for Programming languages | (right) Graph comparing &amp; benchmarking the file processing time for Execution Engines | Images by Author</figcaption></figure></div><p id="29c5" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">对于编程语言，我们观察到<strong class="ki hj"> Python </strong>对于小文件和大文件的执行时间最少，而<strong class="ki hj"> Scala </strong>的执行时间最长。有趣的是，<em class="lh"> Scala </em>处理小文件比处理大文件多花了7秒。</p><p id="6936" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">对于执行引擎，我们观察到<strong class="ki hj"> Spark引擎</strong>具有最少的执行时间，而<strong class="ki hj"> Hadoop的Mapreduce引擎</strong>具有最高的执行时间。这符合Spark比Hadoop快100倍的说法。</p><p id="aeb9" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">我希望这个实验能对你的下一个项目应该使用哪种编程语言或执行方式有所启发。总的来说，每种编程语言和执行引擎都有各自的优缺点，但是通过这次实验，我们现在知道了哪种语言和执行引擎具有最好的性能基准。</p><p id="9634" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">这个项目正在成长，如果你想用更多的编程语言和执行引擎为它做出贡献，请在<a class="ae jn" href="https://github.com/Thomas-George-T/File-Processing-Comparative-Analytics" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上这样做。感谢您的阅读。</p><h1 id="4db8" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">参考</h1><ol class=""><li id="137c" class="nm nn hi ki b kj kk km kn kp no kt np kx nq lb nr ns nt nu bi translated"><a class="ae jn" href="https://norvig.com/ngrams/" rel="noopener ugc nofollow" target="_blank">自然语言语料库数据:美丽数据</a></li><li id="9322" class="nm nn hi ki b kj nv km nw kp nx kt ny kx nz lb nr ns nt nu bi translated"><a class="ae jn" href="https://en.wikipedia.org/wiki/Apache_Hadoop" rel="noopener ugc nofollow" target="_blank">阿帕奇Hadoop维基百科</a></li></ol></div></div>    
</body>
</html>