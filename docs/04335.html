<html>
<head>
<title>Using Facial recognition to launch an AWS instance in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用面部识别在Python中启动AWS实例</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/using-facial-recognition-to-launch-an-aws-instance-in-python-2b6ea2765bcb?source=collection_archive---------39-----------------------#2021-06-24">https://medium.com/geekculture/using-facial-recognition-to-launch-an-aws-instance-in-python-2b6ea2765bcb?source=collection_archive---------39-----------------------#2021-06-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><a href="https://www.americancityandcounty.com/2020/08/17/facing-the-controversy-of-facial-recognition-technology/"><div class="er es if"><img src="../Images/27614246b914cd6006405666e6d23fb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lSuvnUxWkuXmbhZKyd7vTw.jpeg"/></div></a></figure><h1 id="19ac" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">介绍</h1><p id="c4e3" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">Python为有趣的项目提供了许多库，所以这是我做的另一个有趣的任务。虽然当你的脸被识别时在AWS上启动一个资源的想法可能看起来很随意，但我在这里的意图只是展示这种语言可以多么通用，以及如果你只是对一些细节有一个小想法，它可以多么容易。所以让我们开始有趣的事情吧。</p></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="d44a" class="im in hi bd io ip kp ir is it kq iv iw ix kr iz ja jb ks jd je jf kt jh ji jj bi translated">面部识别</h1><h2 id="797b" class="ku in hi bd io kv kw kx is ky kz la iw jv lb lc ja jz ld le je kd lf lg ji lh bi translated">创建样品组</h2><p id="f644" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">首先，我们需要所需的库:<code class="du li lj lk ll b">opencv-python</code>、<code class="du li lj lk ll b">opencv-contrib-python</code>、<code class="du li lj lk ll b">numpy</code>。如果您没有安装这些，请先使用pip安装它们。</p><pre class="lm ln lo lp fd lq ll lr ls aw lt bi"><span id="c508" class="ku in hi ll b fi lu lv l lw lx">import cv2<br/>import numpy as np</span></pre><p id="8961" class="pw-post-body-paragraph jk jl hi jm b jn ly jp jq jr lz jt ju jv ma jx jy jz mb kb kc kd mc kf kg kh hb bi translated">为了检测人脸，我们将使用哈尔级联。哈尔级联可以用来检测图像中的各种对象，但对于我们在这里的使用，我在我的工作空间中有<code class="du li lj lk ll b">haarcascade_frontalface_default.xml</code>文件(用于检测人脸)。你可以在这里下载文件<a class="ae md" href="https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="1847" class="pw-post-body-paragraph jk jl hi jm b jn ly jp jq jr lz jt ju jv ma jx jy jz mb kb kc kd mc kf kg kh hb bi translated">我们现在可以使用这个文件作为预先建立的人脸分类器。使用函数<code class="du li lj lk ll b">cv2.CascadeClassifier()</code>将文件加载到python中，作为一个现成的分类器。</p><pre class="lm ln lo lp fd lq ll lr ls aw lt bi"><span id="dafb" class="ku in hi ll b fi lu lv l lw lx"># Load HAAR Cascade face classifier<br/>face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')</span></pre><p id="6b04" class="pw-post-body-paragraph jk jl hi jm b jn ly jp jq jr lz jt ju jv ma jx jy jz mb kb kc kd mc kf kg kh hb bi translated">接下来，我设置目录的路径，我将在其中保存我所有的样本图像。请随意将其更改为任何其他有效的目录路径。</p><pre class="lm ln lo lp fd lq ll lr ls aw lt bi"><span id="9b7e" class="ku in hi ll b fi lu lv l lw lx"># Setting file path for storing and retrieving data<br/>path = './faces/user/'</span></pre><p id="7519" class="pw-post-body-paragraph jk jl hi jm b jn ly jp jq jr lz jt ju jv ma jx jy jz mb kb kc kd mc kf kg kh hb bi translated">接下来，让我们定义一个函数，该函数将网络摄像头捕捉的每一帧作为参数，将该帧的颜色空间从BGR转换为灰度，然后使用<code class="du li lj lk ll b">face_detector</code>分类器将检测到的人脸作为矩形列表返回。然后，该函数获取坐标，并返回作为参数传递的原始帧的裁剪部分。</p><pre class="lm ln lo lp fd lq ll lr ls aw lt bi"><span id="0657" class="ku in hi ll b fi lu lv l lw lx"># Function detects faces and returns cropped image | Returns None if no face detected<br/>def face_extractor(frame):<br/>    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)<br/>    face = face_detector.detectMultiScale(gray, 1.3, 5)<br/>    <br/>    if len(face) == 0:<br/>        return None<br/>    <br/>    # Crop detected face<br/>    (x, y, w, h) = face[0]<br/>    cropped_face = frame[y:y+h, x:x+w]<br/>    return cropped_face</span></pre><p id="45d6" class="pw-post-body-paragraph jk jl hi jm b jn ly jp jq jr lz jt ju jv ma jx jy jz mb kb kc kd mc kf kg kh hb bi translated">接下来，我们可以通过调用上面的函数来创建收集样本的代码部分。使用<code class="du li lj lk ll b">cv2.VideoCapture()</code>将网络摄像头设置为视频捕捉设备。我还声明了一个变量<code class="du li lj lk ll b">count </code>来定义样本集的大小；这里我制作了一组500张图片。在while循环中，使用视频捕获对象的<code class="du li lj lk ll b">read()</code>方法捕获图像，并使用捕获的图像作为参数调用<code class="du li lj lk ll b">face_extractor()</code>方法。如果返回的对象不是<code class="du li lj lk ll b">None</code>，则减少计数值，将图像大小调整为200x200，将其颜色空间更改为灰度，然后将图像写入给定的文件路径。我们还通过使用<code class="du li lj lk ll b">cv2.putText()</code>和<code class="du li lj lk ll b">cv2.imshow()</code>方法显示帧上的计数值，向用户显示捕获的图像，以验证拍摄的图像数量。如果用户按下Return键或计数达到0，则循环中断，样本收集完成。这是该部分的外观:</p><pre class="lm ln lo lp fd lq ll lr ls aw lt bi"><span id="da77" class="ku in hi ll b fi lu lv l lw lx">cap = cv2.VideoCapture(0)<br/>count = 500    # size of sample (number of images needed)</span><span id="a66d" class="ku in hi ll b fi me lv l lw lx">while True:<br/>    ret, frame = cap.read()<br/>    face = face_extractor(frame)<br/>    if face is not None:<br/>        count -= 1<br/>        face = cv2.resize(face, (200, 200))<br/>        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)<br/>        <br/>        # Save file in the specified directory with a unique name<br/>        file_path = path + str(count) + '.jpg'<br/>        cv2.imwrite(file_path, face)<br/>        <br/>        cv2.putText(face, str(count), (10, 190), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [255,0,0], 1)<br/>        cv2.imshow('samples', face)<br/>        <br/>    else:<br/>        print("Face not found")<br/>        pass<br/>    <br/>    if cv2.waitKey(10) == 13 or count &lt;= 0:<br/>        break<br/>        <br/>cv2.destroyAllWindows()<br/>print("Sample Collection Complete")<br/>cap.release()</span></pre><h2 id="1226" class="ku in hi bd io kv kw kx is ky kz la iw jv lb lc ja jz ld le je kd lf lg ji lh bi translated">训练模型</h2><p id="6cca" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">我正在从<code class="du li lj lk ll b">os</code>导入一些模块来读取目录中的图像。</p><pre class="lm ln lo lp fd lq ll lr ls aw lt bi"><span id="6c36" class="ku in hi ll b fi lu lv l lw lx">from os import listdir<br/>from os.path import isfile, join</span></pre><p id="e12f" class="pw-post-body-paragraph jk jl hi jm b jn ly jp jq jr lz jt ju jv ma jx jy jz mb kb kc kd mc kf kg kh hb bi translated">然后，使用for循环，我们可以将图像存储在一个数组<code class="du li lj lk ll b">training_data</code>中。<code class="du li lj lk ll b">file_paths</code>列表存储目录中每个图像文件的名称。</p><pre class="lm ln lo lp fd lq ll lr ls aw lt bi"><span id="0ded" class="ku in hi ll b fi lu lv l lw lx"># Fetching the paths of sample data for training<br/>data_path = path<br/>file_paths = [f for f in listdir(data_path) if isfile(join(data_path, f))]</span><span id="fea8" class="ku in hi ll b fi me lv l lw lx"># Lists for training data and labels<br/>training_data, labels = [], []</span><span id="4f2c" class="ku in hi ll b fi me lv l lw lx"># Open images from the file paths and create numpy array for training data<br/>for i, f_path in enumerate(file_paths):<br/>    image_path = data_path + f_path<br/>    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)<br/>    training_data.append(np.asarray(images, dtype=np.uint8))<br/>    labels.append(i)</span></pre><p id="a5b1" class="pw-post-body-paragraph jk jl hi jm b jn ly jp jq jr lz jt ju jv ma jx jy jz mb kb kc kd mc kf kg kh hb bi translated">我们正在使用<code class="du li lj lk ll b">cv2.face_LBPHFaceRecognizer.create()</code>方法初始化一个模型。然后使用<code class="du li lj lk ll b">training_data</code>阵列训练模型。</p><pre class="lm ln lo lp fd lq ll lr ls aw lt bi"><span id="e0fd" class="ku in hi ll b fi lu lv l lw lx"># Initialize the face recognizer model<br/>my_model = cv2.face_LBPHFaceRecognizer.create()</span><span id="4268" class="ku in hi ll b fi me lv l lw lx"># Training the model<br/>my_model.train(training_data, labels)<br/>print("Model Trained")</span></pre><h2 id="db39" class="ku in hi bd io kv kw kx is ky kz la iw jv lb lc ja jz ld le je kd lf lg ji lh bi translated">运行模型</h2><p id="f741" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">这类似于样本集合中的提取部分。我们开始视频捕捉，读取图像，并将其传递给一个函数来检测面部并返回裁剪后的图像。然后，我们将这个图像传递给我们的<code class="du li lj lk ll b">model.predict()</code>方法并存储结果。然后，结果的可信度可以计算为百分比，并使用<code class="du li lj lk ll b">cv2.putText()</code>方法作为文本放在框架上。如果置信度得分在90%以上，我们可以设置一个标志为真，并打破循环。您会注意到，我声明了一个变量<code class="du li lj lk ll b">correction</code>，它是为了确保在确认确实是用户之前，足够多的用户图像被集体预测正确。在这里，我设置了<code class="du li lj lk ll b">correction=50</code>，这意味着必须连续预测50帧作为用户的面部，否则校正值将被重置。</p><pre class="lm ln lo lp fd lq ll lr ls aw lt bi"><span id="c6c3" class="ku in hi ll b fi lu lv l lw lx">cap = cv2.VideoCapture(0)<br/>correction = 50 # Number of times the user's face must bre read correctly before sending the mail<br/>recog = False<br/>while True:<br/>    ret, frame = cap.read()<br/>    face = detect_face(frame)<br/>    <br/>    try:<br/>        grayface = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)<br/>        <br/>        # Passing face to the model for prediction<br/>        result = my_model.predict(grayface)<br/>        <br/>        if result[1] &lt; 500:<br/>            confidence = int(100 * (1 - result[1]/400))<br/>            display_str = 'Confidence score : ' + str(confidence) + '%'<br/>            <br/>        cv2.putText(frame, display_str, (230, 450), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [255,120,150], 1)<br/>        <br/>        if confidence &gt; 90:<br/>            cv2.putText(frame, "Hello User", (276, 430), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [178, 255, 25], 1)<br/>            c += 1<br/>            if c &gt;= correction:<br/>                recog = True<br/>                break<br/>        else:<br/>            cv2.putText(frame, "Face not recognized", (240, 430), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [80,19,247], 1)<br/>            c = 0<br/>        <br/>    except:<br/>        cv2.putText(frame, "Face not found", (260, 430), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [255,255,255], 1)<br/>        cv2.putText(frame, "Looking for a face", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [255,255,255], 1)<br/>        c = 0<br/>    cv2.imshow('Face Recognition', frame)<br/>        <br/>    if cv2.waitKey(10) == 13:<br/>        break</span><span id="4c09" class="ku in hi ll b fi me lv l lw lx">cv2.destroyAllWindows()<br/>cap.release()</span><span id="10cc" class="ku in hi ll b fi me lv l lw lx">if recog:<br/>    res = createEC2Instance()</span></pre><p id="1434" class="pw-post-body-paragraph jk jl hi jm b jn ly jp jq jr lz jt ju jv ma jx jy jz mb kb kc kd mc kf kg kh hb bi translated">如果标志<code class="du li lj lk ll b">recog</code>设置为True，那么我们可以进入下一个阶段，调用函数<code class="du li lj lk ll b">createEC2Instance()</code>，这将启动一个AWS EC2实例，但是您可以在这里选择执行您希望的任何其他操作。</p><h1 id="dccb" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">在AWS上发布资源</h1><p id="64b9" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">为了在AWS中使用资源，我们需要为Python安装名为<strong class="jm hj"> boto3 </strong>的AWS SDK。它允许我们从Python脚本中创建、更新和删除AWS资源。通过运行<code class="du li lj lk ll b">pip install boto3</code>来安装它。</p><p id="7ece" class="pw-post-body-paragraph jk jl hi jm b jn ly jp jq jr lz jt ju jv ma jx jy jz mb kb kc kd mc kf kg kh hb bi translated">管理AWS资源。我们还需要IAM用户的凭证，这可以通过使用AWS CLI或手动创建包含以下内容的凭证文件<code class="du li lj lk ll b">~/.aws/credentials</code>来完成，(更多信息，请参考<a class="ae md" href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html" rel="noopener ugc nofollow" target="_blank">这里的</a></p><pre class="lm ln lo lp fd lq ll lr ls aw lt bi"><span id="6d29" class="ku in hi ll b fi lu lv l lw lx">[default]<br/>aws_access_key_id = YOUR_ACCESS_KEY<br/>aws_secret_access_key = YOUR_SECRET_KEY</span></pre><p id="5d1a" class="pw-post-body-paragraph jk jl hi jm b jn ly jp jq jr lz jt ju jv ma jx jy jz mb kb kc kd mc kf kg kh hb bi translated">接下来，我们可以导入boto3库并定义一个函数来创建一个实例。这方面的基本参数(如映像ID、实例类型、安全组和密钥对)存储为字符串。这里，我给出了我的控制台中已经存在的安全组和密钥对，但是如果您没有它们，您可以使用python程序创建密钥对和安全组，或者在AWS控制台中手动创建。</p><pre class="lm ln lo lp fd lq ll lr ls aw lt bi"><span id="f49a" class="ku in hi ll b fi lu lv l lw lx">import boto3</span><span id="4d8c" class="ku in hi ll b fi me lv l lw lx">def createEC2Instance():<br/>    image = 'ami-06a0b4e3b7eb7a300'<br/>    instType = 't2.micro'<br/>    secGroup = 'default'<br/>    keyPair = 'testKey'</span></pre><p id="fbf3" class="pw-post-body-paragraph jk jl hi jm b jn ly jp jq jr lz jt ju jv ma jx jy jz mb kb kc kd mc kf kg kh hb bi translated">接下来，我们可以使用<code class="du li lj lk ll b">boto3.resource()</code>方法初始化EC2资源对象。然后，我们可以使用资源对象和传递上述参数的<code class="du li lj lk ll b">create_instances()</code>方法来创建实例。我还将实例ID值保存在变量<code class="du li lj lk ll b">instId</code>中，以便使用<code class="du li lj lk ll b">create_tags()</code>方法向我的实例添加标签。</p><pre class="lm ln lo lp fd lq ll lr ls aw lt bi"><span id="cfad" class="ku in hi ll b fi lu lv l lw lx">    ec2 = boto3.resource('ec2')<br/>    print("Creating EC2 Instance...")<br/>    instance = ec2.create_instances(<br/>    ImageId=image, InstanceType=instType, SecurityGroups=[secGroup],<br/>    MinCount=1, MaxCount=1, KeyName=keyPair)<br/>    <br/>    instId = instance[0].id<br/>    ec2.create_tags(<br/>        Resources=[instId],<br/>        Tags=[<br/>            {<br/>                'Key': 'Name',<br/>                'Value': 'testInstance'<br/>            }<br/>        ]<br/>    )</span></pre><p id="b2cc" class="pw-post-body-paragraph jk jl hi jm b jn ly jp jq jr lz jt ju jv ma jx jy jz mb kb kc kd mc kf kg kh hb bi translated">您可以选择使用boto3 SDK添加AWS的许多其他功能，比如创建一个EBS卷并将其附加到实例，创建安全组、S3桶、存储对象等。在此参考boto3文档<a class="ae md" href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html" rel="noopener ugc nofollow" target="_blank">。</a></p></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><p id="d443" class="pw-post-body-paragraph jk jl hi jm b jn ly jp jq jr lz jt ju jv ma jx jy jz mb kb kc kd mc kf kg kh hb bi translated">希望这对你有用。请随意检查我上传到GitHub上的全部代码，其中包含一些发送电子邮件和WhatsApp消息的功能。</p><p id="529f" class="pw-post-body-paragraph jk jl hi jm b jn ly jp jq jr lz jt ju jv ma jx jy jz mb kb kc kd mc kf kg kh hb bi translated"><strong class="jm hj">谢谢:)</strong></p></div></div>    
</body>
</html>