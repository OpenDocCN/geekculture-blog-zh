<html>
<head>
<title>The Magic of Feed-Forward. Deep Learning with PyTorch Part #3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">前馈的魔力。PyTorch深度学习第3部分</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/the-magic-of-feed-forward-deep-learning-with-pytorch-part-3-2135aa74cb38?source=collection_archive---------21-----------------------#2021-04-25">https://medium.com/geekculture/the-magic-of-feed-forward-deep-learning-with-pytorch-part-3-2135aa74cb38?source=collection_archive---------21-----------------------#2021-04-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="6137" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">征服深度学习的基础</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/f9e6cb0cd670a4b403bc76b56c790aab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Lcvy4RspyTuFk_Tu"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@carsive?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Ahmed Hasan</a> on <a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="7e61" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">知道什么是人工神经网络(ANN)是一回事，知道它实际上如何工作是另一回事。如果你想利用深度学习来构建酷项目，理解人工神经网络是必不可少的。ann的概念可以应用于几乎所有其他类型的神经网络。谈到人工神经网络，有两个主要概念需要理解:<strong class="jq hj">前馈和反向传播。</strong>这两个概念都需要大量的深入理解，所以我会把它们拆分成不同的文章。在本文中，我们将接触前馈概念。公平的警告，为了理解前馈，你需要理解基本的矩阵/向量运算。如果你需要复习，这里有一些参考资料:<a class="ae jn" href="http://math.mit.edu/~dyatlov/54summer10/matalg.pdf" rel="noopener ugc nofollow" target="_blank">基础矩阵运算复习</a>。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es kk"><img src="../Images/51b776a5050ac9899c12032d3845b3c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Fdc1aBpn-XEbHxjL"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@urielsc26?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Uriel SC</a> on <a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="8a4e" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">前馈</h1><p id="ed37" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">前馈是一个相当简单的概念。本质上，你所做的就是通过你的网络发送你的数据。换句话说，您正在通过输入层将数据发送到隐藏层，并最终发送到输出层。这里有一个很好的形象化的例子来说明这个概念:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es li"><img src="../Images/39c0025fe6b6d3fcc7f6331e2307ba9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*PjXtY1NKfyZO4m0z8SKsdA.jpeg"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">A Feed-Forward Neural Network, Image by <a class="ae jn" href="https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Architecture/feedforward.html" rel="noopener ugc nofollow" target="_blank">Stanford University</a>, Public Domain</figcaption></figure><p id="666f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如上图所示，<strong class="jq hj">前馈本质上是获取你的输入(你的特征)并通过你的人工神经网络得到你的输出的过程。然而，在这个讨论中仍然有一个问题没有得到回答:在每个节点上发生了什么？接下来我们来回答这个问题。</strong></p><h2 id="3425" class="lj km hi bd kn lk ll lm kr ln lo lp kv jx lq lr kx kb ls lt kz kf lu lv lb lw bi translated">每个节点发生了什么？</h2><p id="4188" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">发生在每个节点的计算非常非常重要。每个节点对其输入进行加权求和，然后通过激活函数进行求和。迷茫？别担心，让我们把它拆开。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lx"><img src="../Images/ada50b0a1b19c734a96ba4e43ca4b007.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*wGipju2ju3g6DnSNO-tMnQ.jpeg"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Examples of Cat &amp; Dog Images, Image by Adrian Rosebrock on <a class="ae jn" href="https://www.pyimagesearch.com/2016/08/08/k-nn-classifier-for-image-classification/" rel="noopener ugc nofollow" target="_blank">PyImageSearch</a></figcaption></figure><p id="a149" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">每个输入都有一个权重。这是因为一些输入可能比其他输入更重要/更不重要。例如，如果我正在构建一个神经网络来对猫和狗的图像进行分类，我会更关心眼睛、耳朵等的形状。而不是图像是在室内还是室外等。我希望你不要仅仅根据地点(室内或室外)来决定什么是猫或狗。我想你会根据每种动物的特征，比如眼睛或耳朵，来判断某样东西是猫还是狗。很明显，正如你所看到的，给每个输入相同的权重是不合理的。有些投入肯定比其他投入更值得重视。</p><p id="72b6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">为了将权重应用于给定节点的输入，我们执行加权求和。如果你熟悉机器学习，你的脑海中可能会有一个灯泡熄灭。这是因为这个过程和线性回归一模一样！</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ly"><img src="../Images/dc7945b105d683aec873dfc46a1fa62c.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*8USrZyzzH39TZI4SII3h3A.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Linear Regression Equation, Image Reference: <a class="ae jn" href="http://sites.utexas.edu/sos/guided/inferential/numeric/bivariate/cor/" rel="noopener ugc nofollow" target="_blank">Pearson Correlation and Linear Regression</a></figcaption></figure><p id="d203" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">左边的图像显示了一个基本的一元线性方程。b0代表偏置项，b1代表应用于输入X的权重，Y是您的输出。这是在只有1个输入且没有激活功能的节点上发生的情况。在真实的场景中，您的节点会有很多很多的输入。这样，我们可以将这个方程展开成如下:<strong class="jq hj"> Y = b + W1*X1 + W2*X2 + … +WnXn。</strong> Wn代表第n个输入x的第n个权重。可以使用线性代数简化该方程(注意，权重&amp;输入通常出现在矩阵中)。当我们将权重&amp;输入视为矩阵时，我们得到以下等式:<strong class="jq hj"> W^T*X + b </strong>。注意^T代表转置(我假设你知道转置是什么意思，但是如果你不知道，请参考下面的参考资料)。此外，注意“W^T * X”部分可以根据权重矩阵&amp;输入矩阵的形状不时地重新排列。这种计算在人工神经网络的每个节点上进行。</p><p id="c5ab" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在我们已经对每个节点的加权求和有了具体的了解，让我们对激活函数有一个具体的了解。</p><h2 id="5272" class="lj km hi bd kn lk ll lm kr ln lo lp kv jx lq lr kx kb ls lt kz kf lu lv lb lw bi translated">激活功能</h2><p id="9e5e" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">激活函数非常非常容易理解。它本质上是一个函数，根据函数的特性接受一些输入并提供一些输出。例如，常见的激活函数是sigmoid函数。sigmoid函数以将其值压缩在0和1之间而自豪。同样，有许多激活函数对您的输入执行某种转换。考虑到这一点，现在我想介绍一下观察单个节点上发生的情况的正式数学方法:</p><p id="94e9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">一个节点的输出= y(W^T * X + b) </strong></p><ul class=""><li id="d450" class="lz ma hi jq b jr js ju jv jx mb kb mc kf md kj me mf mg mh bi translated">y =激活函数</li><li id="f1b4" class="lz ma hi jq b jr mi ju mj jx mk kb ml kf mm kj me mf mg mh bi translated">W =权重矩阵</li><li id="ef9f" class="lz ma hi jq b jr mi ju mj jx mk kb ml kf mm kj me mf mg mh bi translated">X =输入矩阵</li><li id="e43e" class="lz ma hi jq b jr mi ju mj jx mk kb ml kf mm kj me mf mg mh bi translated">b =偏差项</li></ul><p id="7504" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">本质上，你在取你的加权和&amp;通过一个激活函数。关于这个问题，我最后想说两点:</p><ul class=""><li id="4b83" class="lz ma hi jq b jr js ju jv jx mb kb mc kf md kj me mf mg mh bi translated">没有必要有激活功能。你的安没有它也能工作得很好。但是，激活函数允许您转换节点的输出。这些转换使你的人工神经网络有更好的性能。</li><li id="aed1" class="lz ma hi jq b jr mi ju mj jx mk kb ml kf mm kj me mf mg mh bi translated">每个隐藏层上激活函数的选择取决于你的问题。</li></ul><h2 id="7188" class="lj km hi bd kn lk ll lm kr ln lo lp kv jx lq lr kx kb ls lt kz kf lu lv lb lw bi translated">最终意见</h2><p id="1c34" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">前馈是一个需要理解的重要概念。话虽如此，我还是在这里列出了一些要点和概念。请注意，尽管我已经列出了一些关键概念，但如果您还没有阅读前馈部分，我还是强烈建议您阅读一下。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mn"><img src="../Images/a696d2b338ea5c5d48090b1476e7fc4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1PCn89i8fn4Be_de"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@jaye_haych?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jaye Haych</a> on <a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="c050" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> <em class="mo">关键概念:</em> </strong></p><ul class=""><li id="0850" class="lz ma hi jq b jr js ju jv jx mb kb mc kf md kj me mf mg mh bi translated">前馈指的是通过人工神经网络(数据-&gt;输入-&gt;隐藏层-&gt;输出层)发送数据</li><li id="3fe4" class="lz ma hi jq b jr mi ju mj jx mk kb ml kf mm kj me mf mg mh bi translated">前馈过程通常用于进行预测和反向传播(我们将在以后的文章中讨论这个概念)。</li><li id="85d7" class="lz ma hi jq b jr mi ju mj jx mk kb ml kf mm kj me mf mg mh bi translated">在人工神经网络的每个节点上，节点执行加权求和，并通过一个激活函数进行求和。数学上看起来是这样的:节点的输出=激活function(Weights^T *输入+偏置)。</li><li id="4b7b" class="lz ma hi jq b jr mi ju mj jx mk kb ml kf mm kj me mf mg mh bi translated">激活函数变换加权求和，使得它可以针对问题的上下文被适当地变换。</li></ul><p id="aa88" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果你已经完成了这篇文章，我感谢你。看到人们阅读我的内容并学习新的东西对我来说真的很重要。请在下面的评论中告诉我你对这篇文章的想法。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mp"><img src="../Images/f607ac1cc7be7a591bdc9184326ba95e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WkL8SJGf-FvglyLH"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@mike_swigunski?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Mike Swigunski</a> on <a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="3ae7" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">关于作者</h1><p id="2f5d" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">我是罗格斯大学新不伦瑞克分校的本科生，正在攻读计算机科学和认知科学专业。此外，我正在辅修工商管理和数据科学证书。我已经应用机器学习一年多了，最近我开始涉足深度学习。我对人工智能的力量非常感兴趣，迫不及待地想与社区分享我的学习成果！请随时通过LinkedIn联系我，或者给我发电子邮件到jinal.shah2821@gmail.com。</p></div></div>    
</body>
</html>