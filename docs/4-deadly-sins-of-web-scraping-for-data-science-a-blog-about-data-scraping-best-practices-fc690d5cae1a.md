# 数据科学网络搜集的 4 大罪:关于数据搜集最佳实践的博客

> 原文：<https://medium.com/geekculture/4-deadly-sins-of-web-scraping-for-data-science-a-blog-about-data-scraping-best-practices-fc690d5cae1a?source=collection_archive---------16----------------------->

想知道在网页抓取中不要做什么吗？看下面！

![](img/d91f9e225fba51b4c59037459c748865.png)

Photo by [Igor Miske](https://unsplash.com/@igormiske?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

Web 抓取是许多数据科学项目的重要组成部分。当你发现你没想到会发现的信息时，结果会令人大开眼界。然而，当事情出错时，它们会变得非常糟糕。抓取数据的企业应该努力避免四宗罪。

Web 抓取已经成为数据科学和机器学习不可或缺的一部分。这是我们如何从互联网上访问和收集数据，并在我们的算法和模型中使用它，这是一项不断增长和改进的技能。但是，网络抓取并不是没有复杂性，尤其是当你处理大量数据的时候。

# 什么是网页抓取？

网络抓取是一种从网站提取数据的方式。这些数据可用于进一步分析。这听起来很简单，但事实是网络抓取有很多争议，因为它经常被视为侵犯隐私或损害主机站点。另一方面，如果做得好的话，网页抓取会非常有用。什么是“做得对”？好问题！它通常是当网页抓取过程是以一种不伤害主机站点的方式完成的。有些人可能会认为，因为网络抓取违反了网站的服务条款，所以这本身就是错误的，但事实上，这通常是出于善意。它可以以一种不会对主机站点造成损害的方式来完成。人们想要从网站上抓取数据的原因有很多，但在这篇博文中，我们将讨论数据科学的网络抓取。

Web 抓取，也称为 web 收获或 web 数据提取，是一种从网站提取信息的计算机软件技术。网络抓取软件可以使用超文本传输协议直接访问万维网，或者通过网络浏览器访问万维网。术语“网页抓取”是用词不当，因为该软件并不从网站本身“抓取”信息，而是从浏览器缓存或网页代理缓存中抓取信息。网络抓取的做法已经引起了关于版权和 robots.txt 的法律问题。

![](img/d129ec8068e74fb85ab11cacbf62f67c.png)

Photo by [Jefferson Santos](https://unsplash.com/@jefflssantos?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

# 什么是网络抓取最佳实践？

网络抓取是一种用于从互联网上获取数据的技术。Web 抓取的用途非常广泛，例如用于数据科学。网上有很多信息，有的比有的好。一些网站不允许收集数据，这篇文章将会解释为什么会这样，以及如何解决这个问题。从互联网上抓取数据时，你必须遵守一些规则。这些规则会保护你不被黑，也保护网站不被黑。从互联网上抓取数据是一种黑客行为。网络抓取是一个非常强大的工具，如果使用不当，可能会给你或你的企业带来麻烦。

没有什么比试图为您的数据科学或机器学习项目收集数据，却发现您的数据已损坏或不可读更糟糕的了。数据是任何伟大的数据科学项目的关键，但数据不必是完美的。使用正确的工具，你可以获取不完美的数据，但仍然可以收集有用的见解。数据抓取是使用自动化脚本从网页中提取数据的过程。虽然它很容易使用，但也很容易出错。数据搜集有几种可能出错的方式，但也有几种避免出错的方式。本指南将涵盖最常见的陷阱，以避免。

众所周知，网络抓取是一种低效的数据收集方式。但是为什么会这样呢？在数据科学的背景下，网络搜集是一种通过脚本从网站收集数据的方式，该脚本从网站上的页面读取内容，然后将数据存储在数据库或电子表格中。这是一种从网站上收集数据的快速而简单的方法，但这是有代价的。在本文中，我想概述一些在使用数据科学的 web 抓取时可能会遇到的常见问题。人们经常将 web 抓取用于数据科学，因为这是一种从网站收集大量结构化数据的好方法。但是如果你做的不对，会导致一些严重的问题。

![](img/47e1d12570e55d95f05ee236ddcb4e92.png)

Photo by [Nick Fewings](https://unsplash.com/@jannerboy62?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

# 网络抓取的 4 大罪

## 1.打破数据科学的网络搜集标准规则

数据抓取是一种从网络上获取数据的流行方式。然而，这并不总是容易做到的，会给你的数据和网站带来很多问题。在抓取网页时，数据抓取者需要记住许多事情。在这里，我们讨论了网络抓取的四个重要方面，你在做这项工作时应该牢记在心。Web 抓取是从 web 中提取有用数据的一种有用方式。但是，它也可以用来从网络上提取任何信息，包括您的登录信息，您的信用卡号码，您的电话号码，甚至可能是您的社会安全号码。如果你知道正确的技术，你可以很容易地收集这些数据。这里有一些从网上搜集数据的基本技巧，但是请记住，在做这些工作时，你应该小心。

Web 抓取是收集数据的最简单的方法，但是它会导致几个问题。网页抓取工具并不总是理解网站的结构。这可能导致对数据的误解。web scraper 也可能意外地使服务器过载，从而导致 scraper 被阻塞。有些网站刮起来会很慢。这似乎是一个小问题，但它可以导致刮刀运行超过其时间限制。抓取工具可能无法收集页面上的所有数据。一些网站试图通过增加访问代码的难度来阻止网络抓取。网页抓取工具会被 JavaScript 或 cookies 屏蔽。

Web 抓取是数据科学家从 web 中提取数据的最强大的工具之一。Web 抓取用于自动从网页中提取数据。网络抓取可用于从几乎任何类型的网站提取数据，包括博客、新闻网站、论坛和社交媒体网站。Web 抓取用于为许多不同的目的提取数据，包括数据挖掘、数据聚合、web 索引和信息过滤。

![](img/936bc1fd1cd947395078678392644f1c.png)

Photo by [Roman Synkevych](https://unsplash.com/@synkevych?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

## 2.GitHub 上的分叉网页

在过去的几年里，网络抓取已经得到了很多关注。虽然这种方法在互联网早期就已经存在，但随着越来越多的数据科学应用程序的开发，尤其是随着大数据和数据科学应用程序的兴起，这一主题越来越受到关注。web 抓取最常见的应用之一是数据抓取。企业和组织广泛使用数据抓取从 web 和 Internet 中提取数据。与传统的数据收集方法相比，网络搜集不仅高效，而且节省成本。

网络搜集是从互联网上收集数据的一种很好的方式，但它也可能让你与网站的法律团队发生冲突。那么，考虑到风险，数据科学家应该做些什么呢？一种选择是使用像 Scrapy 这样的库。Scrapy 是一个 Python 库，可以让你编写一个模仿人类用户代理的网络爬虫。Scrapy 包括一个命令行工具，可以让你轻松地从网站下载网页。它还允许您使用浏览器从网站下载网页。

抓取网页需要大量的工作和代码。作为一名数据科学家，您可能已经知道，很多时候您需要从 web 上抓取数据来创建数据集。这是数据科学过程中必不可少的一部分，但这并不意味着它是微不足道的。事实上，从网页中提取数据可能是一个困难的过程。但是如果有一种方法可以从网上抓取数据而不需要所有的艰苦工作呢？如果您可以使用已经构建好的工具或流程来为您完成繁重的工作，会怎么样？它存在！这叫做“分叉网页”。分叉一个网页基本上意味着你正在从一个像 GitHub 或者 Bitbucket 这样的站点克隆一个网页。这是一个非常简单的过程，任何人都可以做。

当你编写代码来抓取网页数据时，有很多事情可能会出错。最常见的陷阱之一是分叉。如果你不小心，你的代码很容易分叉你抓取的网页，这是一个坏消息。对于那些不熟悉这个术语的人来说，“分叉”与网页在互联网上的加载方式有关。网页是使用 HTML、CSS 和 JavaScript 构建的。HTML 负责页面的内容。CSS 负责页面的显示属性，JavaScript 负责页面上的动态功能。当您查看网页时，您的浏览器会检查是否拥有显示该网页所需的所有资源。它通过从服务于该页面的 web 服务器加载它们来实现这一点。加载的每个资源被称为“脚本标签”。您的浏览器将按顺序加载这些资源，如果其中一个资源损坏，您的浏览器将停止加载页面，直到脚本标签被修复。

## 3.使用 Scrapy

Web 抓取或 web 采集是一种探索性的数据提取过程，其中一个计算机系统自动(即无需人工干预)访问另一个计算机系统的在线数据资源。网络抓取软件可以通过使用由系统暴露的 API(应用程序编程接口)或者通过使用底层网络协议(例如，网络爬虫可以通过使用 HTTP 请求页面)来访问数据源。

Scrapy 是一个网页抓取框架，用 Python 写的。这是一个从网站上提取你需要的数据的工具——一个非常强大的工具。Scrapy 是一个快速的高级屏幕抓取和网页抓取框架，用于抓取网站并从其页面中提取结构化数据。它可以用于广泛的目的，从数据挖掘到监控和自动化测试。Scrapy 是开源的，并且是在 BSD 许可下授权的。

网络抓取或网络采集是从网站提取数据的过程。Web 抓取器使用各种技术从 web 中提取和处理数据。最常见和众所周知的技术是屏幕抓取，即程序从网站的 HTML 源代码中复制数据，然后分析和处理数据。这种技术被许多公司用来收集数据进行分析和商业智能。例如，亚马逊使用一个网络抓取器为其在线商店收集产品数据。然而，网络抓取也被用于更邪恶的目的。过去，网络犯罪分子利用网络抓取从网站上窃取数据，然后卖给出价最高的买家。如果你认为网络抓取只有大公司才使用，那就再想想吧！任何稍懂代码的人都可以使用 Web scrapers。

![](img/bc4529355cfa26670828bc2fb5953c1f.png)

Photo by [Stefan Cosma](https://unsplash.com/@stefanbc?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

## 4.重复内容

重复的内容或重复的信息会给你的网站带来问题。如果您的网站包含重复的内容，这意味着相同的内容可以在两个或更多的地方使用。如果你因为“低质量”的内容而受到搜索引擎算法的惩罚，这可能是个问题。如果有人先这么做了，而你最终建立了一个重复竞争对手内容的网站，这也是一个问题。如果您最终从其他来源复制和粘贴内容，然后在您的网站上使用该内容，这种内容复制也会导致法律问题。

内容重复是当今很多站长面临的问题。你可能听说过重复的内容，或者在这个博客上读到过。但是什么是重复内容，它如何影响你的网站和你的搜索引擎排名？重复内容是指发布在网站的多个页面上的内容，或者发布在多个网站上的重复内容。重复会给搜索引擎爬虫和索引器造成混乱，而且会影响你网站的排名。重复的内容和重复的页面是不同的。重复页面是具有相同内容的页面。重复会在很多方面影响你网站的排名，也会带来搜索引擎的惩罚。像谷歌、雅虎和必应这样的搜索引擎有一个重复内容过滤器，如果有大量重复内容，它会惩罚一个网站。网站因重复内容而受到的惩罚包括:-网站加载时间延长-不允许搜索引擎爬虫对网站进行索引-网站排名下降-被搜索引擎禁止

![](img/f41a55592b83cd08545935304b91a1ec.png)

Photo by [Markus Spiske](https://unsplash.com/@markusspiske?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

# 网络抓取最佳实践——如何做好？

网络抓取最佳实践:如何做好？对于大多数数据科学项目来说，数据收集是最难的部分。互联网为分析提供了几乎无限的数据来源，但很难收集、处理和分析所有的数据。人们很容易被互联网上的大量数据淹没。因此，您可能会觉得需要收集大量数据来全面了解您的问题领域。这可能非常昂贵和耗时，甚至对某些项目来说是不可能的。

您可以使用网络爬虫或网络爬虫从网页中获取数据。要从网站上获取数据，web scraper 是更好的选择。Web scraper 是一个从网站下载信息并保存的计算机程序。换句话说，网络爬虫从网站或其他在线来源收集信息。这是一个从网上下载各种用途的数据的软件。

网络抓取是数据科学中的一个大问题。这是获取数据科学项目所需数据的最具成本效益的方式之一。网络抓取的问题是不容易做好。网络是一个混乱的地方。你需要的信息通常分散在互联网上。网络搜集允许你收集这些信息。使用正确的工具，您可以自动化整个过程。然而，合适的工具并不便宜。网络抓取工具的市场是巨大的。有可以买的工具，有可以租的工具，甚至有可以租的工具。问题是，当你使用这些工具时，你永远不知道你会遇到什么。这些工具中的大多数是由不属于数据科学甚至编程行业的公司开发的。通常，这些公司从事向企业销售线索的业务。创建这些工具是为了从网站上搜集信息。通过这些工具获得的信息通常不可靠，并且很难用于数据科学项目。

![](img/d45250d15ed6332bfbc2e566009bf08a.png)

Photo by [Alexas_Fotos](https://unsplash.com/@alexas_fotos?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

> **结论—**

我们希望你喜欢这篇关于网络抓取的 4 大罪的博客。这是过去几年媒体一直强调的一个主题。随着数据科学越来越受欢迎，对于公司来说，确保他们在数据搜集方面遵循最佳实践是非常重要的。这篇博文强调了在数据科学中进行网络搜集时应该遵循的一些注意事项。