<html>
<head>
<title>Step by Step Decision Tree: ID3 Algorithm From Scratch in Python [No Fancy Library]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分步决策树:Python中从头开始的ID3算法[没有花哨的库]</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/step-by-step-decision-tree-id3-algorithm-from-scratch-in-python-no-fancy-library-4822bbfdd88f?source=collection_archive---------0-----------------------#2021-03-27">https://medium.com/geekculture/step-by-step-decision-tree-id3-algorithm-from-scratch-in-python-no-fancy-library-4822bbfdd88f?source=collection_archive---------0-----------------------#2021-03-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7ff9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们都知道决策树的算法:ID3。我们中的一些人可能已经出于学术目的用数学方法完成了算法。如果你还没有，没关系，在这里我们也将讨论基础知识。该算法非常简单明了。所以，我们开始吧！</p><h1 id="9565" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">目标:</h1><ol class=""><li id="e530" class="kb kc hi ih b ii kd im ke iq kf iu kg iy kh jc ki kj kk kl bi translated">了解<strong class="ih hj"> ID3算法</strong>的基础知识</li><li id="dd1c" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">用python加载<em class="kr"> csv </em>数据，(使用<em class="kr">熊猫</em>库)</li><li id="7be4" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">使用<strong class="ih hj"> ID3算法</strong>从头开始训练和构建<strong class="ih hj">决策树</strong></li><li id="fa7d" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">从树上预测</li><li id="7363" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">找出准确性</li></ol><h1 id="8af9" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤1:观察数据集</h1><p id="4517" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">首先，我们应该查看我们的数据集，<em class="kr">‘打网球</em>’。这是一个非常著名的数学例子数据集。是啊！你猜对了！我们将使用这个简单的数据集，以便您可以更容易地理解python实现。<br/>数据集的链接:<a class="ae kv" href="https://www.kaggle.com/tareqjoy/trainplaytennis" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">https://www.kaggle.com/tareqjoy/trainplaytennis</strong></a></p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es kw"><img src="../Images/6e78a503d0ee085586d429014174255b.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*I2Gvq_qMYO8uTw8GVW63Wg.jpeg"/></div><figcaption class="le lf et er es lg lh bd b be z dx">Table 1: Play Tennis Dataset</figcaption></figure><blockquote class="li lj lk"><p id="842e" class="if ig kr ih b ii ij ik il im in io ip ll ir is it lm iv iw ix ln iz ja jb jc hb bi translated"><em class="hi">观察数据集后我们可以说:</em> <br/> <strong class="ih hj"> <em class="hi">特征</em> </strong> : <em class="hi">展望、温度、湿度、</em> <br/> <strong class="ih hj"> <em class="hi">标签</em> </strong> : <em class="hi">打网球(我们要预测的输出特征)</em> <br/> <strong class="ih hj"> <em class="hi">类</em> </strong> : <em class="hi">是，否(标签的唯一值)</em></p></blockquote><h1 id="a595" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤2:导入必要的基本python库</h1><p id="794b" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">我们将使用<em class="kr"> pandas </em>操作数据集，使用<em class="kr"> numpy </em>库进行数学计算。</p><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="50f4" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤3:读取数据集</h1><p id="cf5f" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">我们将读取数据集(csv文件)并将其加载到pandas dataframe中。下面可以看到，<em class="kr"> train_data_m是</em>我们的数据帧。<br/>用<em class="kr"/>data frame的<em class="kr"> head() </em>方法我们可以查看前5行。</p><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><p id="00c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出将是:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lq"><img src="../Images/944d9039b2a208b949e9e888839766b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*qL9odAw4TWLkNsyqScWXmA.jpeg"/></div><figcaption class="le lf et er es lg lh bd b be z dx">The output of head() method</figcaption></figure><h1 id="82b9" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤4:计算整个数据集的熵</h1><p id="1c2a" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">在数学中，我们必须首先计算整个数据集的熵，如下所示:</p><pre class="kx ky kz la fd lr ls lt lu aw lv bi"><span id="568d" class="lw je hi ls b fi lx ly l lz ma">Total row = 14<br/>Row with "Yes" class = 9<br/>Row with "No" class = 5</span><span id="7dc1" class="lw je hi ls b fi mb ly l lz ma">Complete entropy of dataset is -<br/>H(S) = - p(Yes) * log2(p(Yes)) - p(No) * log2(p(No))<br/>     = - (9/14) * log2(9/14) - (5/14) * log2(5/14)<br/>     = - (-0.41) - (-0.53)<br/>     = 0.94</span></pre><p id="9374" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，这里我们将和上面的等式做同样的事情。</p><blockquote class="li lj lk"><p id="a8b6" class="if ig kr ih b ii ij ik il im in io ip ll ir is it lm iv iw ix ln iz ja jb jc hb bi translated"><em class="hi">方法描述:<br/>计算整个数据集的熵。<br/></em><strong class="ih hj"><em class="hi">train _ data</em></strong><em class="hi">:熊猫dataframe<br/></em><strong class="ih hj"><em class="hi">label</em></strong><em class="hi">:string，data frame的标签名称(= </em>打网球<em class="hi">)<br/></em><strong class="ih hj"><em class="hi">class _ list</em></strong><em class="hi">:list，标签的唯一类别(=[ </em> Yes <em class="hi">，</em> No<br/>  <strong class="ih hj"> <em class="hi">返回</em> </strong> <em class="hi">:浮点，计算整个数据帧的熵(=0.94) </em></p></blockquote><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="e0b9" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤5:计算过滤数据集的熵</h1><p id="be92" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">使用步骤1的表格，特征<strong class="ih hj"> <em class="kr">前景</em> </strong>的数学计算如下:</p><pre class="kx ky kz la fd lr ls lt lu aw lv bi"><span id="bc70" class="lw je hi ls b fi lx ly l lz ma">Categorical values of Outlook - Sunny, Overcast and Rain</span><span id="74d3" class="lw je hi ls b fi mb ly l lz ma">Total count of row containing:<br/>  Sunny = 5<br/>  Sunny &amp; Yes = 2<br/>  Sunny &amp; No = 3</span><span id="f24d" class="lw je hi ls b fi mb ly l lz ma">&gt;&gt; H(Outlook=Sunny) = -(2/5)*log(2/5)-(3/5)*log(3/5) = 0.971</span><span id="87c3" class="lw je hi ls b fi mb ly l lz ma">Total count of row containing:  <br/>  Rain = 5<br/>  Rain &amp; Yes = 3<br/>  Rain &amp; No = 2</span><span id="b02e" class="lw je hi ls b fi mb ly l lz ma">&gt;&gt; H(Outlook=Rain) = -(3/5)*log(3/5)-(2/5)*log(2/5) = 0.971</span><span id="27f4" class="lw je hi ls b fi mb ly l lz ma">Total count of row containing:  <br/>  Overcast = 4<br/>  Overcast &amp; Yes = 4<br/>  Overcast &amp; No = 0</span><span id="530a" class="lw je hi ls b fi mb ly l lz ma">&gt;&gt; H(Outlook=Overcast) = -(4/4)*log(4/4)-0 = 0</span></pre><p id="4a12" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意:我们必须对所有的特征做同样的处理，比如<strong class="ih hj"><em class="kr"/></strong><strong class="ih hj"><em class="kr">湿度</em> </strong>等等。<br/>等效的Python实现如下所示:</p><blockquote class="li lj lk"><p id="fe22" class="if ig kr ih b ii ij ik il im in io ip ll ir is it lm iv iw ix ln iz ja jb jc hb bi translated"><em class="hi">方法描述:<br/>计算特定特征的熵=值。<br/></em><strong class="ih hj"><em class="hi">feature _ value _ data:</em></strong><em class="hi">一个熊猫数据帧，它包含了一个特性的特定值的数据(例如。仅带有</em>Outlook<strong class="ih hj"><em class="hi"/></strong><em class="hi">=</em><em class="hi">)<br/></em><strong class="ih hj"><em class="hi">标签的数据:</em> </strong> <em class="hi">字符串，dataframe的标签名称(= </em>打网球<em class="hi">)<br/></em><strong class="ih hj"><em class="hi">class _ list:</em><br/>  <strong class="ih hj"> <em class="hi">返回:</em> </strong> <em class="hi">浮点，计算特征值dataframe的熵(例如。对于</em>展望<strong class="ih hj"><em class="hi"/></strong><em class="hi">=</em>晴天<em class="hi">，返回0.971) </em></strong></p></blockquote><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="115c" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤6:计算特征的信息增益</h1><p id="486b" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">在计算熵之后，我们必须计算该特征的信息增益。在数学上，首先我们要这样计算那个特征的信息:(对于特征<strong class="ih hj"> <em class="kr">展望</em> </strong> <em class="kr"> ) </em></p><pre class="kx ky kz la fd lr ls lt lu aw lv bi"><span id="0aed" class="lw je hi ls b fi lx ly l lz ma">I(Outlook) = p(Sunny) * H(Outlook=Sunny) + p(Rain) * H(Outlook=Rain) + p(Overcast) * H(Outlook=Overcast)<br/>= (5/14)*0.971 + (5/14)*0.971 + (4/14)*0<br/>= 0.693</span></pre><p id="7d84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们必须从数据集的总熵中减去它，总熵就是特征的信息增益。</p><pre class="kx ky kz la fd lr ls lt lu aw lv bi"><span id="9f60" class="lw je hi ls b fi lx ly l lz ma">Information Gain = H(S) - I(Outlook)<br/>                 = 0.94 - 0.693<br/>                 = 0.247</span></pre><p id="d9f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在python中，我们这样做了:</p><blockquote class="li lj lk"><p id="dcc8" class="if ig kr ih b ii ij ik il im in io ip ll ir is it lm iv iw ix ln iz ja jb jc hb bi translated"><em class="hi">方法描述:<br/>计算一个特征的信息增益。<br/></em><strong class="ih hj"><em class="hi">feature _ name:</em></strong><em class="hi">string，我们要查找信息增益的特征的名称(例如。</em>Outlook<em class="hi">)<br/></em><strong class="ih hj"><em class="hi">train _ data:</em></strong><em class="hi">a pandas dataframe<br/></em><strong class="ih hj"><em class="hi">label:</em></strong><em class="hi">string，data frame的标签名称(= </em>打网球<em class="hi">)<br/></em><strong class="ih hj"><em class="hi">class _ list:</em></strong><em class="hi">list</em><strong class="ih hj"><br/>  <strong class="ih hj"> <em class="hi">返回:</em> </strong> <em class="hi">计算特征的信息增益(例如。对于</em>展望<em class="hi">，返回0.247) </em></strong></p></blockquote><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="0692" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">第7步:寻找信息最丰富的特征(信息增益最高的特征)</h1><p id="3bc2" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">像<strong class="ih hj"> <em class="kr"> Outlook </em> </strong>特征一样，我们必须计算数据集中每个特征的信息增益。然后，我们必须选择具有最高信息增益的特征。经过数学计算后，我们将得到如下数值:</p><pre class="kx ky kz la fd lr ls lt lu aw lv bi"><span id="2554" class="lw je hi ls b fi lx ly l lz ma">Information gain:<br/>  Outlook = 0.247 (Highest value)<br/>  Temperature = 0.0292<br/>  Humidity = 0.153<br/>  Wind = 0.048</span></pre><p id="292d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于特征<strong class="ih hj"> <em class="kr"> Outlook </em> </strong>的值最高，所以它将被选为我们的树节点。</p><blockquote class="li lj lk"><p id="9fc8" class="if ig kr ih b ii ij ik il im in io ip ll ir is it lm iv iw ix ln iz ja jb jc hb bi translated"><em class="hi">方法描述:<br/>从当前数据集中寻找最有信息的特征。<br/></em><strong class="ih hj"><em class="hi">train _ data:</em></strong><em class="hi">a pandas dataframe<br/></em><strong class="ih hj"><em class="hi">label:</em></strong><em class="hi">string，data frame的标签名称(= </em>打网球<em class="hi">)<br/></em><strong class="ih hj"><em class="hi">class _ list:</em></strong><em class="hi">list</em><br/>  <strong class="ih hj"> <em class="hi">返回:</em> </strong> <em class="hi">字符串，特征名</em></p></blockquote><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="7872" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤8:向树中添加节点</h1><p id="f301" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">因为我们已经找到了具有最高信息增益的特征名称，所以我们必须在树中生成一个节点，并将其值作为分支。比如我们选择了<strong class="ih hj"> <em class="kr"> Outlook </em> </strong>，那么我们就要在树中添加<strong class="ih hj"> <em class="kr"> Outlook </em> </strong>作为节点，其值<em class="kr">晴天</em>或<em class="kr">下雨</em>或<em class="kr">阴天</em>作为分支。</p><p id="69e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">如果任何特征值仅代表一个类别(例如只有Play Tennis = 'Yes '或' No '的行，我们才能说特征值代表一个纯类。如果值不代表纯值，我们必须进一步扩展它，直到我们找到一个纯类。</strong></p><pre class="kx ky kz la fd lr ls lt lu aw lv bi"><span id="354c" class="lw je hi ls b fi lx ly l lz ma">Outlook is selected as Node.<br/>(Outlook = Sunny): Not pure class, contains both class Yes and No<br/>(Outlook = Overcast): Pure class, contains only one class Yes<br/>(Outlook = Rain): Not pure class, contains both class Yes and No</span></pre><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mc"><img src="../Images/bf37158e143ec40d5f7d76d2328adc16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZSl6SGLICNIZkRjPN0nTHQ.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx">The generated tree after finding Outlook</figcaption></figure><p id="45dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在选择了<strong class="ih hj">一个纯类* </strong>之后，我们必须从数据集中删除对应于特征值的行。例如:我们必须删除前景为<strong class="ih hj"><em class="kr"/></strong>=<em class="kr"/>的行。生成的数据集如下所示:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es mh"><img src="../Images/10de395f74847c39bf45675d181779d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*vPTyo2X_R4nNiVrl4O7g-Q.jpeg"/></div><figcaption class="le lf et er es lg lh bd b be z dx">The updated dataset (Without Outlook = Overcast)</figcaption></figure><blockquote class="li lj lk"><p id="1906" class="if ig kr ih b ii ij ik il im in io ip ll ir is it lm iv iw ix ln iz ja jb jc hb bi translated">注意:我们必须在下一次迭代中使用更新的数据集。《出埃及记》为了获得信息，我们必须将它用作train_data</p></blockquote><p id="37dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">等效的代码将是:</p><blockquote class="li lj lk"><p id="60cc" class="if ig kr ih b ii ij ik il im in io ip ll ir is it lm iv iw ix ln iz ja jb jc hb bi translated"><em class="hi">方法描述:<br/>生成特征的子树，并从数据集中删除feature = value。该树可能包含“？”如果树节点不是一个纯类，则作为一个值。<br/></em><strong class="ih hj"><em class="hi">feature _ name:</em></strong><em class="hi">string，我们要添加到树和收缩数据集的特征的名称(例如。</em>Outlook<em class="hi">)<br/></em><strong class="ih hj"><em class="hi">train _ data:</em></strong><em class="hi">a pandas dataframe<br/></em><strong class="ih hj"><em class="hi">label:</em></strong><em class="hi">string，data frame的标签名称(= </em>打网球<em class="hi">)<br/></em><strong class="ih hj"><em class="hi">class _ list:</em></strong><em class="hi">list</em><strong class="ih hj"><em class="hi"><br/> </em> <strong class="ih hj"> <em class="hi">返回:</em> </strong> <em class="hi">元组(dictionary，dataframe)，树节点及其分支和更新的数据集</em></strong></p></blockquote><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="fb13" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤9:执行ID3算法并生成树</h1><p id="41b2" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">现在，我们应该集合应该递归执行<strong class="ih hj">步骤4 </strong> — <strong class="ih hj">步骤8 </strong>的方法。所以，总的步骤是:</p><ul class=""><li id="1eb2" class="kb kc hi ih b ii ij im in iq mi iu mj iy mk jc ml kj kk kl bi translated">寻找信息最丰富的特征</li><li id="0cfe" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ml kj kk kl bi translated">制作一个以特征名和特征值作为分支的树节点<br/> -如果是纯类，添加叶节点(=类)到树节点<br/> -如果是不纯类，添加可扩展节点(= '？')到树节点</li><li id="256b" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ml kj kk kl bi translated">根据纯类收缩/更新数据集</li><li id="066f" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ml kj kk kl bi translated">将带有分支的节点添加到树中</li><li id="785a" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ml kj kk kl bi translated">展开下一个不纯类的分支(= '？')和更新的数据集</li></ul><p id="6cf7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">递归端点:</p><ul class=""><li id="2a81" class="kb kc hi ih b ii ij im in iq mi iu mj iy mk jc ml kj kk kl bi translated">更新后，数据集变为空</li><li id="eb75" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ml kj kk kl bi translated">没有可扩展的分支</li></ul><blockquote class="li lj lk"><p id="9aa4" class="if ig kr ih b ii ij ik il im in io ip ll ir is it lm iv iw ix ln iz ja jb jc hb bi translated"><em class="hi">方法描述:<br/>使用字典中的字典生成树。树的叶节点将是要素值=类名。结果树通过引用返回。<br/></em><strong class="ih hj"><em class="hi">root:</em></strong><em class="hi">字典，将包含通过递归子树得到的结果树，最初应该是一个空字典，递归调用后应该包含结果<br/></em><strong class="ih hj"><em class="hi">prev _ feature _ value:</em></strong><em class="hi">任意数据类型(Int或Float或String等。)取决于先前特征的数据类型，所指向的节点/特征的先前值，最初应该是None<br/></em><strong class="ih hj"><em class="hi">train _ data:</em></strong><em class="hi">a pandas dataframe<br/></em><strong class="ih hj"><em class="hi">label:</em></strong><em class="hi">string，data frame的标签名称(=</em>Play Tennis【T31)<br/><strong class="ih hj"><em class="hi">class _ list:</em></strong></p></blockquote><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="a3a7" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤10:找到标签的唯一类别并开始算法</h1><p id="822a" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">首先，我们需要了解预期的树应该是什么:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mm"><img src="../Images/2fe5795f7a2530ecdeb2d2622ae0fa7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y1IClqqHrR01Gy6efVhpJQ.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx">The complete tree</figcaption></figure><p id="1f14" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">找到类名后，我们可以开始调用ID3的递归树构建算法。</p><blockquote class="li lj lk"><p id="bde5" class="if ig kr ih b ii ij ik il im in io ip ll ir is it lm iv iw ix ln iz ja jb jc hb bi translated"><em class="hi">方法描述:<br/>生成id3树。<br/></em><strong class="ih hj"><em class="hi">train _ data _ m:</em></strong><em class="hi">a pandas dataframe<br/></em><strong class="ih hj"><em class="hi">label:</em></strong><em class="hi">string，data frame的标签名称(= </em>【打网球】<em class="hi">)<br/></em><strong class="ih hj"><em class="hi">returns:</em></strong><em class="hi"/></p></blockquote><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><p id="4314" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以这样开始id3:</p><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><p id="62f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们打印出<em class="kr">树</em>我们可以看到:</p><pre class="kx ky kz la fd lr ls lt lu aw lv bi"><span id="07ab" class="lw je hi ls b fi lx ly l lz ma">{<br/>   'Outlook': <br/>   {<br/>       'Rain': <br/>       {<br/>           'Wind': <br/>           {<br/>               'Strong': 'No', <br/>               'Weak': 'Yes'<br/>           }<br/>        },<br/>       'Sunny': <br/>       {<br/>           'Humidity': <br/>           {<br/>               'High': 'No', <br/>               'Normal': 'Yes'<br/>           }<br/>       },<br/>       'Overcast': 'Yes'<br/>    }<br/>}</span></pre><p id="b21d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">树/字典的根是<strong class="ih hj"> <em class="kr"> Outlook </em> </strong> <em class="kr">。</em>key的值是另一个字典，其中key对应于特性的值(= ' <em class="kr"> Rain </em>'，'<em class="kr">阴天</em>'，'<em class="kr"> Sunny </em>')等等。在每个嵌套字典的末尾是一个类名(= ' <em class="kr"> Yes </em>'，'<em class="kr"> No </em>')。<br/>我们可以看到生成的树与预期的输出完全相同。所以，我们的算法非常有效！</p><h1 id="22a9" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤11:从树中预测</h1><p id="09f5" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">我们已经生成了树。现在，我们可以用树来预测。我们将递归遍历嵌套字典，直到找到任何叶节点(=类)。请记住，字典的关键字是特性名称，它是字符串的数据类型，值或者是字典，这意味着我们必须更多地遍历树，或者是任何基本的数据类型，如字符串、整型或浮点型，这取决于类数据类型，这意味着它是一个叶节点。</p><p id="073d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们想预测<strong class="ih hj">前景</strong> = ' <em class="kr">雨</em>和<strong class="ih hj">风</strong> = ' <em class="kr">强</em>'，我们必须像这样遍历字典:</p><pre class="kx ky kz la fd lr ls lt lu aw lv bi"><span id="a014" class="lw je hi ls b fi lx ly l lz ma">tree[‘Outlook’][‘Rain’][‘Wind’][‘Strong’]</span></pre><blockquote class="li lj lk"><p id="4874" class="if ig kr ih b ii ij ik il im in io ip ll ir is it lm iv iw ix ln iz ja jb jc hb bi translated"><em class="hi">方法描述:<br/>从生成的树中预测使用特征集/实例<br/> </em> <strong class="ih hj"> <em class="hi">树:</em> </strong> <em class="hi">字典(of dictionary)，决策树<br/> </em> <strong class="ih hj"> <em class="hi">实例:</em> </strong> <em class="hi">一行或快照或数据集的特征集。该行不能包含标签<br/> </em> <strong class="ih hj"> <em class="hi">返回:</em> </strong> <em class="hi">任何数据类型(Int、Float或String等。)根据类的数据类型，预测的类</em></p></blockquote><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="16f5" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤12:评估测试数据集</h1><p id="40ab" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">为了评估模型，即树，我们需要一个带标签的测试数据集。然后，在预测之后，我们可以计算实际值和预测值之间的百分比差异。</p><blockquote class="li lj lk"><p id="7d7a" class="if ig kr ih b ii ij ik il im in io ip ll ir is it lm iv iw ix ln iz ja jb jc hb bi translated"><em class="hi">方法描述:<br/>通过对照预期结果进行测试来评估id3树的准确性<br/> </em> <strong class="ih hj"> <em class="hi">树:</em> </strong> <em class="hi">字典(的字典)，决策树<br/></em><strong class="ih hj"><em class="hi">test _ data _ m:</em></strong><em class="hi">一个熊猫数据帧/测试数据集<br/> </em> <strong class="ih hj"> <em class="hi">返回:</em> </strong> <em class="hi"> float，树的准确性</em></p></blockquote><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><h1 id="43d0" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤13:检查测试数据集并评估它</h1><p id="5927" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">测试数据集如下所示:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es mn"><img src="../Images/a7ae17760b866c2d60865826852b047d.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*8czkyLywUOqyxIBljyj2yg.jpeg"/></div><figcaption class="le lf et er es lg lh bd b be z dx">The test dataset</figcaption></figure><p id="6ee7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">测试数据集的链接:<a class="ae kv" href="https://www.kaggle.com/tareqjoy/testplaytennis" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">https://www.kaggle.com/tareqjoy/testplaytennis</strong></a><br/>在这里，<em class="kr">打网球</em>标签作为预期输出，它将用于找出与预测输出的差异。</p><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lo lp l"/></div></figure><p id="e854" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们打印准确度，我们将得到1.00，这意味着我们的准确度是100%正确的。但是，在大型数据集中，精确度可能不是这样。</p></div><div class="ab cl mo mp gp mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="hb hc hd he hf"><p id="ebdc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢阅读。</p><p id="6a83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以点击这个<strong class="ih hj"> Kaggle </strong>链接查看例子的全部代码(包括数据集):</p><div class="mv mw ez fb mx my"><a href="https://www.kaggle.com/tareqjoy/easy-id3" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab dw"><div class="na ab nb cl cj nc"><h2 class="bd hj fi z dy nd ea eb ne ed ef hh bi translated">Easy_ID3</h2><div class="nf l"><h3 class="bd b fi z dy nd ea eb ne ed ef dx translated">使用Kaggle笔记本探索和运行机器学习代码|使用来自多个数据源的数据</h3></div><div class="ng l"><p class="bd b fp z dy nd ea eb ne ed ef dx translated">www.kaggle.com</p></div></div><div class="nh l"><div class="ni l nj nk nl nh nm lc my"/></div></div></a></div><p id="aeda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">整个数学解释:</p><div class="mv mw ez fb mx my"><a href="https://iq.opengenus.org/id3-algorithm/" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab dw"><div class="na ab nb cl cj nc"><h2 class="bd hj fi z dy nd ea eb ne ed ef hh bi translated">利用ID3算法构建决策树预测天气</h2><div class="nf l"><h3 class="bd b fi z dy nd ea eb ne ed ef dx translated">ID3算法，代表迭代二分法3，是一种遵循贪婪方法的分类算法…</h3></div><div class="ng l"><p class="bd b fp z dy nd ea eb ne ed ef dx translated">iq.opengenus.org</p></div></div><div class="nh l"><div class="nn l nj nk nl nh nm lc my"/></div></div></a></div><p id="240f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在Linkedin上找到我:</p><p id="c2cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae kv" href="https://www.linkedin.com/in/tareqjoy/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/tareqjoy/</a></p></div></div>    
</body>
</html>