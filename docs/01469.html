<html>
<head>
<title>Build Your Own Big Data Ecosystem — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建您自己的大数据生态系统—第2部分</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/build-your-own-big-data-ecosystem-part-2-94c99dc3617?source=collection_archive---------13-----------------------#2021-04-11">https://medium.com/geekculture/build-your-own-big-data-ecosystem-part-2-94c99dc3617?source=collection_archive---------13-----------------------#2021-04-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="4d11" class="hg hh hi bd b fp hj hk hl hm hn ho dx hp translated" aria-label="kicker paragraph">详细的演练</h2><div class=""/><div class=""><h2 id="8790" class="pw-subtitle-paragraph io hr hi bd b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf dx translated">在Kubernetes上用Spark设置Jupyter笔记本</h2></div><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es jg"><img src="../Images/5b6fc7412e0bb0ece6601de0d17a6208.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PrTWFKf_WRCx297td2DYkA.jpeg"/></div></div></figure><p id="f98f" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">Jupyter Notebook是所有数据科学相关活动的首选IDE。它是全球大多数数据科学家和数据工程师的首选工具。Jupyter笔记本为运行Spark提供了非常好的支持，毫无疑问也将成为我们生态系统的IDE。</p><p id="f87b" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在本系列的第一部分中，我们了解了如何在Kubernetes上设置Spark的运行实例。在本文中，让我们探索在同一个Kubernetes集群中设置Jupyter notebook，并将其与我们的Spark实例挂钩。</p><h2 id="d3cb" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kb kz la lb kf lc ld le kj lf lg lh ho bi translated">简而言之，这个博客</h2><p id="0bc4" class="pw-post-body-paragraph js jt hi ju b jv li is jx jy lj iv ka kb lk kd ke kf ll kh ki kj lm kl km kn hb bi translated">我们将在之前的帖子(<a class="ae ln" rel="noopener" href="/geekculture/build-your-own-big-data-ecosystem-part-1-a19e4c778632">第1部分</a>)的基础上，采取以下措施将Jupyter Notebook集成到我们的集群中。</p><ul class=""><li id="f1ff" class="lo lp hi ju b jv jw jy jz kb lq kf lr kj ls kn lt lu lv lw bi translated">为Azure文件服务创建存储类以存储我们的笔记本</li><li id="6477" class="lo lp hi ju b jv lx jy ly kb lz kf ma kj mb kn lt lu lv lw bi translated">为将此存储类附加到我们的驱动程序pod创建一个永久卷声明</li><li id="0ad0" class="lo lp hi ju b jv lx jy ly kb lz kf ma kj mb kn lt lu lv lw bi translated">创建一个部署来启动副本集、驱动程序单元和一个便于驱动程序和执行器单元之间通信的服务。</li><li id="bc01" class="lo lp hi ju b jv lx jy ly kb lz kf ma kj mb kn lt lu lv lw bi translated">从笔记本用户界面创建一个Spark上下文，并查看实时运行的executor窗格。</li></ul><h1 id="f214" class="mc kp hi bd kq md me mf ku mg mh mi ky ix mj iy lb ja mk jb le jd ml je lh mm bi translated">先决条件</h1><ul class=""><li id="2bfc" class="lo lp hi ju b jv li jy lj kb mn kf mo kj mp kn lt lu lv lw bi translated">运行中的Kubernetes星团。(参见<a class="ae ln" rel="noopener" href="/geekculture/build-your-own-big-data-ecosystem-part-1-a19e4c778632">第一部分</a>)</li><li id="f6f1" class="lo lp hi ju b jv lx jy ly kb lz kf ma kj mb kn lt lu lv lw bi translated">Spark工作节点的Docker映像。(参见<a class="ae ln" rel="noopener" href="/geekculture/build-your-own-big-data-ecosystem-part-1-a19e4c778632">第一部分</a>)</li><li id="b727" class="lo lp hi ju b jv lx jy ly kb lz kf ma kj mb kn lt lu lv lw bi translated">基本了解<a class="ae ln" href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/" rel="noopener ugc nofollow" target="_blank"> Kubernetes部署</a>、<a class="ae ln" href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/" rel="noopener ugc nofollow" target="_blank">持久卷</a>和<a class="ae ln" href="https://kubernetes.io/docs/concepts/storage/storage-classes/" rel="noopener ugc nofollow" target="_blank">存储类</a></li></ul><blockquote class="mq mr ms"><p id="7559" class="js jt mt ju b jv jw is jx jy jz iv ka mu kc kd ke mv kg kh ki mw kk kl km kn hb bi translated">我已经用Azure的云Shell运行了我的大部分命令，并且还使用了AKS集群。我将使用Azure文件作为我们的持久数据存储，但你可以选择一个适合你的需求。</p></blockquote></div><div class="ab cl mx my gp mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="hb hc hd he hf"><h1 id="477c" class="mc kp hi bd kq md ne mf ku mg nf mi ky ix ng iy lb ja nh jb le jd ni je lh mm bi translated">Jupyter + Spark + Kubernetes —一些基本原理</h1><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es nj"><img src="../Images/7851a278d996fe5a220311e0a088c277.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*og9T0UrAos2GrMlwxrgfCg.jpeg"/></div></div><figcaption class="nk nl et er es nm nn bd b be z dx">The execution model of Jupyter + Spark on Kubernetes</figcaption></figure><p id="bdd3" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">运行Jupyter笔记本意味着我们不会直接在集群上发出spark-submit命令，而是从k8s集群内部创建spark上下文，然后发出分析查询。这种操作模式被称为在<a class="ae ln" href="https://spark.apache.org/docs/2.4.5/running-on-kubernetes.html#client-mode" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hs">客户端模式</strong> </a>中运行Spark。</p><p id="deec" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在这里，我们通过预装在Jupyter笔记本上的独立docker映像来明确启动我们的驱动程序pod。然后，我们创建一个Spark上下文，指定pod的数量、它们的内存和计算需求、executor docker映像位置和其他配置。Spark context负责与Kubernetes调度程序对话以请求所需的Pods，并与Pods对话以在其上执行单独的命令。</p><p id="c884" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">一个Pod本质上是无状态和短暂的。我们不能保证我们运行Spark driver和Jupyter笔记本的pod会一直可用。因此，我们需要一种机制，将Pod连接到商店并保存笔记本的状态，这样即使Pod由于间歇性故障而重新启动，我们也不会丢失笔记本和代码。为了实现这一点，我们在Kubernetes中创建了一个持久的卷声明，并将其连接到Azure文件共享。</p><h1 id="454c" class="mc kp hi bd kq md me mf ku mg mh mi ky ix mj iy lb ja mk jb le jd ml je lh mm bi translated">步骤1 —创建预装在Jupyter中的Spark驱动程序映像</h1><p id="e330" class="pw-post-body-paragraph js jt hi ju b jv li is jx jy lj iv ka kb lk kd ke kf ll kh ki kj lm kl km kn hb bi translated">使用下面的docker文件生成带有Jupyter笔记本的Spark驱动程序容器。</p><p id="7c7c" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">驱动程序和执行器spark pods的python版本必须相同。我们在<a class="ae ln" rel="noopener" href="/geekculture/build-your-own-big-data-ecosystem-part-1-a19e4c778632">第1部分</a>中使用Spark版本3.0.1构建的Spark映像是Python 3.7附带的，因此我们将Python 3.7作为基础映像，然后在其上安装所有需要的依赖项。</p><p id="19ef" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">Jupyter的默认安装附带了一个特定auth令牌的身份验证机制，我们必须将它与UI端点结合使用。我们修改该行为，要求输入密码，并在docker文件中设置默认密码。这样，我们不必在每次生成或重启驱动程序pod时都获取令牌。</p><figure class="jh ji jj jk fd jl"><div class="bz dy l di"><div class="no np l"/></div><figcaption class="nk nl et er es nm nn bd b be z dx">Dockerfile for deploying Jupyter Notebook with Spark and Python</figcaption></figure><p id="29d1" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在保存docker文件的同一文件夹中创建一个requirements.txt文件。添加所有需要安装的python库，如下所示。</p><pre class="jh ji jj jk fd nq nr ns nt aw nu bi"><span id="38c8" class="ko kp hi nr b fi nv nw l nx ny">jupyter<br/>jupyterlab<br/>matplotlib<br/>numpy<br/>pandas</span></pre><p id="54f3" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">使用下面的命令从上面的docker文件创建docker映像。</p><pre class="jh ji jj jk fd nq nr ns nt aw nu bi"><span id="a93e" class="ko kp hi nr b fi nv nw l nx ny">docker build --tag="&lt;your_container_registry&gt;/jupyter-spark:pybase" .</span></pre><h1 id="056f" class="mc kp hi bd kq md me mf ku mg mh mi ky ix mj iy lb ja mk jb le jd ml je lh mm bi translated">步骤2创建Kubernetes存储类</h1><p id="eac4" class="pw-post-body-paragraph js jt hi ju b jv li is jx jy lj iv ka kb lk kd ke kf ll kh ki kj lm kl km kn hb bi translated">下面是创建与Azure文件存储相对应的存储类的YAML文件。</p><figure class="jh ji jj jk fd jl"><div class="bz dy l di"><div class="no np l"/></div></figure><p id="9b52" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">运行以下命令创建存储类。</p><pre class="jh ji jj jk fd nq nr ns nt aw nu bi"><span id="b2c4" class="ko kp hi nr b fi nv nw l nx ny">kubectl apply -f azure_sc.yaml</span></pre><h1 id="796a" class="mc kp hi bd kq md me mf ku mg mh mi ky ix mj iy lb ja mk jb le jd ml je lh mm bi translated">步骤3:创建永久卷声明</h1><p id="04fe" class="pw-post-body-paragraph js jt hi ju b jv li is jx jy lj iv ka kb lk kd ke kf ll kh ki kj lm kl km kn hb bi translated">我们使用下面的yaml文件在集群中创建一个持久卷声明，并指定之前在其中创建的存储类。然后，我们将此PVC与我们作为整体部署的一部分创建的驱动程序单元相关联。</p><figure class="jh ji jj jk fd jl"><div class="bz dy l di"><div class="no np l"/></div></figure><p id="f851" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">运行以下命令创建存储类</p><pre class="jh ji jj jk fd nq nr ns nt aw nu bi"><span id="3dca" class="ko kp hi nr b fi nv nw l nx ny">kubectl apply -f azure_sc.yaml</span></pre><h1 id="2240" class="mc kp hi bd kq md me mf ku mg mh mi ky ix mj iy lb ja mk jb le jd ml je lh mm bi translated">步骤4-为pod和服务创建部署。</h1><p id="5f9b" class="pw-post-body-paragraph js jt hi ju b jv li is jx jy lj iv ka kb lk kd ke kf ll kh ki kj lm kl km kn hb bi translated">最后，我们创建一个Kubernetes部署，它创建一个在其中运行Jupyter的驱动程序pod和一个服务，该服务将充当驱动程序和执行器pod之间的通信层。</p><figure class="jh ji jj jk fd jl"><div class="bz dy l di"><div class="no np l"/></div></figure><p id="bd3f" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">使用以下命令运行部署。</p><pre class="jh ji jj jk fd nq nr ns nt aw nu bi"><span id="d676" class="ko kp hi nr b fi nv nw l nx ny">kubectl apply -f driver_deployment.yaml</span></pre><h1 id="8ba5" class="mc kp hi bd kq md me mf ku mg mh mi ky ix mj iy lb ja mk jb le jd ml je lh mm bi translated">看到这一切走到一起</h1><p id="f11e" class="pw-post-body-paragraph js jt hi ju b jv li is jx jy lj iv ka kb lk kd ke kf ll kh ki kj lm kl km kn hb bi translated">一旦您创建了部署，您将会看到为我们的驱动程序创建了一个pod。运行kubectl get all应该会给出以下输出。</p><pre class="jh ji jj jk fd nq nr ns nt aw nu bi"><span id="4cd3" class="ko kp hi nr b fi nv nw l nx ny">$ kubectl get all -n spark</span><span id="bc55" class="ko kp hi nr b fi nz nw l nx ny">NAME                                         READY   STATUS    RESTARTS   AGE</span><span id="ce9a" class="ko kp hi nr b fi nz nw l nx ny">pod/my-notebook-deployment-6677b6975-9dxxd   1/1     Running   0          3m30s<br/></span><span id="f508" class="ko kp hi nr b fi nz nw l nx ny">NAME                             TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)     AGE</span><span id="09ce" class="ko kp hi nr b fi nz nw l nx ny">service/my-notebook-deployment   ClusterIP   None         &lt;none&gt;        29413/TCP   3m30s</span><span id="0b33" class="ko kp hi nr b fi nz nw l nx ny">NAME                                     READY   UP-TO-DATE   AVAILABLE   AGE</span><span id="8b1f" class="ko kp hi nr b fi nz nw l nx ny">deployment.apps/my-notebook-deployment   1/1     1            1           3m31s</span><span id="6f11" class="ko kp hi nr b fi nz nw l nx ny">NAME                                               DESIRED   CURRENT   READY   AGE</span><span id="d3d8" class="ko kp hi nr b fi nz nw l nx ny">replicaset.apps/my-notebook-deployment-6677b6975   1         1         1       3m32s</span></pre><p id="f164" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在新的终端中运行下面的port-forward命令，将您的本地系统连接到已部署的Jupyter笔记本</p><pre class="jh ji jj jk fd nq nr ns nt aw nu bi"><span id="57c7" class="ko kp hi nr b fi nv nw l nx ny">kubectl port-forward -n spark deployment.apps/my-notebook-deployment 8888:8888</span></pre><p id="f05e" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">现在将你的浏览器指向http://localhost:8888 ，你会看到Jupyter笔记本登录页面。添加密码“jupyter”(不带引号)</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es oa"><img src="../Images/2aa3c366a024c5fd5b81515328dec132.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RnU6z68noZiLugsqTjBMkQ.png"/></div></div><figcaption class="nk nl et er es nm nn bd b be z dx">Jupyter Login Page</figcaption></figure><h1 id="08bf" class="mc kp hi bd kq md me mf ku mg mh mi ky ix mj iy lb ja mk jb le jd ml je lh mm bi translated">从笔记本运行Spark作业</h1><p id="a1ca" class="pw-post-body-paragraph js jt hi ju b jv li is jx jy lj iv ka kb lk kd ke kf ll kh ki kj lm kl km kn hb bi translated">现在我们已经设置好了笔记本环境，我们继续进行最后也是最重要的一步，通过笔记本在集群上运行Spark作业。</p><p id="ef71" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在UI中创建新的笔记本，并在第一个单元格中添加以下代码。</p><p id="31c5" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">用你的spark executor图像的位置更新第14行(更多细节参考<a class="ae ln" rel="noopener" href="/geekculture/build-your-own-big-data-ecosystem-part-1-a19e4c778632">第1部分</a>)并运行单元。</p><figure class="jh ji jj jk fd jl"><div class="bz dy l di"><div class="no np l"/></div></figure><p id="3f6a" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">这里，我们通过提供相关的配置，在集群上设置了一个spark上下文。上述要点中第29行的命令将创建executor pods。</p><pre class="jh ji jj jk fd nq nr ns nt aw nu bi"><span id="838c" class="ko kp hi nr b fi nv nw l nx ny">SparkSession.builder.config(conf=sparkConf).getOrCreate()</span></pre><p id="261f" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">设置spark上下文后，您应该看到executor pods已经开始运行。我们总共有3个executor pods，因为我们在设置spark上下文时已经提供了计数3。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es ob"><img src="../Images/971184e3379464fa655fdc9d1626c4f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*6LDi_xfqCtrjuhbvK0cHag.png"/></div></figure><p id="b3ed" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">现在我们的Spark集群已经准备好使用这个Spark上下文运行作业。</p><p id="ef02" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">要停止executor窗格，请运行以下命令</p><pre class="jh ji jj jk fd nq nr ns nt aw nu bi"><span id="bca4" class="ko kp hi nr b fi nv nw l nx ny">spark.stop()</span></pre><p id="72fb" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">至此，我们结束了第二部分。我们现在有了一个正在运行的Spark集群，它带有一个笔记本界面，可以在集群中交互地运行我们的作业。</p><p id="1e62" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在下一部分中，我们将探索如何从数据湖中访问数据，并从我们的笔记本中执行数据分析。</p></div></div>    
</body>
</html>