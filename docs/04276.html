<html>
<head>
<title>Linear Regression Algorithm in Practice</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实践中的线性回归算法</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/linear-regression-algorithm-in-practice-526ce0e4b1d5?source=collection_archive---------43-----------------------#2021-06-23">https://medium.com/geekculture/linear-regression-algorithm-in-practice-526ce0e4b1d5?source=collection_archive---------43-----------------------#2021-06-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="0005" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">什么是线性回归算法，以及如何在回归任务中使用它。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/0517ffdb1dc91fe8921e436568dab256.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FqCiwWyxfVaAbQ3w"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Photo by <a class="ae jt" href="https://unsplash.com/@starysmok?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Stary Smok</a> on <a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="2856" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">介绍</h1><p id="15ff" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">回归分析是在给定解释变量的情况下预测响应变量的过程。响应变量也称为因变量，解释变量称为自变量。给定一个问题陈述，当有多个解释变量和一个响应变量时，那么这个过程称为<strong class="ih hj">多元线性回归</strong>。相反，如果一个问题陈述只包含一个解释变量和一个响应变量，则称为<strong class="ih hj">简单线性回归</strong>。</p><p id="1cf4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注</strong> —为了实施回归分析，需要在解释变量和响应变量之间建立强有力的关系。</p><p id="0f4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与预测类别标签(在分类任务中)不同，这里我们预测新的看不见的数据的真实值(连续值)。</p><h1 id="d2cc" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">数学模型</h1><p id="2e97" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">让我们将响应变量表示为<code class="du kx ky kz la b">y</code>，将解释变量表示为<code class="du kx ky kz la b">X</code>。这里的<code class="du kx ky kz la b">X</code>，既可以取单个特征，也可以取多个特征。</p><p id="160d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<code class="du kx ky kz la b">X</code>有一个特征的情况下，模型将是-</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lb"><img src="../Images/361ea7ba7ffa9e1acbe2fe3c7dcd3a2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*u-paYUCmKq1cmNTP-41xpA.png"/></div></figure><p id="93fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<code class="du kx ky kz la b">X</code>有多个特征的情况下，模型将是-</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lc"><img src="../Images/59cfc8496ba1de683ff013c35ac79bae.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*K6o4RCVWbaC0FUy1lAhTBA.png"/></div></figure><p id="f525" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数学模型(1)用于简单的线性回归任务，而(2)用于多重线性回归任务。在这两种情况下，响应变量<code class="du kx ky kz la b">y^</code>都是目标特征。</p><p id="c0e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">实际的响应变量表示为<code class="du kx ky kz la b">y</code>，我们都知道机器学习模型无法非常准确地预测。如果它不能准确预测，它肯定包含一个错误。因此，现在的主要焦点转移到使误差尽可能小。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ld"><img src="../Images/e754be16f21b8dca466d15bfc4aa4cd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/format:webp/1*8S_nJXVpX8tR5W0sLwrg_g.png"/></div></figure><p id="72ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将(3)中的(1)代入简单线性回归，我们得到-</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es le"><img src="../Images/19455898075045ca65592669c17df22d.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*Lhh2x0c4EABkVVZJ1cqPfw.png"/></div></figure><p id="4e38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将(3)中的(2)代入多元线性回归，我们得到-</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lf"><img src="../Images/47343528fa6cdc0b61aee7e7150eb16a.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*gD4mhvvxdeuNZqBcoDW8-w.png"/></div></figure><p id="193c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">误差<code class="du kx ky kz la b">E</code>是实际目标特征和预测目标特征之间的差异。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lg"><img src="../Images/c5b55d91393bab67391bc8b6fd69bcaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:310/format:webp/1*I1AyE2RZVsv7xd0MWKDnYw.png"/></div></figure><p id="eaee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一切都写得很好，除了两件事还不知道。这两个东西就是参数<code class="du kx ky kz la b">w</code>和<code class="du kx ky kz la b">b</code>。模型中的误差取决于这两个参数值。这里，<code class="du kx ky kz la b">w</code>是系数，<code class="du kx ky kz la b">b</code>是截距。我们不能简单地为<code class="du kx ky kz la b">w</code>和<code class="du kx ky kz la b">b</code>分配随机值。相反，应该借助随机梯度下降过程明智地选择它们。</p><h1 id="2b74" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">随机梯度下降</h1><p id="bd32" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">为了理解最优化，让我们考虑模型方程(1)。</p><p id="8822" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SGD是一个迭代过程，我们最初为<code class="du kx ky kz la b">w</code>和<code class="du kx ky kz la b">b</code>分配随机值(可能是0)。在每次迭代中，</p><ul class=""><li id="53cd" class="lh li hi ih b ii ij im in iq lj iu lk iy ll jc lm ln lo lp bi translated">对于<code class="du kx ky kz la b">w</code>，我们相对于<code class="du kx ky kz la b">w</code>微分(1)，得到<code class="du kx ky kz la b">dw</code>。</li><li id="ca8e" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated">对于<code class="du kx ky kz la b">b</code>，我们相对于<code class="du kx ky kz la b">b</code>微分(1)，得到<code class="du kx ky kz la b">db</code>。</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/d2b8166b1654cf5ab55436219d8a6af8.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/0*LkHpVar6Q0uWY9f0"/></div><figcaption class="jp jq et er es jr js bd b be z dx">Image by Author</figcaption></figure><p id="f5e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数学上，它可以表示为-</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lw"><img src="../Images/cd7197da283bb6f5d903d9647b015ab1.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*1d2TNRpe7-DuSy9-uXbUVw.png"/></div></figure><p id="e9f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">和</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lx"><img src="../Images/21360c1ce17cfbca0bdf30e81ae30a17.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*ZRxHfGmPWhbbOPq430fteg.png"/></div></figure><p id="70f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在每次迭代中分别用<code class="du kx ky kz la b">dw</code>和<code class="du kx ky kz la b">db</code>更新/替换实际的<code class="du kx ky kz la b">w</code>和<code class="du kx ky kz la b">b</code>，直到这些值没有完全最小化。更新过程可以按以下方式理解。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/61f3ec2c8a9e675ee5b54088d6af5839.png" data-original-src="https://miro.medium.com/v2/resize:fit:382/format:webp/1*4g163M--xT-fHt7shNSFew.png"/></div></figure><p id="4baa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">和</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lz"><img src="../Images/b58168e04aedc079326e90ea25a8d426.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/1*iRzMRuWpoYrdXLKvvXdVkw.png"/></div></div></figure><p id="72d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">整个过程对于获得模型方程(2)的最小值<code class="du kx ky kz la b">W</code>和<code class="du kx ky kz la b">b</code>是相同的。</p><p id="fe47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们已经理解了完整的过程，让我们从头开始实现同样的过程。</p><h1 id="0fe2" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">线性回归—代码</h1><p id="f83d" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我们将一如既往地从导入必要的库开始。</p><h2 id="e498" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated">图书馆</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><h2 id="9873" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated">数据创建</h2><p id="a1eb" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">现在，我们将依赖于一个玩具数据集，我们可以通过模块<code class="du kx ky kz la b">sklearn</code>轻松地创建它。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><h2 id="d298" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated">数据分离器</h2><p id="65ff" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我们需要将数据分成两部分——<code class="du kx ky kz la b">training</code>集合和<code class="du kx ky kz la b">testing</code>集合。我们通过一个随机的分裂函数来实现。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="39fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">列车试分裂</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><h2 id="e1e3" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated">建筑</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="bdbb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回归的名字是<code class="du kx ky kz la b">LinearRegression</code>，它是一个我们定义其他方法的类。</p><h2 id="3652" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated"><code class="du kx ky kz la b">__init__()</code>方法</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="d8c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的方法是一个接受五个参数的构造函数</p><ul class=""><li id="895d" class="lh li hi ih b ii ij im in iq lj iu lk iy ll jc lm ln lo lp bi translated"><code class="du kx ky kz la b">train_df</code> →指用于训练回归变量的数据子集。</li><li id="5751" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated"><code class="du kx ky kz la b">test_df</code> →指用于测试回归变量的数据子集。</li><li id="dca0" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated"><code class="du kx ky kz la b">label</code> →指的是一系列数据，实际上是类标签的列名。</li><li id="8594" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated"><code class="du kx ky kz la b">lambda_</code> →指在SGD过程中用于更新参数的常数。</li><li id="1268" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated"><code class="du kx ky kz la b">n_iters</code> →指用于决定SGD过程总迭代次数的常数。</li></ul><h2 id="3316" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated"><code class="du kx ky kz la b">split_features_targets()</code>方法</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="6d9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述方法用于从数据中分离特征和目标。它需要两个参数-</p><ul class=""><li id="8494" class="lh li hi ih b ii ij im in iq lj iu lk iy ll jc lm ln lo lp bi translated"><code class="du kx ky kz la b">df</code> →指通过分类的整个数据集。</li><li id="592a" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated"><code class="du kx ky kz la b">label</code> →指的是<code class="du kx ky kz la b">df</code>的系列，其实就是类标签的列名。</li></ul><h2 id="f9c5" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated"><code class="du kx ky kz la b">diff_params_wb()</code>法</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="215e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述方法用于区分参数。它需要两个参数-</p><ul class=""><li id="e431" class="lh li hi ih b ii ij im in iq lj iu lk iy ll jc lm ln lo lp bi translated"><code class="du kx ky kz la b">w</code> →指SGD过程中使用的初始权重向量。</li><li id="d6ed" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated"><code class="du kx ky kz la b">b</code> →指SGD过程中使用的初始截距值。</li></ul><h2 id="3dec" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated"><code class="du kx ky kz la b">find_best_params()</code>方法</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="2413" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述方法用于获得参数<code class="du kx ky kz la b">w</code>和<code class="du kx ky kz la b">b</code>的最佳(最小)值。它不需要参数。该方法遵循SGD的过程，迭代更新<code class="du kx ky kz la b">w</code>和<code class="du kx ky kz la b">b</code>的初始值。</p><h2 id="1bf0" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated"><code class="du kx ky kz la b">predict()</code>方法</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="d6f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述方法用于预测新的看不见的数据的真实(连续)值。它有两个参数(可选)</p><ul class=""><li id="e444" class="lh li hi ih b ii ij im in iq lj iu lk iy ll jc lm ln lo lp bi translated"><code class="du kx ky kz la b">with_plot</code> →指一个布尔值，决定是否绘制最佳拟合线和数据点。</li><li id="c444" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated"><code class="du kx ky kz la b">save_process</code> →表示一个布尔值，决定是否以<code class="du kx ky kz la b">GIF</code>格式保存SGD的进程。</li></ul><p id="7086" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">默认情况下，这些功能参数采用<code class="du kx ky kz la b">False</code>值，因此是可选的。</p><h2 id="8f9e" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated"><code class="du kx ky kz la b">save_process_togif()</code>方法</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="1a3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以上方法用于以<code class="du kx ky kz la b">GIF</code>的形式保存SGD的进程。它需要两个参数-</p><ul class=""><li id="2f81" class="lh li hi ih b ii ij im in iq lj iu lk iy ll jc lm ln lo lp bi translated"><code class="du kx ky kz la b">test_x</code> →需要预测目标的特征。</li><li id="9e57" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated"><code class="du kx ky kz la b">test_y</code> →指实际目标值。</li></ul><h2 id="37f4" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated"><code class="du kx ky kz la b">score()</code>方法</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="e107" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的方法用于计算R。它需要一个参数-</p><ul class=""><li id="898d" class="lh li hi ih b ii ij im in iq lj iu lk iy ll jc lm ln lo lp bi translated"><code class="du kx ky kz la b">preds</code> →指用于计算R的预测值。</li></ul><p id="e375" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">完整代码</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><h1 id="f256" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">线性回归—测试</h1><p id="5784" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我们已经创建了一个玩具数据集。我们只需要在这些数据上测试模型。</p><p id="69a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注意</strong>:我们创建的数据是随机的。每次执行的结果可能不同。</p><h2 id="5205" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated">对象创建</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><h2 id="234e" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated">砝码</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><h2 id="b4d5" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated">拦截</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><h2 id="f311" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated">预言；预测；预告</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="a500" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">训练&amp;测试地块</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mq"><img src="../Images/e324d200608b98ee617b2ea8b4ba1481.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*_SEdeX81y5j-4JUY"/></div><figcaption class="jp jq et er es jr js bd b be z dx">Image by Author</figcaption></figure><p id="152f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回归线充分穿过数据点。</p><p id="483f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> SGD流程演示</strong></p><p id="237b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">测试值用于执行SGD过程。随着每次迭代<code class="du kx ky kz la b">w</code>和<code class="du kx ky kz la b">b</code>的值改变，最佳拟合线相应地改变，并且在某个点，该线停止改变，这基本上意味着我们已经得到了<code class="du kx ky kz la b">w</code>和<code class="du kx ky kz la b">b</code>的最小值。</p><h2 id="5b28" class="ma jv hi bd jw mb mc md ka me mf mg ke iq mh mi ki iu mj mk km iy ml mm kq mn bi translated">绩效得分</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mo mp l"/></div></figure><p id="346a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于形状为<code class="du kx ky kz la b">(200, 2)</code>的数据，精度几乎为<code class="du kx ky kz la b">69%</code>。如果我们获取/创建了大量数据，那么就会有一些变化。</p></div><div class="ab cl mr ms gp mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="hb hc hd he hf"><h1 id="b13c" class="ju jv hi bd jw jx my jz ka kb mz kd ke kf na kh ki kj nb kl km kn nc kp kq kr bi translated">挑战</h1><p id="44c4" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">嗯，整个代码都是从头开始开发的，从性能上来说，肯定不如库方法高效。但是，理解这项工作背后的数学是很好的。</p><ul class=""><li id="5143" class="lh li hi ih b ii ij im in iq lj iu lk iy ll jc lm ln lo lp bi translated">我的代码很慢。</li><li id="d762" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated">尽管有各种类型的正则化，但没有实现正则化。</li><li id="eb16" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated">使用<strong class="ih hj"> L1 </strong>正则化的线性回归被称为<strong class="ih hj">岭回归</strong>。</li><li id="2ddc" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated">带有<strong class="ih hj"> L2 </strong>正则化的线性回归被称为<strong class="ih hj">套索回归</strong>。</li><li id="19ff" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated">同时具有<strong class="ih hj"> L1 </strong>和<strong class="ih hj"> L2 </strong>正则化的线性回归被称为<strong class="ih hj">弹性回归</strong>。</li><li id="6ef5" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated">如果数据中存在异常值，可能会对模型产生重大影响。</li></ul><h1 id="75ec" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">参考</h1><ul class=""><li id="8d2f" class="lh li hi ih b ii ks im kt iq nd iu ne iy nf jc lm ln lo lp bi translated">YouTube视频→<a class="ae jt" href="https://bit.ly/2TRmnxd" rel="noopener ugc nofollow" target="_blank">bit.ly/2TRmnxd</a></li><li id="112f" class="lh li hi ih b ii lq im lr iq ls iu lt iy lu jc lm ln lo lp bi translated">维基百科文章→<a class="ae jt" href="https://en.wikipedia.org/wiki/Linear_regression" rel="noopener ugc nofollow" target="_blank">en.wikipedia.org/wiki/Linear_regression</a></li></ul><p id="bc9a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">结束</strong></p></div></div>    
</body>
</html>