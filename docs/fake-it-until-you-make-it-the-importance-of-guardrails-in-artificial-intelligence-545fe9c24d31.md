# 伪造它直到你成功——护栏在人工智能中的重要性

> 原文：<https://medium.com/geekculture/fake-it-until-you-make-it-the-importance-of-guardrails-in-artificial-intelligence-545fe9c24d31?source=collection_archive---------15----------------------->

![](img/5b52bbf04e2d6ed95e1f081fbbf44c7b.png)

Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

作为一个社会，我们迷恋——并且经常受制于——我们甚至不了解的技术。

你正在一个设备上阅读这篇文章，这个设备记录了你和你所生活的世界的数据，多得你都无法理解。权衡的结果是，你的手机“知道”得越多，你在试图记住像无缝账户密码这样愚蠢的事情时遇到的摩擦就越少——反过来，无缝或类似的人对你的了解也就越多。

你每天在该设备上使用的各种应用程序——从你开车时的方向到你家里的智能恒温器——部署算法来推荐和影响你的行为和环境，而不会因为你的有意识输入而打扰你。而且，如果有风险投资或特殊目的收购公司的承诺即将到来，那么这种花哨的步法可能还有另一个名字，比如人工智能或机器学习，甚至可能是教室后面的酷孩子的联合学习！为了简单起见，我们称它们为 AI/ML/FL。

当勒德分子只是要求 It 部门在你的工作电脑上安装谷歌 Chrome，并假装知道一个 API 是做什么的时候，这一切都很有趣。见鬼，我们甚至可以假装更广泛地理解 NFT 或加密货币的意义——甚至可能理解它们为何如此昂贵。

我不想轻率，但我认为我们已经把自己困在一个角落里，只有少数拥有深奥技能的开发人员构建了影响现代生活几乎每个角落的技术——而我们大多数人仍然不知道 API 到底是干什么的。我不知道这本身是好是坏，但我坚信我们应该非常仔细地思考这个问题。

今天的科技不仅仅是我们在闲暇时使用或未能使用的工具。我们生活在一个科技触及、塑造和*日益影响我们生活的世界。无论我们谈论的是深层的假货，还是我们在互联网上可以找到的算法诱导的回音室——代码行可能不总是部署变化，但它们肯定可以改变我们对现实的看法。*

## 这不是一篇关于进步和创新的错误的文章，而是一个对整个社会的问题——我们是否知道我们希望做得更好，我们是否考虑过成本？

人类历史上充满了奇迹和看似不可能的创新壮举，我绝不会建议这个时代在建设一个比我们进入的世界更美好的世界时，在智力上不那么好奇，也不那么雄心勃勃。

但相比之下，过去的技术创新主要是提高了人类的效率——就像一个简单的滑轮减轻了负荷。更近的技术发展，如文字处理和互联网协议，增加了输出和范围，同时有时减少了坐在键盘后面的灵长类动物所需的努力。你的打印机可能永远没有墨水，并且在没有拔掉插头的情况下顽固地拒绝打印，但在极少数情况下，它会合作——这是天赐之物。

我所说的区别是指最新和最受追捧的技术领域。这一迫在眉睫的技术创新浪潮并不是真的为人类提供力量倍增或便利。相反，我们正在构建更像人而不是工具的技术。如果你是一家公司，这是一笔不错的交易，但对于个人消费者来说，这是否是一笔很好的交易还不清楚。虽然这是不是一个积极的消息还没有定论，但这就是我们生活的现实。

要明确的是，问题不在于 AI/ML/FL 是否会继续影响我们的生活，甚至影响我们的决策——那艘船已经启航了。相反，我们需要问我们将如何装备自己来理解 AI/ML/FL，并与它们进行有意义的互动，以实现真正的**自治**。如果我们不能理解影响我们生活的技术，我们就不可能行使自由意志来选择何时或如何与 AI/ML/FL 打交道。

我们的约会应用程序将我们引向那些我们可能会发现相互吸引的人——有罪的人，这很好。我无法想象，如果没有算法来简化我的亚马逊体验，我会经历这个疫情。但是，如果我们连自己想要与之建立健康边界的对手都不了解，我们该如何划清界限呢？

举个简单的例子，每当我们接受医疗程序时，医疗服务提供者都必须告知我们这些程序可能带来的风险和潜在并发症。也许我们没有通过有机化学考试——但是我们的目标是让外行人对他们面临的风险有足够的了解和信息，以便他们能够做出是否同意医疗程序的明智决定。

挑战在于,*true*AI/ML/FL——不仅仅是筹款的废话——不是静态的，它是动态的，不断发展的。理想情况下，它会随着时间的推移而改进——你可以说它是在学习。虽然人类创造者能够，或者至少应该能够告诉世界代码输入是什么，如果他们仔细记录训练过程的话，但对他们构建的黑盒的可见性甚至会让创造者自己难以解释他们构建了什么。更别说，它为什么会这样。

继续以医疗程序为例，未来 AI/ML/FL 可能会以几种方式进入你的医生办公室。但广义地说，帮助你未来访问的算法很可能植根于两种开发方法之一:监督或无监督学习。当 AI/ML/FL 爱好者们集体喘息的时候，我将粗略地简化如下:

*   **监督学习**涉及更多的人类参与、干预和对管道训练的反馈——你可以认为这使得 AI/ML/FL 通常更好地完成它被训练完成的任何特定任务，但不太能够进行“广义”应用。把监督学习想象成一个奥林匹克撑杆跳运动员，他在一个项目上做得惊人地好，但在跑道上跑完全程却比我们其他人好不了多少。
*   **另一方面，无监督学习**是一种允许 AI/ML/FL 观察大范围数据的方法，绘制人眼可能或可能不明显的连接。举例来说，人类和 AI/ML/FL 可能同意一幅图像描绘了一只猫，但是他们可能出于同样的原因而没有得出那个结论。这里的优势，用令人痛苦的轻描淡写的话来说，就是无监督学习方法可以不那么脆弱——或者在遇到边缘或新情况时不容易失败。可以说，这是 3 个赛季的运动员，可以参加包括球在内的任何运动——他们不是精英，我们大多数人都无法理解这是怎么可能的，但大量的训练会为你做到这一点。

AI/ML/FL 各种迭代的扩散、进一步开发和实施有助于提高消费者安全性、增加医疗保健的可及性以及许多其他重要的社会目标。同样，这些进步也不是没有代价的。

让我们暂时回到医疗程序知情同意的概念上来——随着我们采用越来越多的创新方法，并将人工智能/人工智能/人工授精的元素甚至直接诊断纳入我们的医疗保健系统，几乎可以肯定的是，在一段时间内，采用的速度将超过理解的速度。在降低成本和增加缺医少药人群获得护理的机会方面，我们已经看到在社会化医疗保健的国家以及在获得医疗保健提供商和特别昂贵的诊断工具有限的地区相对热切地采用 AI/ML/FL。换句话说，未来就是现在，但在美国，FDA 仍在研究这个问题。

现在，不管他们愿意相信什么，大多数医学博士都不是技术专家。虽然医疗保健提供者经过多年的培训，了解并向患者传达与传统医疗保健相关的风险和潜在并发症，但 AI/ML/FL 呈现出某种“未知的未知”。除非我们，作为一个社会，理解为什么我们正在使用的技术会产生它们正在产生的结果，否则我们就不能开始有意义地思考潜在结果的宇宙——无论它们是好是坏。在一个纯粹假设的层面上，这提出了一个问题——如果 MDs 本身不熟悉这些技术的工作方式，患者能否给予知情同意，这在添加 AI/ML/FL 之前可能已经是一个挑战了？

在充分披露的利益中，我与一个非常能干的专业团队合作，专注于理解、减轻和创造一种通过保险保护消费者的形式，前提是这些技术可以被理解——如果我们选择这样做的话。

同样，我与许多风险投资和 PE 支持的医疗技术公司合作，寻求通过 AI/ML/FL 以各种方式改善患者结果并增加可负担得起的医疗服务。我绝不反对开发、采用或实现这些技术。

然而，我是理解和考虑 AI/ML/FL 在*任何*环境中的全部含义的坚定支持者。

虽然我有幸在 AI/ML/FL 领域与之互动的公司和创始人都有我所认为的建设一个更美好世界的真诚愿望，但所有的人和所有的技术都会犯错。这就是为什么当我们考虑我们委托谁来保护消费者免受任何产品或技术——特别是我们很少人真正理解的技术——时，从最近的航空悲剧中吸取的教训应该动摇我们的核心。

W 无论这意味着增加教育和指导性课程，还是系统的独立审计，唯一错误的答案是我们目前正在做的事情。就目前的情况而言，我们的联邦机构并不了解他们试图监管的基础技术，他们与其对手对抗而不是合作——这创造了一种隐含的敌对态势，而联邦机构根本没有能力赢得这场战争。

无论我们谈论的是 FAA、FDA、FTC、ATF、SEC 还是任何其他联邦机构，当与他们的相关对手对抗而不是合作时，创新就会停滞，但风险将持续甚至升级，因为我们天生就是一个希望创造更新更好的东西的社会，即使父母警告我们炉子很热。

> 正如杰夫·高布伦在电影《侏罗纪公园》中敏锐地观察到的那样:“生活——嗯——会找到出路的”。

即使在一些最严格审查的环境中——通过 FDA 批准的设备在医疗保健中应用 AI/ML/FL——也存在一个问题，即是否有足够的[可见性来了解这些设备在不同人群中的性能和公平性](https://medcitynews.com/2021/04/fda-cleared-ai-devices-lack-critical-information-on-performance-equity/)。[中的底层分析*自然*中的](https://www.nature.com/articles/s41591-021-01312-x.epdf?sharing_token=8BNOnt1UUOf0iPsJ9yU0J9RgN0jAjWel9jnR3ZoTv0M6PlZXWQqbgCrdZtSbNOnPDQlhZJ-fPz8LJ4JqCoxGYshqBh62049hIhMSEfJaE7pKaceG00AD1FUBHLZ5YShokEBQWoF6kBbZitEELPDqWu-9esaFE8DcbdQ1QAgRChw%3D&utm_source=STAT+Newsletters&utm_campaign=fdec4d0d0d-health_tech_4-6-21_COPY_01&utm_medium=email&utm_term=0_8cab1d7961-fdec4d0d0d-152708089)增加了进一步的细节。

虽然这只是一个用例，而且公认是目前相当狭窄的一个，但它也表明了 AI/ML/FL 的应用可以有多复杂——即使是在受控的科学环境中，更不用说在自动驾驶汽车或在社交媒体平台上推荐内容了。越来越清楚的是，尽管我们中很少有人真正理解 AI/ML/FL，但随着越来越多的[利益相关者寻求在面向消费者的应用中增加可解释性和质量控制](https://enterprisersproject.com/article/2021/2/artificial-intelligence-ai-and-privacy-3-key-security-practices)，缺乏消费者成熟度可能不是偷工减料的借口。

因此，如果我们接受上述事实，并且我们总是继续使用这些 AI/ML/FL 技术，无论是在实践中还是仅仅在我们的筹款活动中，我们都应该像分析人类一样分析它们各自的优点——如果不是更仔细的话。

对于一些人来说，当我们受限于 AI/ML/FL 在约会应用和定价算法中发挥其魔力的概念时，可能很容易打消担忧。重要的是要记住，每当我们谈论 AI/ML/FL 在建筑或法律等特许职业中的应用时，这些都是高度监管的部门，通常利用教育、许可和持续监督来保护消费者。

换句话说——如果 AI/ML/FL 正在做你或我需要获得许可或准许才能做的事情，谁负责这些技术的许可或准许，我们真的都被保持在相同的标准上吗？我们知道人类是会犯错的，但是我们不应该盲目地假设 AI/ML/FL 也是如此。相反，越来越多的证据表明，偏见、公平和公正需要负责任地训练算法的刻意努力，坦率地说，AI/ML/FL 的许多应用都有所欠缺。我们不能想当然地认为任何给定的 AI/ML/FL 都符合我们作为一个社会应该接受或拥抱的标准。

尽管目前还没有标准化的质量控制(或确认和验证标准)的 T2，但消息灵通人士认为他们应该并且最终会有。这是几年还是几十年的事情还有待观察，但随着我们进一步让技术在我们的生活中占据主导地位——从自动驾驶汽车到保险承保——我们不能把头埋在沙子里。正如我经常告诉我所建议的公司的那样——如果你不知道一旦被盯上会带来的负面影响，那就不是可计算的风险。同样，仅仅因为我们不理解 AI/ML/FL 是如何工作的，并不意味着我们应该不做任何进一步的考虑就继续下去。

诚然，我的想法可能是低技术含量的，但我认为谨慎的做法是**测量两次，削减一次。**