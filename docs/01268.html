<html>
<head>
<title>Fine-Tune EleutherAI GPT-Neo to Generate Netflix Movie Descriptions in Only 47 Lines of Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">微调伊柳瑟雷GPT尼奥生成网飞电影描述只有47行代码</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/fine-tune-eleutherai-gpt-neo-to-generate-netflix-movie-descriptions-in-only-47-lines-of-code-40c9b4c32475?source=collection_archive---------2-----------------------#2021-04-04">https://medium.com/geekculture/fine-tune-eleutherai-gpt-neo-to-generate-netflix-movie-descriptions-in-only-47-lines-of-code-40c9b4c32475?source=collection_archive---------2-----------------------#2021-04-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/ed733f7fcc0fd678f49dc1ea57705ebc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uuhA5Va5pbGDrPk8crTvNA.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Photo by <a class="ae hv" href="https://unsplash.com/@freestocks" rel="noopener ugc nofollow" target="_blank"><strong class="bd hw">freestocks</strong></a> on Unsplash</figcaption></figure><div class=""/><p id="3b15" class="pw-post-body-paragraph iw ix hz iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">最近，<a class="ae hv" href="https://www.eleuther.ai/" rel="noopener ugc nofollow" target="_blank"> <strong class="iy ia"> EleutherAI </strong> </a>发布了他们的类似GPT-3的模型<a class="ae hv" href="https://github.com/EleutherAI/gpt-neo/" rel="noopener ugc nofollow" target="_blank"> <strong class="iy ia"> GPT-Neo </strong> </a> <strong class="iy ia">，</strong>而前几天，又是<a class="ae hv" href="https://huggingface.co/EleutherAI/gpt-neo-1.3B" rel="noopener ugc nofollow" target="_blank"> <strong class="iy ia">发布了</strong> </a>作为<a class="ae hv" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank"> <strong class="iy ia">抱脸</strong> </a>框架的一部分。在撰写本文时，这个模型只在<a class="ae hv" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank"> <strong class="iy ia">变形金刚</strong> </a>库的主分支可用，所以你需要这样安装它:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="1817" class="kd ke hz jz b fi kf kg l kh ki">pip install git+<a class="ae hv" href="https://github.com/huggingface/transformers@master" rel="noopener ugc nofollow" target="_blank">https://github.com/huggingface/transformers@master</a></span></pre><p id="d78f" class="pw-post-body-paragraph iw ix hz iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">主要目标是向您展示微调GPT-尼奥模型的最简单方法，以使用网飞电影和电视节目的数据集<a class="ae hv" href="https://www.kaggle.com/shivamb/netflix-shows" rel="noopener ugc nofollow" target="_blank"><strong class="iy ia"/></a>生成新的电影描述。</p><figure class="ju jv jw jx fd hk er es paragraph-image"><div class="er es kj"><img src="../Images/1125cbe9bf0da6377ff804766576b766.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*WgXgLkD2TsudDCjOu6sRag.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx">CUDA device used for this project, please note that the GPT-Neo is a very VRAM demanding model!</figcaption></figure><p id="c93a" class="pw-post-body-paragraph iw ix hz iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">首先，我们需要下载并准备好GPT近地天体模型:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="7253" class="kd ke hz jz b fi kf kg l kh ki"><strong class="jz ia"># Set the random seed to a fixed value to get reproducible results <br/></strong>torch.manual_seed(42)<br/><strong class="jz ia"># Download the pre-trained GPT-Neo model's tokenizer<br/># Add the custom tokens denoting the beginning and the end <br/># of the sequence and a special token for padding<br/></strong>tokenizer = GPT2Tokenizer.from_pretrained(“<strong class="jz ia">EleutherAI/gpt-neo-1.3B</strong>”,    <br/>                            bos_token=’<strong class="jz ia">&lt;|startoftext|&gt;</strong>’,<br/>                            eos_token=’<strong class="jz ia">&lt;|endoftext|&gt;</strong>’,<br/>                            pad_token=’<strong class="jz ia">&lt;|pad|&gt;</strong>’)<br/><strong class="jz ia"># Download the pre-trained GPT-Neo model and transfer it to the GPU<br/></strong>model = GPTNeoForCausalLM.from_pretrained("<strong class="jz ia">EleutherAI/gpt-neo-1.3B</strong>")<br/>                         <strong class="jz ia">.cuda()</strong><br/><strong class="jz ia"># Resize the token embeddings because we've just added 3 new tokens <br/></strong>model.resize_token_embeddings(len(tokenizer))</span></pre><p id="3f70" class="pw-post-body-paragraph iw ix hz iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">下一步是读取网飞数据集，并计算数据集中电影描述的最大可能长度:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="6fbf" class="kd ke hz jz b fi kf kg l kh ki">descriptions = pd.read_csv(‘<strong class="jz ia">netflix_titles.csv</strong>’)[‘description’]<br/>max_length = max([len(tokenizer.encode(description)) for description in descriptions])</span></pre><p id="2ce6" class="pw-post-body-paragraph iw ix hz iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">这个自定义的<a class="ae hv" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" rel="noopener ugc nofollow" target="_blank"> <strong class="iy ia">数据集</strong> </a>类便于使用<a class="ae hv" href="https://huggingface.co/transformers/main_classes/trainer.html" rel="noopener ugc nofollow" target="_blank"> <strong class="iy ia">训练器</strong> </a>工具进行微调:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="ad29" class="kd ke hz jz b fi kf kg l kh ki"><strong class="jz ia">class NetflixDataset(Dataset):</strong><br/>    def __init__(self, txt_list, tokenizer, max_length):<br/>        self.input_ids = []<br/>        self.attn_masks = []<br/>        self.labels = []<br/>        for txt in txt_list:<br/>            <strong class="jz ia"># Encode the descriptions using the GPT-Neo tokenizer<br/>            </strong>encodings_dict = tokenizer(‘<strong class="jz ia">&lt;|startoftext|&gt;</strong>’ <br/>                                        + <strong class="jz ia">txt</strong> +    <br/>                                        ‘<strong class="jz ia">&lt;|endoftext|&gt;</strong>’,<br/>                                        <strong class="jz ia">truncation=True</strong>,<br/>                                        <strong class="jz ia">max_length=max_length</strong>, <br/>                                        <strong class="jz ia">padding=”max_length”</strong>)<br/>        input_ids = torch.tensor(encodings_dict[‘<strong class="jz ia">input_ids</strong>’])    <br/>        self.input_ids.append(input_ids)<br/>        mask = torch.tensor(encodings_dict[‘<strong class="jz ia">attention_mask</strong>’])<br/>        self.attn_masks.append(mask)</span><span id="6742" class="kd ke hz jz b fi kk kg l kh ki"><strong class="jz ia">def __len__(self):</strong><br/> return len(self.input_ids)</span><span id="837f" class="kd ke hz jz b fi kk kg l kh ki"><strong class="jz ia">def __getitem__(self, idx):</strong><br/> return self.input_ids[idx], self.attn_masks[idx]</span></pre><p id="7c1c" class="pw-post-body-paragraph iw ix hz iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">现在初始化数据集:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="44e6" class="kd ke hz jz b fi kf kg l kh ki">dataset = NetflixDataset(<strong class="jz ia">descriptions</strong>, <strong class="jz ia">tokenizer</strong>, <strong class="jz ia">max_length</strong>)</span></pre><p id="c1eb" class="pw-post-body-paragraph iw ix hz iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">接下来，您需要将整个数据集分成<strong class="iy ia">训练(90%) </strong>和<strong class="iy ia">验证(10%) </strong>集合:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="c68d" class="kd ke hz jz b fi kf kg l kh ki"><strong class="jz ia">train_size</strong> = int(<strong class="jz ia">0.9</strong> * len(dataset))<br/><strong class="jz ia">train_dataset, val_dataset</strong> = random_split(dataset, <br/>                            [train_size, len(dataset) — train_size])</span></pre><p id="773f" class="pw-post-body-paragraph iw ix hz iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">拥抱脸工具包提供了一个有用的<a class="ae hv" href="https://huggingface.co/transformers/main_classes/trainer.html" rel="noopener ugc nofollow" target="_blank"> <strong class="iy ia">训练器</strong> </a>工具，帮助用户在大多数标准用例中微调预训练的模型。所有的训练参数都应该使用<a class="ae hv" href="https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments" rel="noopener ugc nofollow" target="_blank"> <strong class="iy ia">训练参数</strong> </a>进行配置:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="8732" class="kd ke hz jz b fi kf kg l kh ki"><strong class="jz ia"># Here I will pass the output directory where <br/># the model predictions and checkpoints will be stored, <br/># batch sizes for the training and validation steps, <br/># and warmup_steps to gradually increase the learning rate</strong><br/>training_args = TrainingArguments(output_dir=’<strong class="jz ia">./results</strong>’,<br/>                                  num_train_epochs=<strong class="jz ia">5</strong>,<br/>                                  logging_steps=<strong class="jz ia">5000</strong>,<br/>                                  save_steps=<strong class="jz ia">5000, </strong>                                  <br/>                                  per_device_train_batch_size=<strong class="jz ia">2</strong>,<br/>                                  per_device_eval_batch_size=<strong class="jz ia">2</strong>,<br/>                                  warmup_steps=<strong class="jz ia">100</strong>,<br/>                                  weight_decay=<strong class="jz ia">0.01</strong>,  <br/>                                  logging_dir=’<strong class="jz ia">./logs</strong>’)</span></pre><p id="ffba" class="pw-post-body-paragraph iw ix hz iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">最后，剩下的就是微调我们的模型并检查结果！</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="f13c" class="kd ke hz jz b fi kf kg l kh ki">trainer = Trainer(model=<strong class="jz ia">model</strong>, args=<strong class="jz ia">training_args</strong>,  <br/>                  train_dataset=<strong class="jz ia">train_dataset</strong>,<br/>                  eval_dataset=<strong class="jz ia">val_dataset</strong>, <br/>                  <strong class="jz ia"># This custom collate function is necessary <br/>                  # to built batches of data<br/>                  </strong>data_collator=lambda data: <br/>              {‘<strong class="jz ia">input_ids</strong>’: <strong class="jz ia">torch.stack([f[0] for f in data])</strong>,       <br/>               ‘<strong class="jz ia">attention_mask</strong>’: <strong class="jz ia">torch.stack([f[1] for f in data])</strong>,<br/>               ‘<strong class="jz ia">labels</strong>’: <strong class="jz ia">torch.stack([f[0] for f in data])</strong>})<br/><strong class="jz ia"># Start training process!<br/></strong>trainer.train()</span></pre><figure class="ju jv jw jx fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kl"><img src="../Images/d5851fe3ef62a3eddff59021de9cbb89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RgnwbvQ001agIV6tBIUyoQ.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Training process</figcaption></figure><p id="c6c9" class="pw-post-body-paragraph iw ix hz iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">训练后，我们可以使用内置的<a class="ae hv" href="https://huggingface.co/transformers/main_classes/model.html#transformers.generation_utils.GenerationMixin.generate" rel="noopener ugc nofollow" target="_blank"> <strong class="iy ia">生成</strong> </a>函数来评估结果:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="3a9d" class="kd ke hz jz b fi kf kg l kh ki"><strong class="jz ia"># Start every description with a special BOS token</strong><br/>generated = tokenizer(“<strong class="jz ia">&lt;|startoftext|&gt; </strong>“,   <br/>                      return_tensors=”pt”).input_ids.cuda()<br/><strong class="jz ia"># Generate 3 movie descriptions<br/></strong>sample_outputs = model.generate(generated, <br/>                 <strong class="jz ia"># Use sampling instead of greedy decoding </strong><br/>                 do_sample=True, <br/>              <strong class="jz ia">   # Keep only top 50 token with <br/>                 # the highest probability<br/>                 </strong>top_k=50, <br/>                 <strong class="jz ia"># Maximum sequence length</strong><br/>                 max_length=300, <br/>                <strong class="jz ia"> # Keep only the most probable tokens <br/>                 # with cumulative probability of 95%</strong><br/>                 top_p=0.95, <br/>                 <strong class="jz ia"># Changes randomness of generated sequences<br/>                 </strong>temperature=1.9,<br/>                 <strong class="jz ia"># Number of sequences to generate   </strong>              <br/>                 num_return_sequences=20)<br/><strong class="jz ia"># Print generated descriptions<br/></strong>for i, sample_output in enumerate(sample_outputs): <br/>    print(“{}: {}”.format(i, tokenizer.decode(sample_output, <br/>                               skip_special_tokens=True)))</span></pre><p id="29be" class="pw-post-body-paragraph iw ix hz iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">以下是一些生成的示例:</p><figure class="ju jv jw jx fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es km"><img src="../Images/b14f1e7137efb6447867b2eed2aab6c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i3oX0oMsPtGcqI53f7gUWw.png"/></div></div></figure><p id="ea08" class="pw-post-body-paragraph iw ix hz iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">正如你所看到的，拥抱脸框架为各种NLP任务提供了一个非常友好的API，并允许我们与许多预先训练好的强大模型一起工作— <strong class="iy ia">这就是为什么</strong> <strong class="iy ia">这个项目只用了47行代码！</strong></p><figure class="ju jv jw jx fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kn"><img src="../Images/c248212bcef40049643e061d325c33df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bQDmoboEVi8I7BHEb6zzWg.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="bd hw">This code is also available </strong><a class="ae hv" href="https://gist.github.com/dredwardhyde/8419b8adc130075ba82ffe75bbe0a819" rel="noopener ugc nofollow" target="_blank"><strong class="bd hw">on my GitHub</strong></a><strong class="bd hw">.</strong></figcaption></figure><p id="7615" class="pw-post-body-paragraph iw ix hz iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">同样，可以使用<strong class="iy ia"/><a class="ae hv" href="https://github.com/microsoft/DeepSpeed" rel="noopener ugc nofollow" target="_blank"><strong class="iy ia"><a class="ae hv" href="https://huggingface.co/EleutherAI/gpt-neo-2.7B" rel="noopener ugc nofollow" target="_blank"><strong class="iy ia">对【GPT-尼奥-2.7B】</strong></a><strong class="iy ia"/>型号进行微调。</strong> </a><a class="ae hv" href="https://github.com/dredwardhyde/gpt-neo-fine-tuning-example" rel="noopener ugc nofollow" target="_blank"> <strong class="iy ia">这里有一个例子</strong> </a> <strong class="iy ia"> </strong>对这个批量相当大的型号进行了微调<strong class="iy ia"> RTX 3090 </strong>！</p><figure class="ju jv jw jx fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ko"><img src="../Images/4d2c81e520ccc69cf039cc97efb1b2f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1QdqnIT5EVZkbBXdqf3OMA.png"/></div></div></figure><figure class="ju jv jw jx fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kp"><img src="../Images/a52061b23b4cec457e1a8e0c2d18ad4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zwYG4o7j-tjFub-ihlAyQg.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Some samples generated by the GPT-Neo-2.7B model</figcaption></figure></div></div>    
</body>
</html>