<html>
<head>
<title>LightGBM Starter Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LightGBM启动代码</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/lightgbm-starter-code-ea6377c97039?source=collection_archive---------23-----------------------#2022-01-16">https://medium.com/geekculture/lightgbm-starter-code-ea6377c97039?source=collection_archive---------23-----------------------#2022-01-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="e50d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是你的第一个LightGBM代码！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/c87fc4b327ae19d61dee4ff2b712a888.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aquQwFrT9WARFqwizQ4MBw.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Photo by <a class="ae jt" href="https://unsplash.com/@benchaccounting?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Bench Accounting</a> on <a class="ae jt" href="https://unsplash.com/s/photos/online-classes?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="b105" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LightGBM 是一个梯度推进框架，使用基于树的学习算法。它被设计为分布式和高效的，具有以下优点:</p><ul class=""><li id="a373" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">训练速度更快，效率更高</li><li id="3eee" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">更低的内存使用率</li><li id="91cd" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">更高的精确度</li><li id="6c6f" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">支持并行和GPU学习</li><li id="0c01" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">能够处理大规模数据</li></ul><pre class="je jf jg jh fd ki kj kk kl aw km bi"><span id="f5f8" class="kn ko hi kj b fi kp kq l kr ks">import os <em class="kt">#to access files</em><br/>import pandas as pd <em class="kt">#to work with dataframes</em><br/>import numpy as np <em class="kt">#just a tradition</em><br/>from sklearn.model_selection import StratifiedKFold <em class="kt">#for cross-validation</em><br/>from sklearn.metrics import roc_auc_score <em class="kt">#this is we are trying to increase</em><br/>import matplotlib.pyplot as plt <em class="kt">#we will plot something at the end)</em><br/>import seaborn as sns <em class="kt">#same reason</em><br/>import lightgbm as lgb <em class="kt">#the model we gonna use</em></span></pre><p id="db02" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们来读数据:训练，目标和测试</p><pre class="je jf jg jh fd ki kj kk kl aw km bi"><span id="4f81" class="kn ko hi kj b fi kp kq l kr ks">train = pd.read_csv('../input/train.csv')<br/>test = pd.read_csv('../input/test.csv')<br/><br/>for c in train.columns:<br/>    if train[c].dtype == 'object':<br/>        lbl = LabelEncoder() <br/>        lbl.fit(list(train[c].values) + list(test[c].values)) <br/>        train[c] = lbl.transform(list(train[c].values))<br/>        test[c] =  lbl.transform(list(test[c].values))</span></pre><p id="826e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集的形状</p><pre class="je jf jg jh fd ki kj kk kl aw km bi"><span id="a1f0" class="kn ko hi kj b fi kp kq l kr ks">print('Shape train: {}\nShape test: {}'.format(train.shape, test.shape))</span><span id="836b" class="kn ko hi kj b fi ku kq l kr ks">n_comp = 6<br/><br/># PCA<br/>pca = PCA(n_components=n_comp, random_state=42)<br/>pca2_results_train = pca.fit_transform(train.drop(["y"], axis=1))<br/>pca2_results_test = pca.transform(test)<br/><br/># ICA<br/>ica = FastICA(n_components=n_comp, random_state=42)<br/>ica2_results_train = ica.fit_transform(train.drop(["y"], axis=1))<br/>ica2_results_test = ica.transform(test)<br/><br/># Append decomposition components to datasets<br/>for i in range(1, n_comp+1):<br/>    train['pca_' + str(i)] = pca2_results_train[:,i-1]<br/>    test['pca_' + str(i)] = pca2_results_test[:, i-1]<br/>    <br/>    train['ica_' + str(i)] = ica2_results_train[:,i-1]<br/>    test['ica_' + str(i)] = ica2_results_test[:, i-1]<br/>  <br/>    <br/># remove  duplicates - needs to be applied to test too<br/># train = train.T.drop_duplicates().T<br/># test = test.T.drop_duplicates().T<br/><br/>    <br/>y_train = train["y"]<br/>y_mean = np.mean(y_train)<br/>train.drop('y', axis=1, inplace=True)</span></pre><p id="a89f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练模型！</p><pre class="je jf jg jh fd ki kj kk kl aw km bi"><span id="cd81" class="kn ko hi kj b fi kp kq l kr ks">X_train, X_valid, y_train, y_valid = train_test_split(<br/>       train, y_train, test_size=0.2, random_state=9127)<br/><br/># create dataset for lightgbm<br/>lgb_train = lgb.Dataset(X_train, y_train)<br/>lgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train)<br/><br/># to record eval results for plotting<br/>evals_result = {} <br/><br/># The r2 is:  0.648019302812 the rmse is: 7.2525692268<br/># specify your configurations as a dict<br/>params = {<br/>    'task': 'train',<br/>    'boosting_type': 'gbdt',<br/>    'objective': 'regression',<br/>    'metric': {'l2'},<br/>    'num_leaves': 5,<br/>    'learning_rate': 0.06,<br/>    'max_depth': 4,<br/>    'subsample': 0.95,<br/>    'feature_fraction': 0.9,<br/>    'bagging_fraction': 0.85,<br/>    'bagging_freq': 4,<br/>    'min_data_in_leaf':4,<br/>    'min_sum_hessian_in_leaf': 0.8,<br/>    'verbose':10<br/>}<br/><br/>print('Start training...')<br/><br/># train<br/>gbm = lgb.train(params,<br/>                lgb_train,<br/>                num_boost_round=8000, # 200<br/>                valid_sets=[lgb_train, lgb_valid],<br/>                evals_result=evals_result,<br/>                verbose_eval=10,<br/>                early_stopping_rounds=50) # 50<br/><br/>#print('\nSave model...')<br/># save model to file<br/>#gbm.save_model('model.txt')<br/><br/>print('Start predicting...')<br/># predict<br/>y_pred = gbm.predict(X_valid, num_iteration=gbm.best_iteration)</span></pre><p id="c80f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">估价</p><pre class="je jf jg jh fd ki kj kk kl aw km bi"><span id="da3f" class="kn ko hi kj b fi kp kq l kr ks"># feature importances<br/>print('Feature importances:', list(gbm.feature_importance()))<br/><br/># -------------------------------------------------------<br/>print('Plot metrics during training...')<br/>ax = lgb.plot_metric(evals_result, metric='l2')<br/>plt.show()<br/><br/>print('Plot feature importances...')<br/>ax = lgb.plot_importance(gbm, max_num_features=10)<br/>plt.show()<br/># -------------------------------------------------------<br/># eval r2-score <br/>from sklearn.metrics import r2_score<br/>r2 = r2_score(y_valid, y_pred)<br/><br/># eval rmse (lower is better)<br/>print('\nThe r2 is: ',r2, 'the rmse is:', mean_squared_error(y_valid, y_pred) ** 0.5)<br/><br/># -------------------------------------------------------<br/>print('\nPredicting test set...')<br/>y_pred = gbm.predict(test, num_iteration=gbm.best_iteration)<br/><br/># y_pred = model.predict(dtest)<br/>output = pd.DataFrame({'id': test['ID'], 'y': y_pred})<br/>output.to_csv('submit-lightgbm-ICA-PCA.csv', index=False)<br/><br/># -----------------------------------------------------------------------------<br/>print("Finished.")</span></pre><p id="0db1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这应该对你有用！干杯！</p><p id="148b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你卡住了，一定要伸出手来评论！</p><p id="4e7e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其他可能感兴趣的文章:<br/>-<a class="ae jt" rel="noopener" href="/geekculture/getting-started-with-apache-spark-i-5fbbe7b47667">Apache Spark入门— I | by Sam |极客文化| 2022年1月| Medium</a><br/>-<a class="ae jt" rel="noopener" href="/geekculture/getting-started-with-apache-spark-ii-fffeab9f5df7">Apache Spark入门II | by Sam |极客文化| 2022年1月| Medium</a><br/>-<a class="ae jt" rel="noopener" href="/geekculture/getting-started-with-apache-spark-iii-1758581d87f3">Apache Spark入门III | by Sam |极客文化| 2022年1月| Medium</a><br/>-<a class="ae jt" rel="noopener" href="/geekculture/streamlit-and-palmer-penguins-92a09004ed45">Streamlit和帕尔默企鹅。上周在网飞的Binged非典型… |作者Sam | Geek Culture | Medium</a><br/>-<a class="ae jt" rel="noopener" href="/geekculture/getting-started-with-streamlit-ed81eafcb298">Streamlit入门。使用Streamlit解释你的EDA和… | by Sam | Geek Culture | Medium </a></p><p id="9d89" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">干杯，请关注更多此类内容！:)</p><p id="ef50" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你喜欢它的内容，你现在也可以给我买一杯咖啡！<br/> <a class="ae jt" href="https://www.buymeacoffee.com/samunderscore12" rel="noopener ugc nofollow" target="_blank"> samunderscore12正在创作数据科学内容！(buymeacoffee.com)</a></p></div></div>    
</body>
</html>