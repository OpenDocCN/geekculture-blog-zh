<html>
<head>
<title>TensorFlow CNN for Multilabel Image Classification Task</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于多标记图像分类任务的张量流CNN</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/tensorflow-cnn-for-intel-image-classification-task-2f6326e83ea?source=collection_archive---------16-----------------------#2021-11-16">https://medium.com/geekculture/tensorflow-cnn-for-intel-image-classification-task-2f6326e83ea?source=collection_archive---------16-----------------------#2021-11-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/16a9875a552a8072e7bd352f008a0cde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1MTy0gfVGGMRcCOE"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Photo by <a class="ae hv" href="https://unsplash.com/@pietrozj?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Pietro Jeng</a> on <a class="ae hv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><div class=""><h2 id="5f23" class="pw-subtitle-paragraph iv hx hy bd b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm dx translated">用TensorFlow建立一个简单的CNN并使用数据扩充</h2></div><p id="4750" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">卷积神经网络(CNN)诞生于1990年，源于Yann LeCun及其团队基于人脑视觉皮层功能的研究[1][2]。由于它们能够获得的优异性能，尤其是在图像识别领域，即使在今天，CNN也被认为是模式和图像识别领域的“最先进水平”。Yann LeCun在2019年因其工作获得了图灵奖。</p><p id="ea69" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">今天，建立一个卷积网络并获得良好的结果是相对简单和容易的。我们将在这个简短的指南中了解如何使用这样的网络来解决英特尔图像分类任务，您可以在以下链接中找到:<a class="ae hv" href="https://www.kaggle.com/puneet6060/intel-image-classification" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/puneet 6060/Intel-Image-Classification</a>。</p><h2 id="b0a6" class="kj kk hy bd kl km kn ko kp kq kr ks kt jw ku kv kw ka kx ky kz ke la lb lc ld bi translated">资料组</h2><p id="dc8f" class="pw-post-body-paragraph jn jo hy jp b jq le iz js jt lf jc jv jw lg jy jz ka lh kc kd ke li kg kh ki hb bi translated">普内特.班萨尔。(2019年1月)。英特尔图像分类，第2版。检索于2021年11月16日，来自<a class="ae hv" href="https://www.kaggle.com/puneet6060/intel-image-classification" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/rtatman/r-vs-python-the-kitchen-gadget-test</a>。</p><h2 id="a6a3" class="kj kk hy bd kl km kn ko kp kq kr ks kt jw ku kv kw ka kx ky kz ke la lb lc ld bi translated">数据准备</h2><p id="fd55" class="pw-post-body-paragraph jn jo hy jp b jq le iz js jt lf jc jv jw lg jy jz ka lh kc kd ke li kg kh ki hb bi translated">在下载数据集的zip文件并提取它之后，要做的第一件事是组织所有的图像。训练图像都在“seg_train”文件夹中。我们将创建一个包含子文件夹“train”和“val”的新文件夹“training”。然后，让我们编写代码，将“seg_train”中的图像分割到这两个新的子文件夹中。</p><p id="3bf5" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们将要定义的<em class="lj"> split_data </em>函数将有3个输入参数，原始文件夹的路径和两个新的子文件夹的路径。</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lk"><img src="../Images/1a4bd321c4e0dfa670ffd2f6320c5ea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cD4uLNd35kMlJ-kMGeczGQ.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Split your data into T<em class="lp">rain and Val folders</em></figcaption></figure><p id="bdd4" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">既然我们已经清理了我们的文件系统，我们可以使用我们的数据来实际创建训练、验证和测试集，以馈送到我们的网络。TensorFlow为我们提供了<em class="lj"> ImageDataGenerator </em>类<em class="lj"> </em>以非常简单的方式编写基本的数据处理。</p><p id="b110" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">训练集预处理器将执行输入图像像素的缩放，将它们除以255。<em class="lj"> rotation_range </em>和<em class="lj"> width_shift_range </em>通过修改图像的一些特征来进行一些数据扩充。请注意，验证数据的预处理器没有数据扩充特性，因为我们希望保持不变，以便更好地验证我们的模型。</p><p id="90e0" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">然后，我们使用这些处理器通过<em class="lj"> flow_from_directory </em>函数从目录中读取数据。注意此功能可以自动计算出每张图片的标签，因为它会将<em class="lj">森林文件夹</em>等中的所有图片标记为<em class="lj">森林</em></p><p id="3ff2" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">其他需要指定的是图像的路径、图像的大小、3个RGB通道、数据混洗、批量大小，并指定我们正在谈论的类别。</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lq"><img src="../Images/d366b0091601b5baed7b3b39a740691e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*urp9L-OtNSppMJNOxAXHJA.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Use generators to create the actual datasets</figcaption></figure><h2 id="627b" class="kj kk hy bd kl km kn ko kp kq kr ks kt jw ku kv kw ka kx ky kz ke la lb lc ld bi translated">模型定义</h2><p id="6775" class="pw-post-body-paragraph jn jo hy jp b jq le iz js jt lf jc jv jw lg jy jz ka lh kc kd ke li kg kh ki hb bi translated">最后，我们继续定义卷积模型。为了保持本指南的简单，模型将仅由定义输入图像大小的<em class="lj">输入层</em>构成。然后将有几个<em class="lj">卷积层</em>，后面是<em class="lj">最大池</em>层。最后，两个<em class="lj">密集层</em>，其中输出神经元的数量等于要分类的类的数量，以便softmax函数返回概率分布。(<em class="lj">展平</em>层用于将多维输入张量展平为一维)</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lr"><img src="../Images/3e8db9544bebb00b1956ecf2d29e0f3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_N5QvYVR_cQwSo2netborw.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Let’s define the deep learning model</figcaption></figure><p id="9763" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz">培训</strong></p><p id="ca6d" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">导入必要的库:</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ls"><img src="../Images/cca64ca366b555c38fdac383539c5f58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jYy-wTG0xfMDS-WGjYlI-g.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Import the necessary libraries</figcaption></figure><p id="449a" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在训练步骤中，我们将使用回调<em class="lj">模型检查点</em>，它允许我们不时地保存在每个时期找到的最佳模型(根据验证损失进行评估)。如果在<em class="lj">耐心=x </em>次后没有改善，则<em class="lj">提前停止</em>回调用于中断训练阶段。我们照常编译和拟合模型。记得包括两个回调。</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lt"><img src="../Images/6526f1af20f6b29055280d74e6833e31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cu21xdwn5CRHYxZ3WeuaIQ.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Training phase with callbacks definition</figcaption></figure><h2 id="60cc" class="kj kk hy bd kl km kn ko kp kq kr ks kt jw ku kv kw ka kx ky kz ke la lb lc ld bi translated">评价</h2><p id="e801" class="pw-post-body-paragraph jn jo hy jp b jq le iz js jt lf jc jv jw lg jy jz ka lh kc kd ke li kg kh ki hb bi translated">现在让我们加载我们保存的最佳模型。我们可以使用<em class="lj"> summary() </em>函数再次检查我们的模型架构。然后让我们在验证集和测试集上评估这个模型！</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lu"><img src="../Images/64794fabff97de002a6102454b293bfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-UWqBn0SPfk5NucHwhZbFQ.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Model evaluation</figcaption></figure><h2 id="7ca0" class="kj kk hy bd kl km kn ko kp kq kr ks kt jw ku kv kw ka kx ky kz ke la lb lc ld bi translated">预测</h2><p id="0503" class="pw-post-body-paragraph jn jo hy jp b jq le iz js jt lf jc jv jw lg jy jz ka lh kc kd ke li kg kh ki hb bi translated">既然模型已经被训练和保存，我们可以用它来预测新的图像！<br/>在函数<em class="lj"> predict_with_model </em>中，我们必须首先做一些无聊的预处理步骤，以调整输入图像的大小，使其为150x150，以便将其输入网络。<br/>预测函数将返回各种类别的概率分布，使用<em class="lj"> argmax </em>函数，我们将返回最有可能的类别。我们可以使用字典映射将获得的数字转换为最终的标签！</p><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lv"><img src="../Images/fbeab71128d6f5c747106a6262c20a91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hmd-QtK_i3YiUbif0Oh-zA.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Let’s predict new images!</figcaption></figure><h2 id="b81d" class="kj kk hy bd kl km kn ko kp kq kr ks kt jw ku kv kw ka kx ky kz ke la lb lc ld bi translated">结束了</h2><p id="5a6d" class="pw-post-body-paragraph jn jo hy jp b jq le iz js jt lf jc jv jw lg jy jz ka lh kc kd ke li kg kh ki hb bi translated">马尔切洛·波利蒂</p></div><div class="ab cl lw lx gp ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="hb hc hd he hf"><h1 id="b0d6" class="md kk hy bd kl me mf mg kp mh mi mj kt je mk jf kw jh ml ji kz jk mm jl lc mn bi translated">文献学</h1><p id="43ed" class="pw-post-body-paragraph jn jo hy jp b jq le iz js jt lf jc jv jw lg jy jz ka lh kc kd ke li kg kh ki hb bi translated">[1] Y. LeCunn e团队:用反向传播网络进行手写数字识别，NeurIPS会议，(1989年)</p><p id="d544" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">[2]大卫·H·哈贝尔:我们关于猫皮层的第一篇论文，牛津网站，(1959年)</p></div></div>    
</body>
</html>