<html>
<head>
<title>Classifying spiders of Kentucky with fastAi. Part III</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用fastAi分类肯塔基蜘蛛。第三部分</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/building-a-state-of-the-art-fastai-app-to-identify-the-strange-and-dangerous-spiders-of-kentucky-9e070246c180?source=collection_archive---------26-----------------------#2021-08-15">https://medium.com/geekculture/building-a-state-of-the-art-fastai-app-to-identify-the-strange-and-dangerous-spiders-of-kentucky-9e070246c180?source=collection_archive---------26-----------------------#2021-08-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7fde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第三部分</strong></p><p id="4314" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好了，你回来了，我们的蜘蛛探测器模型的第三部分。为了概括我们到目前为止的进展，我们回顾一下第一部分。第一部分演示了我们如何使用bing API来获取web上的蜘蛛图像，将我们的数据下载到单独的文件夹中，并使用fastAi通过数据加载器来管理我们的下载。数据加载器用于将我们的训练和验证文件输入机器学习模型。</p><p id="a4a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" rel="noopener" href="/@chris.kehl/building-a-state-of-the-art-fastai-app-to-identify-the-strange-and-dangerous-spiders-of-kentucky-50c0995b20c3">第二部分</a>建立我们的初始基线模型，以便在我们创建更复杂的模型时对自己进行评估，目的是通过微调超参数进行改进。使用VGG19迁移学习模型时，我们的基线错误率为0.047，使用resnet34时，基线模型的错误率为0.049。因此，为了改进这些模型，我们将应用某些技术，如清理我们的数据，微调我们的超参数以降低我们的错误率。我用来清理数据集的技术是查看每个文件夹中的每张照片。这似乎很乏味，而且确实如此。我删除了所有包含蜘蛛位置地图的照片；另外，我把所有看起来和其余蜘蛛不搭的照片都去掉了。从第二部分的混淆矩阵中，我注意到模型很难区分北方黑寡妇蜘蛛和南方黑寡妇蜘蛛。为了努力改进模型，我在谷歌上搜索了差异。我发现南方黑寡妇的下腹有完整的沙漏形状，而北方黑寡妇的沙漏有一个缺口。你可以在谷歌上搜索每个文件夹中的物种，了解这个物种的样子。如果你在我们的数据集中得到奇怪的图像，我会把它们去掉。</p><p id="168e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从我们的模型改进开始，我将设置我们的笔记本来安装所有必要的库。这一步和第一部分完全一样。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="f4d9" class="jn jo hi jj b fi jp jq l jr js"># import all the needed libraries and packages</span><span id="8ac7" class="jn jo hi jj b fi jt jq l jr js">!pip install -Uqq fastbook<br/>import fastbook<br/>import warnings<br/>import os</span><span id="c6ce" class="jn jo hi jj b fi jt jq l jr js">fastbook.setup_book()<br/>from fastai.vision.all import *<br/>from fastbook import *<br/>from fastai.vision.widgets import *</span></pre><p id="71b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我还将确保我们的设备正在gpu上运行，因此，如果gpu可用，我将使用以下代码来启用它。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="2687" class="jn jo hi jj b fi jp jq l jr js"># enable fastai to access the GPU<br/># ensure to enable runtime to GPU</span><span id="64ac" class="jn jo hi jj b fi jt jq l jr js">if torch.cuda.is_available():<br/>device = torch.device("cuda")<br/>else:<br/>device = torch.device("cpu")</span><span id="fa75" class="jn jo hi jj b fi jt jq l jr js">!nvidia-smi</span></pre><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es ju"><img src="../Images/36fadf39d4e2dd4110721ce90773af87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qDVXjkvqs9UcnkhONIf0_w.png"/></div></div></figure><p id="d968" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">运行上述代码后，我们可以看到我正在使用Tesla p100-PCIE GPU运行笔记本和模型。现在我正在使用谷歌Colab，如果你是深度学习的新手，并且没有配备英伟达GPU的系统，我建议你使用Colab。</p><p id="47c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我还将我的文件存储在Google Drive上，所以我使用下面的代码来更改我的驱动器，并将我的路径设置为spider目录。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="342a" class="jn jo hi jj b fi jp jq l jr js">os.getcwd()</span></pre><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es kc"><img src="../Images/f469119a05cceb1555435fa93ccf01ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NUoI8JdFGI3cyuWXc-ojNQ.png"/></div></div></figure><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="79d0" class="jn jo hi jj b fi jp jq l jr js"># change to your working directory where you have your spider folders</span><span id="74dd" class="jn jo hi jj b fi jt jq l jr js">os.chdir('/content/gdrive/MyDrive/')<br/>os.getcwd()</span></pre><figure class="je jf jg jh fd jv er es paragraph-image"><div class="er es kd"><img src="../Images/ddc1f499bc6b78e00bfdc971b1ba75eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*L3_SYY_4BuoDnAXhY7UAsA.png"/></div></figure><p id="1726" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用path = Path('spider ')来设置目录，在这个目录中我们有每种蜘蛛的所有文件夹。在第一部分中，我们使用Bing API来抓取网页，并得到许多蜘蛛标本的图像。如果您没有执行该步骤，您可以返回并重新访问第一部分。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="d675" class="jn jo hi jj b fi jp jq l jr js">path = Path('spider')</span></pre><p id="38c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们实际上通过简单地命名fns来获得图像文件，因为我们想要获得路径path中的所有蜘蛛种类文件夹。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="ec21" class="jn jo hi jj b fi jp jq l jr js">fns = get_image_files(path)<br/>fns</span></pre><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es ke"><img src="../Images/76a322fa75c6dc6d30bf15dd21054f1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pyds5qeyyvArk8zpQLalUw.png"/></div></div></figure><p id="8b11" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面的代码为我们设置了数据加载器。DataLoader是pytorch在数据集(spider目录和所有子目录)周围包装iterable的方法，这允许fastai(即pytorch)轻松访问我们的样本图像。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="e11f" class="jn jo hi jj b fi jp jq l jr js">class DataLoaders(GetAttr):<br/>    def __init(self, *loaders): self.loaders = loaders<br/>    def __getitem__(self, i): return self.loaders[i]<br/>    train, valid = add_props(lambda i,self: self[i])</span></pre><p id="3202" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这一点上，就像在第一部分中一样，我们将识别我们的数据，执行所有的过程，让我们的模型说这是我们的数据，并将数据分成我们的训练和验证集。我们将80%的数据设置为训练集，20%的数据进入验证集。你还会注意到，我们已经调整了我们的图像大小为224像素。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="2583" class="jn jo hi jj b fi jp jq l jr js"># were using the splitter here to split the data 80% training set and 20% test set<br/># with this we are resizing our images to 224</span><span id="3d7a" class="jn jo hi jj b fi jt jq l jr js">spiders = DataBlock(<br/>    blocks=(ImageBlock, CategoryBlock),<br/>    get_items=get_image_files,<br/>    splitter=RandomSplitter(valid_pct=0.2, seed=42),<br/>    get_y=parent_label,<br/>    item_tfms=Resize(224))</span></pre><p id="94c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们检查并确保我们的数据加载器正在工作，我们指向正确的路径。现在，我的路径再次指向我的google drive中的蜘蛛目录。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="e9fe" class="jn jo hi jj b fi jp jq l jr js">dls = spiders.dataloaders(path)<br/>dls.valid.show_batch(max_n=4, nrows=1)</span></pre><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es kf"><img src="../Images/601ce943ec0b4502cb787e02ab191d84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nftnvot9XFD6GpNgPk1wZw.png"/></div></div></figure><p id="0a48" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在第一部分中，我们讨论了数据扩充。现在，数据增强帮助我们让数据集看起来更大。我们通过旋转图像、裁剪图像的一部分、模糊图像等方式来改变图像。对于我们正在处理的数据集，我们绝对需要这个。清理该数据集后，我们创建了一个不平衡的数据集。这真的是一种不可取的数据科学方法，但是嘿，我们不是要去月球。如果我们想尽可能完美，我会聘请专家收集照片，把它们送到野外，让他们给每个物种分类。这可能需要很长时间，所以现在我们只是让Bing做它的事情。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="1074" class="jn jo hi jj b fi jp jq l jr js"># apply augmented transformations to the images</span><span id="02ab" class="jn jo hi jj b fi jt jq l jr js">spiders = spiders.new(item_tfms=RandomResizedCrop(224, min_scale=0.5),<br/>batch_tfms=aug_transforms(size=224, min_scale=0.75))<br/>dls = spiders.dataloaders(path)</span></pre><p id="7de8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">很好，目前为止我们做得很好。现在是时候开始用我们的模型工作了，让它打败我们的基线模型。让我们开始让这个模型学习。</p><p id="838a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我添加了下面的代码，你会看到我只是将学习率设置为0.0001。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="2939" class="jn jo hi jj b fi jp jq l jr js">learn = cnn_learner(dls, resnet152,metrics=error_rate)<br/>learn.fit_one_cycle(3, 0.0001)</span></pre><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es kg"><img src="../Images/a186119843dacc7642d13687b77aae01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zTgrgrPyvnPDUNZhfMmanQ.png"/></div></div></figure><p id="9578" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在模型中使用迁移学习。这里我用的是resnet152。当我们使用迁移学习时，我们使用的是一个已经包含训练权重和模型的预训练模型。resnet152是我上次运行的型号。为了使本文简单，resnet152是我结束我的模型的地方。我从resnet18开始，然后运行resnet34、resnet50，一直到resnet152。我建议做同样的事情，这样你就可以看到不同的转移模型是提高了还是降低了。所以，我有resnet152使用152层，最后一层可能不会为蜘蛛模型工作，所以我们需要扔掉它，并添加另一层，我们可以训练。我们将冻结训练好的模型，并允许我们使用微调方法修改最终层，这将使我们的模型符合数据。让我们开始吧。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="5ddb" class="jn jo hi jj b fi jp jq l jr js">learn.unfreeze()</span></pre><p id="29d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Fastai有一个工具，我们可以找到合适的学习率。我们需要这一点，这样我们就不只是猜测使用什么学习率，或者必须使用一个通用的学习率，如0.001，或0.0001。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="8ded" class="jn jo hi jj b fi jp jq l jr js">learn.lr_find()</span></pre><figure class="je jf jg jh fd jv er es paragraph-image"><div class="er es kh"><img src="../Images/692545096849383e1b3d6c0f72b3ee94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*ego67NebWLwLDSGIfH19Hw.png"/></div></figure><p id="7246" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你跟着代码走，你会注意到在我们的学习率图表上面会给你建议的学习率。它提供了0.000275，所以我将它四舍五入为0.0003，如下面的代码所示。</p><figure class="je jf jg jh fd jv er es paragraph-image"><div class="er es ki"><img src="../Images/b5faaa2483ec1b0c16a44aca172d24fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*74mZJ0mRiKUf_LtGzMi2jQ.png"/></div></figure><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="993f" class="jn jo hi jj b fi jp jq l jr js">learn.fit_one_cycle(6, lr_max=0.0003)</span></pre><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es kc"><img src="../Images/a8ffc0be0324c2ebc321dd0154bb9763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pVEGimcGCtMGHHEM_BwOlA.png"/></div></div></figure><p id="0383" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以看到我用的是学习率max 0.0003。顺便说一下，我们已经用6个时期0.41的错误率击败了我们的基线模型。fit_one_cycle是我们的模型从低训练重量开始，逐步提高学习率的一种方式。这里，我们将最大学习速率设置为0.0003。我们可以使用learn.fit_one_cycle(6，lr_max=slice(1e-5，1e-3 ),这将为我们的图形提供一个范围，以找到我们的梯度，而不是反弹到我们的图形的一部分向上。让我们来看一个混淆矩阵，看看我们的模型在找到与我们的样本完全匹配时遇到了什么问题。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="41f6" class="jn jo hi jj b fi jp jq l jr js">interp = ClassificationInterpretation.from_learner(learn)<br/>interp.plot_confusion_matrix(figsize=(12,12),dpi=60)</span></pre><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es kj"><img src="../Images/82701ee0f24b4c4d62fd1149e53d417e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Vu7-myMbxWHh2rQYcpmug.png"/></div></div></figure><p id="9557" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Geezz看起来我们的模型真的很难区分北黑寡妇蜘蛛和南黑寡妇蜘蛛。同样在这个模型中，捕鱼蜘蛛很难被区分。圆球蜘蛛遇到了一点小问题。其余的都马马虎虎。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="a5d1" class="jn jo hi jj b fi jp jq l jr js"># look at the predictions that have greater than 5 wrong<br/>interp.most_confused(min_val=5)</span></pre><figure class="je jf jg jh fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es kk"><img src="../Images/a80fb0e110cae72802ce955f121700a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t7Vlo083ihY_hP7jGKw79g.png"/></div></div></figure><p id="5fb0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好，我们看着这个，然后说，嘿，我们从这里去哪里。嗯，就像我之前说的，要取得更大的进步需要一些时间来平衡我们的数据集，并雇佣主题专家去实地识别这些野生物种，或者找到一个平衡的数据集，并为我们准确标记所有蜘蛛图像。我会看着Kaggle，我想我在那里看到了一些蜘蛛种类的数据集。</p><p id="7f17" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我不想再浪费你的时间了，事实上0.41和6个纪元是我最好的模型。如果您愿意，您可以进一步重新启动您的模型并添加更多的历元，或者使用learn.fit_one_cycle(6，lr_max=slice(1e-5，1e-3)来尝试降低错误率。你可以在github <a class="ae jd" href="https://github.com/chris-kehl/Spider_Classifier" rel="noopener ugc nofollow" target="_blank">这里</a>关注我的模型。</p></div></div>    
</body>
</html>