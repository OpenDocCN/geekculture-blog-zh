<html>
<head>
<title>Important points to know from ISLR chapter 2 (Statistical Learning)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从《ISLR》第二章(统计学习)中了解的要点</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/important-points-to-know-from-islr-chapter-2-statistical-learning-c1cfbe8bf48c?source=collection_archive---------22-----------------------#2021-07-18">https://medium.com/geekculture/important-points-to-know-from-islr-chapter-2-statistical-learning-c1cfbe8bf48c?source=collection_archive---------22-----------------------#2021-07-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/aa2fb562c16245d694ce4ae21d07bab1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SHZ4lQrZJWSa3waX"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Photo by <a class="ae iu" href="https://unsplash.com/@franki?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Franki Chamaki</a> on <a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="34dc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">哇！刚刚找到这篇文章的精彩图片，标题为<strong class="ix hj">数据有更好的想法，</strong>是的，数据有真正的想法，为你提供进一步的行动，无论是你的业务，股票市场，金融等。<br/>它会给你进一步思考的正确方法。甚至当我们准备工作面试时，我们也会看过去的面试问题(数据)来获得更好的想法。</p><p id="1e28" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们继续我们的主要话题，我正在读一本很棒的书“<strong class="ix hj"> <em class="jt">【统计学习导论】</em> </strong>第二版。阅读第2章(统计学习)，并想分享一些我认为重要的观点，这些观点应该为任何数据科学、数据分析或机器学习的有志之士所知。</p><p id="a401" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">统计学习是指一套寻找黑箱函数<strong class="ix hj"> f </strong>的方法，黑箱函数是数据点之间的关系。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><ul class=""><li id="c629" class="kb kc hi ix b iy iz jc jd jg kd jk ke jo kf js kg kh ki kj bi translated">可约误差和不可约误差<br/>可约误差是我们可以通过使用最合适的统计学习技术来改善(减少)的误差。然而，伴随目标值而来的不可约误差(ε)不能通过使用预测值(或标记点X)来预测。</li><li id="20f7" class="kb kc hi ix b iy kk jc kl jg km jk kn jo ko js kg kh ki kj bi translated">参数和非参数方法(算法)<br/>参数方法包括逻辑回归、朴素贝叶斯、简单神经网络等等。这些模型更容易解释，在较少的训练数据上表现良好。然而离实际功能太远的<strong class="ix hj"> f. <br/> </strong>非参数方法包括K近邻、决策树、支持向量机等。当你有大量数据时，这些模型表现良好。它们更灵活，因此它们的可解释性更低。然而，它们有过度拟合训练数据的缺点。</li><li id="71e5" class="kb kc hi ix b iy kk jc kl jg km jk kn jo ko js kg kh ki kj bi translated">一般来说，随着方法灵活性的增加，其可解释性会降低。然而，当灵活性增加时，数据过度拟合的机会也会增加。</li></ul><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kp"><img src="../Images/2ea32cabdfdc853cf6df89d4ece035a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ov4jNMyN1QyDESxryyndwg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">A representation of the tradeoff between flexibility and interpretability, using different statistical learning methods.</figcaption></figure><ul class=""><li id="bb36" class="kb kc hi ix b iy iz jc jd jg kd jk ke jo kf js kg kh ki kj bi translated">监督和非监督学习<br/>监督学习，其中我们有预测器(标签)或对应于预测器的响应(目标),我们的目标是预测未来观察的响应。<br/>无监督学习，在这种情况下，我们不知道关于观察的响应。因此，我们寻求理解观察之间的关系。例如:聚类分析。<br/>还有第三种类型也发生在我们对某些观测值有响应(目标值)而对某些没有响应的时候，可能是由于收集响应的高成本。这种类型的学习被称为半监督学习。</li><li id="7a5a" class="kb kc hi ix b iy kk jc kl jg km jk kn jo ko js kg kh ki kj bi translated">监督学习分为回归问题和分类问题两类。<br/>当响应(目标)是真实值或连续值，或数量变量类型，如“工资”、“物品价格”时，这些类型的问题归类于回归问题。<br/>当响应(目标)的定性变量的类型(分类值)像“雄性或雌性”、“狗或猫”时，那么这些问题归类于分类问题。<br/>在回归和分类问题中，选择正确的灵活性水平对任何统计学习方法的成功都至关重要。</li><li id="e0e6" class="kb kc hi ix b iy kk jc kl jg km jk kn jo ko js kg kh ki kj bi translated">随着该方法灵活性的增加，均方误差(简称MSE)单调下降。<br/>然而，当该方法在训练数据上给出小误差(均方误差值)而在测试数据上给出大误差时，我们可以说该模型在训练数据上过度拟合。<br/>为了最小化预期测试误差，我们需要选择一种统计学习方法，同时实现低方差&amp;低偏差。如果一个方法具有低方差，那么对新数据的预测是差的，或者可以说该方法对训练数据过度拟合。</li></ul><figure class="kq kr ks kt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ku"><img src="../Images/d09cb5b809dd62fec54637dd8af40fbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u-WZJf64o0r5miUxzoufyg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Bias (blue curve), variance (orange curve), and test MSE (red curve). The vertical dotted line indicates the flexibility level corresponding to the smallest test MSE</figcaption></figure><p id="0f70" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从上面的图中，我们可以观察到，随着统计方法灵活性的增加，偏差开始减小，比方差的增加要快。我们需要选择方差和偏差都较低的方法。</p><ul class=""><li id="9c75" class="kb kc hi ix b iy iz jc jd jg kd jk ke jo kf js kg kh ki kj bi translated">在分类问题中，当K=1时，K-最近邻(KNN)分类器具有低偏差和高方差。随着K的增长，该方法变得不太灵活，并且具有低方差和高偏差，分类的决策边界变成线性的。</li></ul></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="28a2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这些是我想与社区分享的一些要点。我希望你明白这些事情，或者这篇文章帮助你修正你的概念。</p><p id="9d74" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">敬请期待！我很快会写下一章。我还计划写一些MySQL的操作者，在采访中会被问到哪些问题。</p></div></div>    
</body>
</html>