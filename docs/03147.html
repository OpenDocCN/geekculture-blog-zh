<html>
<head>
<title>Sentiment Analysis using Keras &amp; LSTM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras &amp; LSTM进行情感分析</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/sentiment-analysis-using-rnn-keras-e545fbe000?source=collection_archive---------19-----------------------#2021-06-01">https://medium.com/geekculture/sentiment-analysis-using-rnn-keras-e545fbe000?source=collection_archive---------19-----------------------#2021-06-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="33c7" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用Keras、Python和LSTM构建情感分析器</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/92b69bf3d70dbb7f31eeb9702754d16e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*R97ANpkTHnt55DDG"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@austindistel?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Austin Distel</a> on <a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="19b7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><a class="ae jn" href="https://dictionary.cambridge.org/dictionary/english/sentiment" rel="noopener ugc nofollow" target="_blank"> <strong class="jq hj">情绪</strong> </a> <strong class="jq hj"> </strong>是<strong class="jq hj"> </strong>基于对某一情况的感觉或对某一事物的思考方式而产生的思想、观点或想法。可以是关于电影、食物、餐馆等等。</p><p id="86c5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">借助<em class="kk">用户情感</em>，我们倾向于推荐电影、美食等。</p><p id="5f99" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这里，我们将重点关注由25000条评论组成的<strong class="jq hj"> IMDB电影数据集</strong>，这些评论在训练集中带有正面/负面情感标签，在测试集中也带有相同数量的标签。这个数据集的好处是它默认带有Keras，你不需要从另一个网站下载。</p><p id="19d9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们开始实现吧。</p><p id="c037" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">导入所有的<strong class="jq hj">基础库</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="dc32" class="kq kr hi km b fi ks kt l ku kv">import numpy as np<br/>import pandas as pd<br/>import tensorflow as tf<br/>import keras</span></pre><p id="81b1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">导入IMDB数据集</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="bdd9" class="kq kr hi km b fi ks kt l ku kv">from keras.datasets import imdb</span><span id="1259" class="kq kr hi km b fi kw kt l ku kv">(x_train, y_train),(x_test, y_test) = imdb.load_data(num_words=5000)</span></pre><p id="4400" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">确认数据集大小为25000:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="5a79" class="kq kr hi km b fi ks kt l ku kv">print(x_train.shape)<br/>print(x_test.shape)<br/>print(y_train.shape)<br/>print(y_test.shape)</span></pre><p id="ed55" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们分析一下训练集:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="45f8" class="kq kr hi km b fi ks kt l ku kv">x_train[0]</span></pre><p id="37bb" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">输出</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="0e1a" class="kq kr hi km b fi ks kt l ku kv">[1,<br/> 14,<br/> 22,<br/> 16,<br/> 43,<br/> 530,<br/> 973,<br/> 458,<br/> 4468,<br/> 112,<br/> 50,<br/> 670,<br/> 2,<br/> 9,<br/> 35,<br/> .<br/> .<br/> .<br/> 178,<br/> 32] </span></pre><p id="30e4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这些是<strong class="jq hj">单词索引</strong>的向量表示。我们需要<strong class="jq hj">填充</strong>这个序列到最多500个单词。为此，Keras为我们提供了<em class="kk"> pad_sequences </em>方法:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="d476" class="kq kr hi km b fi ks kt l ku kv">from keras.preprocessing import sequence</span><span id="5d49" class="kq kr hi km b fi kw kt l ku kv">x_train = sequence.pad_sequences(x_train, 500)<br/>x_test = sequence.pad_sequences(x_test, 500)</span></pre><p id="1ef8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在让我们想象一下它是如何改变我们的训练组合的:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="8ec7" class="kq kr hi km b fi ks kt l ku kv">x_train[10]</span></pre><p id="e752" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">输出</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="3192" class="kq kr hi km b fi ks kt l ku kv">array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,<br/>          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,<br/>          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,<br/>          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,<br/>          0,    0,    0,    0,    0,    0,    1,  785,  189,  438,   47,<br/>        110,  142,    7,    6,    2,  120,    4,  236,  378,    7,  153,<br/>         19,   87,  108,  141,   17, 1004,    5,    2,  883,    2,   23,<br/>          8,    4,  136,    2,    2,    4,    2,   43, 1076,   21, 1407,<br/>        419,    5,    2,  120,   91,  682,  189, 2818,    5,    9, 1348,<br/>         31,    7,    4,  118,  785,  189,  108,  126,   93,    2,   16,<br/>        540,  324,   23,    6,  364,  352,   21,   14,    9,   93,   56,<br/>         18,   11,  230,   53,  771,   74,   31,   34,    4, 2834,    7,<br/>          4,   22,    5,   14,   11,  471,    9,    2,   34,    4,  321,<br/>        487,    5,  116,   15,    2,    4,   22,    9,    6, 2286,    4,<br/>        114, 2679,   23,  107,  293, 1008, 1172,    5,  328, 1236,    4,<br/>       1375,  109,    9,    6,  132,  773,    2, 1412,    8, 1172,   18,<br/>          2,   29,    9,  276,   11,    6, 2768,   19,  289,  409,    4,<br/>          2, 2140,    2,  648, 1430,    2,    2,    5,   27, 3000, 1432,<br/>          2,  103,    6,  346,  137,   11,    4, 2768,  295,   36,    2,<br/>        725,    6, 3208,  273,   11,    4, 1513,   15, 1367,   35,  154,<br/>          2,  103,    2,  173,    7,   12,   36,  515, 3547,   94, 2547,<br/>       1722,    5, 3547,   36,  203,   30,  502,    8,  361,   12,    8,<br/>        989,  143,    4, 1172, 3404,   10,   10,  328, 1236,    9,    6,<br/>         55,  221, 2989,    5,  146,  165,  179,  770,   15,   50,  713,<br/>         53,  108,  448,   23,   12,   17,  225,   38,   76, 4397,   18,<br/>        183,    8,   81,   19,   12,   45, 1257,    8,  135,   15,    2,<br/>        166,    4,  118,    7,   45,    2,   17,  466,   45,    2,    4,<br/>         22,  115,  165,  764,    2,    5, 1030,    8, 2973,   73,  469,<br/>        167, 2127,    2, 1568,    6,   87,  841,   18,    4,   22,    4,<br/>        192,   15,   91,    7,   12,  304,  273, 1004,    4, 1375, 1172,<br/>       2768,    2,   15,    4,   22,  764,   55,    2,    5,   14, 4233,<br/>          2,    4, 1375,  326,    7,    4, 4760, 1786,    8,  361, 1236,<br/>          8,  989,   46,    7,    4, 2768,   45,   55,  776,    8,   79,<br/>        496,   98,   45,  400,  301,   15,    4, 1859,    9,    4,  155,<br/>         15,   66,    2,   84,    5,   14,   22, 1534,   15,   17,    4,<br/>        167,    2,   15,   75,   70,  115,   66,   30,  252,    7,  618,<br/>         51,    9, 2161,    4, 3130,    5,   14, 1525,    8,    2,   15,<br/>          2,  165,  127, 1921,    8,   30,  179, 2532,    4,   22,    9,<br/>        906,   18,    6,  176,    7, 1007, 1005,    4, 1375,  114,    4,<br/>        105,   26,   32,   55,  221,   11,   68,  205,   96,    5,    4,<br/>        192,   15,    4,  274,  410,  220,  304,   23,   94,  205,  109,<br/>          9,   55,   73,  224,  259, 3786,   15,    4,   22,  528, 1645,<br/>         34,    4,  130,  528,   30,  685,  345,   17,    4,  277,  199,<br/>        166,  281,    5, 1030,    8,   30,  179, 4442,  444,    2,    9,<br/>          6,  371,   87,  189,   22,    5,   31,    7,    4,  118,    7,<br/>          4, 2068,  545, 1178,  829], dtype=int32)</span></pre><p id="5749" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在我们需要构建一个word_to_id字典，这样这些索引就可以转换成单词，以便进一步分析。在字典中，我们将为索引0提供填充令牌，为索引1提供开始令牌，为索引2提供UNK令牌。所以我们必须将默认索引移动3来调整这些标记。</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="6949" class="kq kr hi km b fi ks kt l ku kv">word_to_id = imdb.get_word_index()<br/>word_to_id = {k:(v+3) for k,v in word_to_id.items()}<br/>word_to_id["&lt;PAD&gt;"] = 0<br/>word_to_id["&lt;START&gt;"] = 1<br/>word_to_id["&lt;UNK&gt;"] = 2</span></pre><p id="5e2c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">构建完word_to_it之后，我们需要对word进行标识:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="ff44" class="kq kr hi km b fi ks kt l ku kv">id_to_word = {idx:word for word, idx in word_to_id.items()}</span></pre><p id="ac27" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在我们可以为id_to_word提供一个索引，它将输出与之相关的单词。</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="05f1" class="kq kr hi km b fi ks kt l ku kv">id_to_word[20]</span></pre><p id="ad9a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">输出</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="ed21" class="kq kr hi km b fi ks kt l ku kv">'movie'</span></pre><p id="c2e0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，我们甚至可以阅读我们训练集中的内容:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="a03d" class="kq kr hi km b fi ks kt l ku kv">print(" ".join(id_to_word[id] for id in x_train[10]))</span></pre><p id="171d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">输出</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="f370" class="kq kr hi km b fi ks kt l ku kv">&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;START&gt; french horror cinema has seen something of a &lt;UNK&gt; over the last couple of years with great films such as inside and &lt;UNK&gt; romance &lt;UNK&gt; on to the scene &lt;UNK&gt; &lt;UNK&gt; the &lt;UNK&gt; just slightly but stands head and &lt;UNK&gt; over most modern horror titles and is surely one of the best french horror films ever made &lt;UNK&gt; was obviously shot on a low budget but this is made up for in far more ways than one by the originality of the film and this in turn is &lt;UNK&gt; by the excellent writing and acting that &lt;UNK&gt; the film is a winner the plot focuses on two main ideas prison and black magic the central character is a man named &lt;UNK&gt; sent to prison for &lt;UNK&gt; he is put in a cell with three others the &lt;UNK&gt; insane &lt;UNK&gt; body building &lt;UNK&gt; &lt;UNK&gt; and his retarded boyfriend &lt;UNK&gt; after a short while in the cell together they &lt;UNK&gt; upon a hiding place in the wall that contains an old &lt;UNK&gt; after &lt;UNK&gt; part of it they soon realise its magical powers and realise they may be able to use it to break through the prison walls br br black magic is a very interesting topic and i'm actually quite surprised that there aren't more films based on it as there's so much scope for things to do with it it's fair to say that &lt;UNK&gt; makes the best of it's &lt;UNK&gt; as despite it's &lt;UNK&gt; the film never actually feels &lt;UNK&gt; and manages to flow well throughout director eric &lt;UNK&gt; provides a great atmosphere for the film the fact that most of it takes place inside the central prison cell &lt;UNK&gt; that the film feels very &lt;UNK&gt; and this immensely &lt;UNK&gt; the central idea of the prisoners wanting to use magic to break out of the cell it's very easy to get behind them it's often said that the unknown is the thing that really &lt;UNK&gt; people and this film proves that as the director &lt;UNK&gt; that we can never really be sure of exactly what is round the corner and this helps to &lt;UNK&gt; that &lt;UNK&gt; actually does manage to be quite frightening the film is memorable for a lot of reasons outside the central plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone worried that the film won't deliver by the end won't be disappointed either as the ending both makes sense and manages to be quite horrifying overall &lt;UNK&gt; is a truly great horror film and one of the best of the decade highly recommended viewing</span></pre><p id="b84b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">您还可以尝试训练集中的其他索引来进一步分析用户评论。也试着分析一下y_train集合。你会看到<em class="kk"> 2标签</em>或者<strong class="jq hj"> 0 </strong>(负面评价)或者<strong class="jq hj"> 1 </strong>(正面评价)。</p></div><div class="ab cl kx ky gp kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="hb hc hd he hf"><p id="ac3f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">下一步将是<strong class="jq hj">建立一个模型</strong>，它可以输入训练集并输出<em class="kk">用户评论好坏的概率</em>。</p><ol class=""><li id="bc82" class="le lf hi jq b jr js ju jv jx lg kb lh kf li kj lj lk ll lm bi translated">创建顺序模型的实例</li><li id="72b0" class="le lf hi jq b jr ln ju lo jx lp kb lq kf lr kj lj lk ll lm bi translated">在这种情况下，添加具有最大vocab大小和输出尺寸的嵌入层。</li><li id="d87a" class="le lf hi jq b jr ln ju lo jx lp kb lq kf lr kj lj lk ll lm bi translated">现在添加一层LSTM。</li><li id="b432" class="le lf hi jq b jr ln ju lo jx lp kb lq kf lr kj lj lk ll lm bi translated">为了输出，我们必须添加一个具有一个节点的密集层。</li><li id="35fe" class="le lf hi jq b jr ln ju lo jx lp kb lq kf lr kj lj lk ll lm bi translated">最后，我们必须用损失函数作为二进制交叉熵，优化器作为adam，度量作为准确性来编译用于训练的模型。</li></ol><p id="d6c3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">进口</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="9a05" class="kq kr hi km b fi ks kt l ku kv">from keras.layers import Embedding, LSTM, Dense, Dropout<br/>from keras import Sequential</span></pre><p id="f721" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">模型搭建</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="7d68" class="kq kr hi km b fi ks kt l ku kv">embedding_vector_length = 32 <br/>model = Sequential() <br/>model.add(Embedding(5000, embedding_vector_length, input_length=500)) <br/>model.add(LSTM(100)) <br/>model.add(Dense(1, activation='sigmoid')) <br/>model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy']) </span><span id="354d" class="kq kr hi km b fi kw kt l ku kv">model.summary()</span></pre><p id="8437" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">输出</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="ac20" class="kq kr hi km b fi ks kt l ku kv">Model: "sequential_1"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>embedding_1 (Embedding)      (None, 500, 32)           160000    <br/>_________________________________________________________________<br/>lstm_1 (LSTM)                (None, 100)               53200     <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 1)                 101       <br/>=================================================================<br/>Total params: 213,301<br/>Trainable params: 213,301<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><p id="9aa3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，通过提供训练集、标签、时期、批次等参数来训练模型。我们将使用validation_data，并为其提供x_test和y_test，以便在每个时期我们可以分析训练集和验证集的损失和准确性。</p><p id="3a6b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="kk">批量_大小，历元，LSTM单位等。都是超参数，可以将</em><strong class="jq hj"><em class="kk"/></strong><em class="kk">进一步调整为</em><strong class="jq hj"><em class="kk"/></strong><em class="kk">。</em></p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="f7b4" class="kq kr hi km b fi ks kt l ku kv">model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=64)</span></pre><p id="9063" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">输出</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="6584" class="kq kr hi km b fi ks kt l ku kv">Epoch 1/5<br/>391/391 [==============================] - 297s 750ms/step - loss: 0.5608 - accuracy: 0.7023 - val_loss: 0.3261 - val_accuracy: 0.8634<br/>Epoch 2/5<br/>391/391 [==============================] - 262s 670ms/step - loss: 0.2781 - accuracy: 0.8933 - val_loss: 0.3209 - val_accuracy: 0.8713<br/>Epoch 3/5<br/>391/391 [==============================] - 320s 820ms/step - loss: 0.2390 - accuracy: 0.9074 - val_loss: 0.3154 - val_accuracy: 0.8704<br/>Epoch 4/5<br/>391/391 [==============================] - 370s 947ms/step - loss: 0.2252 - accuracy: 0.9115 - val_loss: 0.3198 - val_accuracy: 0.8698<br/>.<br/>.<br/>.</span></pre><p id="04c3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">在测试中评估我们的车型</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="63d7" class="kq kr hi km b fi ks kt l ku kv">model_eval = model.evaluate(x_test, y_test)</span></pre><p id="e996" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">输出</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="cdc8" class="kq kr hi km b fi ks kt l ku kv">782/782 [==============================] - 103s 131ms/step - loss: 0.4072 - accuracy: 0.8279</span></pre><p id="6795" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">根据您在训练时选择的超参数，您的情况可能会有所不同。</p><p id="5c35" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">保存模型</strong>，以便下次可以直接加载，避免训练阶段。</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="6cb9" class="kq kr hi km b fi ks kt l ku kv">model.save('imdb.h5')</span></pre><p id="0b35" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在让我们预测一些随机评论，看看我们的模型表现如何:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="d753" class="kq kr hi km b fi ks kt l ku kv"># for user prediction<br/>def user_input_processing(review):<br/>    vec = []<br/>    for word in review.split(" "):<br/>        if word[-1] == ".":<br/>            word = word[:-1]<br/>        vec.append(word_to_id[str.lower(word)])<br/>    vec_padded = sequence.pad_sequences([vec], 500)<br/>    print(review, model.predict(vec_padded))</span></pre><p id="37c9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">一个好的复习例子</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="45a5" class="kq kr hi km b fi ks kt l ku kv">user_input_processing("One of the finest films made in recent years.")</span></pre><p id="2c7b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">输出</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="61ba" class="kq kr hi km b fi ks kt l ku kv">One of the finest films made in recent years. [[0.9403163]]</span></pre><p id="9907" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们可以看到我们的模型如何给出0.94 的<strong class="jq hj">输出，从而接近1。因此有了<strong class="jq hj">高度肯定的评价</strong>。</strong></p><p id="97bd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">一个差评例子</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="56d6" class="kq kr hi km b fi ks kt l ku kv">user_input_processing("Predictable and bad. The acting was terrible and the story was common.")</span></pre><p id="46e3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">输出</strong>:</p><pre class="iy iz ja jb fd kl km kn ko aw kp bi"><span id="26b5" class="kq kr hi km b fi ks kt l ku kv">Predictable and bad. The acting was terrible and the story was common. [[0.20036736]]</span></pre><p id="e15f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们可以看到我们的模型如何给出0.2 的<strong class="jq hj">输出，从而接近0。因此出现了<strong class="jq hj">高度负面的评论</strong>。</strong></p><p id="8180" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">你甚至可以从IMDB网站上获取一些用户评论，看看这个模型预测了什么。</p><p id="5125" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果你喜欢读这篇文章，<strong class="jq hj">为它鼓掌。如果你有任何问题或建议，可以在评论区联系我。</strong></p></div></div>    
</body>
</html>