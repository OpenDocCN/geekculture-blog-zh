<html>
<head>
<title>Your Tensorflow Pocket References on Image Data Task</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图像数据任务上的Tensorflow袖珍参考</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/your-tensorflow-pocket-references-on-image-data-88ff84a5a44d?source=collection_archive---------18-----------------------#2022-08-03">https://medium.com/geekculture/your-tensorflow-pocket-references-on-image-data-88ff84a5a44d?source=collection_archive---------18-----------------------#2022-08-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="8c99" class="hg hh hi bd b fp hj hk hl hm hn ho dx hp translated" aria-label="kicker paragraph">张量流</h2><div class=""/><div class=""><h2 id="8740" class="pw-subtitle-paragraph io hr hi bd b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf dx translated">如何使用Tensorflow为图像数据任务建立深度学习模型？</h2></div><figure class="jg jh ji jj fd jk"><div class="bz dy l di"><div class="jl jm l"/></div><figcaption class="jn jo et er es jp jq bd b be z dx">Tensorflow in 100 Seconds</figcaption></figure><blockquote class="jr"><p id="148e" class="js jt hi bd ju jv jw jx jy jz ka kb dx translated">在阅读这篇文章之前，我想让你看一下这个100秒的Tensorflow视频。我发现它很有趣。喜欢读这篇文章。</p></blockquote><p id="8a03" class="pw-post-body-paragraph kc kd hi ke b kf kg is kh ki kj iv kk kl km kn ko kp kq kr ks kt ku kv kw kb hb bi translated">Tensorflow一直是最深入的学习框架之一。基于Stackoverflow的<a class="ae kx" href="https://survey.stackoverflow.co/2022/?" rel="noopener ugc nofollow" target="_blank">最新调查</a>。据说<strong class="ke hs"> 18% </strong>的人比Pytorch( <strong class="ke hs"> 8% </strong>)更可能使用Tensorflow进行深度学习框架的相同比较。因此，花时间学习Tensorflow来建立更好的深度学习模型是非常有益的。我将尽可能多地解释大多数TensorFlow开发人员在从初级到高级建立深度学习模型时使用的技术。</p><p id="5a97" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated">目录<br/> <a class="ae kx" href="#45ae" rel="noopener ugc nofollow">张量</a> <br/> <a class="ae kx" href="#9cd3" rel="noopener ugc nofollow">张量流</a> <br/> <a class="ae kx" href="#dd32" rel="noopener ugc nofollow">预处理数据</a> <br/> <a class="ae kx" href="#f8a2" rel="noopener ugc nofollow">建模</a> <br/> <a class="ae kx" href="#1ec2" rel="noopener ugc nofollow">超参数调谐</a> <br/> <a class="ae kx" href="#465d" rel="noopener ugc nofollow">张量板</a> <br/> <a class="ae kx" href="#e6f9" rel="noopener ugc nofollow">感谢阅读！</a></p><h1 id="45ae" class="ld le hi bd lf lg lh li lj lk ll lm ln ix lo iy lp ja lq jb lr jd ls je lt lu bi translated"><strong class="ak">张量</strong></h1><p id="2ec9" class="pw-post-body-paragraph kc kd hi ke b kf lv is kh ki lw iv kk kl lx kn ko kp ly kr ks kt lz kv kw kb hb bi translated">在进入你能在文档中看到的TensorFlow库中的许多方法之前，最好先了解一下叫做<strong class="ke hs">张量的基本概念。</strong></p><blockquote class="jr"><p id="1876" class="js jt hi bd ju jv ma mb mc md me kb dx translated">张量是什么？</p></blockquote><p id="3b1e" class="pw-post-body-paragraph kc kd hi ke b kf kg is kh ki kj iv kk kl km kn ko kp kq kr ks kt ku kv kw kb hb bi translated">张量是运行在GPU上的n维数组。大多数深度学习模型都是基于张量的。因此，在适合深度学习模型之前，必须将数据转换为张量。张量有几种类型，即<strong class="ke hs">标量(仅幅度)、矢量(幅度和方向)、矩阵(数字表)、3-张量(数字的立方)和n-张量(任意数字&gt; 3)，如以下注释所示。</strong></p><pre class="jg jh ji jj fd mf mg mh mi aw mj bi"><span id="0b75" class="mk le hi mg b fi ml mm l mn mo"><strong class="mg hs">scalar</strong> = 60<br/><strong class="mg hs">vector </strong>= [1.5, 2.6, 3.9]<br/><strong class="mg hs">matrix</strong> = [[1, 4, 6], [7, 6, 8], [2, 5, 10]]<br/><strong class="mg hs">3-tensor</strong> = [[[4], [5], [6]], [[7], [9], [10]], [[16], [18], [20]]]<br/>.....<br/><strong class="mg hs">n-tensor</strong></span></pre><p id="19a1" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated">如果你曾经使用Numpy做过矩阵计算，你将能够更快地学习张量，因为它们非常相似。它们之间的区别是Numpy是使用CPU计算的，而tensor是使用GPU计算的，这将加快我们的深度学习模型的运行速度，因为它的能力和一些优势。因此，张量非常需要运行深度神经网络来解决回归、分类等任何问题，甚至解决自动驾驶汽车问题，如(图像分割、实例分割和对象检测)。</p></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><h1 id="9cd3" class="ld le hi bd lf lg mw li lj lk mx lm ln ix my iy lp ja mz jb lr jd na je lt lu bi translated"><strong class="ak">张量流</strong></h1><blockquote class="jr"><p id="a7b5" class="js jt hi bd ju jv ma mb mc md me kb dx translated">什么是张量流？</p></blockquote><p id="dc7e" class="pw-post-body-paragraph kc kd hi ke b kf kg is kh ki kj iv kk kl km kn ko kp kq kr ks kt ku kv kw kb hb bi translated">Tensorflow是一个端到端的开源平台，用于构建深度学习模型。我们使用Tensorflow来计算张量和建立深度学习模型。我们可以使用TensorFlow创建任何类型的张量。</p><pre class="jg jh ji jj fd mf mg mh mi aw mj bi"><span id="1d00" class="mk le hi mg b fi ml mm l mn mo">import tensorflow as tf <br/>scalar =tf.Variable(60)<br/>vector =tf.Variable([1.5, 2.6, 3.9])<br/>matrix =tf.Variable([[1, 4, 6], [7, 6, 8], [2, 5, 10]])</span></pre><p id="fb44" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated">以上是在Tensorflow中创建张量的几个例子。有各种各样的方法可以使用，比如tf.constant。我们不会深入探讨这些主题，因为我们将涵盖预处理数据、构建模型和调整超参数以使用tensorboard可视化数据的大多数技术和方法。</p></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><h1 id="dd32" class="ld le hi bd lf lg mw li lj lk mx lm ln ix my iy lp ja mz jb lr jd na je lt lu bi translated"><strong class="ak">预处理数据</strong></h1><p id="5d1e" class="pw-post-body-paragraph kc kd hi ke b kf lv is kh ki lw iv kk kl lx kn ko kp ly kr ks kt lz kv kw kb hb bi translated">数据以各种形式出现。它们可以是文本、图像、音频等。如果数据不是像字符串类型的文本那样的数字，所有这些类型的形式都不能适合神经网络。我们必须将其转换为数字形式，以便适应深度学习模型。在本文中，我们将重点关注图像数据。图像基本上是数字的形式。它是一个从0到255的像素数组的集合，可以是灰度图像(黑白)或RGB图像。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es nb"><img src="../Images/3b077c1623c2456f2dd30e94c33353b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*L30-5YxZDM2-lClCPIdUVA.png"/></div><figcaption class="jn jo et er es jp jq bd b be z dx">Grayscale Image in Pixels</figcaption></figure><p id="6b7b" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated">您可以从由0到255之间的数字组成的灰度图像中看到。值越低，图像越暗，反之亦然。图像可以分为灰度和RGB。我们在现实世界中看到的大多数图像都是RGB图像。RGB是红色、绿色和蓝色的缩写。一幅图像由每个R、G和B部分上的0-255组成。大多数深度学习从业者将此称为术语通道。在将我们的数据拟合到深度学习模型之前，我们必须要做各种技术，例如通过将每个像素除以255(归一化)，将数据重新缩放到0到1。这种技术有助于神经网络更快地学习数据，与没有重新缩放/归一化的数据相比更快地收敛。在TensorFlow中，我们可以通过使用TensorFlow框架<strong class="ke hs">中可用的<strong class="ke hs"> ImageDataGenerator </strong>和<strong class="ke hs">预处理实例</strong>来重新缩放数据。</strong>此外，它可以用于执行数据扩充，如以下代码所示</p><pre class="jg jh ji jj fd mf mg mh mi aw mj bi"><span id="04f6" class="mk le hi mg b fi ml mm l mn mo">from tensorflow.keras.preprocessing.image import ImageDataGenerator<br/>train_datagen_augmented = ImageDataGenerator(rescale=1/255.,rotation_range=0.2,<br/>                                  zoom_range=0.2,<br/>                                  width_shift_range=0.2,<br/>                                  height_shift_range=0.0,)</span></pre><p id="f88b" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated">对于数据扩充，Tensorflow还提供了另一个类来扩充数据，如以下代码所示。当我们在不同的文章中对人类皮肤数据集上的<strong class="ke hs">蚊子实现这些代码时，你会进一步理解。因此，在将其应用于深度学习模型之前，请确保您了解TensorFlow如何帮助增强图像数据。你可以看到我们水平翻转图像，旋转图像20%，等等。</strong></p><pre class="jg jh ji jj fd mf mg mh mi aw mj bi"><span id="601b" class="mk le hi mg b fi ml mm l mn mo">from tensorflow.keras.layers.experimental import preprocessing<br/>data_augmentation = keras.Sequential([<br/>  preprocessing.RandomFlip("horizontal"),<br/>  preprocessing.RandomRotation(0.2),<br/>  preprocessing.RandomZoom(0.2),<br/>  preprocessing.RandomHeight(0.2),<br/>  preprocessing.RandomWidth(0.2),<br/>  <em class="ne">#preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNetB0</em><br/>], name ="data_augmentation")</span></pre><p id="32d2" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated">在预处理图像之前，如重新调整数据、扩充数据等。最好是将数据可视化，以便知道我们要建模什么样的图像。使用matplotlib或TensorFlow有两种方法可以做到这一点。</p><p id="4bf8" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated"><strong class="ke hs">使用Matplotlib </strong></p><pre class="jg jh ji jj fd mf mg mh mi aw mj bi"><span id="d2b9" class="mk le hi mg b fi ml mm l mn mo">from pylab import imread,subplot,imshow,show<br/><br/>import matplotlib.pyplot as plt<br/><br/>image = imread(target_image_url)  // choose target folder<br/><br/>plt.imshow(image)<br/>plt.title(target_class)<br/>plt.axis("off");</span></pre><p id="123c" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated"><strong class="ke hs">使用张量流</strong></p><pre class="jg jh ji jj fd mf mg mh mi aw mj bi"><span id="f2cd" class="mk le hi mg b fi ml mm l mn mo">import tensorflow as tf<br/>import matplotlib.pyplot as plt<br/>img =tf.io.read_file("target_image_url")<br/>img=tf.io.decode_image(img,3)<br/>plt.imshow(img.numpy())<br/>plt.axis(False)</span></pre></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><h1 id="f8a2" class="ld le hi bd lf lg mw li lj lk mx lm ln ix my iy lp ja mz jb lr jd na je lt lu bi translated"><strong class="ak">建模</strong></h1><p id="449e" class="pw-post-body-paragraph kc kd hi ke b kf lv is kh ki lw iv kk kl lx kn ko kp ly kr ks kt lz kv kw kb hb bi translated">大多数深度学习框架中的建模包括两种方式，要么从头实现，要么进行迁移学习。从零开始实施意味着通过实施所需的层来建立深度学习模型，并根据有多少图像可用来训练数据。迁移学习带来了不同的方式。我们受益于使用特定模型架构中可用的几个层，这些层已经在更大的数据集上进行了训练，可以在我们的特定数据集中使用。这可能是有帮助的，因为使用神经网络训练数据需要更多的计算机资源，这些资源可以通过使用迁移学习来减少。</p><p id="50c7" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated">下面显示了从头开始的模型架构的实现。</p><pre class="jg jh ji jj fd mf mg mh mi aw mj bi"><span id="7610" class="mk le hi mg b fi ml mm l mn mo">model = tf.keras.models.Sequential([<br/>  tf.keras.layers.Flatten(input_shape=(224, 224,3)),<br/>  tf.keras.layers.Dense(128, activation='relu'),<br/>  tf.keras.layers.Dense(10,activation="softmax")<br/>])</span></pre><p id="634a" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated">您可以看到这个简单的模型架构，它具有224*224的输入图像和3个RGB通道，以确定10个输出。你必须记住的一件事是，在对下一个隐藏层进行张量计算之前，不要忘记展平图像。在现实生活中，创建模型架构有多种方式，即<strong class="ke hs">顺序API、函数API和模型子类化</strong>。上面的代码是一个顺序API。我们将在另一篇文章中对此进行更深入的探讨。</p><p id="bed3" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated">使用迁移学习的模型架构的实现可以通过如下所示的两种方式进行</p><p id="0529" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated"><strong class="ke hs">使用tf.keras.application </strong></p><pre class="jg jh ji jj fd mf mg mh mi aw mj bi"><span id="50ff" class="mk le hi mg b fi ml mm l mn mo">IMG_SHAPE = (224,224) + (3,)<br/>base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,<br/>                                               include_top=False,<br/>                                               weights='imagenet')</span></pre><p id="28c3" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated"><strong class="ke hs">使用Tensorflow Hub </strong></p><pre class="jg jh ji jj fd mf mg mh mi aw mj bi"><span id="7767" class="mk le hi mg b fi ml mm l mn mo">mobilenet_v2 ="https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4"<br/>IMAGE_SHAPE = (224, 224)<br/><br/>classifier = tf.keras.Sequential([<br/>    hub.KerasLayer(mobilenet_v2, input_shape=IMAGE_SHAPE+(3,))<br/>])</span></pre><p id="cedf" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated">你可以看到我们使用<strong class="ke hs"> MobileNet版本2 </strong>对图像进行分类。我们使用<strong class="ke hs"> include_top=False </strong>来表示我们基于自己的数据集有不同的输出。您可以通过查看<a class="ae kx" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications" rel="noopener ugc nofollow" target="_blank"> <strong class="ke hs">迁移学习模型架构</strong> </a>或<a class="ae kx" href="https://tfhub.dev/" rel="noopener ugc nofollow" target="_blank"><strong class="ke hs">tensor flow Hub</strong></a>中的文档来调整不同的模型架构。</p></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><h1 id="1ec2" class="ld le hi bd lf lg mw li lj lk mx lm ln ix my iy lp ja mz jb lr jd na je lt lu bi translated"><strong class="ak">超参数调谐</strong></h1><p id="bf33" class="pw-post-body-paragraph kc kd hi ke b kf lv is kh ki lw iv kk kl lx kn ko kp ly kr ks kt lz kv kw kb hb bi translated">在建立深度学习模型时，我们必须设置一些超参数，以便在我们定义的指标上创建更好的分数。它们是学习速率、批量大小、引入非线性的激活函数以及时期的数量。<strong class="ke hs">太大的学习率</strong>会使步长爆炸，不能收敛到全局最小值，而太小的学习率会消失梯度下降。为了避免这种情况，可以实现这个回调Tensorflow，并在拟合数据时实现这个实例。</p><pre class="jg jh ji jj fd mf mg mh mi aw mj bi"><span id="3b9e" class="mk le hi mg b fi ml mm l mn mo">reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor="val_loss",  <br/>                                                 factor=0.2, <em class="ne">#multiply the learning rate by 0.2 (reduce by 5x)</em><br/>                                                 patience=2,<br/>                                                 verbose=1, <em class="ne"># print</em><br/>                                                 min_lr=1e-7)</span></pre><p id="427a" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated"><strong class="ke hs">批量大小</strong>在达到收敛方面也起着重要作用。建议对图像数据使用32。关于批量大小的有意义的见解可以在这条推特上查看，这条推特来自我最喜欢的机器学习的影响者之一(【PyTorch和Scikit-Learn 的机器学习的作者)，关于是否在批量大小中使用2的幂。</p><figure class="jg jh ji jj fd jk"><div class="bz dy l di"><div class="nf jm l"/></div></figure><p id="c7ef" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated"><strong class="ke hs">次数</strong>显示整个训练数据在训练网络中的次数。您可以看到，我们使用5个历元，并在前向和后向传播期间训练了5次，以根据损失来估计最佳权重。时代的数量取决于许多因素，无论我们是使用迁移学习还是从头开始实施。如果我们使用迁移学习，我们可以使用小的时期，因为它已经从更大的数据集(如<a class="ae kx" href="https://www.image-net.org/update-mar-11-2021.php" rel="noopener ugc nofollow" target="_blank"> <strong class="ke hs"> ImageNet </strong> </a>)中学习了模式，并在从头实现模型架构时使用更大的时期。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="er es ng"><img src="../Images/ea87bc33c772aced397f0bc5b084e9cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1oBjKvgQZ9bY4b0nQGYgGw.png"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx">Epochs</figcaption></figure></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><h1 id="465d" class="ld le hi bd lf lg mw li lj lk mx lm ln ix my iy lp ja mz jb lr jd na je lt lu bi translated"><strong class="ak">张量板</strong></h1><p id="ae5a" class="pw-post-body-paragraph kc kd hi ke b kf lv is kh ki lw iv kk kl lx kn ko kp ly kr ks kt lz kv kw kb hb bi translated">Tensorboard是我最喜欢的试镜之一。我们可以根据拟合数据时所做的训练来可视化数据。此外，Tensorflow提供了Tensorboard Dev，以便我们可以在<strong class="ke hs">t</strong><a class="ae kx" href="https://tensorboard.dev/" rel="noopener ugc nofollow" target="_blank"><strong class="ke hs">ensor board . Dev</strong></a><strong class="ke hs">中分享我们在云中开发的可视化。</strong>通过评估训练和验证数据的准确性和损失，显示模型架构的摘要，解释从数据中学习到的每一层的模式等，可以将许多事情可视化。我发现这个工具相当不错。需要注意的一点是，您必须确定数据不是私有数据，因为其他任何人都可以访问它。您可以实现tensorboard回调并上传可视化，如以下代码所示</p><pre class="jg jh ji jj fd mf mg mh mi aw mj bi"><span id="e0bc" class="mk le hi mg b fi ml mm l mn mo">import tensorflow as tf<br/>import datetime</span><span id="3b53" class="mk le hi mg b fi nl mm l mn mo">log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")<br/>tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)<br/>model.fit(x=x_train, <br/>          y=y_train, <br/>          epochs=5, <br/>          validation_data=(x_test, y_test), <br/>          callbacks=[tensorboard_callback])</span></pre><p id="28e6" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated"><strong class="ke hs">上传到Tensorboard.dev </strong></p><pre class="jg jh ji jj fd mf mg mh mi aw mj bi"><span id="7174" class="mk le hi mg b fi ml mm l mn mo">tensorboard dev upload --logdir logs \<br/>    --name "(optional) My latest experiment" \<br/>    --description "(optional) Simple comparison of several hyperparameters"</span></pre><p id="3a39" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated">不要忘记通过<strong class="ke hs"> pip install -U tensorboard安装tensorboard。</strong></p><p id="fc56" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated">当我们建立深度学习模型来解决图像数据集中的任何问题时，这些都是口袋参考。然后，我将展示从零开始构建模型架构的真实世界示例，以及使用基于<a class="ae kx" href="https://data.mendeley.com/datasets/zw4p9kj6nt/2" rel="noopener ugc nofollow" target="_blank"> <strong class="ke hs">蚊子对人类皮肤数据集</strong> </a> <strong class="ke hs"> </strong>的真实数据的迁移学习，如下点击第二篇文章</p><div class="nm nn ez fb no np"><a rel="noopener follow" target="_blank" href="/geekculture/you-can-get-a-better-f1-score-when-carrying-out-transfer-learning-in-your-image-data-classification-bc46165766b3"><div class="nq ab dw"><div class="nr ab ns cl cj nt"><h2 class="bd hs fi z dy nu ea eb nv ed ef hr bi translated">在对图像数据进行迁移学习时，您可以获得更高的精度…</h2><div class="nw l"><h3 class="bd b fi z dy nu ea eb nv ed ef dx translated">如何用Tensorflow对人体皮肤上的蚊子进行类型分类？</h3></div><div class="nx l"><p class="bd b fp z dy nu ea eb nv ed ef dx translated">medium.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od nc np"/></div></div></a></div></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><h1 id="e6f9" class="ld le hi bd lf lg mw li lj lk mx lm ln ix my iy lp ja mz jb lr jd na je lt lu bi translated">感谢您的阅读！</h1><p id="1bd6" class="pw-post-body-paragraph kc kd hi ke b kf lv is kh ki lw iv kk kl lx kn ko kp ly kr ks kt lz kv kw kb hb bi translated">我真的很感激！🤗<em class="ne">如果你喜欢这个帖子并想看更多，可以考虑</em> <a class="ae kx" href="https://naiborhujosua.medium.com/" rel="noopener"> <strong class="ke hs"> <em class="ne">关注我</em> </strong> </a> <em class="ne">。我发布与机器学习和深度学习相关的主题。我尽量让我的帖子简单而精确，总是提供可视化和模拟。</em></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es oe"><img src="../Images/b6cef9e5d1cf6205f4ef06c129df3607.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/0*14phCsySAIpeTQiN.png"/></div></figure><p id="a8aa" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated"><strong class="ke hs"> Josua Naiborhu </strong>是一名业务发展分析师，后来变成了一名自学成才的机器学习工程师。他的兴趣包括<strong class="ke hs">统计学习、预测建模和可解释机器学习</strong>。他喜欢跑步，这教会他不要放弃做任何事情，即使是在实施<strong class="ke hs">机器学习生命周期(MLOps) </strong>的时候。除了追求他对机器学习的热情，他还热衷于投资印度尼西亚证券交易所和加密货币。他一直在跑2015年<strong class="ke hs">雅加达马拉松和2019年</strong>大阪马拉松的全程马拉松。他的下一个梦想是参加波士顿马拉松赛、TCS纽约市马拉松赛和伦敦维珍马拉松赛(T21)。</p><p id="0200" class="pw-post-body-paragraph kc kd hi ke b kf ky is kh ki kz iv kk kl la kn ko kp lb kr ks kt lc kv kw kb hb bi translated"><em class="ne">你可以在</em><strong class="ke hs"><em class="ne">LinkedIn</em></strong><em class="ne">，</em><strong class="ke hs"><em class="ne">Twitter</em></strong><em class="ne">，G</em><strong class="ke hs"><em class="ne">ithub</em></strong><em class="ne">，</em> <strong class="ke hs"> <em class="ne"> Kaggle，</em> </strong> <em class="ne">上与他联系或者直接在他的</em> <strong class="ke hs"> <em class="ne">个人网站上与他联系。</em>T51】</strong></p></div></div>    
</body>
</html>