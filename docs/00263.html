<html>
<head>
<title>Fake News Detection Using Machine Learning and Natural Language Processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于机器学习和自然语言处理的假新闻检测</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/fake-news-detection-using-machine-learning-and-natural-language-processing-68e8e485f05d?source=collection_archive---------0-----------------------#2020-12-19">https://medium.com/geekculture/fake-news-detection-using-machine-learning-and-natural-language-processing-68e8e485f05d?source=collection_archive---------0-----------------------#2020-12-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="0f22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假新闻是误导性的新闻故事，来源不可靠，对我们的社会生活有重大影响。假新闻检测是一个新兴的研究领域，它正在引起人们的兴趣，但由于可用资源(即数据集、出版文献)的数量有限，因此涉及一些挑战。</p><p id="0270" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了确保我们的机器学习模型给出准确的结果，我们需要检查我们训练模型的数据集，即数据集应该无偏地包含相同数量的假新闻实例和真实新闻实例。今天，我们将研究这个问题，并提出一些机器学习算法，这有助于预测新闻是否是假的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/3a41f79eb89be84a32b92c6057bb1b92.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*phXS7eI3LnpY5rVD5Z8l5A.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx">Unbiased Dataset (Good for training the models)</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/9915ea7248db808baafbfb98fe92da1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*pjjkDwU87e9Ur5m_xCJmTw.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx">Biased Dataset (Not give accurate results on future data)</figcaption></figure><p id="be67" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此我们将看到各种机器学习模型的结果，为此我们首先对<em class="jp">无偏</em>数据集的文本数据应用自然语言处理技术。</p><h1 id="6552" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">文本预处理</strong></h1><p id="41a7" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">对于下面所有的函数，你可以使用像nltk，re等’这样的库。</p><ol class=""><li id="9125" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">标记化:首先我们创建文本数据的标记。</li><li id="a742" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">删除停用词:删除停用词，如“a、an、the、then等”因为我们知道，这些话对一个新闻是不是假的没有影响或者影响很小。</li><li id="4507" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">词干:将单词转换成它的基本形式，例如:将“worked”转换成它的基本形式“work”。</li></ol><p id="72a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上述预处理之后，我们可以使用来自sklearn库“sk learn . feature _ extraction . text”的CountVectorizer类来应用“单词包”特征提取技术。这个类也可以使用单字和双字的组合来构建单词包。为了训练模型，我们使用了这些一元和二元的组合。</p><p id="ed9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还应用RNN(递归神经网络)的变体“双LSTM”，为此我们将使用“手套嵌入”来将单词转换成它们的嵌入。</p><h1 id="e782" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">模型</h1><p id="81d2" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">我们使用的机器学习模型:</p><ol class=""><li id="7943" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">逻辑回归</li><li id="2ee4" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">支持向量机</li><li id="b796" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">多项式朴素贝叶斯(朴素贝叶斯变体)</li><li id="e9ea" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">梯度推进</li><li id="e2f4" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">双LSTM(双向长短期记忆)</li></ol><h2 id="dae5" class="lh jr hi bd js li lj lk jw ll lm ln ka iq lo lp ke iu lq lr ki iy ls lt km lu bi translated">为什么我们选择文本+标题语料库来训练模型？</h2><p id="a375" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">我们尝试了语料库的多种变体，例如选择新闻标题、新闻正文以及两者。我们使用语料库的所有三个变体来训练逻辑回归(<strong class="ih hj"> <em class="jp"> LR </em> </strong>)模型，并且观察到语料库的<em class="jp">文本+标题</em>组合给出了良好的结果。我们可以从下表中观察到相同的精度:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/22ef36fe19d51e1230a94004487a3be3.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*YrXbqtEFutwF-JuQGay9kg.png"/></div></figure><p id="d848" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，为了进一步的训练，我们在上述模型上应用了文本+标题语料库，并取得了下表中提到的令人鼓舞的准确性，并且从图中也是可见的:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lw"><img src="../Images/ff1c18cfb42949504a487bbb94f52b49.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*cNQAQqRYh8dTDX7tRPf4Ag.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx">Table for accuracies on mentioned models</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es lx"><img src="../Images/5d9c55b240d7847b78032d3cba7737fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uPGtMN39o9rwFjc2beX_6g.png"/></div></div></figure><h1 id="a029" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结论</h1><p id="396f" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">使用上述算法，即朴素贝叶斯分类器、支持向量机和逻辑回归、梯度提升和双向LSTM。获得的最大准确度是使用具有梯度增强分类器的文本+标题。LR和梯度推进给出了几乎相似的准确性，SVM和双向LSTM稍低，然而，从朴素贝叶斯获得的准确性相对低于其他模型。LR和梯度提升表现更好，因为我们从语料库中提取的特征被很好地分离，逻辑回归和梯度提升都能够捕捉上下文。</p><h2 id="02a1" class="lh jr hi bd js li lj lk jw ll lm ln ka iq lo lp ke iu lq lr ki iy ls lt km lu bi translated">链接到源代码:</h2><p id="eef0" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated"><a class="ae mc" href="https://meet.google.com/linkredirect?authuser=0&amp;dest=https%3A%2F%2Fgithub.com%2FVineetMaheshwari%2FFakeNewsDetection" rel="noopener ugc nofollow" target="_blank">https://github.com/VineetMaheshwari/FakeNewsDetection</a></p><h2 id="4afe" class="lh jr hi bd js li lj lk jw ll lm ln ka iq lo lp ke iu lq lr ki iy ls lt km lu bi translated">数据集来自Kaggle和<a class="ae mc" href="http://constraint-shared-task-2021.github.io/" rel="noopener ugc nofollow" target="_blank"> Codalab的比赛</a></h2><div class="md me ez fb mf mg"><a href="https://www.kaggle.com/c/fake-news/data" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hj fi z dy ml ea eb mm ed ef hh bi translated">假新闻</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">建立一个系统来识别不可靠的新闻文章</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">www.kaggle.com</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu jj mg"/></div></div></a></div><h2 id="7876" class="lh jr hi bd js li lj lk jw ll lm ln ka iq lo lp ke iu lq lr ki iy ls lt km lu bi translated"><a class="ae mc" href="http://competitions.codalab.org/competitions/26655#participate" rel="noopener ugc nofollow" target="_blank">竞赛链接(包含我们使用的数据集)</a></h2><h1 id="420b" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">博客作者和投稿:</strong></h1><p id="948e" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated"><strong class="ih hj">Deepankar Kansal</strong>(<a class="ae mc" href="https://www.linkedin.com/in/deepankar-kansal-255911152" rel="noopener ugc nofollow" target="_blank">linkedin.com/in/deepankar-kansal-255911152</a>):文献调查，词袋的Unigram &amp; Bigram组合，逻辑回归，多项朴素贝叶斯，报告&amp;模型分析。</p><p id="ce50" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">维尼特·马赫什瓦里</strong>(<a class="ae mc" href="https://www.linkedin.com/in/vineet-maheshwari-9117b3180" rel="noopener ugc nofollow" target="_blank">linkedin.com/in/vineet-maheshwari-9117b3180</a>):文献调查，数据集处理，SVM，手套+比-LSTM，报告&amp;模型分析。</p><p id="f886" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">帕拉克提瓦里</strong>(<a class="ae mc" href="https://www.linkedin.com/in/palak-2810-tiwari" rel="noopener ugc nofollow" target="_blank">linkedin.com/in/palak-2810-tiwari</a>):文献调查、文本预处理、梯度提升、数据&amp;结果可视化、报告&amp;模型分析。</p><h1 id="de5d" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">在的指导下</h1><ol class=""><li id="ed7a" class="kt ku hi ih b ii ko im kp iq mv iu mw iy mx jc ky kz la lb bi translated">教授:linkedin.com/in/tanmoy-chakraborty-89553324</li><li id="f931" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">教授网站:<a class="ae mc" href="http://faculty.iiitd.ac.in/~tanmoy/" rel="noopener ugc nofollow" target="_blank">faculty.iiitd.ac.in/~tanmoy/</a></li><li id="fe5c" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">助教:Ishita Bajaj女士</li><li id="ee8d" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">助教:Pragya Srivastava、Shiv Kumar Gehlot、Chhavi Jain、Vivek Reddy、Shikha Singh和Nirav Diwan。</li></ol><h1 id="3cdf" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">参考文献</strong></h1><ol class=""><li id="4794" class="kt ku hi ih b ii ko im kp iq mv iu mw iy mx jc ky kz la lb bi translated">圣乔治·格拉瓦尼斯、雅典娜·瓦卡利、康斯坦丁诺·迪亚曼塔拉斯、帕纳吉奥蒂斯·卡拉戴斯，“线索背后:假新闻检测的基准研究”，应用专家系统第128卷，2019年8月15日，第201-213页。</li><li id="3708" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">Kushal Agarwalla，Shubham Nandan，Varun Anil Nair，D. Deva Hema，“使用机器学习和自然语言处理的假新闻检测”，国际近期技术与工程杂志(ij rte)ISSN:2277–3878，Volume-7，Issue-6，2019年3月。</li><li id="0206" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">Shlok Gilda，“评估假新闻检测的机器学习算法”，IEEE第15届学生研发会议(已评分)，2017年12月，第110–115页。</li><li id="0a86" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">名词（noun的缩写）K. Conroy，V. L. Rubin，Y. Chen，“自动欺骗检测:发现假新闻的方法”，《信息科学与技术协会学报》，第52卷第1期，第1–4页，2015年。</li></ol></div></div>    
</body>
</html>