<html>
<head>
<title>15 great resources about the UX of A.I.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于人工智能UX的15大资源</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/15-great-resources-about-the-ux-of-a-i-212fdee301fe?source=collection_archive---------23-----------------------#2021-11-23">https://medium.com/geekculture/15-great-resources-about-the-ux-of-a-i-212fdee301fe?source=collection_archive---------23-----------------------#2021-11-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="e0e4" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">探索人工智能和机器学习如何影响我们日常体验的书籍、纪录片和播客。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/3de83fca84acb8df34e3cc13ec5d28ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qZ-azXgAm2OcIyVaxnWHlA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo credit: Chunumunu, Getty Images</figcaption></figure><p id="a2ca" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">技术正在快速发展，我们看到人工智能(AI)和机器学习(ML)正在用于汽车、医疗保健和医药、营销、农业、生物识别和许多其他行业。这些技术的一些应用对社会负责，并极大地改善了日常生活，而其他应用则导致歧视和有害的用户体验。</p><p id="9ea8" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这份书籍、纪录片和播客的列表将提供关于人工智能和人工智能如何影响人类体验的宝贵见解。</p><h1 id="d88e" class="kj kk hi bd kl km kn ko kp kq kr ks kt io ku ip kv ir kw is kx iu ky iv kz la bi translated">书</h1><p id="7d20" class="pw-post-body-paragraph jn jo hi jp b jq lb ij js jt lc im jv jw ld jy jz ka le kc kd ke lf kg kh ki hb bi translated"><strong class="jp hj"> 1。</strong> <a class="ae lg" href="https://safiyaunoble.com/research-writing/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj">压迫的算法</strong> </a> <strong class="jp hj"> <br/> </strong> <em class="lh">作者萨菲亚·诺布尔博士</em> <br/>发人深省地审视了搜索引擎和算法的不平等，因为数量有限的互联网搜索引擎和疏忽设计的算法导致搜索结果偏向白人，歧视有色人种，特别是有色人种妇女。基于对在线搜索和付费在线广告的研究和分析，作者揭示了搜索引擎如何延续污名。</p><p id="1a61" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> 2。</strong> <a class="ae lg" href="https://www.ruhabenjamin.com/race-after-technology" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj">科技之后的种族</strong> </a> <strong class="jp hj"> <br/> </strong> <em class="lh">鲁哈·本杰明博士</em> <br/>深刻审视算法如何强化和加深社会不平等。作者展示了歧视性的设计，虽然看起来是中性的，但往往编码了不平等并放大了种族等级，她称之为“新吉姆代码”。对技术的追逐促使我们质疑技术和我们自己。</p><p id="9cee" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> 3。</strong> <a class="ae lg" href="https://mitpress.mit.edu/contributors/mar-hicks" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj">你的电脑着火了</strong> </a> <strong class="jp hj"> <br/> </strong> <em class="lh">作者Mar Hicks </em> <br/>这是一本散文集，突出了技术的负面影响，并展示了不平等、边缘化和偏见是如何融入技术和算法的。这本书是对行动的呼吁；去理解和解决这些技术问题，尽管这些问题有着非常真实的社会后果，但却经常被忽视。</p><p id="94ff" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> 4。</strong> <a class="ae lg" href="https://www.amazon.com/gp/product/B08BT23822/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj">人工怂</strong> </a> <strong class="jp hj"> <br/> </strong> <em class="lh">作者梅雷迪思·布鲁萨德</em> <br/>这本书让人们注意到技术可以解决一切的集体天真。作者是一名软件开发人员和记者，他通过一系列生动的个人故事指出了技术的局限性，这些故事讲述了人工智能在修复美国竞选财务系统、调查标准化测试问题以及无人驾驶汽车方面的经历。Broussard断言，如果我们能够更好地选择什么可以用技术解决，什么不能用技术解决，那么我们就可以为每个人创造一个更美好的世界。</p><p id="f5e1" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> 5。</strong> <a class="ae lg" href="https://www.amazon.com/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj">数学毁灭的武器</strong> </a> <strong class="jp hj"> <br/> </strong> <em class="lh">作者凯茜·奥尼尔，博士</em> <br/>令人信服地审视了算法是如何在我们生活的每一个部分中被使用的，并假设技术是公平和公正的，但不幸的是，事实并非如此。它暴露了大数据的阴暗面，以及不受监管的黑盒算法如何被用于不计后果地做出有关民生的决策。作者呼吁政策制定者实施立法，呼吁算法工程师负起责任，呼吁我们要求改变。</p><h1 id="723a" class="kj kk hi bd kl km kn ko kp kq kr ks kt io ku ip kv ir kw is kx iu ky iv kz la bi translated">纪录片</h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/a3789bfdb1e9c945b8c42f3997b8fe60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*p_pHflmb91DTNVHV.jpg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">The Social Dilemma | 2020 | 2hr 35m</figcaption></figure><p id="cd0b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> 6。</strong> <a class="ae lg" href="https://www.netflix.com/title/81254224" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj">社交困境</strong> </a> <strong class="jp hj"> <br/> </strong>一部揭露社交媒体公司如何利用算法操纵人类行为的纪录片。它揭示了当我们不断滚动、点击、轻击和检查我们的应用程序时，我们是如何滑入的“T33”漩涡的。通过跟踪和测量我们采取的每一个行动，他们可以使用有说服力的算法设计模式，如垃圾邮件通知，虚假的稀缺信息，并提供确认偏差的内容，以有效地刺激，戳和戳我们。正如你将在这部电影中看到的，数字成瘾是一个日益严重的问题，它让我们不断渴望更多，永远无法满足。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/5bbd94b38d35d5e5040364e115ca2295.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zZ7qm-1NyFrZ_2-0.jpg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Coded Bias | 2020 | 1h 25m</figcaption></figure><p id="c933" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">7 .<strong class="jp hj">。</strong> <a class="ae lg" href="https://www.netflix.com/title/81328723" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj">编码偏见</strong> </a> <strong class="jp hj"> <br/> </strong>由Shalini Kantayyamit执导，这部纪录片跟随麻省理工学院研究员Joy Buolamwini博士在面部识别算法中发现种族和性别偏见后的旅程。Buolamwini博士研究了有偏见的算法，这些算法不能准确地检测出肤色较深的面部，或者对女性的面部进行了错误分类。她继续提高意识，并推动美国立法来治理算法偏见。乔伊现在是<a class="ae lg" href="https://www.ajl.org/" rel="noopener ugc nofollow" target="_blank">算法正义联盟(AJL) </a>的创始人，呼吁研究人员、政策制定者和行业从业者采取行动，减轻人工智能的伤害和偏见。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/acc212c70a01e3f9b1d03a041d359d74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hyeJLy_9yZ0aEiSH.jpg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Do You Trust This Computer? | 2018 | 1h 30m</figcaption></figure><p id="1e82" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> 8。</strong> <a class="ae lg" href="https://doyoutrustthiscomputer.org/watch" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj">你信任这台电脑吗<br/> </strong> </a>这部纪录片由包括吴恩达、石黑一雄、埃隆马斯克在内的专家评论，讨论了人工智能的进化。从超人的好处到潜在的危险和风险，这部电影探索了人工智能过去和现在的应用，包括人工智能驱动的假新闻，机器人伴侣，无人机和机器人辅助手术。这一篇有点悲观，但它绝对是有见地的，并提出了许多关于疏忽设计和使用人工智能的结果的有效关注。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/6524317cb971195ea3e885593d27403e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fYTbAbmQ9sT_AWK1.jpg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">The Age of A.I. | 2019 | 8 episode docuseries</figcaption></figure><p id="9ceb" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> 9。</strong> <a class="ae lg" href="https://youtube.com/playlist?list=PLjq6DwYksrzz_fsWIpPcf6V7p2RNAneKc" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj">人工智能时代</strong> </a> <strong class="jp hj"> <br/> </strong>由小罗伯特·唐尼讲述，这部纪录片展示了人工智能和机器学习的许多惊人好处。与警告人工智能疏忽和滥用的电影引发的恐惧相反，这个系列给了我这么多希望。这部电影展示了许多关于人工智能在医疗保健和医学中的好处的故事，其中有一些真正突破性的研究和创新，正在改善人们的生活。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es li"><img src="../Images/7652527d144ea098a482d8d7d20932a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xoiuBPUpXpCwLngF.jpg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">iHuman | 2019 | 1h 39m</figcaption></figure><p id="8567" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">10。一部真正的政治惊悚纪录片。它专注于人工智能技术可能对我们的社会产生负面影响的方式。它讨论了不道德和不负责任的人工智能工程如何加剧现有的系统性不平等和不公正，以及对有关数据收集、监控和生物识别技术使用的监管政策的需求。</p><h1 id="0ae0" class="kj kk hi bd kl km kn ko kp kq kr ks kt io ku ip kv ir kw is kx iu ky iv kz la bi translated">播客</h1><p id="c90f" class="pw-post-body-paragraph jn jo hi jp b jq lb ij js jt lc im jv jw ld jy jz ka le kc kd ke lf kg kh ki hb bi translated"><strong class="jp hj"> 11。</strong> <a class="ae lg" href="https://www.radicalai.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj">激进的人工智能播客</strong> </a> <strong class="jp hj"> <br/> </strong>由Dylan Doyle-Burke和Jess Smith主持，激进的人工智能播客中心在工业界和学术界就人工智能伦理领域以及人类和机器学习之间的关系进行对话、合作和辩论。</p><p id="0c4c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> 12。</strong> <a class="ae lg" href="https://twimlai.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj">由Sam Charrington主持的TWIML AI播客</strong></a><strong class="jp hj"><br/></strong>TWIML AI播客将来自ML和AI领域的顶级思想和想法带到了一个由ML/AI研究人员、数据科学家、工程师和精通技术的业务和IT领导者组成的广泛而有影响力的社区。</p><p id="4bb7" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> 13。</strong> <a class="ae lg" href="https://www.areyouarobot.co.uk/episodes" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj">你是机器人吗？由Demetrios Brinkmann主持的《你是机器人吗》通过采访专家和思想领袖，探讨了围绕技术的伦理问题以及技术给人类带来的挑战和机遇。</strong></a></p><p id="4b17" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">14。在詹妮弗·斯特朗主持的《我们信任的机器》中，我们通过研究人工智能对我们日常生活的深远影响，并通过人们对技术力量的思考来探索人工智能的崛起，来审视将我们最敏感的决策委托给人工智能意味着什么。</p><p id="5a2f" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">15。 <a class="ae lg" href="https://www.machine-ethics.net/podcast/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj">机器伦理播客</strong> </a> <strong class="jp hj"> <br/> </strong>由本·拜福德主持，机器伦理播客采访了学者、作者、商业领袖、设计师和工程师，主题是自主算法、人工智能、机器学习和技术对社会的影响。</p><h1 id="2c4c" class="kj kk hi bd kl km kn ko kp kq kr ks kt io ku ip kv ir kw is kx iu ky iv kz la bi translated">最后的想法</h1><p id="cb51" class="pw-post-body-paragraph jn jo hi jp b jq lb ij js jt lc im jv jw ld jy jz ka le kc kd ke lf kg kh ki hb bi translated">人工智能有可能改善人类的体验，也有可能摧毁它。人工智能的一些使用导致了排斥甚至悲剧——人脸识别中的<a class="ae lg" href="http://gendershades.org/" rel="noopener ugc nofollow" target="_blank">算法偏差</a>和特斯拉驾驶辅助功能中的<a class="ae lg" href="https://www.theguardian.com/technology/2016/jul/02/elon-musk-self-driving-tesla-autopilot-joshua-brown-risks" rel="noopener ugc nofollow" target="_blank">过度自信</a>就是这样的例子。而人工智能的其他应用对社会负责，并创造了生活增强技术，如<a class="ae lg" href="https://medicalfuturist.com/the-future-of-prosthetics-depends-on-a-i/" rel="noopener ugc nofollow" target="_blank">大脑控制的机器人假肢</a>。</p><p id="5643" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">为了最大限度地减少人工智能的疏忽使用，我们需要企业在STEM(科学、技术、工程和医学)招聘和晋升中致力于多样性、公平和包容性，主动寻求第三方审计，并确保他们使用包容性的培训数据集。还需要更多的公众意识到疏忽设计的人工智能的风险，因为公众监督和请愿是政策变化的强大催化剂，以加强算法问责制。</p><blockquote class="lj lk ll"><p id="a66b" class="jn jo lh jp b jq jr ij js jt ju im jv lm jx jy jz ln kb kc kd lo kf kg kh ki hb bi translated">我们可以使用人工智能来治疗疾病，应对气候变化，让每个人摆脱贫困……但是，我们可以使用完全相同的技术来创建一个残酷的全球独裁政权，带来前所未有的监控、不平等和痛苦。<br/> —最大泰格马克</p></blockquote></div><div class="ab cl lp lq gp lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="hb hc hd he hf"><h1 id="fd8d" class="kj kk hi bd kl km lw ko kp kq lx ks kt io ly ip kv ir lz is kx iu ma iv kz la bi translated">谢谢你</h1><p id="45de" class="pw-post-body-paragraph jn jo hi jp b jq lb ij js jt lc im jv jw ld jy jz ka le kc kd ke lf kg kh ki hb bi translated">如果你喜欢这篇文章，关注我:<a class="ae lg" rel="noopener" href="/@itsuxforthewin">Medium</a>|<a class="ae lg" href="https://www.instagram.com/ux.forthewin" rel="noopener ugc nofollow" target="_blank">insta gram</a>|<a class="ae lg" href="https://twitter.com/uxforthewin" rel="noopener ugc nofollow" target="_blank">Twitter</a></p><p id="8347" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">如果你喜欢看这样的文章，想支持我这个作家，可以考虑报名<a class="ae lg" rel="noopener" href="/@itsuxforthewin/membership">成为媒介会员</a>。每月5美元，可以无限制地访问所有媒体文章，加上支持我的写作，因为我将赚取一小笔佣金。</p><div class="mb mc ez fb md me"><a rel="noopener follow" target="_blank" href="/@itsuxforthewin/membership"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hj fi z dy mj ea eb mk ed ef hh bi translated">通过我的推荐链接加入Medium-Trina Moore per wall</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">medium.com</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms jh me"/></div></div></a></div></div></div>    
</body>
</html>