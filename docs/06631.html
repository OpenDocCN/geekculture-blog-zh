<html>
<head>
<title>Listen to Postgres Changes with Apache Kafka</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用阿帕奇卡夫卡听Postgres的变化</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/listen-to-database-changes-with-apache-kafka-35440a3344f0?source=collection_archive---------0-----------------------#2021-08-25">https://medium.com/geekculture/listen-to-database-changes-with-apache-kafka-35440a3344f0?source=collection_archive---------0-----------------------#2021-08-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/30fe90a694598f08f66b7666c0df2e8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IWKTDXElpzLDMMnFLdn4Zw.jpeg"/></div></div></figure><p id="4e2b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您曾经遇到过不同的应用程序和数据源在同一个数据库中插入数据的情况，并且您希望根据存储的、更新的或删除的数据采取行动，本文可能会帮助您。</p><p id="213a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">考虑下图中的一个案例:</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es jo"><img src="../Images/2cc91754be574e075c08a8e8c4480a84.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*77GNjnTNcsG7GtgsmbIYww.png"/></div><figcaption class="jt ju et er es jv jw bd b be z dx">Different applications using the same database</figcaption></figure><p id="d407" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用相同数据库的不同应用程序</p><p id="6494" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该系统使用微服务，将数据处理分解成更小的任务。每个应用程序将其数据输入数据库。您希望对数据库中的某些更改做出反应，例如，当其中一条记录更新时。你不想让自己和团队的其他成员的生活变得更加复杂。您希望避免这样的情况，即每个应用程序都有一段代码发送通知，告知数据库中的某些内容已被更新。</p><p id="c977" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">变更数据捕获(CDC) </strong>开始发挥作用——一种软件设计模式，用于监控数据的变更，并根据数据变更执行某些操作。这主要包括读取、更新或删除操作。这些动作大多来自另一个系统(或者在本例中是多个服务)。</p></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><p id="f09e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">这样的方法有什么好处？</strong> <br/>原始数据库(我们监听的)保持不变——我们没有添加任何触发器或日志表。这很有帮助，因为这样的操作会降低数据库的性能，最终会影响整个系统。</p><p id="1c49" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了实现CDC软件设计模式，我们需要在管道中添加两个项目:</p><ul class=""><li id="fada" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn kj kk kl km bi translated">监听数据库中行更改的服务</li><li id="96a1" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">流式传输数据的服务</li></ul><p id="ea7d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于数据流来说，<strong class="is hj"> Apache Kafk </strong> a已被证明是业内许多主要参与者的理想组合——<em class="ks">Pinterest、Airbnb、思科、Cloudflare、高盛、LinkedIn、Mozilla Firefox、甲骨文、Paypal、Spotify、Shopify、腾讯、Twitter、</em>等等。<br/>与Apache Kafka一起，<strong class="is hj"> Debezium </strong>被证明是Postgres(和其他数据库)的原生CDC连接器之一。为了让Apache Kafka和Debezium进行通信，使用了Apache Connector它是一个<strong class="is hj">开箱即用的</strong> <strong class="is hj">解决方案</strong>,作为一个集中式数据中心，用于数据库、键值存储、搜索索引和文件系统之间的简单数据集成。</p></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h2 id="e3dd" class="kt ku hi bd kv kw kx ky kz la lb lc ld jb le lf lg jf lh li lj jj lk ll lm ln bi translated">什么是阿帕奇卡夫卡和德贝兹姆？</h2><p id="cfc2" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">这里简单介绍一下将要使用的技术，它们的主要功能和优点。</p><p id="9626" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> Apache Kafka </strong> <br/>简而言之，Apache Kafka是一个开源的分布式事件流媒体平台。它是一个分布式的发布-订阅消息传递系统，是作为现有解决方案的高度<strong class="is hj">快速</strong>、<strong class="is hj">可伸缩</strong>和<strong class="is hj">持久</strong>的替代方案而创建的。它也是可靠的，因为它会在发生故障时自动平衡消费者。</p><p id="0d04" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">总共有5个Kafka核心API，其中一些将数据发送到Kafka主题，而另一些从Kafka主题读取和使用数据:</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/502e6fc11a7912618ff9f05309204cdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yduYFcm4LrCiX96j44NBbQ.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx">Apache Kafka Producer, Connect Source, Streams, Consumer and Connect Sink API</figcaption></figure><ul class=""><li id="2196" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn kj kk kl km bi translated"><strong class="is hj"> Kafka Producer API: </strong>允许应用程序向Kafka集群中的主题发送数据流。(日志、物联网、流)。</li><li id="77f6" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated"><strong class="is hj"> Kafka Connect Source API: </strong>允许实现不断从某个源系统或应用程序拉入Kafka或从Kafka推入某个接收系统或应用程序(REST API、CDC、MySQL、Postgres、MongoDB、Twitter、Slack)的连接器。</li><li id="26c9" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated"><strong class="is hj"> Kafka Streams API / KSQL: </strong>允许将数据流从输入主题转换为输出主题。</li><li id="4e7c" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated"><strong class="is hj"> Kafka消费者API: </strong>允许应用程序从Kafka集群中的主题读取数据流。(发送电子邮件、请求、存储到文件)</li><li id="e143" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated"><strong class="is hj"> Kafka Connect Sink API </strong>:允许应用程序读取流并将其存储到目标存储中(Kafka to S3、HDFS、PostgreSQL、MongoDB、Telegram)</li></ul><p id="a799" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> Debezium </strong></p><p id="3db4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Debezium构建于Apache Kafka项目之上，使用Kafka将变更从一个系统传输到另一个系统。它利用<em class="ks">变更数据捕获</em>模式。它确保所有数据更改都被<strong class="is hj">捕获</strong>，非常<strong class="is hj">低延迟</strong>，不改变数据模型。它可以捕获已删除的事务id和附加元数据。一些主要特征是:</p><ul class=""><li id="1d3c" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn kj kk kl km bi translated"><strong class="is hj">快照</strong> —虽然是可选的，但是如果连接器已经启动并且不是所有日志都存在，您可以获取数据库的当前状态。</li><li id="f3b9" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated"><strong class="is hj">过滤器</strong> —您可以使用包含/排除列表过滤器配置捕获的模式、表和列的集合。</li><li id="df6b" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated"><strong class="is hj">屏蔽</strong> —特定列中的值可以被屏蔽，例如，当它们包含敏感数据时。</li><li id="1f83" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated"><strong class="is hj">监控</strong></li><li id="da79" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated"><strong class="is hj">随时可用的消息转换</strong></li></ul><p id="943a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，Apache Kafka发布的消息由终端<em class="ks">消费者</em>或<em class="ks">接收器</em>消费——事实上，这可以是各种各样的事情——取决于用例。</p><p id="0c4e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你想把你的数据流式传输到一个众所周知的服务中，比如另一个数据库(psql，Maria DB，Mongo DB)，Elastic Search，Hadoop，AWS S3桶，你会使用开箱即用的可配置连接器——<strong class="is hj">sinks</strong>。</p><p id="cb0d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你想有一个定制的逻辑，你将使用<strong class="is hj">消费者API </strong>。</p></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h1 id="9fbd" class="lu ku hi bd kv lv lw lx kz ly lz ma ld mb mc md lg me mf mg lj mh mi mj lm mk bi translated">概念证明(示例)</h1><p id="13f9" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">在这个例子中，我将使用Postgres、Debezium、Apache Connect + Apache Kafka和一个将充当消费者的NodeJS应用程序来展示整个工作流。</p><p id="fead" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">除了NodeJS应用程序之外的所有东西都在docker容器中，所以我创建了一个单独的<strong class="is hj"> docker-compose.yml </strong>文件，其中包含了您需要知道的所有东西。</p><p id="1347" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">系统的架构概述:</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ml"><img src="../Images/55a82fad77486e3ff42c283f7bca3539.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8K9smjIrF6qh3RbZoYtryg.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx">Apache Kafka + Connect (Debezium) secure that all database changes will be reported to the Consumer Application</figcaption></figure><ol class=""><li id="532c" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn mm kk kl km bi translated">应用程序1、2和3将各自把自己的数据存储到Postgres数据库中。既然这已经是广为人知的事情，我就不在这上面浪费时间了，我们就直接在psql(简单更新)里面做更新吧。</li><li id="6c21" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn mm kk kl km bi translated">一旦Postgres中的数据发生变化，Debezium就会检测到，并将变化发送给Kafka</li><li id="b54b" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn mm kk kl km bi translated">Kafka会将数据发布到一个特定的主题中(<em class="ks">servername . schema . table</em>)</li><li id="59be" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn mm kk kl km bi translated">之前订阅的NodeJS消费者将收到Apache Kafka发布的数据</li></ol><p id="816e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我设法将除消费者应用程序之外的所有内容放在一个单独的<em class="ks"> docker-compose.yml </em>中，因此您只需复制/粘贴下面的配置即可完成所有内容:</p><figure class="jp jq jr js fd ij"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="4d52" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它由四项服务组成:</p><ol class=""><li id="8cb5" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn mm kk kl km bi translated"><strong class="is hj">Zookeeper</strong>—Zookeeper<strong class="is hj">跟踪Kafka集群节点的状态</strong>，它还跟踪Kafka主题、分区等。Zookeeper允许多个客户端同时执行读写操作，并作为系统内的共享配置服务。</li><li id="7226" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn mm kk kl km bi translated"><strong class="is hj"> kafka </strong> — Apache Kafka服务器</li><li id="c06a" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn mm kk kl km bi translated"><strong class="is hj"> postgres </strong> — Postgres数据库</li><li id="140f" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn mm kk kl km bi translated"><strong class="is hj"> postgres-connector </strong> —用于变更数据捕获的Debezium connect实例</li></ol><p id="17b5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在运行所有服务之前，您可以看到我们正在使用一个<code class="du mp mq mr ms b">${HOST_IP} </code>环境变量。如果你想了解更多关于<code class="du mp mq mr ms b">${HOST_IP}</code>的用法，看看<a class="ae mt" href="https://github.com/wurstmeister/kafka-docker/wiki/Connectivity" rel="noopener ugc nofollow" target="_blank"> Kafka Connectivity </a>。</p><p id="8448" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">按照这个一步一步的例子，如何把所有的东西放在一起工作。</p><p id="9783" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">运行码头集装箱:</strong></p><ul class=""><li id="f931" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn kj kk kl km bi translated">打开终端并创建新文件夹</li><li id="3be3" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">将<code class="du mp mq mr ms b">docker-compose.yml</code>复制/粘贴到一个文件中并保存</li><li id="b367" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">设置<code class="du mp mq mr ms b">HOST_IP</code>地址(环境变量):</li></ul><p id="62a5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du mp mq mr ms b">export HOST_IP=$(ifconfig | grep -E "([0-9]{1,3}\.){3}[0-9]{1,3}" | grep -v 127.0.0.1 | awk '{print $2}' | cut -f2 -d: |head -n1)</code></p><ul class=""><li id="a3c8" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn kj kk kl km bi translated">运行<strong class="is hj"> </strong> <code class="du mp mq mr ms b">docker-compose up -d </code> →这将创建四个容器，初始化可能需要一段时间(几秒钟)。</li><li id="c82d" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">可选:您可以通过执行<code class="du mp mq mr ms b">docker ps.</code>来检查docker容器的状态</li></ul><pre class="jp jq jr js fd mu ms mv mw aw mx bi"><span id="524e" class="kt ku hi ms b fi my mz l na nb">b1b37bf623db   debezium/example-postgres:1.3   "docker-entrypoint.s…"   About a minute ago   Up About a minute     0.0.0.0:5433-&gt;5432/tcp, :::5433-&gt;5432/tcp                                                                       postgres</span><span id="6f0f" class="kt ku hi ms b fi nc mz l na nb">1b9a3be29c09   debezium/zookeeper:1.3          "/docker-entrypoint.…"   About a minute ago   Up 58 seconds         2888/tcp, 3888/tcp, 8778/tcp, 0.0.0.0:2181-&gt;2181/tcp, :::2181-&gt;2181/tcp, 9779/tcp                               zookeeper</span></pre><p id="25ea" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">创建postgres数据库:</strong></p><ul class=""><li id="30b1" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn kj kk kl km bi translated">通过执行以下命令连接到psql实例:<code class="du mp mq mr ms b">docker exec -it postgres bash</code></li><li id="d309" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">登录到您的psql服务器:<code class="du mp mq mr ms b">psql -U postgres</code></li><li id="8e41" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">输入postgres密码(如果您遵循示例，密码为“postgres”)</li><li id="e84b" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">创建新表格:</li></ul><figure class="jp jq jr js fd ij"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="f3c4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以检查是否存储了新插入的记录:</p><pre class="jp jq jr js fd mu ms mv mw aw mx bi"><span id="21e4" class="kt ku hi ms b fi my mz l na nb">postgres=# select * from customers;</span><span id="f6b1" class="kt ku hi ms b fi nc mz l na nb">id | name<br/>----+------<br/>1 | john<br/>2 | jack<br/>3 | jane<br/>(3 rows)</span></pre><ul class=""><li id="2e12" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn kj kk kl km bi translated">退出psql服务器和postgres容器</li></ul><p id="c93b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">配置Kafka Connect (Debezium)连接到数据库:</strong></p><ul class=""><li id="8bda" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn kj kk kl km bi translated">Kafka Connect有一个REST端点，我们可以使用它来查看容器中启用了哪些连接器(并测试连接):</li></ul><figure class="jp jq jr js fd ij"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="318e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果一切正常，这将返回一个空数组[ ]。</p><ul class=""><li id="abf5" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn kj kk kl km bi translated">为Kafka Connector (Debezium)创建一个配置文件，以便它能够连接到数据库并监听更改。</li></ul><figure class="jp jq jr js fd ij"><div class="bz dy l di"><div class="mn mo l"/></div><figcaption class="jt ju et er es jv jw bd b be z dx">Debezium configurational file — pg-source-config.json</figcaption></figure><p id="f9fb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将此复制到一个文件中，并将该文件保存在<code class="du mp mq mr ms b">pg-source-config.json.</code>下</p><p id="cf28" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面将启动一个连接器，从源postgres数据库中读取customer表:</p><figure class="jp jq jr js fd ij"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="6b7d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这应该会返回一个与您发送的JSON对象相同的响应。</p><p id="1fd6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，您应该有一个启动并运行的管道——数据表“Customers”中的每个更改都将传输到Kafka，并发布到<strong class="is hj">my server . public . Customers</strong>topic。</p><p id="7ac6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为什么是这个名字？Kafka将根据<strong class="is hj"> pg-source-config.json </strong>中的<strong class="is hj">database . server . name(my server)</strong>属性自动创建一个主题，然后是模式和数据表(分别为<strong class="is hj"> public </strong>、<strong class="is hj"> customers </strong>)。</p><p id="bbb0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">创建消费者应用</strong></p><p id="9e51" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们只能创建一个消费者应用程序，它将使用Apache Kafka发布的更改。为此，我创建了一个简单的NodeJS应用程序。您可以通过以下步骤完成同样的操作:</p><ul class=""><li id="0dba" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn kj kk kl km bi translated">用<code class="du mp mq mr ms b">npm init</code>创建一个新的NodeJS文件夹和项目</li><li id="87f8" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">安装依赖项:<code class="du mp mq mr ms b">npm i --save dotenv ip kafkajs</code></li><li id="554f" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">创建环境文件(。环境):</li></ul><figure class="jp jq jr js fd ij"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="7bbd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">TOPIC是我们的KafkaJS消费者应用程序将要监听的主题。</p><ul class=""><li id="2a31" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn kj kk kl km bi translated">在NodeJS文件夹中创建<code class="du mp mq mr ms b">kafka.js</code>文件，用于配置Kafka消费者。</li></ul><figure class="jp jq jr js fd ij"><div class="bz dy l di"><div class="mn mo l"/></div></figure><ul class=""><li id="b9d7" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn kj kk kl km bi translated">在NodeJS项目中创建<code class="du mp mq mr ms b">index.js</code>文件，该文件将消费者连接到Kafka broker，订阅“myserver.public.consumer”模式，并为每个接收到的消息设置一个处理程序:</li></ul><figure class="jp jq jr js fd ij"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="3bcd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通过执行<code class="du mp mq mr ms b">node index.js</code>运行应用程序。</p><p id="fa2a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这应该会在控制台中输出一个响应:</p><pre class="jp jq jr js fd mu ms mv mw aw mx bi"><span id="b047" class="kt ku hi ms b fi my mz l na nb">[<br/> ‘pg_connect_statuses’,<br/> ‘myserver.public.customers’,<br/> ‘__consumer_offsets’,<br/> ‘pg_connect_offsets’,<br/> ‘pg_connect_configs’<br/>]<br/>{“level”:”INFO”,”timestamp”:”2021–08–25T07:44:20.562Z”,”logger”:”kafkajs”,”message”:”[Consumer] Starting”,”groupId”:”nodejs-consumer”}<br/>{“level”:”INFO”,”timestamp”:”2021–08–25T07:44:44.686Z”,”logger”:”kafkajs”,”message”:”[ConsumerGroup] Consumer has joined the group”,”groupId”:”nodejs-consumer”,”memberId”:”node-consumer-5e4e7ecc-2330–4038–9d28–1dc089c7af31",”leaderId”:”node-consumer-5e4e7ecc-2330–4038–9d28–1dc089c7af31",”isLeader”:true,”memberAssignment”:{“myserver.public.customers”:[0]},”groupProtocol”:”RoundRobinAssigner”,”duration”:24124}</span></pre><p id="2303" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此时，您应该已经连接了整个管道。当postgres数据库中的数据发生变化时，Debezium会检测到并将其传输到Kafka。Kafka将根据服务器名称、模式和表，将其发布到特定主题。</p><p id="8623" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">在数据库中插入记录</strong></p><p id="d209" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，是测试一切的时候了。我们将在之前创建的表<em class="ks"> customers </em>中插入一条记录。连接到postgres容器中的psql数据库。运行以下命令:</p><figure class="jp jq jr js fd ij"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="1934" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">简言之，您应该会看到NodeJS应用程序控制台日志:</p><pre class="jp jq jr js fd mu ms mv mw aw mx bi"><span id="4925" class="kt ku hi ms b fi my mz l na nb">{<br/>  before: null,<br/>  after: { id: 4, name: 'josip' },<br/>  source: {<br/>    version: '1.3.1.Final',<br/>    connector: 'postgresql',<br/>    name: 'myserver',<br/>    ts_ms: 1629878089981,<br/>    snapshot: 'false',<br/>    db: 'postgres',<br/>    schema: 'public',<br/>    table: 'customers',<br/>    txId: 606,<br/>    lsn: 34250448,<br/>    xmin: null<br/>  },<br/>  op: 'c',<br/>  ts_ms: 1629878090452,<br/>  transaction: null<br/>}</span></pre><h2 id="bbee" class="kt ku hi bd kv kw kx ky kz la lb lc ld jb le lf lg jf lh li lj jj lk ll lm ln bi translated">最后的话</h2><p id="9501" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">虽然使用简单的数据库触发器也可以产生类似的结果，但是该解决方案提供了更多的功能:</p><ul class=""><li id="164b" class="ke kf hi is b it iu ix iy jb kg jf kh jj ki jn kj kk kl km bi translated">您不会遇到数据库性能下降的情况</li><li id="8ea7" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">使用的技术(debezium，kafka)可以通过配置文件轻松调整</li><li id="23df" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">容器化允许您在任何服务器上轻松、快速、高效地运行这个管道</li><li id="8c3a" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">Kafka连接器是现成的产品，您不需要为其编写任何代码，而是开箱即用</li><li id="2693" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">使用已经建立的强大公司使用的技术，这些公司背后有一个庞大的社区</li><li id="b436" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">技术是快速的、可扩展的、持久的和可靠的</li><li id="548b" class="ke kf hi is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km bi translated">如果需要，您可以轻松地更改每个组件</li></ul><p id="ed4e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">无论如何，我认为这个解决方案非常有效，尽管一开始设置起来有点复杂，因为它与底层事务日志交互。</p></div></div>    
</body>
</html>