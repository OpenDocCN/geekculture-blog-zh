<html>
<head>
<title>Hadoop MapReduce Multi-node Cluster over AWS using Ansible Automation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Ansible Automation的基于AWS的Hadoop MapReduce多节点集群</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/hadoop-mapreduce-multi-node-cluster-over-aws-using-ansible-automation-56970a22cf81?source=collection_archive---------61-----------------------#2021-05-27">https://medium.com/geekculture/hadoop-mapreduce-multi-node-cluster-over-aws-using-ansible-automation-56970a22cf81?source=collection_archive---------61-----------------------#2021-05-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/b6c07c5a623dccf3e09ed3a2e828fc12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*bNPBDr-STeWj2JkhB_xYDg.gif"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="bd hv">Created by Akanksha</strong></figcaption></figure><div class=""/><div class=""><h2 id="80f4" class="pw-subtitle-paragraph iv hx hy bd b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm dx translated">使用作为MR集群的一部分的作业跟踪器和任务跟踪器节点来来回回地完成文档和分析，并提供运行分析程序的好处，从而提供分布式计算资源…</h2></div><p id="4542" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">读者们好，这篇博客是我之前的博客的扩展版，在我之前的博客中，我讨论了HDFS集群设置(Hadoop提供的分布式存储文件系统)，我们已经使用配置管理工具“Ansible”在AWS上完成了这个设置。</p><div class="hh hi ez fb hj kj"><a href="https://akanksha77.medium.com/big-data-hadoop-multi-node-cluster-over-aws-using-ansible-28215fa562a5" rel="noopener follow" target="_blank"><div class="kk ab dw"><div class="kl ab km cl cj kn"><h2 class="bd hz fi z dy ko ea eb kp ed ef hx bi translated">使用Ansible的AWS上的大数据Hadoop多节点集群</h2><div class="kq l"><h3 class="bd b fi z dy ko ea eb kp ed ef dx translated">Apache框架—通过分布式方法进行大数据计算和存储。大文件被剥离出来…</h3></div><div class="kr l"><p class="bd b fp z dy ko ea eb kp ed ef dx translated">akanksha77.medium.com</p></div></div><div class="ks l"><div class="kt l ku kv kw ks kx hp kj"/></div></div></a></div><p id="ff20" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">🤔我们要在这里讨论什么新闻？</p><ul class=""><li id="89db" class="ky kz hy jp b jq jr jt ju jw la ka lb ke lc ki ld le lf lg bi translated">Hadoop分布式计算集群</li><li id="b752" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki ld le lf lg bi translated">作业跟踪器节点的工作</li><li id="6b13" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki ld le lf lg bi translated">任务跟踪器节点的工作</li><li id="300d" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki ld le lf lg bi translated">Hadoop如何提供内部排序程序？</li><li id="40cc" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki ld le lf lg bi translated">如何设置工作追踪系统？</li><li id="024d" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki ld le lf lg bi translated">如何设置任务跟踪器？</li></ul><p id="a824" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Hadoop是一个大数据存储和分析工具，永远不要采用多节点设置。实际上，当我们实施Hadoop DFS(分布式文件系统)或Hadoop DCC(分布式计算集群)时，数据文件条带会分布在从属节点上，进而元数据或格式文件系统会跟踪存储的数据，这有助于稍后快速检索原始数据。</p><h2 id="452f" class="lm ln hy bd hv lo lp lq lr ls lt lu lv jw lw lx ly ka lz ma mb ke mc md me mf bi translated">Hadoop分布式计算集群:</h2><figure class="mh mi mj mk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mg"><img src="../Images/0ba2002e6665e00b5b59f577b5a010b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*plHypSJo8w0KW8YVdABZRg.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="bd hv">Fig 1. Hadoop Distributed Computing Cluster</strong></figcaption></figure><p id="5a28" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">MapReduce框架只是定义数据处理任务。它关注的是原始数据应该关注的逻辑。分布式计算集群将在多台机器上运行数据处理任务，管理内存，管理处理等。用户使用MapReduce API to Job Tracker节点定义映射器和缩减器任务。它可以帮助我们使用Java和其他已定义的语言。Map defines id程序被打包到由Hadoop中的集群执行的作业中。</p><p id="3edc" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">众所周知，HDFS是一种文件系统，用于管理群集中跨计算机的数据存储。也许MapReduce是一个跨多个服务器处理数据的框架。因此，它从HDFS集群中获取数据，并在任务跟踪器节点中填充映射器和缩减器程序，任务跟踪器节点处理原始数据集并给出所需的输出。输出也是数据，因此它存储在Hadoop分布式存储集群中。</p><p id="49cd" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Hadoop用于大数据处理和业务分析操作，为了获得业务报告，我们继续通过一些Java或任何其他语言程序来解决用例，这些程序在对数据和程序进行分类后分发数据和程序，然后执行Reducer函数最终结果。这就是所谓的“MapReduce多节点Hadoop集群”。</p><h2 id="ff9d" class="lm ln hy bd hv lo lp lq lr ls lt lu lv jw lw lx ly ka lz ma mb ke mc md me mf bi translated">作业跟踪器节点的工作:</h2><p id="6e19" class="pw-post-body-paragraph jn jo hy jp b jq ml iz js jt mm jc jv jw mn jy jz ka mo kc kd ke mp kg kh ki hb bi translated">Job Tracker的功能是资源管理，跟踪资源可用性，跟踪容错进度。作业跟踪器与名称节点通信，以确定数据的位置。查找任务跟踪器节点以在给定节点上执行任务。它跟踪从本地到从节点的Map Reduce的执行。它是HDFS集群与任务跟踪器节点的通信点，用于数据分发和处理单元。</p><figure class="mh mi mj mk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mq"><img src="../Images/1ce7485fadfa4dbf550e980038ac0907.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RgAMRvXXR3yNhCl9.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="bd hv">Fig 2. Flow Diagram of Hadoop Data Flow</strong></figcaption></figure><h2 id="f239" class="lm ln hy bd hv lo lp lq lr ls lt lu lv jw lw lx ly ka lz ma mb ke mc md me mf bi translated">任务跟踪器节点的工作</h2><p id="3250" class="pw-post-body-paragraph jn jo hy jp b jq ml iz js jt mm jc jv jw mn jy jz ka mo kc kd ke mp kg kh ki hb bi translated">每个任务跟踪器都配置有一组<em class="mr">插槽</em>，这些插槽表示它可以接受的任务数量。当作业跟踪器试图在Map Reduce操作中寻找某个位置来调度任务时，它首先在托管包含数据的数据节点的同一服务器上寻找空插槽，如果没有，它就在同一机架中的机器上寻找空插槽。</p><h2 id="3426" class="lm ln hy bd hv lo lp lq lr ls lt lu lv jw lw lx ly ka lz ma mb ke mc md me mf bi translated">Hadoop如何提供内部排序程序？</h2><p id="bd97" class="pw-post-body-paragraph jn jo hy jp b jq ml iz js jt mm jc jv jw mn jy jz ka mo kc kd ke mp kg kh ki hb bi translated">在搜索关于映射器和缩减器程序的实际工作的事实时，得出的结论是，当我们具有从HDFS集群导入数据的映射器程序和使缩减器程序在大数据集中运行得更快和更准确的排序规则时，我们具有与缩减器程序一起在过滤和管理程序两个部分中工作的一些算法。</p><p id="c9ac" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Reducer主要工作在<em class="mr"> R-way merge </em>排序算法上，而在Hadoop的场景映射器后面，内部提供了一个名为Quick Sort的内置排序算法，它工作在任务跟踪器节点上，在将数据推送到reducer程序之前，根据用户\组织的用例过滤和管理数据。</p><p id="6ec2" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">reduce-Merge排序用于reduce端。合并排序是MapReduce的默认功能。不能改变MapReduce排序方法，原因是数据来自不同的节点到一个点，所以这里可以使用的最佳算法是合并排序。</p><h2 id="fcec" class="lm ln hy bd hv lo lp lq lr ls lt lu lv jw lw lx ly ka lz ma mb ke mc md me mf bi translated">如何设置工作追踪系统？</h2><p id="b0cc" class="pw-post-body-paragraph jn jo hy jp b jq ml iz js jt mm jc jv jw mn jy jz ka mo kc kd ke mp kg kh ki hb bi translated">作业跟踪器与名称节点对话，以确定数据的位置。作业跟踪器定位在数据处或数据附近具有可用槽的任务跟踪器节点。作业跟踪器将工作提交给所选的任务跟踪器节点。任务跟踪器节点被监控。如果它们没有足够频繁地提交心跳信号，它们就被认为失败了，工作被安排在不同的任务跟踪器上。当任务失败时，任务跟踪器会通知作业跟踪器。作业跟踪器决定接下来做什么:它可能会在其他地方重新提交作业，它可能会将该特定记录标记为要避免的内容，甚至可能会将任务跟踪器列入不可靠的黑名单。当工作完成时，作业跟踪器更新其状态。客户端应用程序可以轮询作业跟踪器以获取信息。</p><h2 id="f18e" class="lm ln hy bd hv lo lp lq lr ls lt lu lv jw lw lx ly ka lz ma mb ke mc md me mf bi translated">如何设置任务跟踪器？</h2><p id="fa6b" class="pw-post-body-paragraph jn jo hy jp b jq ml iz js jt mm jc jv jw mn jy jz ka mo kc kd ke mp kg kh ki hb bi translated">任务跟踪器产生一个独立的JVM进程来完成实际的工作；这是为了确保流程失败不会关闭任务跟踪器。任务跟踪器监视这些衍生的进程，捕获输出和退出代码。当该过程完成时，无论成功与否，跟踪器都会通知作业跟踪器。任务跟踪器还向作业跟踪器发送心跳消息，通常每隔几分钟一次，以向作业跟踪器保证它还活着。这些消息还通知作业跟踪器可用插槽的数量，因此作业跟踪器可以及时了解集群中可以委派工作的位置。这里，映射程序并行工作，而缩减程序作为合并器工作。</p></div><div class="ab cl ms mt gp mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="hb hc hd he hf"><h1 id="6588" class="mz ln hy bd hv na nb nc lr nd ne nf lv je ng jf ly jh nh ji mb jk ni jl me nj bi translated">现在让我引导你到实际的部分，</h1><p id="e2c5" class="pw-post-body-paragraph jn jo hy jp b jq ml iz js jt mm jc jv jw mn jy jz ka mo kc kd ke mp kg kh ki hb bi translated">我们将在这里创建两个集群— <strong class="jp hz"> MR集群</strong> (Map Reduce集群)和<strong class="jp hz"> HDFS集群</strong> (Hadoop分布式文件系统)集群，我们将分别用于客户端数据操作和存储。为了对数据执行任何操作，我们需要将程序和最重要的数据放在一个地方，但是如前所述，<strong class="jp hz">任务跟踪器(TT) </strong>节点通过<strong class="jp hz">作业跟踪器(JT) </strong>节点分配处理部分，它们在两个处理中评估任务，即<strong class="jp hz">使用映射程序</strong>和<strong class="jp hz">使用简化程序</strong>以获得所需的输出。输出进一步存储在<strong class="jp hz">数据节点(DN) </strong>中，因为JT节点和<strong class="jp hz"> NN(名称节点)</strong>在大数据的整个过程中相互依赖。因此称为Hadoop分布式计算和Hadoop分布式存储文件系统特性。</p><p id="62d7" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在此实践中，我们包括9个实时实例，其中我们将配置3个节点作为数据节点，3个节点作为任务跟踪节点，3个节点将是一个名称节点，一个作业跟踪节点，最后是一个Hadoop客户端节点，我们将提到两个群集的地址。这9个实例将通过使用EC2服务的公共云(AWS)启动，在Ansible角色的帮助下动态启动。我们将使用动态清单概念进一步配置集群部分，这些主机组将实例分为5个不同的类别，即</p><figure class="mh mi mj mk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nk"><img src="../Images/c54133eb42545e259bdec20e7d4d95d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NyvaaY4so_mh6jutEbEo6Q.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="bd hv">Fig 3. Practical Setup of our HDFS and MR Cluster</strong></figcaption></figure><ol class=""><li id="3b1c" class="ky kz hy jp b jq jr jt ju jw la ka lb ke lc ki nl le lf lg bi translated"><strong class="jp hz">名称节点:</strong>名称节点也称为主节点。名称节点仅存储文件系统中所有文件的目录树HDFS的元数据，并跨群集跟踪文件。</li><li id="567a" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki nl le lf lg bi translated"><strong class="jp hz">作业跟踪器节点:</strong>作业跟踪器是Hadoop中的一项服务，它将MapReduce任务分配给集群中的特定节点，理想情况下，这些节点拥有数据，或者至少在同一个机架中。客户端应用程序向作业跟踪器提交作业。</li><li id="cb9b" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki nl le lf lg bi translated"><strong class="jp hz"> Hadoop客户端节点:</strong>客户端与名称节点和作业追踪器通信，用于存储数据，并通过到达作业追踪器节点，使用一组程序对其进行处理，以获得所需的输出。</li><li id="9be6" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki nl le lf lg bi translated"><strong class="jp hz">任务追踪器节点:</strong>任务追踪器是集群中的一个节点，它接受来自作业追踪器的任务——映射、减少和重排操作。每个任务跟踪器都配置有一组<em class="mr">插槽</em>，这些插槽指示它可以接受的任务数量。</li><li id="1d6f" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki nl le lf lg bi translated"><strong class="jp hz">数据节点:</strong>数据节点也称为从节点。名称节点和数据节点持续通信。当一个数据节点启动时，它向名称节点通告它自己以及它所负责的块的列表。</li></ol><p id="cd61" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz">我的本地机器配置:</strong><br/>&gt;VBox Manager上的RHEL 8虚拟机，2个CPU，4GB RAM。<br/>安装了ansi ble 2 . 10 . 4版本。<br/> &gt;使用桥接适配器进行适当的网络连接。</p><figure class="mh mi mj mk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nk"><img src="../Images/c22c9fd6cb2808b1bc2c0769add0b3c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OH2IFkjknFQBPcIBnfa9xA.png"/></div></div></figure><p id="3398" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz"> <em class="mr">第一步:创建可行的配置文件:</em> </strong></p><p id="1b30" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Ansible是一个无代理的自动化工具，它需要控制器节点上的清单文件，我已经提到这是我们的本地系统。清单文件可以在路径(/etc/ansible/ansible.cfg)中的控制器节点内全局创建，也可以在我们将要运行剧本/角色的工作区中创建。</p><p id="3337" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz"> <em class="mr">为此项目创建工作区:</em> </strong></p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="72c5" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># mkdir hadoop-ws<br/># cd hadoop-ws<br/># mkdir roles</strong></span></pre><p id="f2a6" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz"> <em class="mr">配置文件:</em> </strong></p><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 4. ansible.cfg File</strong></figcaption></figure><p id="28b1" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">有关上述文件的解释，请访问！</p><p id="ba62" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz"> <em class="mr">第二步:创建两个文件</em> </strong></p><ul class=""><li id="a1f2" class="ky kz hy jp b jq jr jt ju jw la ka lb ke lc ki ld le lf lg bi translated"><strong class="jp hz"> <em class="mr">首先:</em> </strong></li></ul><p id="f543" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">一个名为<code class="du ny nz oa nn b">cred.yml</code>的安全库文件，包含IAM访问权限和用于验证您的AWS帐户的密钥。在您的目录“my-ws”中使用<code class="du ny nz oa nn b">ansible-vault create cred.yml</code>创建(给出密码)</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="22ba" class="lm ln hy nn b fi nr ns l nt nu"><em class="mr">file format:<br/></em>access_key: GUJGWDUYGUEWVVFEWGVFUYV <br/>secret_key: huadub7635897^%&amp;hdfqt57gvhg</span></pre><ul class=""><li id="506a" class="ky kz hy jp b jq jr jt ju jw la ka lb ke lc ki ld le lf lg bi translated"><strong class="jp hz"> <em class="mr">第二</em> </strong></li></ul><p id="6191" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">创建名为<code class="du ny nz oa nn b">hadoop_instance.pem</code>的文件，这是我们用来通过AWS帐户远程创建ec2实例的密钥对。</p><h2 id="8a76" class="lm ln hy bd hv lo lp lq lr ls lt lu lv jw lw lx ly ka lz ma mb ke mc md me mf bi translated">步骤:</h2><ul class=""><li id="614b" class="ky kz hy jp b jq ml jt mm jw ob ka oc ke od ki ld le lf lg bi translated"><em class="mr">转到AWS管理控制台</em></li><li id="44bc" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki ld le lf lg bi translated"><em class="mr"> EC2仪表板</em></li><li id="0371" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki ld le lf lg bi translated"><em class="mr">钥匙对</em></li><li id="d6ce" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki ld le lf lg bi translated"><em class="mr">创建新的密钥对</em></li><li id="7643" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki ld le lf lg bi translated"><em class="mr">起名叫</em> <code class="du ny nz oa nn b"><em class="mr">hadoop_instance</em></code></li><li id="54e2" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki ld le lf lg bi translated"><em class="mr">选择’。PEM '文件格式</em></li><li id="7817" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki ld le lf lg bi translated"><em class="mr">将密钥下载到您的本地系统</em></li><li id="b254" class="ky kz hy jp b jq lh jt li jw lj ka lk ke ll ki ld le lf lg bi translated"><em class="mr">将密钥转移到您的角色为</em> <code class="du ny nz oa nn b"><em class="mr">hadoop-ws</em></code>的同一目录下的Ansible Controller节点</li></ul><p id="ee34" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz"> <em class="mr">第三步:创建职责角色</em> </strong></p><p id="71b2" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">接下来，我们将创建六个主要角色，即<br/> ◼ AWS-EC2实例创建和动态IP检索角色、<br/>◼Hadoop-主配置和启动名称节点服务角色、<br/>◼Hadoop-从配置和启动数据节点服务角色、<br/>◼Hadoop-客户端配置和注册到集群、<br/> ◼ Hadoop-JobTracker配置和启动作业跟踪器服务角色、<br/> ◼ Hadoop-TaskTracker配置和启动任务跟踪器服务角色。</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="463f" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># mkdir role<br/># cd role<br/># ansible-galaxy init ec2<br/># ansible-galaxy init hadoop_master<br/># ansible-galaxy init hadoop_slave<br/># ansible-galaxy init hadoop_client<br/># ansible-galaxy init hadoop_jobtracker<br/># ansible-galaxy init hadoop_tasktracker</strong></span></pre><p id="8120" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">现在我们已经有了所有的任务、模板、变量文件<em class="mr">和其他基于已知文件结构</em>的可解析工件，它们都被预嵌入到角色中，我们只需要通过包含模块和jinja属性注释来编写我们所需要的所有东西的声明/描述(用YAML语言)。</p><p id="a2d9" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><a class="ae nx" href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html" rel="noopener ugc nofollow" target="_blank">欲了解更多角色信息，请访问！</a></p><figure class="mh mi mj mk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nk"><img src="../Images/ab7ff0bc0c9f11bce6a72d4562f7cd5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IIZ_9laUJlFEEv_J2DtZtg.png"/></div></div></figure><p id="f1a1" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz"> <em class="mr">第四步:编写EC2角色:</em> </strong></p><p id="75c8" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Ansible的EC2模块提供了通过AWS Cloud启动和供应实例的属性。我们更喜欢用<strong class="jp hz"> t2.micro作为instance_type </strong>和<strong class="jp hz"> Amazon Linux 2 image作为AMI </strong>。我们还有<strong class="jp hz">安全组，允许来自任何地方的所有流量</strong>，而不是您可以使用HDFS协议和一些SSH以及一些端口入站出站规则，如端口9001、50070、9002和10020…等等。</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="872d" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/ec2/tasks<br/># vim main.yml</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 5. Task File for EC2 Role</strong></figcaption></figure><p id="530e" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">模板和变量文件夹中包含了一些变量和文件，如<strong class="jp hz"><em class="mr">instance _ tags</em></strong><em class="mr"/><strong class="jp hz"><em class="mr">Python _ pkg</em></strong><em class="mr"/><strong class="jp hz"><em class="mr">SG _ name</em></strong><em class="mr"/><strong class="jp hz"><em class="mr">region _ name</em></strong><em class="mr"/><strong class="jp hz"><em class="mr">subnet _ name</em></strong>根据Ansible工件，可以在ec2 roles/ec2/tasks/main.yml文件中直接调用这些变量。</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="aa49" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/ec2/vars<br/># vim main.yml</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 6. Variable File for EC2 Role</strong></figcaption></figure><figure class="mh mi mj mk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nk"><img src="../Images/06d61c7f5fe57d2d2478aa1093dc4054.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZluNgPGphmvLudq5FyCoHg.png"/></div></div></figure><p id="4d82" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz"> <em class="mr">第五步:编写Hadoop_master角色:</em> </strong></p><p id="ceda" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Hadoop master具有以xml格式写在core-site.xml文件上的集群的主要元数据，如集群ID和端口，我们需要在此主节点上执行的关键事情是格式化我们的master共享文件夹，只需执行一次。此外，我们必须给出主设备与其从设备和客户端通信的端口，即端口9001。</p><p id="eed0" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">考虑需要在hadoop_master/tasks文件夹的main.yml中编写以下代码。</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="565f" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_master/tasks<br/># vim main.yml</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 7. Tasks for Master Ansible Role</strong></figcaption></figure><p id="d36d" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们在template文件夹中包含的<strong class="jp hz"> jinja2格式文件</strong>该文件是我们的master在配置master时配置的<strong class="jp hz">HDFS-site . XML</strong>；</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="d576" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_master/templates<br/># vim hdfs-site.xml.j2</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 8. hdfs-site.xml.j2 file</strong></figcaption></figure><p id="078b" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们有变量文件，它包含在角色执行时将被直接调用/替换的值。这些变量包括— <em class="mr"> pkgs_name和hadoop_folder </em>。</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="5c78" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_master/vars<br/># vim main.yml</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 9. Variable file for Hadoop-master Role</strong></figcaption></figure><p id="22be" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Hadoop中有两个文件需要配置，一个是core-site.xml，另一个是hdfs-site.xml。要通过ansible配置这两个文件，我们有两种策略，一种是使用复制模块复制它们，另一种是使用模板模块复制它们并做一些更改。通常我们在拷贝时使用模板进行数据处理，这些模板文件是以jinja2文件格式编写的。</p><p id="6f1c" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">您需要做的是将core-site.xml文件放在我们角色的files文件夹中。所以只要转到hadoop_master/files，把下面的文件。</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="0a77" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_master/templates<br/># vim main.yml</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 10. core-site.xml.j2 file</strong></figcaption></figure><figure class="mh mi mj mk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nk"><img src="../Images/cf419df4ab3acb9341d417227ca879c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vQ6Co0h2R5QSajURJaIvWA.png"/></div></div></figure><p id="db57" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz"> <em class="mr">第六步:编写Hadoop_slave角色:</em> </strong></p><p id="2492" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">现在我们必须配置Hadoop-slave，我们希望有多少Hadoop slave就有多少，以获得分布式存储能力和计算资源。下面是task/main.yml文件，其中所有步骤都以YAML格式声明。从安装依赖项开始，然后在最后，我们在slave中的最终任务是运行数据节点服务。</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="8cab" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_slave/tasks<br/># vim main.yml</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 11. Hadoop-Slave Task File</strong></figcaption></figure><p id="3c31" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">下面是来自我们的<strong class="jp hz"> hadoop_slave </strong>角色的var/main.yml文件，其中我们有两个var，<strong class="jp hz"> pkgs_name </strong>和<strong class="jp hz"> hadoop_folder </strong>，我们需要调用它们来获取各自的值。</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="9a77" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_slave/vars<br/># vim main.yml</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 12. Hadoop-Slave Variable File</strong></figcaption></figure><p id="c98d" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">由于我们必须在task/main.yml文件中使用模板模块，以便在进行一些处理后将两个文件都复制到文件中，或者说将更改复制到文件中，然后将文件复制到从节点，这些文件是<strong class="jp hz"> core-site.xml </strong>和<strong class="jp hz"> hdfs-site.xml </strong>它们在<strong class="jp hz"> jinja2 </strong>文件格式中的角色模板文件夹中提到:</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="3538" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_slave/templates<br/># vim core-site.xml.j2</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 13. core-site.xml.j2 File</strong></figcaption></figure><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="e931" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_slave/templates<br/># vim hdfs-site.xml.j2</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 14. hdfs-site.xml.j2 File</strong></figcaption></figure><figure class="mh mi mj mk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nk"><img src="../Images/139ca0057cf566ed3cd5b4ebdda9634e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qm3DF_JO_Q0NMtTe9Vbr5A.png"/></div></div></figure><p id="83db" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz"> <em class="mr">第七步:编写Hadoop_jobtracker角色:</em> </strong></p><p id="1496" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">作业跟踪器节点配置由该角色完成，该角色遵循一个任务流，在该任务流中，下载JVM并进一步安装Hadoop和Java。该角色有助于为MR集群设置主节点，该集群加载映射器和缩减器程序，并将它们分发到从节点，即用于分布式计算的任务跟踪器节点。为此，我们在路径/roles/Hadoop _ job tracker/tasks ansi ble role目录下的main.yml文件中编写以下任务:</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="0be9" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_jobtracker/tasks<br/># vim main.yml</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 15. Task File for Job Tracker Role</strong></figcaption></figure><p id="6040" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">许多任务，包括安装Hadoop软件、配置将这些节点连接到其MR集群主机(JT)的mapred-site.xml文件，以及下一次启动任务跟踪节点服务，并在诸如<strong class="jp hz"> <em class="mr">命令、模板、lineinfile、shell和get_url等可扩展模块的帮助下使服务守护进程永久化。</em>T29】</strong></p><p id="4c8f" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">接下来，在hadoop_jobtracker角色内的vars目录中提到了这些变量:名为<strong class="jp hz"><em class="mr">pkgs _ name</em></strong><em class="mr"/>的变量保存了我们安装hadoop所需的包的值。</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="9eff" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_jobtracker/vars<br/># vim main.yml</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 16. Variable File for Job Tracker Role</strong></figcaption></figure><p id="2fae" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们在角色的模板文件夹中找到了两个主要的配置文件，用于进一步配置作业跟踪器节点。名为<strong class="jp hz"> <em class="mr"> core-site.xml.j2 </em> </strong>的文件将管理HDFS集群与作业跟踪器的连接，另一个名为<strong class="jp hz"><em class="mr">mapred-site . XML . J2</em></strong>的文件用于MR集群设置。</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="36e8" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_jobtracker/templates<br/># vim core-site.xml.j2</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 17. Core-Site.xml.j2 File</strong></figcaption></figure><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="c9c6" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_jobtracker/templates<br/># vim mapred-site.xml.j2</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 18. Mapred-Site.xml.j2 File</strong></figcaption></figure><figure class="mh mi mj mk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nk"><img src="../Images/465df9a16ccbe1bbe20762e83bdd518d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wRJuhnX-e60Qt9V5RyjQXQ.png"/></div></div></figure><p id="1503" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz"> <em class="mr">第八步:编写Hadoop_tasktracker角色:</em> </strong></p><p id="0c84" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">任务跟踪器节点在数量上更多。它们被配置为与作业跟踪器节点通信，并为映射器和缩减器获取数据和程序输入。任务跟踪器节点的主要思想是对大量数据进行并行计算。因此，我们在hadoop_tasktracker角色中为节点配置编写了以下剧本:</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="e95b" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_tasktracker/tasks<br/># vim main.yml</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 19. Task File for Task Tracker Role</strong></figcaption></figure><p id="4aaa" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在这里，我们有许多任务，如安装Hadoop软件、配置mapred-site.xml文件，该文件将这些节点连接到它们的MR集群主节点(JT ),以及下一次启动任务跟踪节点服务，并在诸如<strong class="jp hz"> <em class="mr">命令、模板、lineinfile、shell和get_url等可转换模块的帮助下使服务守护进程永久化。</em> </strong></p><p id="9a9f" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">以下是hadoop_tasktracker角色内vars文件夹中的变量文件。main.yml文件内。它只包含一个名为<strong class="jp hz"> <em class="mr"> pkgs_name </em> </strong>的变量，该变量包含在我们的任务跟踪器节点中安装hadoop所需的包名。</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="6e55" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_tasktracker/vars<br/># vim main.yml</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 20. Variable File for Task Tracker Role</strong></figcaption></figure><p id="9be7" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">接下来是我们的角色文件下的templates文件夹，它包含一个主地址文件，用于我们的任务跟踪器节点的主连接。mapred-site.xml.j2文件将在模板模块的帮助下在指定位置进行处理和复制。</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="0b96" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_tasktracker/templates<br/># vim mapred-site.xml.j2</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 21. Mapred-Site.xml.j2 File</strong></figcaption></figure><figure class="mh mi mj mk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nk"><img src="../Images/08d722e7f66339c600961e0bc21962f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ypftCtZiI5R0JznZ6c8A7w.png"/></div></div></figure><p id="3969" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz"> <em class="mr">第九步:编写Hadoop_client角色:</em> </strong></p><p id="e978" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">客户端的目标是使用主IP访问群集，然后执行放/读/写/编辑/删除任何其他操作，将大文件存储在所需的块大小中，并进一步复制以提高其文件的可用性。</p><p id="1261" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">此外，对于MR (Map Reduce)操作代码，Hadoop提供了一个单独的计算集群，这些程序文件将在其中分发，通过从HDFS集群获取数据块，它将适当的输出提供给客户端，客户端将进一步存储在我们的HDFS集群中。下面是我们角色的roles/Hadoop _ client/task/main . yml文件，其中给出了客户端配置的描述性代码:</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="4e9c" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_client/tasks<br/># vim main.yml</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 22.Tasks for Hadoop Client Role</strong></figcaption></figure><p id="91e6" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">变量将在vars/main.yml文件夹中提及，该文件夹包括- <strong class="jp hz"> pkgs_name </strong>，其中包含安装Hadoop软件所需的软件包名称。</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="cc43" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_client/vars<br/># vim main.yml</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 23. Variable File for Hadoop Client Role</strong></figcaption></figure><p id="76e3" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">由于在配置客户端节点时我们只需要提到主节点名称，因此我们只需要更改文件<strong class="jp hz"> core-site.xml </strong>，对于作业跟踪器节点，我们以jinja 2格式配置<strong class="jp hz"> mapred-site.xml.j2 </strong>，我们将把它放在我们角色的模板文件夹中:</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="6501" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_client/templates<br/># vim core-site.xml.j2</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 24. Core-Site.xml.j2 File</strong></figcaption></figure><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="86a6" class="lm ln hy nn b fi nr ns l nt nu"><strong class="nn hz"># cd role/hadoop_client/templates<br/># vim mapred-site.xml.j2</strong></span></pre><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 25. Mapred-Site.xml.j2 File</strong></figcaption></figure><p id="ce99" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在这里，我们通过我们的动态清单中的事实<strong class="jp hz">主机变量</strong>来检索mater IP，我们从我们的主配置输出中获得mater将侦听/响应的端口，即9001、9002和其他端口。</p><p id="ac8d" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">最后，我们完成了所有角色的创建，现在我们只需要运行这些角色，为此我们必须创建一个剧本，并通过以逻辑方式一个接一个地包含这些角色来继续运行这些角色。我们知道，首先需要通过AWS启动节点，然后是主配置，接着是从配置、作业跟踪器和任务跟踪器配置，最后是客户端注册到HDFS和MR集群。</p><figure class="mh mi mj mk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nk"><img src="../Images/58645e47f37dfec6b08531314e201e3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x2ccT78guUSyTfsHJayv9A.png"/></div></div></figure><p id="5e83" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz"> <em class="mr">步骤10:创建设置行动手册以运行所有角色并在AWS上创建集群:</em> </strong></p><p id="f1c4" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">下面是我们的工作目录<code class="du ny nz oa nn b"><em class="mr">hadoop-ws</em></code> <em class="mr">中需要的剧本文件——setup . yml。</em>这里我们通过调用<strong class="jp hz"> <em class="mr"> include_role </em> </strong>模块和相关变量文件中的角色名称来编写所有角色，作为<strong class="jp hz"> <em class="mr"> vars_files </em> </strong>参数。</p><figure class="mh mi mj mk fd hk"><div class="bz dy l di"><div class="nv nw l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><strong class="ak">Fig 26. setup.yml File</strong></figcaption></figure><p id="161f" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">因此，我们调用了我们在这里创建的所有五个角色:ec2角色、hadoop_master角色、hadoop_slave角色、hadoop_jobtracker角色、hadoop_tasktracker角色和hadoop_client角色。其中一个变量文件名为cred.yml，它是一个包含登录AWS公共云平台的凭据的vault文件。</p><p id="d211" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz">步骤11:运行剧本Setup.yml </strong></p><p id="979b" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">使用ansible-playbook命令运行剧本，并提供vault密码以验证和登录AWS帐户。(请参考上述步骤中的vault文件创建)。</p><pre class="mh mi mj mk fd nm nn no np aw nq bi"><span id="0550" class="lm ln hy nn b fi nr ns l nt nu"># ansible-playbook setup.yml -ask-vault-pass</span></pre><p id="ec45" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">因此，我们已经实现了“使用Ansible Automation在AWS上实现Hadoop MapReduce多节点集群”的目标。</p></div><div class="ab cl ms mt gp mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="hb hc hd he hf"><p id="733a" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">你可以在我的GitHub上找到这个项目，只要fork和let使这个项目对客户来说更加系统独立和可靠。</p><div class="hh hi ez fb hj kj"><a href="https://github.com/akankshaS77/Hadoop-HDFS-MR-Multi-Node-Cluster-AWS-Ansible.git" rel="noopener  ugc nofollow" target="_blank"><div class="kk ab dw"><div class="kl ab km cl cj kn"><h2 class="bd hz fi z dy ko ea eb kp ed ef hx bi translated">akankshas 77/Hadoop-HDFS-MR-多节点-集群-AWS-Ansible</h2><div class="kq l"><h3 class="bd b fi z dy ko ea eb kp ed ef dx translated">创建可启动9个AWS EC2实例的角色。动态获取IP并创建清单以运行进一步的…</h3></div><div class="kr l"><p class="bd b fp z dy ko ea eb kp ed ef dx translated">github.com</p></div></div><div class="ks l"><div class="oe l ku kv kw ks kx hp kj"/></div></div></a></div><p id="f85c" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">如果您想为这个项目做出贡献，或者有进一步的疑问或意见，您可以通过LinkedIN联系我:</p><div class="hh hi ez fb hj kj"><a href="https://www.linkedin.com/in/akanksha-singh-as/" rel="noopener  ugc nofollow" target="_blank"><div class="kk ab dw"><div class="kl ab km cl cj kn"><h2 class="bd hz fi z dy ko ea eb kp ed ef hx bi translated">阿康沙·辛格-成功负责人@ ARTH -技术学院- LinuxWorld Informatics Pvt有限公司…</h2><div class="kq l"><h3 class="bd b fi z dy ko ea eb kp ed ef dx translated">在全球最大的职业社区LinkedIn上查看阿康沙·辛格的个人资料。阿康沙有3个工作列在…</h3></div><div class="kr l"><p class="bd b fp z dy ko ea eb kp ed ef dx translated">www.linkedin.com</p></div></div><div class="ks l"><div class="of l ku kv kw ks kx hp kj"/></div></div></a></div><figure class="mh mi mj mk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nk"><img src="../Images/91f11c47895599f53e3601b94318961c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oZF0ISEoYeLdEYfVQ_CR9Q.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">(: — )</figcaption></figure><h2 id="d137" class="lm ln hy bd hv lo lp lq lr ls lt lu lv jw lw lx ly ka lz ma mb ke mc md me mf bi translated">感谢阅读。希望这个博客给你一些有价值的输入！！</h2></div></div>    
</body>
</html>