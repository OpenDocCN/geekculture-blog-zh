<html>
<head>
<title>Developing Reinforcement Learning Environment Using OpenAI Gym</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用OpenAI Gym开发强化学习环境</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/developing-reinforcement-learning-environment-using-openai-gym-f510b0393eb7?source=collection_archive---------1-----------------------#2021-12-27">https://medium.com/geekculture/developing-reinforcement-learning-environment-using-openai-gym-f510b0393eb7?source=collection_archive---------1-----------------------#2021-12-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="c62c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="c6aa" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">强化学习问题由主体和环境组成。该环境向代理提供反馈，以便它可以学习哪个动作适合于特定的状态。在本帖中，我们将使用OpenAI Gym构建一个强化学习环境，用于训练代理。</p><p id="3edb" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">本教程分为两部分。在第一部分中，我们将使用Python和PyGLET构建一个简单的游戏。然后，我们将调整OpenAI Gym接口，以标准化我们的环境，以便当我们开发学习算法时，我们不必了解它在内部是如何工作的。</p><h1 id="14bc" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">游戏</h1><p id="782b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们要建立一个迷宫游戏，它有两个简单的规则:</p><ul class=""><li id="f129" class="kg kh hi jf b jg kb jk kc jo ki js kj jw kk ka kl km kn ko bi translated">代理可以在4个方向上一次移动1步:上、下、左、右。</li><li id="0671" class="kg kh hi jf b jg kp jk kq jo kr js ks jw kt ka kl km kn ko bi translated">当代理人到达目标时，游戏结束。</li></ul><p id="dc8f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">下图展示了游戏的样子。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es ku"><img src="../Images/e11485778637bc614bc9d1713fc25e5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/1*QhC790Piot1VlmYB5GXXwA.gif"/></div><figcaption class="lc ld et er es le lf bd b be z dx">The maze game. (Image by author)</figcaption></figure><h1 id="da1c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">游戏开发</h1><p id="88d5" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">本节简要说明项目的游戏开发部分。因为游戏开发不是这篇文章的主要焦点，我们不打算深究它的细节。然而，如果你感兴趣，这个项目的代码可以在<a class="ae lg" href="https://github.com/thanakorn/gym-image-maze" rel="noopener ugc nofollow" target="_blank">这个GitHub库</a>中找到。</p><h2 id="fe58" class="lh ig hi bd ih li lj lk il ll lm ln ip jo lo lp it js lq lr ix jw ls lt jb lu bi translated">业务逻辑</h2><p id="a428" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">首先，我们将创建一个<code class="du lv lw lx ly b">Maze</code>类，它代表一个迷宫并封装了上述规则。迷宫的状态由三样东西表示:代理人的位置、目标的位置和墙壁的位置。这些将成为这个类的属性。</p><p id="a14b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">迷宫中唯一可以改变的是代理人的位置。因此，该类将拥有将方向作为参数的<code class="du lv lw lx ly b">move_robot</code>方法。此外，我们将有一些getter方法来检查迷宫的状态，如代理到目标之间的距离。当我们稍后构建奖励函数时，这些方法会派上用场。</p><h2 id="d828" class="lh ig hi bd ih li lj lk il ll lm ln ip jo lo lp it js lq lr ix jw ls lt jb lu bi translated">表示层</h2><p id="4716" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">一旦游戏逻辑完成，下一步就是开发表示层。我们将为这一层使用的库是一个名为<a class="ae lg" href="http://pyglet.org/" rel="noopener ugc nofollow" target="_blank"> PyGLET </a>的Python游戏开发库。</p><p id="5009" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">首先，我们将创建一个<code class="du lv lw lx ly b">MazeDrawer</code>类，负责制作一个代表迷宫当前状态的图像。然后，该图像被传递到<code class="du lv lw lx ly b">Renderer</code>以将其呈现给图形用户界面。最后，所有组件都组装在<code class="du lv lw lx ly b">MazeGame</code>类中，该类控制主循环并将按键映射到动作。</p><p id="4e08" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">下图显示了所有组件是如何组合在一起的。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es lz"><img src="../Images/e2d1caab6beec02c151b520eb5a776ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sqpGRAMA3089TPX42ay0fA.jpeg"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx">The architecture of the game. (Image by author)</figcaption></figure><h1 id="a3c1" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">整合开放式健身房</h1><p id="725c" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">虽然游戏已经准备好了，但是有一个小问题需要首先解决。为了开发一个模型，用户仍然必须理解我们游戏的机制，这样他们才能让学习算法与它互动。这是有问题的，因为我们希望我们的用户专注于解决问题，而不是学习系统如何工作。此外，如果在某个时候，我们对我们的游戏进行了更改，这可能会毁掉他们所有的作品。听起来很糟糕，对吧？</p><p id="2505" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">为了防止这一点，我们将标准化我们游戏的界面，以便无论它在内部如何工作，它对用户来说看起来都是一样的，我们将应用的标准是由OpenAI Gym设计的。</p><h2 id="cad6" class="lh ig hi bd ih li lj lk il ll lm ln ip jo lo lp it js lq lr ix jw ls lt jb lu bi translated">什么是OpenAI健身房？</h2><p id="b381" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">OpenAI Gym是一个用于强化学习算法开发的工具包。该库提供了一组众所周知的强化学习问题的环境，如CartPole和MountainCar。有了这些现成的东西，开发人员就可以专注于学习算法和模型。</p><p id="a315" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">除了内置环境之外，OpenAI Gym还允许通过简单地扩展提供的<code class="du lv lw lx ly b">Env</code>类的抽象来创建用户定义的环境。</p><h2 id="b65a" class="lh ig hi bd ih li lj lk il ll lm ln ip jo lo lp it js lq lr ix jw ls lt jb lu bi translated">OpenAI健身房界面</h2><p id="44d9" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">要构建一个定制的OpenAI Gym环境，您必须扩展库提供的<code class="du lv lw lx ly b">Env</code>类，如下所示:</p><pre class="kv kw kx ky fd me ly mf mg aw mh bi"><span id="5ed9" class="lh ig hi ly b fi mi mj l mk ml">import gym</span><span id="0cb4" class="lh ig hi ly b fi mm mj l mk ml">class ImageMazeEnv(gym.Env):<br/>     def __init__(self):<br/>         ...</span><span id="1f55" class="lh ig hi ly b fi mm mj l mk ml">     def step(self, action):<br/>         ...</span><span id="6aa7" class="lh ig hi ly b fi mm mj l mk ml">     def reset(self):<br/>         ...</span><span id="a1ac" class="lh ig hi ly b fi mm mj l mk ml">     def render(self):<br/>         ...</span><span id="b1db" class="lh ig hi ly b fi mm mj l mk ml">     def close(self):<br/>         ...</span></pre><p id="c287" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">然后，您需要覆盖2个属性和4个方法，它们的作用如下:</p><ul class=""><li id="7beb" class="kg kh hi jf b jg kb jk kc jo ki js kj jw kk ka kl km kn ko bi translated">属性<br/> - <code class="du lv lw lx ly b">action_space</code>:代理可以执行的所有可用动作。<br/> - <code class="du lv lw lx ly b">observation_space</code>:观察的结构。</li><li id="c622" class="kg kh hi jf b jg kp jk kq jo kr js ks jw kt ka kl km kn ko bi translated">方法<br/> - <code class="du lv lw lx ly b">step</code>:对环境执行一个动作，然后返回环境的状态，动作的奖励，以及剧集是否结束。<br/> - <code class="du lv lw lx ly b">reset</code>:重置环境状态，然后返回初始状态。<br/> - <code class="du lv lw lx ly b">render</code>(可选):渲染环境进行可视化。<br/> - <code class="du lv lw lx ly b">close</code>(可选):执行清理。</li></ul><p id="99b4" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">请注意，与此相关的所有代码必须位于项目目录下的<code class="du lv lw lx ly b">envs</code>文件夹中。</p><h2 id="16eb" class="lh ig hi bd ih li lj lk il ll lm ln ip jo lo lp it js lq lr ix jw ls lt jb lu bi translated">行动和观察空间</h2><p id="179c" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">动作空间很简单。有4种可用的动作:向左、向右、向上和向下。我们可以使用为离散空间提供的<code class="du lv lw lx ly b">Discrete</code>类来定义它。</p><p id="d3ca" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">观察空间定义了我们希望代理如何感知环境。因为我们已经实现了用于生成迷宫图像的<code class="du lv lw lx ly b">MazeDrawer</code>,我们将使用该图像作为对我们环境的观察。为了定义这一点，我们可以使用<code class="du lv lw lx ly b">Box</code>类，它允许您指定观察的形状及其取值范围。</p><p id="8fa4" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">动作和观察空间定义如下:</p><pre class="kv kw kx ky fd me ly mf mg aw mh bi"><span id="2ebb" class="lh ig hi ly b fi mi mj l mk ml">import gym<br/>from gym.spaces import Discrete, Box</span><span id="881e" class="lh ig hi ly b fi mm mj l mk ml"><strong class="ly hj">class</strong> ImageMazeEnv(gym.Env):<br/>     <strong class="ly hj">def</strong> __init__(self):<br/>        self.maze = .... # Create a maze object<br/>        ....<br/>        self.action_space = Discrete(4)<br/>        self.observation_space = Box(low=0,high=255,shape=[500,500])</span></pre><h2 id="cf5c" class="lh ig hi bd ih li lj lk il ll lm ln ip jo lo lp it js lq lr ix jw ls lt jb lu bi translated">阶跃函数</h2><p id="3725" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在我们定义了动作和观察空间之后，接下来是实现step函数。这个功能有3个职责:执行一个动作，提供对新状态的观察，以及提供一个奖励。</p><p id="10b0" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">前两个是微不足道的，因为我们已经做到了。<code class="du lv lw lx ly b">Maze</code>类已经有了<code class="du lv lw lx ly b">move_robot</code>方法，所以我们只需将动作传递给它。为了便于观察，我们实现了<code class="du lv lw lx ly b">MazeDrawer</code>,它可以生成一个代表迷宫对象当前状态的图像。剩下的工作是设计和实现奖励函数，这是开发学习算法的关键部分。</p><p id="37ba" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">奖励机制应该与我们想要实现的目标相关联。在迷宫问题中，任务是到达智能体不知道在哪里的目标。我们将使用奖励函数作为一个信号，每当代理向目标靠近时提供一个积极的奖励，反之亦然。此外，代理人应该避免撞到墙上，因为这是无用的，所以我们也要加上惩罚。迷宫问题的奖励函数具有以下条件:</p><ul class=""><li id="7875" class="kg kh hi jf b jg kb jk kc jo ki js kj jw kk ka kl km kn ko bi translated">如果代理人移动得更接近目标(与前一回合相比)，它将获得奖励+1。</li><li id="c5c2" class="kg kh hi jf b jg kp jk kq jo kr js ks jw kt ka kl km kn ko bi translated">如果代理人远离目标，它得到一个惩罚-1。</li><li id="5278" class="kg kh hi jf b jg kp jk kq jo kr js ks jw kt ka kl km kn ko bi translated">如果代理撞上了墙，它会得到一个惩罚-10。</li><li id="d08a" class="kg kh hi jf b jg kp jk kq jo kr js ks jw kt ka kl km kn ko bi translated">如果代理达到目标，则获得奖励+100。</li><li id="d897" class="kg kh hi jf b jg kp jk kq jo kr js ks jw kt ka kl km kn ko bi translated">代理和目标之间的距离使用欧几里德距离计算，不考虑墙壁。</li><li id="a281" class="kg kh hi jf b jg kp jk kq jo kr js ks jw kt ka kl km kn ko bi translated">如果代理人在特定的回合数内没有达到目标，游戏就结束了。</li></ul><p id="c36b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">下面是阶跃函数的样子:</p><pre class="kv kw kx ky fd me ly mf mg aw mh bi"><span id="ae0f" class="lh ig hi ly b fi mi mj l mk ml"><strong class="ly hj">def</strong> step(self, action):<br/>   self.timestep += 1</span><span id="6ccf" class="lh ig hi ly b fi mm mj l mk ml">   current_dist_to_goal = self.maze.dist_to_goal()<br/>   self.maze.move_robot(action)<br/>   new_dist_to_goal = self.maze.dist_to_goal()<br/>   is_collide = current_dist_to_goal == new_dist_to_goal</span><span id="890c" class="lh ig hi ly b fi mm mj l mk ml">   self.done = self.maze.is_robot_reach_goal() or self.timestep ==     self.time_limit</span><span id="aa00" class="lh ig hi ly b fi mm mj l mk ml">   reward = 0.<br/>   if self.maze.is_robot_reach_goal():<br/>      reward = 100<br/>   elif is_collide:<br/>      reward = -10<br/>   elif new_dist_to_goal &lt; current_dist_to_goal:<br/>      reward = 1<br/>   else:<br/>      reward = -1</span><span id="1885" class="lh ig hi ly b fi mm mj l mk ml">   <strong class="ly hj">return</strong> MazeDrawer.draw_maze(self.maze, 500, 500), reward.value, self.done, {}</span></pre><h2 id="e13d" class="lh ig hi bd ih li lj lk il ll lm ln ip jo lo lp it js lq lr ix jw ls lt jb lu bi translated">重置、渲染和关闭</h2><p id="1b84" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><code class="du lv lw lx ly b">reset</code>函数要将游戏重新初始化到开始状态，并返回观察结果。为了简单起见，我们将初始状态存储在一个JSON文件中，并从中创建一个新的迷宫实例。类似于阶跃函数，MazeDrawer用于生成观测值。</p><p id="70ff" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><code class="du lv lw lx ly b">render</code>函数渲染环境，这样我们就可以将它可视化。我们将使用<code class="du lv lw lx ly b">MazeDrawer</code>和<code class="du lv lw lx ly b">Renderer</code>类来做到这一点。<code class="du lv lw lx ly b">close</code>方法用于清理。这里我们唯一要做的就是摧毁<code class="du lv lw lx ly b">Renderer</code>物体。</p><p id="3935" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这三种方法的实现如下:</p><pre class="kv kw kx ky fd me ly mf mg aw mh bi"><span id="9c17" class="lh ig hi ly b fi mi mj l mk ml"><strong class="ly hj">def</strong> reset(self):<br/>   self.maze = Maze.from_config(self.config_file)<br/>   self.done = False<br/>   self.timestep = 0<br/>   <br/>   if self.visualize:<br/>     self.renderer.render(MazeDrawer.draw_maze(self.maze, 500, 500))</span><span id="0ce8" class="lh ig hi ly b fi mm mj l mk ml">   <strong class="ly hj">return</strong> MazeDrawer.draw_maze(self.maze, 500, 500)</span><span id="4877" class="lh ig hi ly b fi mm mj l mk ml"><strong class="ly hj">def</strong> render(self, mode='human'):<br/>   self.renderer.render(MazeDrawer.draw_maze(self.maze, 500, 500))</span><span id="b439" class="lh ig hi ly b fi mm mj l mk ml"><strong class="ly hj">def</strong> close(self):<br/>   if self.visualize:<br/>      self.renderer.close()</span></pre><h1 id="4d44" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">注册并使用环境</h1><p id="27af" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">现在我们的环境已经准备好了，最后要做的就是将它注册到OpenAI Gym环境注册表中。以下是如何做到这一点:</p><p id="117c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">首先，创建一个代表您的环境的特定版本的类。</p><pre class="kv kw kx ky fd me ly mf mg aw mh bi"><span id="185f" class="lh ig hi ly b fi mi mj l mk ml"><strong class="ly hj">class</strong> ImageMazeV0(ImageMazeEnv):<br/>     <strong class="ly hj">def</strong> __init__(self):<br/>         super().__init__(time_limit=200)</span></pre><p id="e051" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">然后，通过将下面的代码放到项目目录的<code class="du lv lw lx ly b">__init__.py</code>中，将它注册到gym <code class="du lv lw lx ly b">register</code>中。</p><pre class="kv kw kx ky fd me ly mf mg aw mh bi"><span id="d096" class="lh ig hi ly b fi mi mj l mk ml">from gym.envs.registration import register</span><span id="7e8f" class="lh ig hi ly b fi mm mj l mk ml">register(<br/>   id='ImageMaze-v0',<br/>   entry_point='gym_image_maze.envs:ImageMazeV0'<br/>)</span></pre><p id="7dc6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">最后，向您的<code class="du lv lw lx ly b">envs</code>目录中的<code class="du lv lw lx ly b">__init__.py</code>添加一个导入语句。</p><pre class="kv kw kx ky fd me ly mf mg aw mh bi"><span id="1dca" class="lh ig hi ly b fi mi mj l mk ml">from gym_image_maze.envs.image_maze_env import ImageMazeV0</span></pre><p id="a559" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">新环境准备好了！！！让我们用下面的代码测试一下:</p><pre class="kv kw kx ky fd me ly mf mg aw mh bi"><span id="4ace" class="lh ig hi ly b fi mi mj l mk ml">import gym</span><span id="2faa" class="lh ig hi ly b fi mm mj l mk ml">if __name__=='__main__':<br/>   env = gym.make('ImageMaze-v0')<br/>   env.reset()<br/>   for i in range(500):<br/>       env.render()<br/>       observation, reward, done, _ = env.step(env.action_space.sample())<br/>       print('Observation : ' + str(observation.shape))<br/>       print('Reward      : ' + str(reward))<br/>       print('Done        : ' + str(done))<br/>       print('---------------------')<br/>env.close()</span></pre><p id="8618" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">您应该会在屏幕和终端上看到类似这样的内容。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es ku"><img src="../Images/1b9bc6c857008127a6cba8d8b04c814d.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/1*bVuKavyB4ckWb8jSakDKQw.gif"/></div></figure><pre class="kv kw kx ky fd me ly mf mg aw mh bi"><span id="f519" class="lh ig hi ly b fi mi mj l mk ml">---------------------<br/>Observation : (500, 500)<br/>Reward      : -10<br/>Done        : False<br/>---------------------<br/>Observation : (500, 500)<br/>Reward      : 1<br/>Done        : False<br/>---------------------<br/>Observation : (500, 500)<br/>Reward      : 1<br/>Done        : False<br/>---------------------</span></pre><p id="59f4" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">就是这样。我们完了。现在我们的环境已经可以使用了。<br/>如果你想看这个项目的代码，这里有<a class="ae lg" href="https://github.com/thanakorn/gym-image-maze" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="9921" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结论</h1><p id="20db" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在本文中，我们学习了如何使用OpenAI Gym构建一个定制的强化学习算法。这允许您创建针对您的特定用例定制的强化学习问题，这些用例不在OpenAI Gym提供的标准环境中。</p><p id="df41" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">感谢阅读。如果你喜欢这篇文章，你可以<a class="ae lg" rel="noopener" href="/subscribe/@thanakornpanyapiang">关注我</a>了解更多。下一篇文章再见。</p></div></div>    
</body>
</html>