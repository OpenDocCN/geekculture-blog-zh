<html>
<head>
<title>Data Preprocessing and EDA for Natural Language Processing.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理中的数据预处理和EDA。</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/data-preprocessing-and-eda-for-natural-language-processing-56e45c1df36d?source=collection_archive---------5-----------------------#2021-05-02">https://medium.com/geekculture/data-preprocessing-and-eda-for-natural-language-processing-56e45c1df36d?source=collection_archive---------5-----------------------#2021-05-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c7d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在实现任何机器学习模型或执行统计假设测试之前，了解关于您的数据的足够见解是非常重要的。探索性数据分析为您提供了对数据的洞察。</p><p id="a595" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将讨论各自可用的python包，以及在自然语言处理领域应该执行的不同探索性任务。对于这篇文章，我使用的是<a class="ae jd" href="https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews" rel="noopener ugc nofollow" target="_blank"> Kaggle IMDB情感分析</a>数据和Google colab平台。那么，让我们开始…</p><h2 id="3405" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated"><strong class="ak">安装和导入软件包</strong></h2><p id="ee8e" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">我们将使用这些包进行分析。最后提到了软件包的参考文献。</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="0f12" class="je jf hi kj b fi kn ko l kp kq">!pip install texthero<br/>!pip install -q kaggle # to download the dataset<br/>!pip install wordcloud<br/>!pip install -U textblob<br/>!python -m textblob.download_corpora</span><span id="0d4a" class="je jf hi kj b fi kr ko l kp kq"># importing<br/>import pandas as pd<br/>import matplotlib as plt<br/>import seaborn as sns<br/>import texthero as hero<br/>from texthero import stopwords<br/>import os<br/>from wordcloud import WordCloud<br/>import nltk<br/>nltk.download('wordnet')<br/>from nltk.stem import WordNetLemmatizer<br/>from textblob import TextBlob,Word</span></pre><h2 id="9975" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">读取数据</h2><p id="d8d7" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">从Kaggle下载和读取数据集。现在，只考虑5000行的探索。</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="61a4" class="je jf hi kj b fi kn ko l kp kq">!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews<br/>!unzip 'imdb-dataset-of-50k-movie-reviews.zip' -d kaggle_IMDB</span><span id="b8e3" class="je jf hi kj b fi kr ko l kp kq">#reading data<br/>file_name='kaggle_IMDB/IMDB Dataset.csv'</span><span id="d845" class="je jf hi kj b fi kr ko l kp kq">#reading dataframe<br/>df= pd.read_csv(file_name, header='infer',nrows=5000)</span><span id="bcf3" class="je jf hi kj b fi kr ko l kp kq">df.head()</span></pre><figure class="ke kf kg kh fd kt er es paragraph-image"><div class="er es ks"><img src="../Images/40ea545cf9f4b9b74b86d3dec3468111.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*nTbSOpasbuSu_-JGlHIjLg.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx">Kaggle IMDB dataset</figcaption></figure><h2 id="3f77" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">数据预处理</h2><p id="2e84" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">有各种各样的任务需要在数据处理中执行，如小写，删除停用词，删除数字，删除网址，HTML标签等等。</p><p id="3b95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于基本的清理和词汇化，我使用了<a class="ae jd" href="https://github.com/jbesomi/texthero" rel="noopener ugc nofollow" target="_blank"> texthero </a>和nltk包，它提供了与文本预处理和数据探索相关的特性。代码如下:</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="df3c" class="je jf hi kj b fi kn ko l kp kq">def lemma_per_pos(sent):<br/>'''function to lemmatize according to part of speech tag'''<br/>   t = TextBlob(sent)<br/>   t_dict = {"J": 'a',"N": 'n',"V": 'v',"R": 'r'}<br/>   w_n_t = [(w, t_dict.get(p[0], 'n')) for w, p in t.tags]<br/>   lemmatized_list = [w.lemmatize(t) for w, t in w_n_t]<br/>   return " ".join(lemmatized_list)</span><span id="32b1" class="je jf hi kj b fi kr ko l kp kq">def df_preprocessing(df,col_name):<br/>    default_stopwords = stopwords.DEFAULT</span><span id="0e31" class="je jf hi kj b fi kr ko l kp kq">   # adding some stop words as for movie review,so removing it<br/>   custom_stopwords = default_stopwords.union(set(["movie","film"]))</span><span id="9224" class="je jf hi kj b fi kr ko l kp kq">   df[col_name]=[text.replace('&lt;br','') for text in df[col_name]]</span><span id="8836" class="je jf hi kj b fi kr ko l kp kq">   # cleaning<br/>   df[col_name]= (<br/>              df[col_name]<br/>              .pipe(hero.clean)<br/>              .pipe(hero.remove_html_tags)<br/>              .pipe(hero.remove_brackets)<br/>              .pipe(hero.remove_urls))</span><span id="63ca" class="je jf hi kj b fi kr ko l kp kq">    # lemmatization<br/>   df[col_name]= [lemma_per_pos(sent) for sent in df[col_name]]<br/>   df[col_name]=hero.remove_stopwords(df[col_name],custom_stopwords)</span><span id="7fc6" class="je jf hi kj b fi kr ko l kp kq">   return df</span></pre><p id="6703" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们在预处理中看到的，我删除了一些最常见的词，如电影，电影。这背后的原因可以在下图中看到，文本数据中最常见的单词在情感分析中不起作用。这就是为什么分析数据在任何文本处理中都是一个重要的先决条件，以后，您可以根据自己的需要改变预处理步骤。</p><figure class="ke kf kg kh fd kt er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es la"><img src="../Images/8bf49698b6422931d518fcf9d6584bc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MVlR1bkU36w1qMGxdYwI6g.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx">Most common words (generated without removing common words)</figcaption></figure><p id="107e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，还有像<em class="lf"> make、made、films、film、characters这样的单词,</em>被视为不同的单词。因此，术语化对于解决这个问题很重要。</p><p id="054f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" href="https://en.wikipedia.org/wiki/Lemmatisation" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"><em class="lf"/></strong></a><em class="lf">(</em><strong class="ih hj"><em class="lf">词汇化</em> </strong> <em class="lf">)在语言学中是将一个单词的屈折形式组合在一起的过程，这样它们就可以作为一个单独的项目来分析，通过该单词的词汇或词典形式来识别。(来源:维基百科)</em></p><p id="c546" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有许多不同的词汇化包可供使用。比较那些技术来验证你想要的能不能实现总是比较好的。例如，如下图所示，一个是根据词性标注(POS)的词汇化，另一个是没有词性的词汇化。你可以清楚地看到不同之处。检查你的lemma输出并根据你的需要使用它们是一个很好的实践。</p><figure class="ke kf kg kh fd kt er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lg"><img src="../Images/15ce07c246ac30f047a19da0bd83b22f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nBFZWFGTg1BaQatAwEUWew.png"/></div></div></figure><p id="f683" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">并且，在去掉最常见的单词和词汇化之后，分布看起来是这样的。</p><figure class="ke kf kg kh fd kt er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lh"><img src="../Images/80632bd3e8fe3a2a8fcbdf87a942c1e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nQeiTTj1DVV5bL45UCT1LQ.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx">Most common words after stop words, most common words removal and lemmatization.</figcaption></figure><h2 id="6b81" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">句子层次分析</h2><p id="6a98" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">文本统计包括句子长度分布、最小值、最大值和平均长度。</p><p id="578d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">检查句子长度分布。代码和输出如下:</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="019a" class="je jf hi kj b fi kn ko l kp kq">df['len']= df['review'].str.len()</span><span id="3b85" class="je jf hi kj b fi kr ko l kp kq">print('Max length: {}, Min length: {}, Average Length :  {}'.format(max(df['len']),min(df['len']),df['len'].mean()))</span><span id="7f8a" class="je jf hi kj b fi kr ko l kp kq">df['len'].hist()</span></pre><figure class="ke kf kg kh fd kt er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es li"><img src="../Images/26ea227d6a03b3c2e9f8ae9b4ab02985.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ms2lnCY2jq9Ke11gn60vWg.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx">Length distribution</figcaption></figure><p id="33d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从分布来看，大部分文章长度在0-1000之间，最大长度、最小长度和平均长度分别为6136、45、757。这里要注意的一点是，句子长度包括单词之间的空格。如果你想要没有空间的分配，你可以使用下面的代码。</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="21f3" class="je jf hi kj b fi kn ko l kp kq">df['len']= df['review']str.split().map(lambda x: len(x))<br/>df['len'].hist()</span></pre><h2 id="62a2" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">单词级分析</h2><p id="29ce" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">对于单词级分析，我们需要将一个完整的文本样本组合成一个文本文档，然后拆分成单词。</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="b04c" class="je jf hi kj b fi kn ko l kp kq">text= ' '.join(t for t in df['review'])<br/>words_list= text.split()</span></pre><p id="a1f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建一个字典，将单词作为关键字，将它们的计数作为值，然后创建单词的数据帧。</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="7aec" class="je jf hi kj b fi kn ko l kp kq">word_freq= {}<br/>for word in set(words_list):<br/>    word_freq[word]= words_list.count(word)</span><span id="0af1" class="je jf hi kj b fi kr ko l kp kq">#Creating dataframe of words<br/>df_word= pd.DataFrame(word_freq.items(),columns=['word','count'])</span></pre><p id="08d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在为word创建了数据帧之后，现在我们可以添加每个单词的长度。</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="101f" class="je jf hi kj b fi kn ko l kp kq">df_word['word_len']= df_word['word'].map(lambda x: len(x))</span><span id="3173" class="je jf hi kj b fi kr ko l kp kq"># sorting values <br/>df_word=df_word.sort_values('count',ascending=False).reset_index(drop=True)</span><span id="0765" class="je jf hi kj b fi kr ko l kp kq">df_word</span></pre><figure class="ke kf kg kh fd kt er es paragraph-image"><div class="er es lj"><img src="../Images/2ac29098d60e02cc027d74686c299ffd.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*aCjkixarAIwjO306QqplQw.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx">word dataframe</figcaption></figure><p id="0722" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最常见的50个单词是:</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="f3c0" class="je jf hi kj b fi kn ko l kp kq">df_top= df_word.head(50)</span><span id="f658" class="je jf hi kj b fi kr ko l kp kq">sns.barplot(df_top['count'],df_top['word'])</span></pre><figure class="ke kf kg kh fd kt er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lk"><img src="../Images/1afae28a788dfcc8767cdf2a1dd5dea4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ro8i--neNlNby68fRvGEEg.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx">Most common words</figcaption></figure><p id="d1ac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，长度分布。</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="33ae" class="je jf hi kj b fi kn ko l kp kq">df_word['word_len'].hist()</span></pre><figure class="ke kf kg kh fd kt er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ll"><img src="../Images/1afa2ad58a9e64b11a8d58d7ed095a59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sl_zc0ifqGkKbFG8Qc4tiw.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx">Word length distribution</figcaption></figure><p id="a3ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">等等！</strong>，这里有些诡异。有长度超过15的单词。我们必须验证，这些到底是不是英文单词？</p><p id="07d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们检查一下…</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="41a0" class="je jf hi kj b fi kn ko l kp kq">df_word[df_word['word_len']==max(df_word['word_len'])]</span></pre><figure class="ke kf kg kh fd kt er es paragraph-image"><div class="er es lm"><img src="../Images/b6df8c6542fddbcdc31547be28b777c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*cGBazxGzspcD-0keKdboCw.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx">Non-English word</figcaption></figure><p id="188e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有时，用户只是在评论中输入随机字符，我们需要找到并删除它们。我们可以通过检查这个单词实际上是一个英语单词来做到这一点。我已经在预处理代码中添加了这种验证。</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="bdab" class="je jf hi kj b fi kn ko l kp kq">nltk.download('words')<br/>from nltk.corpus import words<br/>setofwords = set(words.words())</span><span id="3bd7" class="je jf hi kj b fi kr ko l kp kq">lemmatized_list = [w.lemmatize(t) for w, t in w_n_t if w in setofwords]</span></pre><p id="9811" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">解决问题后，</p><figure class="ke kf kg kh fd kt er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ln"><img src="../Images/176b1fe392d5f885bead27ef0dbe3b92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Us4yu4TX-7vR0qRKqeVDtQ.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx">Word length distribution</figcaption></figure><p id="f192" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，最长的单词显示如下，这似乎是正确的英语单词。</p><figure class="ke kf kg kh fd kt er es paragraph-image"><div class="er es lo"><img src="../Images/eedbb85a903a407315980fb11118b7e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*_UAZZh244vFSamM5-L3qTQ.png"/></div></figure><p id="aed1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是分析的美妙之处，我们在后期面对问题之前就发现了问题。</p><h2 id="dbfb" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">主题建模</h2><p id="cc82" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">哪些单词代表文本语料库，让我们用python中的<a class="ae jd" href="https://amueller.github.io/word_cloud/" rel="noopener ugc nofollow" target="_blank"> wordcloud </a>包来绘制这些单词。</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="eab0" class="je jf hi kj b fi kn ko l kp kq">wordcloud = WordCloud(background_color=’white’,max_words=100,<br/>                      max_font_size=40,<br/>                      scale=3,<br/>                      random_state=1)<br/>                      .generate(text)<br/>plt.axis(“off”)<br/>plt.imshow(wordcloud)</span></pre><figure class="ke kf kg kh fd kt er es paragraph-image"><div class="er es lp"><img src="../Images/d1344955bcaf5b939f926c17c3964180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*k0deJt5zJEjv4RfybwgC-w.png"/></div></figure><p id="543f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，您可以在文本示例中看到代表电影评论的单词，这些是评论电影最常用的单词。</p><h2 id="bd67" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">评论的情绪</h2><p id="ec9b" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">让我们检查一下情感在文本数据中是如何分布的。对于这个任务，我们将再次使用textblob。</p><p id="4c93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">TextBlob的情绪输出了一个极性和主观性的元组。<strong class="ih hj">极性</strong>范围[-1.0，1.0]其中-1.0为负极性，1.0为正极性，0.0为中性。<strong class="ih hj">主观性</strong>范围【0.0，1.0】其中0.0表示高度客观，1.0表示非常主观。</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="885d" class="je jf hi kj b fi kn ko l kp kq">df[‘review’][8]</span></pre><p id="1388" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">即</p><p id="ad1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lf">“积极向前看看坏错误看真的一坏糟透了几乎每一种方式行事宋蹩脚的乡村曲调少了四次廉价的令人讨厌的令人厌烦的极端的很少高兴看到结局的事给分远了最好的表演最少使咬劲一个”</em></p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="d02c" class="je jf hi kj b fi kn ko l kp kq">TextBlob(df[‘review’][8]).sentiment</span></pre><figure class="ke kf kg kh fd kt er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lq"><img src="../Images/16aae51c1448c069e68a08a3504968b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Va3dbtIGNe_NMrRHKDHijg.png"/></div></div></figure><p id="aa6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据TextBlob，给定的句子带有负面情绪和高度主观，如果我们阅读评论，这是有意义的。</p><p id="1b5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，完成文本语料库中的情感分布。</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="4ff6" class="je jf hi kj b fi kn ko l kp kq">def polarity(x):<br/>    if TextBlob(x).sentiment[0]&lt;-0.25:<br/>       return 'Negative'<br/>    if TextBlob(x).sentiment[0]&gt;0.25:<br/>       return 'Positive'<br/>    return 'Neutral'</span><span id="a05f" class="je jf hi kj b fi kr ko l kp kq">df['sentiment']= df['review'].map(lambda x: polarity(x))<br/>df['sentiment'].hist()</span></pre><figure class="ke kf kg kh fd kt er es paragraph-image"><div class="er es lr"><img src="../Images/49111576b94eeb8f293c4f4738d4522f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*TQtn1k_vZwD2g2SXfWfdig.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx">sentiment distributiion</figcaption></figure><figure class="ke kf kg kh fd kt er es paragraph-image"><div class="er es ls"><img src="../Images/e129795f33d96a4685769b909ffd0bb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*CvBXSXUOM95fv6CQ8Y3LOA.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx">Sentiment distribution without mapping to classes</figcaption></figure><p id="e283" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据情感分布，大多数评论是中性的，极少数评论有负面情感</p><h2 id="19a8" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">进一步探索</h2><p id="bbf7" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">使用tf/idf和主成分分析，我们可以在散点图中显示我们的数据，并检查它在2D散点图中的外观。</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="5f3c" class="je jf hi kj b fi kn ko l kp kq">df[‘pca’] = (df[‘review’].pipe(hero.tfidf).pipe(hero.pca))</span><span id="b604" class="je jf hi kj b fi kr ko l kp kq">hero.scatterplot(df, ‘pca’, color=’sentiment’, title=”sentiment”)</span></pre><figure class="ke kf kg kh fd kt er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lt"><img src="../Images/662007501d16ddea5c2d5fedcf3bc468.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F_brjsr9mzAmoxl4wwUlxg.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx">Scatter plot</figcaption></figure><p id="0d73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们尝试使用k-means聚类来发现文本语料库中的隐藏聚类。</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="6b3e" class="je jf hi kj b fi kn ko l kp kq">df[‘kmeans_labels’] = (df[‘review’].pipe(hero.tfidf)<br/>                       .pipe(hero.kmeans, n_clusters=2)<br/>                        .astype(str))</span><span id="2226" class="je jf hi kj b fi kr ko l kp kq">hero.scatterplot(df, ‘pca’, color=’kmeans_labels’, title=”K-means”)</span></pre><figure class="ke kf kg kh fd kt er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lu"><img src="../Images/7a30930205d3f5f9a6ae9e95ecd9f15d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eO1zWHpSVSV3gchLmoooFA.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx">K-means plot</figcaption></figure><h2 id="7cc3" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated"><strong class="ak">最终意见</strong></h2><p id="eb17" class="pw-post-body-paragraph if ig hi ih b ii jz ik il im ka io ip iq kb is it iu kc iw ix iy kd ja jb jc hb bi translated">在本文中，我们讨论了不同的数据预处理和探索性数据分析包及其实现。像texthero、textblob和nltk这样的包可以简化复杂的任务，节省时间和精力。</p><p id="579a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于情感分析，我发现上述步骤足够了。然而，还有进一步的分析任务，如n-grams分布、词性、可读性测试和实体识别，可以通过提到的python包来实现(对于可读性测试，您可以使用<a class="ae jd" href="https://pypi.org/project/textstat/" rel="noopener ugc nofollow" target="_blank"> Textstat </a>)。请浏览参考资料以获取更多信息。</p><p id="c176" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望如此！，这篇文章很有用，你学到了一些新东西。</p><p id="24d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢你和快乐的分析！</p><h2 id="7c2e" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">参考资料:</h2><ol class=""><li id="3f4b" class="lv lw hi ih b ii jz im ka iq lx iu ly iy lz jc ma mb mc md bi translated"><a class="ae jd" href="https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/Lakshmi 25 npath I/IMDB-dataset-of-50k-movie-reviews</a></li><li id="1d40" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated"><a class="ae jd" href="https://github.com/jbesomi/texthero" rel="noopener ugc nofollow" target="_blank">https://github.com/jbesomi/texthero</a></li><li id="ab57" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated"><a class="ae jd" href="https://textblob.readthedocs.io/en/dev/index.html" rel="noopener ugc nofollow" target="_blank">https://textblob.readthedocs.io/en/dev/index.html</a></li><li id="16c9" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated"><a class="ae jd" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank">https://www.nltk.org/</a></li><li id="0d8c" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated"><a class="ae jd" href="https://amueller.github.io/word_cloud/" rel="noopener ugc nofollow" target="_blank">https://amueller.github.io/word_cloud/</a></li><li id="b081" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated"><a class="ae jd" href="https://pypi.org/project/textstat/" rel="noopener ugc nofollow" target="_blank">https://pypi.org/project/textstat/</a></li></ol></div></div>    
</body>
</html>