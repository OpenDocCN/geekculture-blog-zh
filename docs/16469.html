<html>
<head>
<title>Building Resilient Data Pipelines with deep dive into AirFlow architecture</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入研究气流架构，构建弹性数据管道</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/building-resilient-data-pipelines-with-deep-dive-into-airflow-architecture-38bb9efa7239?source=collection_archive---------9-----------------------#2022-12-29">https://medium.com/geekculture/building-resilient-data-pipelines-with-deep-dive-into-airflow-architecture-38bb9efa7239?source=collection_archive---------9-----------------------#2022-12-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="e2f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">目标:使用Airflow、Hive (HDFS查询分析)和Superset(数据可视化)从零开始构建弹性数据管道</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/72706d8d351c4f0427df5309bccc5a06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*A2KYX3_d5EMtznne"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Photo by <a class="ae jt" href="https://unsplash.com/@kuzzogiu?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Giuseppe CUZZOCREA</a> on <a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="e5ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据管道对任何组织都至关重要，因为它们消除了流程中的大多数手动步骤，并实现了数据从一个阶段到另一个阶段的平稳自动流动。它们对于实时分析至关重要，有助于做出更快的数据驱动型决策，并构建业务洞察力(文章绩效、主题受欢迎程度、优化(如果有)、自动推荐等)。).由于这些管道非常重要，我们决定管理管道的系统/平台必须满足以下SLA</p><ul class=""><li id="46aa" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">处理任务相关性</li><li id="9efc" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">支持并发性(能够在任何时间点调度多个作业)</li><li id="d920" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">处理可伸缩性的分布式系统</li><li id="13a6" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">对失败有弹性(符合<strong class="ih hj">墨菲定律</strong></li><li id="4a86" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">快速调试的可观察性</li><li id="10fc" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">监控(可操作的UI层/仪表板)</li></ul><p id="ddce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们通过一个实际的场景来讨论如何构建一个符合上述SLA的弹性系统。我们将把讨论分为两个阶段。</p><ul class=""><li id="fa4d" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">我们将讨论如何构建一个数据管道，以使用airflow和hive检索、转换和聚合Glance新闻门户合作伙伴的分析数据，从而构建<strong class="ih hj">洞察</strong>并做出<strong class="ih hj">数据驱动的业务决策</strong></li><li id="cb95" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated"><a class="ae jt" href="#a227" rel="noopener ugc nofollow">深入探究气流架构，了解数据管道在幕后的工作原理。</a></li></ul><h1 id="aaa3" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">运行中的数据管道</h1><p id="6c6b" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">我们将讨论如何使用工作流管理平台构建弹性数据管道，但首先让我们深入了解问题陈述。</p><p id="4519" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Glance有几个新闻门户合作伙伴，展示他们的内容(新闻、文章等)。)和这些新闻门户网站的分析数据(浏览量、跳出率、地区用户等。)在他们的谷歌分析账户上捕捉到的。</p><p id="3726" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">我们需要一个集中式仪表板来查看所有合作伙伴分析数据，以便构建业务洞察和数据驱动的决策。到目前为止，这是一个手动流程，每个合作伙伴都需要提交日常分析数据，并在我们的系统中进行本地汇总和更新。这一过程涉及大量的手动工作，容易出现人为错误，导致错误的见解和业务决策。这一过程需要端到端的自动化。</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/d830d751b838fc710c40252d43f47656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lQmEmNNS8BbqX377.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx">Required Data Format</figcaption></figure><p id="68a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从问题陈述中可以明显看出，我们需要构建一个弹性数据管道，该管道每天触发并检索合作伙伴数据-&gt;聚合数据-&gt;存储在各自的目的地以供使用</p><h1 id="acd6" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">设计决策(CRON与气流)</h1><p id="b275" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">任务调度是管理数据管道的任何系统的核心，我们将深入探讨的两个最广泛使用的调度器是Cron和Airflow</p><p id="381a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用于工作流管理的Cron:Cron是一种众所周知的经过试验和测试的方法，用于以预定的方式运行任务，但是它也有一些限制，例如</p><ul class=""><li id="0737" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">Cron作业在单个机器上运行，并且不是分布式的，当涉及较少的依赖关系时，它也能很好地工作。例如，考虑以下情况，如果任何一个作业失败，将会产生级联效应</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/e047dc90afb21e502e19ba7a8f25f108.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9bI8wAHtnangJ1s7.png"/></div></figure><p id="2091" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">工作流依赖性</p><ul class=""><li id="ff67" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">因为Cron作业不生成任何关于任务调度、执行、失败、重试等的元数据。监控和调试成为一项复杂的任务，在未来可能会呈指数级增长。</li></ul><p id="1fc7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Cron本质上不具备<strong class="ih hj">弹性</strong>，也不满足上面列出的任何SLA。如果您的情况相当简单，几乎没有依赖性，Cron就很好，否则就使用适合您需求的适当的WMP。</p><p id="30ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Airflow as WMP </strong> : Airflow是一个让你建立和运行工作流的平台。工作流被表示为一个<a class="ae jt" href="https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html" rel="noopener ugc nofollow" target="_blank"> DAG </a>(一个有向的非循环图，其中可以将单个工作定义为任务),而<em class="lm"> </em>与Cron<strong class="ih hj">不同，它在本质上是分布式的，并且是为弹性而构建的</strong>。让我们看看一些受支持的特性</p><ul class=""><li id="f8a1" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">监控和可观察性<br/> 1。管道中所有DAG及其状态的图形视图<br/> 2。每个任务/子任务级别的失败<br/> 3。暂停/开始/停止DAG的选项<br/> 4。查看使用的所有传感器/触发器</li><li id="7b28" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">元数据生成<br/> 1。下一个预定间隔<br/> 2。任务及其子任务花费的时间</li><li id="9a51" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">弹性<br/> 1。可配置的&amp;强制重试选项<br/> 2。外部故障情况下的数据回填<br/> 3。针对突然的系统行为的警报</li><li id="efba" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">工作流程<br/> 1。依赖关系管理的控制流程<br/> 2。预定义的运算符&amp;连接器，用于从各种来源(数据库、云存储、HDFS、缓存等)接收数据。)</li></ul><p id="61e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Airflow固有地支持前面讨论的所有列出的SLA，并且还提供了一个很好的可操作仪表板来进行监控和观察，因此是我们的用例的默认选择。</p><h1 id="c9bd" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">履行</h1><p id="b3fe" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">下面的体系结构在较高的层次上使用气流根据DAG中指定的任务依赖关系异步执行任务，结果被转换-&gt;聚合并存储在sink (GCS和HIVE)中以供以后使用。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/0bf1266e9953e4600a263d2140a5b9f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DkEh9lBo6hF0A0Do.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx">Pipeline Architecture</figcaption></figure><h1 id="a56d" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">深入探究建筑</h1><ol class=""><li id="52f9" class="ju jv hi ih b ii lg im lh iq ln iu lo iy lp jc lq ka kb kc bi translated">我们将把我们的工作流定义为每天调度的DAG(指定调度信息和要执行的任务的python脚本)</li><li id="c05a" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc lq ka kb kc bi translated">以下是DAG中指定的各个任务</li></ol><ul class=""><li id="7269" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">任务1:检索并转换每个合作伙伴的分析数据</li><li id="2ae2" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">任务2:根据流程日期对数据进行分区(为了加快查询加载时间),并将转换后的数据推送到GCS存储桶</li><li id="15cd" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">任务3:根据流程日期检索GCS存储桶中的数据，并将转换后的数据推送到HIVE</li></ul><p id="65f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.Airflow根据任务依赖关系在内部异步调度和执行指定的任务(使用预定义的执行器(<strong class="ih hj"> celery或k8s </strong>)和worker节点)。</p><p id="c633" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.一旦数据被推送，<strong class="ih hj">超集</strong>将检索、聚合基于预定时间间隔的流程日期范围的配置单元表中的数据，并在仪表板上显示数据。</p><h1 id="05c7" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">将工作流定义为DAG</h1><ul class=""><li id="7e49" class="ju jv hi ih b ii lg im lh iq ln iu lo iy lp jc jz ka kb kc bi translated">每个Dag都需要下面提到的属性，其中最重要的是<br/> 1。<em class="lm">调度间隔</em>:根据用例，您可以将dag调度定义为cron表达式或一些预定义的标签(@daily、@weekly等)。)下面定义的dag将在UTC每天凌晨3:00运行<br/> 2。<em class="lm"> Catchup </em>:需要回填历史数据时使用。为了完成这个设置，过去的时间开始日期和这个字段值为真<br/> 3。<em class="lm">重试_延迟</em></li></ul><pre class="je jf jg jh fd lr ls lt bn lu lv bi"><span id="196b" class="lw kj hi ls b be lx ly l lz ma">default_args = {<br/>    'owner': 'GRAP',<br/>    'depends_on_past': False,<br/>    'start_date': datetime.datetime(2022, 9, 1),<br/>    'email': [alert_email],<br/>    'email_on_failure': True,<br/>    'email_on_retry': False,<br/>    'retries': 5,<br/>    'catchup': True,<br/>    'retry_delay': timedelta(minutes=30)<br/>}dag = DAG(<br/>    dag_id,<br/>    default_args=default_args,<br/>    schedule_interval='0 3 * * *',<br/>    max_active_runs=1,<br/>    catchup=True,<br/>    tags=['DAILY','ANALYTICS']<br/>)</span></pre><ul class=""><li id="688e" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">一旦DAG被初始化，下一步就是定义任务。我们主要有两项任务<br/> 1。从各自的合作伙伴谷歌分析账户- &gt;获取合作伙伴分析数据- &gt;推送到GCP云存储。这里，我们定义了一个带有python可调用函数的任务来执行，op_kwargs表示提供给函数的参数。如果需要，您甚至可以将这个函数分解成多个任务，并使用<strong class="ih hj"> Xcoms </strong>在任务实例之间传递数据，这有点棘手，但提供了更多的可读性。</li></ul><pre class="je jf jg jh fd lr ls lt bn lu lv bi"><span id="c170" class="lw kj hi ls b be lx ly l lz ma">fetch_page_analytics_api_data = PythonOperator(<br/>        task_id='fetch_partner_analytics',<br/>        python_callable=fetch_partner_analytics,<br/>        op_kwargs={ 'dateTemp': '{{ ds }}'},<br/>        provide_context=True,<br/>        dag=dag<br/>    )</span></pre><p id="a408" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.下一个任务是从Gcp云存储中检索数据，并将其推送到按流程日期划分的Hive(HDFS)。</p><pre class="je jf jg jh fd lr ls lt bn lu lv bi"><span id="cafc" class="lw kj hi ls b be lx ly l lz ma">partition_registry_new = HiveOperator(<br/>          hql=register_new_partitions(table_name),<br/>          hive_cli_conn_id='prod_hive_connection_glance_cube',<br/>          schema='glance_google_analytics',<br/>          hiveconf_jinja_translate=True,<br/>          task_id='add_partition_in_hive',<br/>          dag=dag<br/>     )</span></pre><ul class=""><li id="47cb" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">一旦定义了各自的任务，我们就需要引入它们之间的依赖关系(如果有的话)(这里我们希望在创建任何分区之前先获取数据)</li></ul><pre class="je jf jg jh fd lr ls lt bn lu lv bi"><span id="6997" class="lw kj hi ls b be lx ly l lz ma">fetch_page_analytics_api_data &gt;&gt; partition_registry_new</span></pre><ul class=""><li id="c6a2" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">如果不提供依赖性，则由于其分布式性质，气流将并行执行任务。</li></ul><p id="09a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是如何在带有任务的流程中定义DAG，并在它们之间引入依赖关系。上面没有显示任务实现，因为它可能会根据用例以及设计代码的风格而变化，这将留给用户去探索。</p><h1 id="a227" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">气流建筑</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/e9982200ae109f26a8f86e519052fd2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Gnz1O1dl9SOBRToa.png"/></div></figure><p id="fa89" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">高层次上的Airflow是建立在元数据库上的排队系统，该元数据库将任务及其元数据存储在队列中，以及调度器，该调度器可以访问元数据调度(重新安排、设置优先级、删除过期的任务等)。)队列中的任务，并将其提供给执行器，执行器具有自己的工作节点来并行执行任务</p><ul class=""><li id="7824" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">DAG:一个工作流被表示为一个<a class="ae jt" href="https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html" rel="noopener ugc nofollow" target="_blank"> DAG </a>(一个有向无环图)并且包含被称为<a class="ae jt" href="https://airflow.apache.org/docs/apache-airflow/stable/concepts/tasks.html" rel="noopener ugc nofollow" target="_blank">任务</a>的单独的工作片段。DAG指定任务之间的依赖性，以及执行它们和运行重试的顺序<br/> 1。<em class="lm"> Tasks </em>:在DAG中，你可以定义多个任务，并描述每个任务要做的事情，比如获取数据、运行分析、触发其他系统等等。</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/6cbc3a3c8ff7bf94460dac814e8749c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qLmcmeUf1Qcdn2jg.png"/></div></figure><p id="3ef8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">任务状态自动机</p><p id="8354" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<em class="lm">操作符</em>:操作符是预定义任务的模板，可以根据需要在一个任务中使用多个操作符(例如<br/>-&gt;<strong class="ih hj">bash Operator</strong>:执行bash命令<br/> - &gt; <strong class="ih hj"> Python操作符</strong>:执行任意Python函数<br/>-&gt;<strong class="ih hj">simple HTTP Operator</strong>:调用HTTP上的端点<br/> 3 .传感器:一类特殊的操作者，他们完全是在等待外部事件的发生</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/44037a44c356dea8c2e663139935abd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*q-4f9p4L35mmuS1N.png"/></div></figure><p id="5966" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">示例DAG(从各种源获取数据，转换并分发到接收器以供使用)</p><ul class=""><li id="9a26" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated"><strong class="ih hj">调度器</strong>:气流调度器是一个通过元数据库访问所有DAG及其任务的进程，执行以下操作<br/> 1。监控任务并决定任务优先级和执行<br/> 2。一旦任务的依赖关系完成就触发任务。将任务提交给执行者执行</li><li id="30ee" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated"><strong class="ih hj">执行器</strong>:气流执行器从调度器接收要运行的任务实例，并将其放入队列中，稍后由工作节点拾取以执行任务。遗嘱执行人基本上有两种类型<br/> 1。<em class="lm">本地执行器</em>:在本地(在<code class="du mb mc md ls b">scheduler</code>进程内)运行任务<em class="lm">的执行器，主要用于单机安装、本地测试或较小的工作量<br/> 2。<em class="lm">远程执行器</em>:远程</em>运行任务<em class="lm">的执行器(通常通过<em class="lm">工作线程</em>)，如上所示(例如芹菜、库伯内特、芹菜库伯内特执行器)</em></li><li id="1a48" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated"><strong class="ih hj">网络服务器</strong>:气流<em class="lm">网络服务器</em>提供了一个方便的用户界面来检查、触发和调试Dag和任务的行为。</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/46f7812eef2392cf559ddb3391844a15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yRTFGepTRxt3YmJR.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/2ace8a3bf25568d241b8dfbbc1cd958b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QiK9bD8m1YmUdCLm.png"/></div></figure><p id="8e22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果对更多后端感兴趣，请结帐🙂</p><ul class=""><li id="2dd9" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated"><a class="ae jt" href="https://engg.glance.com/computing-live-stream-viewers-count-in-real-time-at-high-scale-ef813bc1b9cb" rel="noopener ugc nofollow" target="_blank">以高比例实时计算直播流观众数！！|瞥</a></li><li id="bd8a" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated"><a class="ae jt" href="https://blog.bitsrc.io/deploy-node-js-application-over-google-cloud-with-ci-cd-36df0cc42231" rel="noopener ugc nofollow" target="_blank">如何使用Google Kubernetes引擎、Jenkins、DockerHub和ArgoCD通过CI/CD实现应用部署自动化</a></li></ul><h1 id="315c" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">离别笔记</h1><p id="f672" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">我希望上面的讨论是富有成效的，并帮助您了解了关于与WMP合作和构建分布式弹性数据管道的一两件事。对<a class="ae jt" href="https://www.linkedin.com/in/bala-mahesh-jampani-6686b1110/" rel="noopener ugc nofollow" target="_blank">马赫什</a>和<a class="ae jt" href="https://www.linkedin.com/in/vbvasa/" rel="noopener ugc nofollow" target="_blank">瓦伊巴夫</a>的大力支持，以及<a class="ae jt" href="https://www.linkedin.com/in/priyansh/" rel="noopener ugc nofollow" target="_blank">普里扬舒·杜贝</a>、<a class="ae jt" href="https://www.linkedin.com/in/kanishkm/" rel="noopener ugc nofollow" target="_blank">卡尼什克·梅塔</a>、<a class="ae jt" href="https://www.linkedin.com/in/shoaib-a-169a649/" rel="noopener ugc nofollow" target="_blank">绍伊布</a>提供机会建造令人敬畏的东西。</p></div></div>    
</body>
</html>