<html>
<head>
<title>Data Science👨‍💻: Data Reduction Techniques Using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学👨‍💻:使用Python的数据简化技术</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/data-science-data-reduction-techniques-using-python-3de757a20a3b?source=collection_archive---------8-----------------------#2021-10-25">https://medium.com/geekculture/data-science-data-reduction-techniques-using-python-3de757a20a3b?source=collection_archive---------8-----------------------#2021-10-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="98f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">欢迎来到数据科学博客系列。</strong>请点击这里查看我之前的数据科学博客系列<a class="ae jd" href="https://manthan-bhikadiya.medium.com/" rel="noopener"> <strong class="ih hj"> <em class="je">的博客。</em> </strong> </a></p><blockquote class="jf"><p id="7710" class="jg jh hi bd ji jj jk jl jm jn jo jc dx translated">成功不是最终的，失败不是致命的</p><p id="81d1" class="jg jh hi bd ji jj jk jl jm jn jo jc dx translated">重要的是继续下去的勇气。</p><p id="1b0c" class="jg jh hi bd ji jj jk jl jm jn jo jc dx translated">~温斯顿·丘吉尔</p></blockquote><blockquote class="jp jq jr"><p id="c7b6" class="if ig je ih b ii js ik il im jt io ip ju jv is it jw jx iw ix jy jz ja jb jc hb bi translated"><strong class="ih hj">数据还原:</strong></p></blockquote><p id="9482" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为数据挖掘是一种用于处理大量数据的技术。在处理大量数据时，这种情况下的分析变得更加困难。为了消除这种情况，我们使用数据简化技术。它旨在提高存储效率，降低数据存储和分析成本。</p><blockquote class="jp jq jr"><p id="4c49" class="if ig je ih b ii ij ik il im in io ip ju ir is it jw iv iw ix jy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">降维:</em> </strong></p></blockquote><p id="3677" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这通过编码机制减小了数据的大小。它可以是有损的，也可以是无损的。如果从压缩数据重建后，原始数据可以恢复，这种减少被称为无损减少，否则它被称为有损减少。两种有效的降维方法是:小波变换和PCA(主成分分析)。</p><blockquote class="jp jq jr"><p id="5b60" class="if ig je ih b ii ij ik il im in io ip ju ir is it jw iv iw ix jy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">主成分分析:</em> </strong></p></blockquote><p id="1953" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">主成分分析(PCA)是一种统计程序，它使用<a class="ae jd" href="https://en.wikipedia.org/wiki/Orthogonal_transformation" rel="noopener ugc nofollow" target="_blank">正交变换</a>将一组可能相关变量的观察值转换为一组被称为主成分的<a class="ae jd" href="https://en.wikipedia.org/wiki/Correlation_and_dependence" rel="noopener ugc nofollow" target="_blank">线性不相关</a>变量的值。不同主成分的数量等于原始变量的较小数量或观察值的数量减一。这种转换的定义方式是，第一个主成分具有最大可能的<a class="ae jd" href="https://en.wikipedia.org/wiki/Variance" rel="noopener ugc nofollow" target="_blank">方差</a>(即，尽可能多地考虑数据中的可变性)，并且每个后续成分在与前面成分<a class="ae jd" href="https://en.wikipedia.org/wiki/Orthogonal" rel="noopener ugc nofollow" target="_blank">正交</a>的约束下依次具有最大可能的方差。得到的矢量是不相关的<a class="ae jd" href="https://en.wikipedia.org/wiki/Orthogonal_basis_set" rel="noopener ugc nofollow" target="_blank">正交基集</a>。</p><p id="f066" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">PCA对原始变量的相对比例很敏感。</p><h2 id="6d6d" class="ka kb hi bd kc kd ke kf kg kh ki kj kk iq kl km kn iu ko kp kq iy kr ks kt ku bi translated"><strong class="ak">关于数据集:</strong></h2><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es kv"><img src="../Images/1aec9626b3d9983983e7fc035fa3cb68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ja98P_6VzRC2H-LbWXFXVg.png"/></div></div></figure><blockquote class="jp jq jr"><p id="7f46" class="if ig je ih b ii ij ik il im in io ip ju ir is it jw iv iw ix jy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">主成分分析:</em> </strong></p></blockquote><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lh"><img src="../Images/26e0f501af49884074c3b9fc7fd4a1de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b8jxN5_E7HPTHamT0Ti6GA.png"/></div></div></figure><blockquote class="jp jq jr"><p id="4c7d" class="if ig je ih b ii ij ik il im in io ip ju ir is it jw iv iw ix jy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">组件投影(2D): </em> </strong></p></blockquote><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es li"><img src="../Images/b71b94a5f80336ab7c2b7f1da6b20aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eZPJBAq48KpAPSlOKopawQ.png"/></div></div></figure><p id="849a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">解释方差告诉你有多少信息(方差)可以归因于每个主成分。这一点很重要，因为当你可以将4维空间转换成2维空间时，你会丢失一些方差(信息)。通过使用属性explained_variance_ratio_，可以看到第一个主成分包含72.77%的方差，第二个主成分包含23.03%的方差。这两个部分总共包含95.80%的信息。</p><blockquote class="jp jq jr"><p id="25e2" class="if ig je ih b ii ij ik il im in io ip ju ir is it jw iv iw ix jy iz ja jb jc hb bi translated"><strong class="ih hj"><em class="hi">(3D)组件投影:</em> </strong></p></blockquote><p id="b3e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">原始数据有4列(萼片长度、萼片宽度、花瓣长度和花瓣宽度)。在这一部分中，代码将4维的原始数据投影到3维。新组件只是变化的三个主要方面。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lj"><img src="../Images/c89b60f0ce4697f6c6693a836c5afc89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8w6aakiZ7qD-rX-n.png"/></div></div></figure><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es lk"><img src="../Images/76bbc7d976b3325006ff485e9b35dfef.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/0*JioGKMdCCZB6qHWF.png"/></div></figure><blockquote class="jp jq jr"><p id="4f85" class="if ig je ih b ii ij ik il im in io ip ju ir is it jw iv iw ix jy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">方差阈值:</em> </strong></p></blockquote><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ll"><img src="../Images/597abdd138593c9c1158707ca0fb9200.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Q35w0TSheNe_26g5YXy1Q.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx"><a class="ae jd" href="https://chrisalbon.com/code/machine_learning/feature_selection/variance_thresholding_for_feature_selection/" rel="noopener ugc nofollow" target="_blank">https://chrisalbon.com/code/machine_learning/feature_selection</a></figcaption></figure><p id="dbda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">方差阈值<em class="je"> </em>是特征选择的简单基线方法。它会移除方差未达到某个阈值的所有要素。默认情况下，它会移除所有零方差特征。我们的数据集没有零方差特性，因此我们的数据在这里不受影响。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lq"><img src="../Images/7c50a85173eefed53ee820572cc232d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pAX-lkk9FJwE54koJ1puWA.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx"><a class="ae jd" href="https://chrisalbon.com/code/machine_learning/feature_selection/variance_thresholding_for_feature_selection/" rel="noopener ugc nofollow" target="_blank">https://chrisalbon.com/code/machine_learning/feature_selection</a></figcaption></figure><blockquote class="jp jq jr"><p id="2b83" class="if ig je ih b ii ij ik il im in io ip ju ir is it jw iv iw ix jy iz ja jb jc hb bi translated"><strong class="ih hj"><em class="hi">t-SNE:</em>T13】</strong></p></blockquote><p id="0643" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">t-分布式随机邻居嵌入(t-SNE)是一种<a class="ae jd" href="https://blogs.sas.com/content/subconsciousmusings/2017/04/12/machine-learning-algorithm-use/" rel="noopener ugc nofollow" target="_blank">无监督的非线性技术</a>，主要用于数据探索和高维数据可视化。更简单地说，t-SNE给你一种感觉或直觉，告诉你数据是如何在高维空间中排列的。它是由劳伦斯·范德·马滕斯和杰弗里·辛顿在2008年开发的。</p><p id="0287" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">更多关于<a class="ae jd" href="https://distill.pub/2016/misread-tsne/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> t-SNE… </strong> </a></p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es lr"><img src="../Images/d1777f2c986d6386f39111bd7d5175f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*KlJqzXW9ctnNDFX1K-X5jw.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx"><a class="ae jd" href="https://towardsdatascience.com/an-introduction-to-t-sne-with-python-example-5a3a293108d1" rel="noopener" target="_blank">https://towardsdatascience.com/an-introduction-to-t-sne-with-python-example-5a3a293108d1</a></figcaption></figure><blockquote class="jp jq jr"><p id="a848" class="if ig je ih b ii ij ik il im in io ip ju ir is it jw iv iw ix jy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">代号:</em> </strong></p></blockquote><div class="ls lt ez fb lu lv"><a href="https://github.com/manthan89-py/Data-Science" rel="noopener  ugc nofollow" target="_blank"><div class="lw ab dw"><div class="lx ab ly cl cj lz"><h2 class="bd hj fi z dy ma ea eb mb ed ef hh bi translated">GitHub-man than 89-py/Data-Science:这个存储库包含概念和项目相关的数据…</h2><div class="mc l"><h3 class="bd b fi z dy ma ea eb mb ed ef dx translated">这个存储库包含数据概念以及媒体博客。这个库是学院工作的一部分，每个文件夹…</h3></div><div class="md l"><p class="bd b fp z dy ma ea eb mb ed ef dx translated">github.com</p></div></div><div class="me l"><div class="mf l mg mh mi me mj lf lv"/></div></div></a></div><blockquote class="jp jq jr"><p id="d6cc" class="if ig je ih b ii ij ik il im in io ip ju ir is it jw iv iw ix jy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">结论:</em> </strong></p></blockquote><p id="598f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望你现在已经了解了数据简化技术，如PCA，VarianceThreshold和t-SNE。</p><p id="f89f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">更多关于<a class="ae jd" href="https://www.geeksforgeeks.org/data-reduction-in-data-mining/" rel="noopener ugc nofollow" target="_blank">数据缩减。</a></p><h2 id="73cf" class="ka kb hi bd kc kd ke kf kg kh ki kj kk iq kl km kn iu ko kp kq iy kr ks kt ku bi translated">LinkedIn:</h2><div class="ls lt ez fb lu lv"><a href="https://in.linkedin.com/in/manthanbhikadiya" rel="noopener  ugc nofollow" target="_blank"><div class="lw ab dw"><div class="lx ab ly cl cj lz"><h2 class="bd hj fi z dy ma ea eb mb ed ef hh bi translated">印度古吉拉特邦苏拉特曼丹·比卡第亚-查罗特科技大学|…</h2><div class="mc l"><h3 class="bd b fi z dy ma ea eb mb ed ef dx translated">查看Manthan Bhikadiya在世界上最大的职业社区LinkedIn上的个人资料。Manthan有3份工作列在…</h3></div><div class="md l"><p class="bd b fp z dy ma ea eb mb ed ef dx translated">in.linkedin.com</p></div></div><div class="me l"><div class="mk l mg mh mi me mj lf lv"/></div></div></a></div><h2 id="723e" class="ka kb hi bd kc kd ke kf kg kh ki kj kk iq kl km kn iu ko kp kq iy kr ks kt ku bi translated">Github:</h2><div class="ls lt ez fb lu lv"><a href="https://github.com/manthan89-py" rel="noopener  ugc nofollow" target="_blank"><div class="lw ab dw"><div class="lx ab ly cl cj lz"><h2 class="bd hj fi z dy ma ea eb mb ed ef hh bi translated">manthan89-py -概述</h2><div class="mc l"><h3 class="bd b fi z dy ma ea eb mb ed ef dx translated">对AI、深度学习、机器学习、计算机视觉、区块链、Flutter感兴趣😇。做一些竞争性的…</h3></div><div class="md l"><p class="bd b fp z dy ma ea eb mb ed ef dx translated">github.com</p></div></div><div class="me l"><div class="ml l mg mh mi me mj lf lv"/></div></div></a></div><p id="33ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">感谢阅读！如果你喜欢这篇文章，请点击</strong>👏<strong class="ih hj">尽可能多的按按钮。这将意味着很多，并鼓励我继续分享我的知识。如果你喜欢我的内容，请在medium上关注我，我会尽可能多地发布博客。</strong></p></div></div>    
</body>
</html>