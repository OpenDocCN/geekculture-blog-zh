<html>
<head>
<title>Learning to predict tweet sentiment using MultinomialNB</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习使用多项式预测推文情绪</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/learning-to-predict-tweet-sentiment-using-multinomialnb-aa150c5fd6b2?source=collection_archive---------16-----------------------#2021-08-04">https://medium.com/geekculture/learning-to-predict-tweet-sentiment-using-multinomialnb-aa150c5fd6b2?source=collection_archive---------16-----------------------#2021-08-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="8d22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一段时间以来，来自网络聊天的情感分析一直是每个品牌的首要任务之一。市场上有很多工具可以帮你做到这一点。以至于“全球情绪分析”市场的行业规模预计到2023年将达到60亿美元左右。</p><p id="28cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文试图揭示潜在的问题，从机器学习的角度来看它到底意味着什么，最后是一个使用#Python为我们执行这一任务的工作模型。</p><p id="0821" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了让事情集中在我们问题的<strong class="ih hj">#机器学习</strong>部分，我将不进入文本预处理和文本清理等细节。使用#NLP进行文本提取和操作是一个很大的主题，我计划在以后的另一篇文章中讨论它。在这里，我正在使用超级棒的scikit-learn库中的一些棒的工具。我使用的是由<a class="je jf ge" href="https://medium.com/u/c7c686fcd4b?source=post_page-----aa150c5fd6b2--------------------------------" rel="noopener" target="_blank">团队AV </a>提供的数据集，可以在#Kaggle上找到，数据集的链接在下面。</p><div class="jg jh ez fb ji jj"><a href="https://www.kaggle.com/dv1453/twitter-sentiment-analysis-analytics-vidya" rel="noopener  ugc nofollow" target="_blank"><div class="jk ab dw"><div class="jl ab jm cl cj jn"><h2 class="bd hj fi z dy jo ea eb jp ed ef hh bi translated">Twitter情绪分析-分析Vidya</h2><div class="jq l"><h3 class="bd b fi z dy jo ea eb jp ed ef dx translated">通过分析实践问题</h3></div><div class="jr l"><p class="bd b fp z dy jo ea eb jp ed ef dx translated">www.kaggle.com</p></div></div><div class="js l"><div class="jt l ju jv jw js jx jy jj"/></div></div></a></div><p id="2998" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好的，让我们从设置编码环境和加载数据集开始。</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="ea6b" class="ki kj hi ke b fi kk kl l km kn">import pandas as pd<br/>import warnings<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.naive_bayes import MultinomialNB<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.pipeline import make_pipeline<br/>from sklearn import metrics</span><span id="9b4e" class="ki kj hi ke b fi ko kl l km kn">warnings.filterwarnings("ignore")<br/><br/>df = pd.read_csv("/kaggle/input/twitter-sentiment-analysis-analytics-vidya/train_E6oV3lV.csv")<br/>dfr = df[['tweet','label']]<br/>print(len(df))<br/>print(df)</span></pre><p id="efb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们看到数据集有<strong class="ih hj"> 31962 </strong>行，包含tweet及其各自的标签和id，这是我们的训练数据集，我们将使用它来训练和测试我们的模型，我们将使用它来预测同一问题数据集的一个单独表中提供的数据的标签。</p><figure class="jz ka kb kc fd kq er es paragraph-image"><div class="er es kp"><img src="../Images/7e3d9582b12c484e90b2e5fd4c3898a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*KbcMnTe1R9-Nd_ez30YBKQ.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx">Checking the content and shape of dataset</figcaption></figure><p id="a2a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">快速查看数据集的摘要，我们发现没有丢失值，我们可以使用整个数据集进行模型训练。我正在使用内置的强大功能，描述如下</p><p id="cb2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> train_test_split() : </strong>我们需要从我们的数据中学习，该函数根据指定的分割标准将数据集分割为训练集和测试集，我们从分数设置0.2开始，这意味着我们将使用80 %的数据集来训练我们的模型，20 %用于测试和评估我们的模型。</p><p id="a45e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">tfidf vectorizer():</strong>Tf-idf是用于机器学习目的的处理文本数据的最有效的方法之一，它代表<strong class="ih hj">术语频率—逆文档频率</strong>并由下面的公式表示，使用该函数我们将所有单词转换成Tf-IDF分数。</p><p id="a849" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> TF — IDF = TF(词频)* IDF(逆文档频)</strong></p><p id="2ef7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kw">术语频率——术语在给定文档中出现的次数。</em></p><p id="3339" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kw"> IDF —找到给定术语的文档数。</em></p><p id="b221" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> make_pipeline() : </strong>此函数用于定义我们的数据管道，我们可以应用一系列转换，然后是最终估计量，在我们的情况下，它是一个多项式。</p><p id="c8c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> MultinomialNB() : </strong>每个有抱负的数据科学家的工具包中都必须有一个，这个版本的著名的Naive Baye算法考虑了术语频率，并计算了给定输入文本的每个标签的概率。</p><p id="2703" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们知道了这些函数的用途，让我们开始用训练数据训练我们的模型，下面的代码块将我们的数据集分成训练和测试数据。我们使用TfidVectorizer()定义了一个50K单词的词汇表，我们的模型将使用它进行学习。</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="47eb" class="ki kj hi ke b fi kk kl l km kn"># split the data such that we have 80% of the data as train size</span><span id="e9a4" class="ki kj hi ke b fi ko kl l km kn">train,test = train_test_split(dfr, test_size=0.2, shuffle=False)</span><span id="a74f" class="ki kj hi ke b fi ko kl l km kn">#Define our model with 50 k Vocabulary and training our model</span><span id="2f3b" class="ki kj hi ke b fi ko kl l km kn">model = make_pipeline(TfidfVectorizer(max_features = 50000,smooth_idf=True), MultinomialNB())</span><span id="542a" class="ki kj hi ke b fi ko kl l km kn">model.fit(train.tweet, train.label)<br/>labels = model.predict(test.tweet)<br/>print(labels)</span><span id="a594" class="ki kj hi ke b fi ko kl l km kn">#Check the accuracy of our MultinomialNB classifier<br/>score = metrics.accuracy_score(test.label,labels,normalize=True)</span><span id="b265" class="ki kj hi ke b fi ko kl l km kn">print("accuracy: %0.3f" % score)</span><span id="af71" class="ki kj hi ke b fi ko kl l km kn">print(metrics.classification_report(test.label,labels,target_names=['label 0','label 1']))</span><span id="de37" class="ki kj hi ke b fi ko kl l km kn">print(metrics.confusion_matrix(test.label, labels))</span></pre><p id="8acb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用问题陈述本身中给出的指标精度、召回率、f1分数和支持来评估我们的模型。我们还打印了指标混淆矩阵。</p><figure class="jz ka kb kc fd kq er es paragraph-image"><div class="er es kx"><img src="../Images/c181dabe45152ba6415a1860e52f63fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*AERddANYg5o3ho4ahTLrtQ.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx">model evaluation and quality scores</figcaption></figure><p id="7434" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对，所以我们的模型的准确度是0.939，这意味着它的预测准确率是93.9 %。为了理解这些术语的含义，我们需要理解度量混乱矩阵。这方面有很多学术资料，我在下面引用一个。</p><figure class="jz ka kb kc fd kq er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es ky"><img src="../Images/c8850f988e826994489dd9469857f7e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sExGpBFG01GLfzWQSH_ebg.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx"><a class="ae jd" href="https://www.researchgate.net/figure/Confusion-matrix-and-evaluation-metrics_fig3_334840641" rel="noopener ugc nofollow" target="_blank">Source : Rune Hylsberg Jacobsen</a></figcaption></figure><p id="b40e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好了，现在我们知道了这些术语的含义，让我们看看模型返回的输出。</p><figure class="jz ka kb kc fd kq er es paragraph-image"><div class="er es ld"><img src="../Images/514801a64639c0b96616b74ed431b96b.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*Xtka34mg2emtrB1UQpLQ-A.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx">Metrics confusion matrix visualised from our trained model</figcaption></figure><p id="451c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">改进我们的模型:</strong>让我们通过微调用于训练的参数来尝试改进我们的模型，例如，让我们将词汇的大小从50k更改为10 k，重新训练模型会给出以下输出。</p><figure class="jz ka kb kc fd kq er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es le"><img src="../Images/3d6e9c6cb6c3341a889f4834f29a00c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uAzTThh8jalATaKBXgWYtw.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Reducing the size of vocabulary to 10 k</figcaption></figure><figure class="jz ka kb kc fd kq er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lf"><img src="../Images/9ad61cc09924f18da7fbc179b2df1dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NtVDDcGP1CJALu1-Of_dTg.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Results with vocabulary 10 K and increase train data size to 90%</figcaption></figure><p id="ca29" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，几个迭代下来，我们有了这个总体性能更好的新模型，我们可以通过增加训练数据大小和调整其他参数来保持<strong class="ih hj">微调</strong>模型，训练中仅增加10%就导致f 1得分和召回的明显更好的性能。</p><p id="8e9e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们进入问题陈述的最后一部分，我们必须预测在文件“test_tweets_anuFYb8.csv”中找到的tweets的类别，并以规定的格式导出一个csv文件。</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="c023" class="ki kj hi ke b fi kk kl l km kn">#import the csv file with tweets to be labelled<br/>test_df = pd.read_csv("/kaggle/input/twitter-sentiment-analysis-analytics-vidya/test_tweets_anuFYb8.csv")<br/>print(len(test_df))<br/>test2=test_df[['tweet',"id"]]<br/>test2["label"] = ""</span><span id="510d" class="ki kj hi ke b fi ko kl l km kn">model.fit(train.tweet, train.label)<br/>labels = model.predict(test2.tweet)</span><span id="abef" class="ki kj hi ke b fi ko kl l km kn">test2["label"] = labels<br/>test2 = test2[['id',"label"]]<br/>print(test2)<br/>test2.to_csv('test_predictions.csv', header=True)</span></pre><figure class="jz ka kb kc fd kq er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lg"><img src="../Images/4f0a265191ea78b3f3e76de908a3a941.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UDqw7cUoAOg432qFz6p8lg.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Final output with predicted labels</figcaption></figure><p id="65af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">笔记本上传到Kaggle上，也可以从下面的链接下载。</p><div class="jg jh ez fb ji jj"><a href="https://www.kaggle.com/vijayendrad/sentiment-prediction-using-multonomialnb" rel="noopener  ugc nofollow" target="_blank"><div class="jk ab dw"><div class="jl ab jm cl cj jn"><h2 class="bd hj fi z dy jo ea eb jp ed ef hh bi translated">使用多术语的情感预测</h2><div class="jq l"><h3 class="bd b fi z dy jo ea eb jp ed ef dx translated">使用Kaggle笔记本探索和运行机器学习代码|使用来自Twitter情绪分析的数据-分析…</h3></div><div class="jr l"><p class="bd b fp z dy jo ea eb jp ed ef dx translated">www.kaggle.com</p></div></div><div class="js l"><div class="lh l ju jv jw js jx jy jj"/></div></div></a></div></div></div>    
</body>
</html>