<html>
<head>
<title>Pick the right memory size for your AWS Lambda functions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为AWS Lambda函数选择合适的内存大小</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/pick-the-right-memory-size-for-your-aws-lambda-functions-682394aa4b21?source=collection_archive---------2-----------------------#2021-06-26">https://medium.com/geekculture/pick-the-right-memory-size-for-your-aws-lambda-functions-682394aa4b21?source=collection_archive---------2-----------------------#2021-06-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="9b45" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">做好这件事可以提高速度，降低成本。但这并不像看起来那么简单。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/0195a186e941cb0ad6916d27d197fe05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D64MhzYpy8X6lf4cLO7JIQ.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@julianhochgesang" rel="noopener ugc nofollow" target="_blank">Julian Hochgesang</a> on <a class="ae jn" href="https://unsplash.com/photos/3-y9vq8uoxk" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="ffef" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">AWS唯一的性能参数是内存大小。但是对于你的真实世界的函数来说，什么是理想的大小呢？为了说明其重要性，我们将回顾一下作为<a class="ae jn" href="https://shortr.link/BcTD6" rel="noopener ugc nofollow" target="_blank"> ShortrLink </a>一部分的无服务器API函数，并比较内存大小对性能和成本的影响。</p><h1 id="1b22" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">AWS结合了内存大小和CPU能力</h1><p id="faa8" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">Lambda只允许我们直接配置内存大小。但是，这一指标与您获得的CPU能力直接相关。简而言之，在达到大约1.7 GB的内存之前，您获得的功率是线性增长的。此时，Lambda提供了1个完整的vCPU内核。此后，每增加一个MB仍然意味着更多的功率，但需要更多的CPU内核。理论上只有多处理功能受益于1.7GB以上的内存！</p><p id="9659" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这听起来很简单，但是在现实世界中这意味着什么呢？大多数Lambda函数都是<a class="ae jn" href="https://dashbird.io/blog/lower-aws-lambda-bill-increasing-memory/" rel="noopener ugc nofollow" target="_blank">，不仅仅是计算斐波那契数列</a>，而是与其他服务相连，并受到这些外部API响应时间的限制。您是否曾经为GET API部署过一个功能，该功能除了从数据库中获取一个项目并执行一些基本的数据转换之外什么也不做？如果是这样，你可能想知道你是否真的<em class="lh">需要</em>更多的CPU能力。</p><h1 id="2351" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">实验设计:一个基本的无服务器GET API</h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es li"><img src="../Images/f886fdb0527f233db3bd691209155c53.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*QWR_-EEZWdZgjG2qjKls2Q.jpeg"/></div></figure><p id="c124" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">为了测试收益递减点，我使用了一个真实的函数:</p><ol class=""><li id="98bb" class="lj lk hi jq b jr js ju jv jx ll kb lm kf ln kj lo lp lq lr bi translated">从API网关接收HTTP事件</li><li id="e2c7" class="lj lk hi jq b jr ls ju lt jx lu kb lv kf lw kj lo lp lq lr bi translated">从DynamoDb获取一项(使用Pynamodb)</li><li id="455e" class="lj lk hi jq b jr ls ju lt jx lu kb lv kf lw kj lo lp lq lr bi translated">将事件发布到EventBridge(使用Boto3)</li><li id="1de0" class="lj lk hi jq b jr ls ju lt jx lu kb lv kf lw kj lo lp lq lr bi translated">返回HTTP响应</li></ol><p id="3805" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，我们依赖于Lambda函数同一区域内的另外两个AWS服务。我们不(直接)执行任何计算，但是在运行时有多个转换步骤。我测试的Lambda配置是128MB、256MB、512MB、768MB、1024MB、1280MB、1536MB、1792MB和2048MB。</p><p id="f5bb" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">用Python编写的Lambda函数在我的本地机器上使用API网关HTTP端点被调用了500次。所有请求都是按顺序发出的，因此每次执行都将重用相同的运行时。这样，我们仍然通过限制我们必须排除在分析之外的冷启动次数来测试纯执行持续时间。</p><p id="8950" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">当然，在现实应用中，冷启动是一个相关因素。特别是对于一个较小的项目，你不能期望每天每5分钟至少调用一次API端点。因此，第二轮执行会调用每个配置20次，每次都强制冷启动。</p><p id="4e4b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">信息的主要来源是AWS Cloudwatch日志。此外，我还测量了从发出GET请求到收到应答所花费的时间，从而从最终用户的角度测量了API的响应性。需要注意的是，所有资源都在AWS的eu-west-1区域，而发出API请求的机器位于东南亚。因此，在查看数字时，您必须记住一般的网络延迟。</p><h1 id="fd46" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">结果:768MB针对速度进行了优化，512MB针对成本，1024+MB针对多次冷启动</h1><p id="3627" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">实验设计结束后，让我们来看看数字:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/49f4a522ad67cb6e17f320e420696808.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lekywCkSmRwHZE3DDfmywQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Average duration per AWS Lambda execution in ms</figcaption></figure><p id="b208" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在较低的区域，增加内存大小(从而增加CPU)的影响是极端的。虽然128MB内存的平均执行时间是令人自豪的226毫秒，但256MB将这一时间降低了60%，降至91毫秒。不过512MB关口周围也有明显的肘子。将内存从512MB增加一倍到1GB只会将我们的性能提高30 %到27毫秒。事实上，在达到768MB后，p50和p90分位数的执行时间保持不变。</p><p id="25f6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这也暗示了我们的lambda函数的成本:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/9d5caf6f99a19fec5d5c15b6601ac16a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NvAvITAkYxCjcekXRPH6UA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Price per 1 Mio AWS Lambda executions in USD (incl. request costs)</figcaption></figure><p id="67d4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">虽然768MB为我们提供了最佳的性能，但我们可以看到512MB的最低成本。在这里，您必须决定是否愿意支付更多费用来获得更快的响应时间。与此同时，我们还观察到，资源调配过少会推高成本。</p><h2 id="bf69" class="ly kl hi bd km lz ma mb kq mc md me ku jx mf mg kw kb mh mi ky kf mj mk la ml bi translated">冷启动问题</h2><p id="9645" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">到目前为止，我们只考虑了最好的情况:总是热函数，所有的模型都预装了Lambda来使用。但是可怕的冷启动怎么办？在这里，事情看起来有点不同:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/c462bd262fde6a943f690a7a04017fb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ko6hRfSpYDfGZv_B11khvQ.png"/></div></div></figure><p id="c779" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">与我们的预热功能不同，冷启动持续时间会随着内存/CPU内核的增加而持续减少。但即使在这里，我们也看到收益递减。从1GB升级到2GB只会带来40%的速度提升。因此，添加更多资源并不总是经济高效的:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/c167eae20823bf17f8cdb6a86d324868.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fweHsl-0QC_UIcHVyckmdw.png"/></div></div></figure><p id="4581" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">同样，我们观察到一个局部最优值，但这次是1024MB，是以前的两倍。因此，分析您的特定用例并估计执行频率对于您的设计过程变得很有必要。</p><h2 id="ba0e" class="ly kl hi bd km lz ma mb kq mc md me ku jx mf mg kw kb mh mi ky kf mj mk la ml bi translated">别忘了现实世界的体验。</h2><p id="9089" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">最后，这种增长对我们的最终用户意味着什么？假设服务器和客户端之间的距离为9500公里，可以想象，并不算远:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/ab15a62c4aecb8c662619d543d7d44b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q2AkAGDHTkHf6hqtO81FMA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Measured response times in ms</figcaption></figure><p id="4d07" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在我们的图表中，仅观察Lambda持续时间时看似巨大的差异变得几乎不可见。从128 MB升级到256MB仍然可以减少大约15%的延迟，从512 MB升级到768MB只会减少6%的延迟。<br/>当然，这是一个极端的例子。然而，它表明，虽然我们很容易沉迷于优化我们核心功能的性能，但外部因素对我们最终用户的体验也有同样甚至更大的影响。</p><h1 id="3911" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">结论:了解您的用例</h1><p id="8226" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">最后，我们有三个选择:如果你知道你的函数几乎不会变冷，并且你纯粹地优化执行持续时间:768MB是我们的赢家。然而，如果成本是您最关心的问题，将内存大小减少到512 MB将会降低7.4%的成本，但也会增加36%的执行时间。)</p><p id="5237" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对于很少使用的功能，越多越好。当然，您可以通过选择1GB来达到最佳成本，但即使是3GB，平均每小时执行1次，您的每月成本也将低于1ct/月。因此，建议至少选择3GB，甚至更多(当然是在测试进一步扩展之后)。</p><p id="7c4b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对第三方服务延迟的依赖意味着您的功能的数字将会不同。每当您的函数等待另一个服务的响应时，它就处于空闲状态(除非是线程化的。)最后，你还得自己测试一下你个人的甜蜜点是什么样的。</p></div></div>    
</body>
</html>