<html>
<head>
<title>Bare Metal Kubernetes with MetalLB, HAProxy, Longhorn, and Prometheus</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">裸机Kubernetes有MetalLB、HAProxy、Longhorn和Prometheus</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/bare-metal-kubernetes-with-metallb-haproxy-longhorn-and-prometheus-370ccfffeba9?source=collection_archive---------0-----------------------#2021-10-18">https://medium.com/geekculture/bare-metal-kubernetes-with-metallb-haproxy-longhorn-and-prometheus-370ccfffeba9?source=collection_archive---------0-----------------------#2021-10-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/06b07cc25556e108fa2b0e9dde874aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JHGi6ZSE7XHbsSFxixmzBw.png"/></div></div></figure><div class=""/><p id="5f0e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">几年前，我写了一篇关于用Rook/Ceph创建Kubernetes集群的博客文章。我当时的主要目标是看看我们是否可以使用Kubernetes作为边缘软件栈的集群解决方案。虽然k3s工作得很好，但其他一切仍然有一些粗糙的边缘。</p><p id="f8d6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，许多依赖项仍然缺乏ARM支持，并且<a class="ae jo" href="https://github.com/metallb/metallb" rel="noopener ugc nofollow" target="_blank"> MetalLB </a>仍然处于早期阶段。HAProxy不可用于Kubernetes，因此唯一的选择是使用Traefik和<a class="ae jo" href="https://k3s.io" rel="noopener ugc nofollow" target="_blank"> k3s </a>(这并不意味着Traefik不是一个好的选择，只是我们广泛使用HAProxy，并且知道它与我们的堆栈配合得很好)。</p><p id="0440" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">不过，从那以后，事情发展得很快！安装MetalLB非常简单，HAProxy现在也支持Kubernetes 。此外，牧场主的人们已经发展出长角牛，这是鲁克/Ceph的绝佳替代品。</p><p id="5360" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以，让我们把一切都旋转一下，看看它是如何工作的。我们将在基于ARM的7节点集群上部署k3s以及MetalLB、HAProxy、Prometheus和一个测试echo服务器。</p><h1 id="d413" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">准备集群节点</h1><p id="cf68" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我们将创建一个7节点集群，其中3个节点作为控制器，4个节点作为工作节点。在每个节点上，我们将安装Ubuntu Server 20.04 LTS，为了帮助我们安装其他的东西，我们将使用Ansible。</p><p id="b6e4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们从以下内容开始:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="54d0" class="lb jq ht kx b fi lc ld l le lf">+----------+--------------+------------+<br/>| Hostname |      IP      |    Role    |<br/>+----------+--------------+------------+<br/>| node1    | 10.211.55.12 | controller |<br/>| node2    | 10.211.55.13 | controller |<br/>| node3    | 10.211.55.14 | controller |<br/>| node4    | 10.211.55.15 | worker     |<br/>| node5    | 10.211.55.16 | worker     |<br/>| node6    | 10.211.55.17 | worker     |<br/>| node7    | 10.211.55.18 | worker     |<br/>+----------+--------------+------------+</span></pre><p id="645c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了方便起见，在每个节点上创建一个用户<code class="du lg lh li kx b">admin</code>:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="0ab8" class="lb jq ht kx b fi lc ld l le lf">$ sudo groupadd -g 1000 admin<br/>$ useradd -u 1000 -d /home/admin -s /bin/bash -m -g admin admin<br/>$ echo my-secret-pw | sudo chpasswd </span></pre><p id="2464" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于密码，我使用了<code class="du lg lh li kx b">my-secret-pw</code>，但你应该使用任何适合你的。为了让你的生活简单，请确保每个主机都是一样的。浏览完本指南后，如果您愿意，您可以更改或完全禁用它。</p><h1 id="acc5" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">节点1集群管理</h1><p id="08e0" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我们将使用<code class="du lg lh li kx b">node1</code>来引导我们的集群。以用户<code class="du lg lh li kx b">admin</code>的身份登录<code class="du lg lh li kx b">node1</code>，在上面安装Ansible:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="b06b" class="lb jq ht kx b fi lc ld l le lf">$ sudo apt-add-repository ppa:ansible/ansible<br/>$ sudo apt-get update<br/>$ sudo apt-get install ansible</span></pre><p id="9570" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，如果还不存在密钥对，在<code class="du lg lh li kx b">node1</code>上为用户<code class="du lg lh li kx b">admin</code>创建一个密钥对，您可以用它来发送到所有其他节点进行登录:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="678a" class="lb jq ht kx b fi lc ld l le lf">$ ssh-keygen</span></pre><p id="da0f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在使用<code class="du lg lh li kx b">ssh-copy-id</code>将用户<code class="du lg lh li kx b">admin</code>的密钥复制到所有其他节点:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="dbfd" class="lb jq ht kx b fi lc ld l le lf">$ ssh-copy-id admin@node2<br/>$ ssh-copy-id admin@node3<br/>$ ssh-copy-id admin@node4<br/>$ ssh-copy-id admin@node5<br/>$ ssh-copy-id admin@node6<br/>$ ssh-copy-id admin@node7</span></pre><p id="1b37" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在创建一个名为<code class="du lg lh li kx b">hosts</code>的文件，内容如下:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="75c4" class="lb jq ht kx b fi lc ld l le lf">[control]<br/>node1  ansible_connection=local<br/>node2<br/>node3</span><span id="e87b" class="lb jq ht kx b fi lj ld l le lf">[workers]<br/>node4<br/>node5<br/>node6<br/>node7</span><span id="eaa5" class="lb jq ht kx b fi lj ld l le lf">[nodes:children]<br/>control<br/>workers</span></pre><p id="bc84" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们测试一下所有的东西:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="97e0" class="lb jq ht kx b fi lc ld l le lf">$ ansible -i hosts nodes -m ping</span></pre><p id="001e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在<code class="du lg lh li kx b">node1</code>上的Ansible应该能够没有问题地ping所有其他节点。通过Ansible的工作，我们现在可以完成k3s安装节点的初始准备工作。</p><p id="df55" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先删除一些我们不需要的软件，以节省一些资源:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="9147" class="lb jq ht kx b fi lc ld l le lf">$ ansible -i hosts nodes \<br/>    -b -K -m shell \<br/>    -a "snap remove lxd &amp;&amp; snap remove core18 &amp;&amp; snap remove snapd"</span></pre><p id="b00b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了更好地测量，请将每个节点上的软件更新到最新版本:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="2d68" class="lb jq ht kx b fi lc ld l le lf">$ ansible -i hosts nodes \<br/>     -b -K -m apt \<br/>     -a "upgrade=yes update_cache=yes"</span></pre><h1 id="b43d" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">安装k3s</h1><p id="7612" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我们的节点现在可以安装k3s了。在<code class="du lg lh li kx b">node1</code>上安装k3s，如下所示:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="b0d7" class="lb jq ht kx b fi lc ld l le lf">$ curl -sfL <a class="ae jo" href="https://get.k3s.io" rel="noopener ugc nofollow" target="_blank">https://get.k3s.io</a> | K3S_TOKEN=my_super_secret \<br/>     sh -s - server --cluster-init \<br/>                    --disable servicelb \<br/>                    --disable traefik</span></pre><p id="604c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这将安装一个kubernetes控制器，没有k3s提供的<code class="du lg lh li kx b">servicelb</code>和<code class="du lg lh li kx b">traefik</code>。对于负载平衡器，我们将使用MetalLB，对于入口，我们将使用HAProxy而不是Traefik。对于<code class="du lg lh li kx b">K3S_TOKEN</code>，我用了一个不那么秘密的<code class="du lg lh li kx b">my_super_secret</code>。稍后将使用这个令牌将其他节点连接到Kubernetes集群，因此可以根据需要更改这个令牌。</p><p id="5552" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在<code class="du lg lh li kx b">node1</code>运行第一个控制器，我们可以将Kubnernetes配置文件复制到<code class="du lg lh li kx b">admin</code>的主目录，这样我们就不需要使用<code class="du lg lh li kx b">sudo</code>来运行<code class="du lg lh li kx b">kubectl</code>:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="8384" class="lb jq ht kx b fi lc ld l le lf">$ mkdir ~/.kube<br/>$ sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/k3s-config <br/>$ sudo chown $USER: ~/.kube/k3s-config <br/>$ export KUBECONFIG=~/.kube/k3s-config</span></pre><p id="049a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以将<code class="du lg lh li kx b">export KUBECONFIG=~/.kube/k3s-config</code>添加到<code class="du lg lh li kx b">~/.profile</code>中，这样就可以用每个新的shell来设置环境变量。</p><p id="3347" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这样一来，我们可以在<code class="du lg lh li kx b">node2</code>和<code class="du lg lh li kx b">node3</code>上安装剩余的控制器。我们可以使用Ansible:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="8a7f" class="lb jq ht kx b fi lc ld l le lf">$ ansible -i hosts node2,node3 -b -K \<br/>     -m shell \<br/>     -a "curl -sfL <a class="ae jo" href="https://get.k3s.io" rel="noopener ugc nofollow" target="_blank">https://get.k3s.io</a> | K3S_TOKEN=my_super_secret sh -s - server --server <a class="ae jo" href="https://10.211.55.12:6443" rel="noopener ugc nofollow" target="_blank">https://10.211.55.12:6443</a> --disable servicelb --disable traefik"</span></pre><p id="860d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如你所见，我们使用了与之前定义的<code class="du lg lh li kx b">node1</code>相同的<code class="du lg lh li kx b">K3S_TOKEN</code>。对于<code class="du lg lh li kx b">server</code>，我们现在使用一个URL指向<code class="du lg lh li kx b">node1</code>上的控制器。作为。通过<code class="du lg lh li kx b">node1</code>，我们还禁用了<code class="du lg lh li kx b">servicelb</code>和<code class="du lg lh li kx b">traefik</code>。</p><p id="32b3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们现在可以安装工人:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="8999" class="lb jq ht kx b fi lc ld l le lf">$ ansible -i hosts workers -b -K \<br/>    -m shell \<br/>    -a "curl -sfL <a class="ae jo" href="https://get.k3s.io" rel="noopener ugc nofollow" target="_blank">https://get.k3s.io</a> | K3S_URL=<a class="ae jo" href="https://10.211.55.12:6443" rel="noopener ugc nofollow" target="_blank">https://10.211.55.12:6443</a> K3S_TOKEN=my_super_secret sh -"</span></pre><p id="061f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">检查一切是否按预期运行:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="258c" class="lb jq ht kx b fi lc ld l le lf">$ kubectl get nodes -A</span></pre><p id="05b4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你应该看看所有的管理员和工人。从输出中，您将看到控制器有一个角色，但是工人没有。让我们通过给工人a适当的角色来解决这个问题:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="66f3" class="lb jq ht kx b fi lc ld l le lf">$ kubectl label nodes node4 kubernetes.io/role=worker<br/>$ kubectl label nodes node5 kubernetes.io/role=worker<br/>$ kubectl label nodes node6 kubernetes.io/role=worker<br/>$ kubectl label nodes node7 kubernetes.io/role=worker</span></pre><p id="dfa0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了控制我们可以在哪些节点上部署什么，我们还将添加另一个名为<code class="du lg lh li kx b">node-type</code>的标签，我们可以在部署规范中使用它:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="925c" class="lb jq ht kx b fi lc ld l le lf">$ kubectl label nodes node4 node-type=worker<br/>$ kubectl label nodes node5 node-type=worker<br/>$ kubectl label nodes node6 node-type=worker<br/>$ kubectl label nodes node7 node-type=worker</span></pre><p id="eadc" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以检查给予所有节点的所有标签，如下所示:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="8886" class="lb jq ht kx b fi lc ld l le lf">$ kubectl get nodes --show-labels</span></pre><h1 id="1802" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">安装舵</h1><p id="8c9b" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">现在Kubernetes已经在我们所有的节点上运行了，请按照这里的说明进行操作:<a class="ae jo" href="https://helm.sh/docs/intro/install/" rel="noopener ugc nofollow" target="_blank">https://helm.sh/docs/intro/install</a></p><p id="e0ad" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我建议使用脚本安装方法。</p><h1 id="5b0d" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">安装金属1b</h1><p id="72bb" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">现在安装了Helm，我们可以使用Helm安装MetalLB:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="9527" class="lb jq ht kx b fi lc ld l le lf">$ helm repo add metallb <a class="ae jo" href="https://metallb.github.io/metallb" rel="noopener ugc nofollow" target="_blank">https://metallb.github.io/metallb</a></span></pre><p id="770d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">添加了MetalLB repo后，我们可以安装MetalLB，但在此之前，需要创建一个名为<code class="du lg lh li kx b">metallb-values.yaml</code>的配置值文件，其内容如下:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="133a" class="lb jq ht kx b fi lc ld l le lf">configInline:<br/>  address-pools:<br/>   - name: default<br/>     protocol: layer2<br/>     addresses:<br/>     - 10.211.55.240-10.211.55.250</span></pre><p id="36b6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上述配置将指示MetalLB使用IP范围<code class="du lg lh li kx b">10.211.55.240</code>到<code class="du lg lh li kx b">250</code>来服务标记为<code class="du lg lh li kx b">LoadBalancer</code>类型的服务。当然，您应该将其更改为对您的环境有意义的值。</p><p id="d888" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们安装MetalLB:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="925b" class="lb jq ht kx b fi lc ld l le lf">helm install metallb metallb/metallb -f metallb-values.yaml</span></pre><p id="0597" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">太棒了。MetalLB现已安装。我们现在可以安装HAProxy了。</p><h1 id="dca9" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">安装HAProxy</h1><p id="590b" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">和MetalLB一样，我们可以使用Helm来安装HAProxy。首先添加回购:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="6917" class="lb jq ht kx b fi lc ld l le lf">$ helm repo add haproxytech <a class="ae jo" href="https://haproxytech.github.io/helm-charts" rel="noopener ugc nofollow" target="_blank">https://haproxytech.github.io/helm-charts</a></span></pre><p id="c377" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然而，在我们安装HAProxy之前，有一个正在进行的问题(<code class="du lg lh li kx b"><a class="ae jo" href="https://github.com/haproxytech/kubernetes-ingress/issues/222" rel="noopener ugc nofollow" target="_blank">#222</a></code>)当在ARM硬件上安装时，您需要使用以下命令:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="a2d0" class="lb jq ht kx b fi lc ld l le lf">$ helm install haproxy haproxytech/kubernetes-ingress --set defaultBackend.image.repository=gcr.io/google_containers/defaultbackend-arm64</span></pre><p id="ffa9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您使用AMD硬件，您可以使用以下软件:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="5d36" class="lb jq ht kx b fi lc ld l le lf">$ helm install haproxy haproxytech/kubernetes-ingress</span></pre><p id="6cb5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">安装HAProxy后，您可以将服务类型从<code class="du lg lh li kx b">NodePort</code>改为<code class="du lg lh li kx b">LoadBalancer</code>。您可以通过如下方式编辑服务规范来实现这一点:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="474e" class="lb jq ht kx b fi lc ld l le lf">$ kubectl edit service/haproxy-kubernetes-ingress</span></pre><p id="c483" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这将打开HAProxy服务规范。寻找当前设置为<code class="du lg lh li kx b">NodePort</code>的<code class="du lg lh li kx b">type</code>。把这个改成<code class="du lg lh li kx b">LoadBalancer</code>。更改后，保存更改并退出编辑器。</p><h1 id="929b" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">安装长角牛</h1><p id="d527" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我们现在可以安装名为Longhorn的共享存储服务。在我们安装它之前，我们需要确保我们的集群已经安装了所有必要的需求。首先在所有节点上安装<code class="du lg lh li kx b">iscsi</code>:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="7616" class="lb jq ht kx b fi lc ld l le lf">$ ansible -i hosts nodes -b -K \<br/>    -m apt \<br/>    -a "name=open-iscsi state=present"</span></pre><p id="512f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来在所有节点上安装<code class="du lg lh li kx b">nfs-common</code>:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="5da8" class="lb jq ht kx b fi lc ld l le lf">$ ansible -i hosts nodes -b -K \<br/>    -m apt \<br/>    -a "name=nfs-common state=present"</span></pre><p id="af16" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在检查我们的集群是否准备好了:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="fd83" class="lb jq ht kx b fi lc ld l le lf">sudo apt install jq<br/>curl -sSfL <a class="ae jo" href="https://raw.githubusercontent.com/longhorn/longhorn/v1.2.2/scripts/environment_check.sh" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/longhorn/longhorn/v1.2.2/scripts/environment_check.sh</a> | bash</span></pre><p id="c058" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该脚本将检查我们的集群是否满足所有要求。如果出现问题，查看<a class="ae jo" href="https://longhorn.io/docs/1.2.2/deploy/install" rel="noopener ugc nofollow" target="_blank"> Longhorn安装指南</a>了解如何修复。如果您遵循了本指南，那么脚本应该已经成功完成。</p><p id="8e9d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们准备安装Longhorn:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="52fd" class="lb jq ht kx b fi lc ld l le lf">$ helm repo add longhorn <a class="ae jo" href="https://charts.longhorn.io" rel="noopener ugc nofollow" target="_blank">https://charts.longhorn.io</a><br/>$ helm repo update<br/>$ kubectl create namespace longhorn-system<br/>$ helm install longhorn longhorn/longhorn --n longhorn-system</span></pre><p id="4612" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你可以查看<a class="ae jo" href="https://longhorn.io/docs/1.2.2/deploy/install/install-with-helm" rel="noopener ugc nofollow" target="_blank">长角牛头盔安装</a>页面了解更多信息。</p><p id="ecd2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">检查Longhorn是否正常运行:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="7626" class="lb jq ht kx b fi lc ld l le lf">$ kubectl -n longhorn-system get pod</span></pre><p id="bafd" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果Longhorn运行正常，将<code class="du lg lh li kx b">longhorn-frontend</code>的<code class="du lg lh li kx b">type</code>从<code class="du lg lh li kx b">ClusterIP</code>改为<code class="du lg lh li kx b">NodePort</code>:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="0ffd" class="lb jq ht kx b fi lc ld l le lf">$ kubectl edit service longhorn-frontend -n longhorn-system</span></pre><p id="d070" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">检查<code class="du lg lh li kx b">longhorn-system</code>服务，查看longhorn-frontend应用程序分配了什么端口号:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="7f2d" class="lb jq ht kx b fi lc ld l le lf">$ kubectl get service longhorn-frontend -n longhorn-system</span></pre><p id="c3af" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您应该会看到类似这样的内容:</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lk"><img src="../Images/3dd04fabb313c33d402bb1d73437c55c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Eg5HIhZaTwYbFilw_WGFHw.png"/></div></div></figure><p id="1702" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从输出中我们可以看到<code class="du lg lh li kx b">longhorn-frontend</code>正在每个集群节点上的端口<code class="du lg lh li kx b">32057</code>上运行。这意味着我们可以使用任何节点IP来访问它，例如:<code class="du lg lh li kx b"><a class="ae jo" href="http://10.211.55.12:32057" rel="noopener ugc nofollow" target="_blank">http://10.211.55.12:32057</a></code></p><h1 id="45b2" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">安装普罗米修斯</h1><p id="829f" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">现在我们已经通过Longhorn提供了集群块设备服务，我们可以部署Prometheus了。为什么？因为我们将让Prometheus将其数据库放在群集块设备上，这样，如果Prometheus在一个节点上出现故障，它可以在另一个节点上安全地重启，而不会(严重)丢失数据。</p><p id="19b9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们首先创建一个名称空间<code class="du lg lh li kx b">monitoring</code>，我们将在其中部署Prometheus:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="08dd" class="lb jq ht kx b fi lc ld l le lf">$ kubectl create namespace monitoring</span></pre><p id="6a74" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们需要为Prometheus创建一个集群角色。创建一个名为<code class="du lg lh li kx b">prometheus-role.yaml</code>的文件，内容如下:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="27f7" class="lb jq ht kx b fi lc ld l le lf">apiVersion: rbac.authorization.k8s.io/v1<br/>kind: ClusterRole<br/>metadata:<br/>  name: prometheus<br/>rules:<br/>- apiGroups: [""]<br/>  resources:<br/>  - nodes<br/>  - nodes/proxy<br/>  - services<br/>  - endpoints<br/>  - pods<br/>  verbs: ["get", "list", "watch"]<br/>- apiGroups:<br/>  - extensions<br/>  resources:<br/>  - ingresses<br/>  verbs: ["get", "list", "watch"]<br/>- nonResourceURLs: ["/metrics"]<br/>  verbs: ["get"]<br/>---<br/>apiVersion: rbac.authorization.k8s.io/v1<br/>kind: ClusterRoleBinding<br/>metadata:<br/>  name: prometheus<br/>roleRef:<br/>  apiGroup: rbac.authorization.k8s.io<br/>  kind: ClusterRole<br/>  name: prometheus<br/>subjects:<br/>- kind: ServiceAccount<br/>  name: default<br/>  namespace: monitoring</span></pre><p id="b8ca" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建RBAC角色:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="97b7" class="lb jq ht kx b fi lc ld l le lf">$ kubectl create -f prometheus-role.yaml</span></pre><p id="2c67" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在创建一个名为<code class="du lg lh li kx b">prometheus-config-map.yaml</code>的文件，内容如下:</p><figure class="ks kt ku kv fd hk"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="98b0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这将配置Prometheus从部署、服务等中获取指标。参见<a class="ae jo" href="https://github.com/prometheus/prometheus/blob/release-2.30/documentation/examples/prometheus-kubernetes.yml" rel="noopener ugc nofollow" target="_blank"> Prometheus Kubernetes的例子</a>了解更多关于上述内容的信息。</p><p id="c940" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为普罗米修斯创建配置图:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="6c4f" class="lb jq ht kx b fi lc ld l le lf">$ kubectl create -f prometheus-config-map.yaml</span></pre><p id="5b67" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在为Prometheus创建一个存储索赔。创建一个名为<code class="du lg lh li kx b">prometheus-pvc.yaml</code>的文件，内容如下:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="57a2" class="lb jq ht kx b fi lc ld l le lf">apiVersion: v1<br/>kind: PersistentVolumeClaim<br/>metadata:<br/>  name: prometheus-pvc<br/>  namespace: monitoring<br/>spec:<br/>  accessModes:<br/>    - ReadWriteOnce<br/>  storageClassName: longhorn<br/>  resources:<br/>    requests:<br/>      storage: 1Gi</span></pre><p id="2a7f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将只分配1G的数据，因为这只是一个测试集群，所以应该足够了。在生产中，你肯定会想要更多。</p><p id="1d9c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建存储索赔:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="7cf8" class="lb jq ht kx b fi lc ld l le lf">$ kubectl create -f prometheus-pvc.yaml</span></pre><p id="5b8c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们准备为Prometheus创建部署规范。使用以下内容创建一个名为<code class="du lg lh li kx b">prometheus-app.yaml</code>的文件:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="2649" class="lb jq ht kx b fi lc ld l le lf">apiVersion: apps/v1<br/>kind: Deployment<br/>metadata:<br/>  name: prometheus-deployment<br/>  namespace: monitoring<br/>  labels:<br/>    app: prometheus-server<br/>spec:<br/>  replicas: 1<br/>  selector:<br/>    matchLabels:<br/>      app: prometheus-server<br/>  template:<br/>    metadata:<br/>      labels:<br/>        app: prometheus-server<br/>    spec:<br/>      securityContext:<br/>        runAsUser: 65534<br/>        runAsGroup: 65534<br/>        fsGroup: 65534      <br/>      containers:<br/>        - name: prometheus<br/>          image: prom/prometheus<br/>          args:<br/>            - "--storage.tsdb.retention.time=12h"<br/>            - "--storage.tsdb.retention.size=500MB"<br/>            - "--config.file=/etc/prometheus/prometheus.yml"<br/>            - "--storage.tsdb.path=/prometheus/"<br/>            - "--web.external-url=<a class="ae jo" href="http://10.211.55.241/prometheus" rel="noopener ugc nofollow" target="_blank">http://10.211.55.240/prometheus</a>"<br/>            - "--web.route-prefix=/"<br/>          ports:<br/>            - containerPort: 9090<br/>          resources:<br/>            requests:<br/>              cpu: 500m<br/>              memory: 250M<br/>            limits:<br/>              cpu: 1<br/>              memory: 500M<br/>          volumeMounts:<br/>            - name: prometheus-config-volume<br/>              mountPath: /etc/prometheus/<br/>            - name: prometheus-storage-volume<br/>              mountPath: /prometheus/<br/>      volumes:<br/>        - name: prometheus-config-volume<br/>          configMap:<br/>            defaultMode: 420<br/>            name: prometheus-server-conf<br/>  <br/>        - name: prometheus-storage-volume<br/>          persistentVolumeClaim:<br/>            claimName: prometheus-pvc</span></pre><p id="b8a0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您应该注意这里的一些事情。我们正在使用一个持久存储卷，我们将把它安装在容器中的<code class="du lg lh li kx b">/prometheus</code>下。为了确保这个挂载获得正确的权限，我们设置了<code class="du lg lh li kx b">securityContext</code> (prometheus作为用户<code class="du lg lh li kx b">nobody</code>运行，该用户的UID是65534，GID是65534)。我们还将Prometheus配置为仅保留12小时的数据，并且永远不会超过500MB。在生产中，您应该对此进行更改(确保它与您为永久卷声明提供的大小相匹配！).最后，我们定义了<code class="du lg lh li kx b">web.external-url</code>来匹配HAProxy的<code class="du lg lh li kx b">LoadBalancer</code> IP，因为我们希望HAProxy在它前面(我们将在普罗米修斯的入口规范中进一步定义)。在生产中，您可能会使用DNS名称。</p><p id="4775" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在集群上创建prometheus部署:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="0922" class="lb jq ht kx b fi lc ld l le lf">$ kubectl create -f prometheus-app.yaml</span></pre><p id="d850" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来创建服务来公开prometheus端口，并告诉它也清理自己。使用以下内容创建一个名为<code class="du lg lh li kx b">prometheus-service.yaml</code>的文件:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="86c8" class="lb jq ht kx b fi lc ld l le lf">apiVersion: v1<br/>kind: Service<br/>metadata:<br/>  name: prometheus-service<br/>  namespace: monitoring<br/>  annotations:<br/>      prometheus.io/scrape: 'true'<br/>      prometheus.io/port:   '9090'<br/>spec:<br/>  selector: <br/>    app: prometheus-server<br/>  ports:<br/>    - port: 8080<br/>      targetPort: 9090</span></pre><p id="daff" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建服务:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="0908" class="lb jq ht kx b fi lc ld l le lf">$ kubectl create -f prometheus-service.yaml</span></pre><p id="8f23" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们有了一个服务，我们可以创建一个入口。使用以下内容创建一个名为<code class="du lg lh li kx b">prometheus-ingress.yaml</code>的文件:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="500e" class="lb jq ht kx b fi lc ld l le lf">apiVersion: networking.k8s.io/v1<br/>kind: Ingress<br/>metadata:<br/>    name: prometheus-ingress<br/>    namespace: monitoring<br/>    annotations:<br/>        haproxy.org/path-rewrite: /prometheus/?(.*) /\1<br/>        kubernetes.io/ingress.class: haproxy<br/>spec:<br/>    rules:<br/>    - http:<br/>        paths:<br/>        - path: /prometheus<br/>          pathType: Prefix<br/>          backend:<br/>            service:<br/>              name: prometheus-service<br/>              port:<br/>                number: 8080</span></pre><p id="83f0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我们指示哈普洛克西为普罗米修斯处理入口。HAProxy收到的任何以路径<code class="du lg lh li kx b">/prometheus</code>开始的请求都将被转发到我们在端口8080公开的prometheus服务。该服务将依次将其转发到容器内部运行的端口9090。</p><p id="def1" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">部署入口配置:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="6236" class="lb jq ht kx b fi lc ld l le lf">$ kubectl create -f prometheus-ingress.yaml</span></pre><p id="3193" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在您应该可以通过以下URL访问Prometheus:<a class="ae jo" href="http://10.211.55.240/prometheus." rel="noopener ugc nofollow" target="_blank">http://10 . 211 . 55 . 240/Prometheus</a>。</p><p id="882f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">太棒了。现在，我们有了一个使用集群块存储的正在运行的prometheus服务器。尽管它已经收集了关于我们的集群的信息，但它还没有收集节点本身生成的任何指标(例如CPU利用率等)。为此，我们需要安装普罗米修斯节点导出器。</p><h1 id="094e" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">普罗米修斯节点导出器</h1><p id="0a4d" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">使用以下内容创建一个名为<code class="du lg lh li kx b">node-exporter-daemon.yaml</code>的文件:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="7670" class="lb jq ht kx b fi lc ld l le lf">apiVersion: apps/v1<br/>kind: DaemonSet<br/>metadata:<br/>  labels:<br/>    app.kubernetes.io/component: exporter<br/>    app.kubernetes.io/name: node-exporter<br/>  name: node-exporter<br/>  namespace: monitoring<br/>spec:<br/>  selector:<br/>    matchLabels:<br/>      app.kubernetes.io/component: exporter<br/>      app.kubernetes.io/name: node-exporter<br/>  template:<br/>    metadata:<br/>      labels:<br/>        app.kubernetes.io/component: exporter<br/>        app.kubernetes.io/name: node-exporter<br/>    spec:<br/>      containers:<br/>      - args:<br/>        - --path.sysfs=/host/sys<br/>        - --path.rootfs=/host/root<br/>        - --no-collector.wifi<br/>        - --no-collector.hwmon<br/>        - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/pods/.+)($|/)<br/>        - --collector.netclass.ignored-devices=^(veth.*)$<br/>        name: node-exporter<br/>        image: prom/node-exporter<br/>        ports:<br/>          - containerPort: 9100<br/>            protocol: TCP<br/>        resources:<br/>          limits:<br/>            cpu: 250m<br/>            memory: 180Mi<br/>          requests:<br/>            cpu: 102m<br/>            memory: 180Mi<br/>        volumeMounts:<br/>        - mountPath: /host/sys<br/>          mountPropagation: HostToContainer<br/>          name: sys<br/>          readOnly: true<br/>        - mountPath: /host/root<br/>          mountPropagation: HostToContainer<br/>          name: root<br/>          readOnly: true<br/>      volumes:<br/>      - hostPath:<br/>          path: /sys<br/>        name: sys<br/>      - hostPath:<br/>          path: /<br/>        name: root</span></pre><p id="dd0c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以前spec的<code class="du lg lh li kx b">kind</code>对于其他人通常是<code class="du lg lh li kx b">Deployment</code>，这里我们将使用<code class="du lg lh li kx b"><a class="ae jo" href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/" rel="noopener ugc nofollow" target="_blank">DaemonSet</a></code>。这将确保节点导出器可以在所有节点上运行，即使我们向群集中添加新节点也是如此。</p><p id="e66d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建守护进程集:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="ce31" class="lb jq ht kx b fi lc ld l le lf">$ kubectl create -f node-exporter-daemon.yaml</span></pre><p id="9024" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在创建一个服务，这样Prometheus就可以从节点导出器中获取数据。使用以下内容创建一个名为<code class="du lg lh li kx b">node-exporter-service.yaml</code>的文件:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="fd2c" class="lb jq ht kx b fi lc ld l le lf">apiVersion: v1<br/>kind: Service<br/>apiVersion: v1<br/>metadata:<br/>  name: node-exporter<br/>  namespace: monitoring<br/>  annotations:<br/>      prometheus.io/scrape: 'true'<br/>      prometheus.io/port:   '9100'<br/>spec:<br/>  selector:<br/>      app.kubernetes.io/component: exporter<br/>      app.kubernetes.io/name: node-exporter<br/>  ports:<br/>  - name: node-exporter<br/>    protocol: TCP<br/>    port: 9100<br/>    targetPort: 9100</span></pre><p id="6c8e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将其部署到群集:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="119f" class="lb jq ht kx b fi lc ld l le lf">$ kubectl create -f node-exporter-service.yaml</span></pre><p id="e05e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">很好！现在，Prometheus还将为我们提供集群中每个节点的所有指标。接下来，让我们为新创建的集群部署一个测试应用程序。</p><h1 id="cb83" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">测试回显服务器</h1><p id="3389" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">为了测试我们的集群，我们将部署一个简单的测试<a class="ae jo" href="https://github.com/fdeantoni/echo-server" rel="noopener ugc nofollow" target="_blank"> echo服务器</a>。我们将把它部署在自己的名为<code class="du lg lh li kx b">test</code>的名称空间中:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="470e" class="lb jq ht kx b fi lc ld l le lf">$ kubectl create namespace test</span></pre><p id="6823" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在创建一个名为<code class="du lg lh li kx b">echo-server-app.yaml</code>的文件，内容如下:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="f42b" class="lb jq ht kx b fi lc ld l le lf">apiVersion: apps/v1<br/>kind: Deployment<br/>metadata:<br/>  labels:<br/>    run: echo<br/>  name: echo<br/>  namespace: test<br/>spec:<br/>  replicas: 3<br/>  selector:<br/>    matchLabels:<br/>      run: echo<br/>  template:<br/>    metadata:<br/>      labels:<br/>        run: echo<br/>    spec:<br/>      nodeSelector:<br/>        node-type: worker    <br/>      containers:<br/>      - name: echo<br/>        image: fdeantoni/echo-server<br/>        ports:<br/>        - containerPort: 9000<br/>        readinessProbe:<br/>          httpGet:<br/>            path: /<br/>            port: 9000<br/>          initialDelaySeconds: 5<br/>          periodSeconds: 5<br/>          successThreshold: 1</span></pre><p id="9e75" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里需要注意几点:</p><ul class=""><li id="3184" class="ln lo ht is b it iu ix iy jb lp jf lq jj lr jn ls lt lu lv bi translated">属性<code class="du lg lh li kx b">replicas</code>被设置为3，因此我们将创建3个echo服务器实例</li><li id="6da6" class="ln lo ht is b it lw ix lx jb ly jf lz jj ma jn ls lt lu lv bi translated">定义了一个<code class="du lg lh li kx b">selector</code>来确保echo服务器只部署在<code class="du lg lh li kx b">worker</code>节点上。</li><li id="9b40" class="ln lo ht is b it lw ix lx jb ly jf lz jj ma jn ls lt lu lv bi translated">我们添加了一个<code class="du lg lh li kx b">readinessProbe</code>，它将测试根路径上的每个实例，以查看服务是否启动。</li></ul><p id="6d00" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们将应用程序部署到集群:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="67e4" class="lb jq ht kx b fi lc ld l le lf">$ kubectl apply -f echo-server-app.yaml</span></pre><p id="f461" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们需要创建一个向集群公开echo服务器服务的服务。使用以下内容创建一个名为<code class="du lg lh li kx b">echo-server-service.yaml</code>的文件:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="e24b" class="lb jq ht kx b fi lc ld l le lf">apiVersion: v1<br/>kind: Service<br/>metadata:<br/>    name: echo-service<br/>    namespace: test<br/>    annotations:<br/>        prometheus.io/scrape: 'true'<br/>        prometheus.io/port:   '9000'<br/>        prometheus.io/path:   '/metrics'    <br/>spec:<br/>    selector:<br/>      run: echo<br/>    ports:<br/>    - name: http<br/>      protocol: TCP<br/>      port: 9000<br/>      targetPort: 9000</span></pre><p id="1574" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里还需要注意一些事情:</p><ul class=""><li id="c16d" class="ln lo ht is b it iu ix iy jb lp jf lq jj lr jn ls lt lu lv bi translated">我们指示Prometheus也在端口<code class="du lg lh li kx b">9000</code>上的路径<code class="du lg lh li kx b">/metrics</code>从echo服务器抓取指标。</li><li id="4345" class="ln lo ht is b it lw ix lx jb ly jf lz jj ma jn ls lt lu lv bi translated">我们打开集群上的端口<code class="du lg lh li kx b">9000</code>来公开容器内部也运行在端口<code class="du lg lh li kx b">9000</code>上的服务。</li></ul><p id="a456" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建服务:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="fbd5" class="lb jq ht kx b fi lc ld l le lf">$ kubectl apply -f echo-server-service.yaml</span></pre><p id="7b20" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在定义一个入口配置，允许HAProxy为我们的echo服务器代理请求。使用以下内容创建一个名为<code class="du lg lh li kx b">echo-server-ingress.yaml</code>的文件:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="ee8a" class="lb jq ht kx b fi lc ld l le lf">apiVersion: networking.k8s.io/v1<br/>kind: Ingress<br/>metadata:<br/>    name: echo-ingress<br/>    namespace: test<br/>    annotations:<br/>        haproxy.org/path-rewrite: /test/?(.*) /\1<br/>        kubernetes.io/ingress.class: haproxy<br/>spec:<br/>    rules:<br/>    - http:<br/>        paths:<br/>        - path: /test<br/>          pathType: Prefix<br/>          backend:<br/>            service:<br/>              name: echo-service<br/>              port:<br/>                number: 9000</span></pre><p id="ce02" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将其部署到群集:</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="49ac" class="lb jq ht kx b fi lc ld l le lf">$ kubectl apply -f echo-server-ingress.yaml</span></pre><p id="b1c5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在测试一下！当我们的HAProxy在<code class="du lg lh li kx b">10.211.55.240</code>运行时，我们应该能够在<code class="du lg lh li kx b"><a class="ae jo" href="http://10.211.55.240/test" rel="noopener ugc nofollow" target="_blank">http://10.211.55.240/test</a></code>访问echo服务器:</p><figure class="ks kt ku kv fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mb"><img src="../Images/14ddf6b8a7ca19dac7627cd14adc369c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V3vzsjp5bZu9RJ74oa4-1A.png"/></div></div></figure><h1 id="ba4c" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">有用的来源</h1><p id="8edd" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">为了帮助我创建这个指南，我使用了以下资源，你也应该看看:</p><ul class=""><li id="0230" class="ln lo ht is b it iu ix iy jb lp jf lq jj lr jn ls lt lu lv bi translated"><a class="ae jo" href="https://rpi4cluster.com" rel="noopener ugc nofollow" target="_blank"> Raspberry Pi集群</a>——在Raspberry Pi集群上安装kubernetes的一个非常好的指南。</li><li id="025a" class="ln lo ht is b it lw ix lx jb ly jf lz jj ma jn ls lt lu lv bi translated"><a class="ae jo" href="https://devopscube.com/setup-prometheus-monitoring-on-kubernetes" rel="noopener ugc nofollow" target="_blank">如何在Kubernetes集群上设置Prometheus监控</a></li><li id="6861" class="ln lo ht is b it lw ix lx jb ly jf lz jj ma jn ls lt lu lv bi translated"><a class="ae jo" href="https://devopscube.com/node-exporter-kubernetes" rel="noopener ugc nofollow" target="_blank">如何在Kubernetes </a>上设置普罗米修斯节点导出器</li></ul><p id="ad54" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">感谢阅读！</p></div></div>    
</body>
</html>