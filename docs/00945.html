<html>
<head>
<title>Shoving Your Docker Container Logs to ELK Made Simple</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">推你的码头集装箱日志到麋鹿变得简单</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/shoving-your-docker-container-logs-to-elk-made-simple-882bffdbcad6?source=collection_archive---------3-----------------------#2021-03-21">https://medium.com/geekculture/shoving-your-docker-container-logs-to-elk-made-simple-882bffdbcad6?source=collection_archive---------3-----------------------#2021-03-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="6105" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">因为管理日志很重要。句号。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/3fd965e1e100550cca2961e3663ec64d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r6Ebu6SazdaLLNuYqmEpPw.png"/></div></div></figure><p id="a8aa" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在本文的其余部分之前，让我们都同意生成适当的日志对于生产中的任何应用程序都是至关重要的。无论是结构化的日志记录，比如JSON格式，还是打印的普通字符串，都必须有某种形式的跟踪软件正在做什么，以便在应用程序出现问题时使用。在这里，我将“应用程序”作为一个通用术语来描述任何一种可能会出现意外行为的软件、代码或工具。</p><p id="7dbb" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">当然，生成日志是不够的。当你需要的时候，日志却不在那里，这有什么用呢？生成的日志必须以某种方式持久化，并在需要时随时提供给风险承担者，如软件工程师、系统管理员和其他可以访问系统的人。根据日志的数量和生成日志的速度，它们的持久化方式会有所不同。</p><ul class=""><li id="6b50" class="kf kg hi jl b jm jn jp jq js kh jw ki ka kj ke kk kl km kn bi translated">如果应用程序以慢到中等的速度记录日志，这样写入磁盘是可行的，那么您只需要日志文件。设置您的Linux系统，按计划轮换日志文件，并将文件发送到永久存储，如备份磁盘或AWS S3，这样就可以了。需要时，可以使用工具<code class="du ko kp kq kr b">grep</code>或常规文本编辑器来访问和查询日志。</li><li id="1bda" class="kf kg hi jl b jm ks jp kt js ku jw kv ka kw ke kk kl km kn bi translated">有时，记录到文件中并不会删除它。没有多少人是Linux命令行工具的奇才，能够剖析和搜索大量的日志文件，在终端中找到他们想要的东西。即使是这样，也很难在命令行上复制一个SQL查询所能做的事情。如果您认为查询日志是一项重要的需求，那么即使日志记录变得有点慢，将日志存储到数据库中也是理想的。无论是关系数据库(如MySQL)还是基于文档的数据库(如MongoDB ),写入速度都会比写入磁盘慢。然而，任何熟悉这些数据库查询语言的人都应该能够快速形成相当复杂的查询，以便能够准确地获得他们想要的数据。</li></ul><p id="0ef3" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">即使在使用Docker的时候，上述两种方法都是可行的。对于记录到文件，您可以向容器添加一个卷装载，以便从容器外部访问日志。对于使用数据库，您可以启动一个数据库容器并持久存储数据(以防您的应用程序还没有使用数据库)。</p><p id="3107" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">然而，上述两种方法都将实际保存日志(到磁盘或数据库)的工作交给了应用程序本身。虽然现代日志库已经很好地优化了并发处理多个流和大量数据的能力，但是如果创建了太多的数据库连接或者系统磁盘本身很慢，日志仍然可能成为应用程序性能的瓶颈。有时让其他工具为您的应用程序处理日志可能是有意义的，而应用程序本身除了将日志扔给<code class="du ko kp kq kr b">stdout</code>之外什么也不做，这是Docker的日志记录方式。</p><p id="1ddd" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这种方法是如何工作的？简单。</p><ul class=""><li id="f09d" class="kf kg hi jl b jm jn jp jq js kh jw ki ka kj ke kk kl km kn bi translated">您的应用程序生成日志并将其发送到<code class="du ko kp kq kr b">stdout</code>或<code class="du ko kp kq kr b">stderr</code>。</li><li id="0c06" class="kf kg hi jl b jm ks jp kt js ku jw kv ka kw ke kk kl km kn bi translated">docker日志记录驱动程序将这些日志发送到一个UDP端点(实际上是一个Logstash实例)。</li><li id="5a5e" class="kf kg hi jl b jm ks jp kt js ku jw kv ka kw ke kk kl km kn bi translated">Logstash将这些日志发送到Elasticsearch，在那里它们被索引和持久化。</li></ul><p id="2aeb" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">为什么采用这种方法？因为基巴纳。使用Kibana带来的易用性和查询性是不言而喻的。当然，弹性<strong class="jl hj">搜索</strong>非常快，说到<strong class="jl hj">搜索</strong> ing。明确地说，我理解，你也应该理解，Kibana是一个通用的可视化工具，用它来分析日志只是它能做的事情之一。您可以通过生成过滤器日志的容器、时间戳来查看过滤器日志，甚至可以添加自定义过滤器。Kibana的全部功能超出了本文的范围，我将它留给感兴趣的读者作为练习。</p><p id="fe6e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们如何做到这一点？首先，您需要设置一个ELK堆栈，我们可以将日志放入其中。如果您愿意，您可以安装并配置这些组件。然而，对于本文，我将使用docker-compose来运行docker容器中的所有服务。</p><p id="d04a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">堆栈是这样工作的:</p><ul class=""><li id="113b" class="kf kg hi jl b jm jn jp jq js kh jw ki ka kj ke kk kl km kn bi translated">我们有一个运行弹性搜索的容器。</li><li id="ed02" class="kf kg hi jl b jm ks jp kt js ku jw kv ka kw ke kk kl km kn bi translated">我们有一个运行Kibana的容器，它连接到Elasticsearch实例。</li><li id="b607" class="kf kg hi jl b jm ks jp kt js ku jw kv ka kw ke kk kl km kn bi translated">我们有一个Logstash“代理”，它唯一的工作是获取任何来自于<code class="du ko kp kq kr b">gelf</code>接口的日志，并将它们放入Redis实例中，该实例的作用类似于日志缓冲区。</li><li id="219c" class="kf kg hi jl b jm ks jp kt js ku jw kv ka kw ke kk kl km kn bi translated">一个“中央”Logstash容器从Redis缓冲区读取日志，并将它们放入Elasticsearch，从那里它们可供Kibana服务使用。</li></ul><p id="e064" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">够直白了吧？让我们把它写在Docker-compose文件中。谢天谢地，完成所有这些设置并不需要太多时间。让我们逐个检查docker-compose文件中的服务。</p><h1 id="ba50" class="kx ky hi bd kz la lb lc ld le lf lg lh io li ip lj ir lk is ll iu lm iv ln lo bi translated">docker-撰写</h1><h2 id="e07e" class="lp ky hi bd kz lq lr ls ld lt lu lv lh js lw lx lj jw ly lz ll ka ma mb ln mc bi translated"><strong class="ak">弹性搜索:</strong></h2><pre class="iy iz ja jb fd md kr me mf aw mg bi"><span id="ea09" class="lp ky hi kr b fi mh mi l mj mk">elasticsearch:<br/>  image: elasticsearch:7.11.1<br/>  environment:<br/>    - discovery.type=single-node<br/>  volumes:<br/>    - ./elasticsearch_data/:/usr/share/elasticsearch/data<br/>  mem_limit: "1g"</span></pre><p id="089d" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">简单。环境变量<code class="du ko kp kq kr b">discovery.type</code>告诉elasticsearch引擎它是作为单个节点而不是集群运行的。卷装载确保了elasticsearch数据在容器重启后仍然存在。这是因为我简陋的笔记本电脑无法处理一个弹性搜索引擎的全部力量。你的可能能够处理2g的内存限制，但是你要自担风险。</p><h2 id="5e8b" class="lp ky hi bd kz lq lr ls ld lt lu lv lh js lw lx lj jw ly lz ll ka ma mb ln mc bi translated"><strong class="ak"> Redis: </strong></h2><pre class="iy iz ja jb fd md kr me mf aw mg bi"><span id="0187" class="lp ky hi kr b fi mh mi l mj mk">redis-cache:<br/>  image: redis:6.2</span></pre><p id="4841" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">出于本文的目的，我们将保留Redis的默认配置。</p><h2 id="ac43" class="lp ky hi bd kz lq lr ls ld lt lu lv lh js lw lx lj jw ly lz ll ka ma mb ln mc bi translated">日志存储(代理):</h2><pre class="iy iz ja jb fd md kr me mf aw mg bi"><span id="1645" class="lp ky hi kr b fi mh mi l mj mk">logstash-agent:<br/>  image: logstash:7.11.1<br/>  volumes:<br/>    - ./logstash-agent:/etc/logstash<br/>  command: logstash -f /etc/logstash/logstash.conf<br/>  depends_on:<br/>    - elasticsearch<br/>  ports:<br/>    - 12201:12201/udp</span></pre><p id="ec02" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">代理公开了UDP端口<code class="du ko kp kq kr b">12201</code>，我们的应用程序docker容器将把它的日志发送到这个端口。我们挂载一个包含我们的<code class="du ko kp kq kr b">logstash.conf</code>的目录<code class="du ko kp kq kr b">logstash-agent</code>，它将配置logstash实例实例，以便将传入的数据发送到我们的redis实例。logstash.conf可能是这样的:</p><pre class="iy iz ja jb fd md kr me mf aw mg bi"><span id="a5e5" class="lp ky hi kr b fi mh mi l mj mk">input {<br/>  gelf {<br/>    port =&gt; 12201<br/>  }<br/>}</span><span id="5215" class="lp ky hi kr b fi ml mi l mj mk">output {<br/>  redis {<br/>    host =&gt; "redis-cache"<br/>    data_type =&gt; "list"<br/>    key =&gt; "logstash"<br/>  }<br/>}</span></pre><p id="23b4" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">Gelf是一种日志格式，我们将通过gelf日志驱动程序将它用于我们的应用程序docker容器的日志输出。你可以在这里了解更多关于gelf <a class="ae mm" href="https://www.graylog.org/features/gelf" rel="noopener ugc nofollow" target="_blank">的信息。</a></p><h2 id="c249" class="lp ky hi bd kz lq lr ls ld lt lu lv lh js lw lx lj jw ly lz ll ka ma mb ln mc bi translated">日志存储(中央)</h2><p id="8c42" class="pw-post-body-paragraph jj jk hi jl b jm mn ij jo jp mo im jr js mp ju jv jw mq jy jz ka mr kc kd ke hb bi translated">“中央”logstash实例执行实际的工作，它从Redis获取日志并将其推送到elasticsearch，在那里它们被索引并可供使用。</p><pre class="iy iz ja jb fd md kr me mf aw mg bi"><span id="565d" class="lp ky hi kr b fi mh mi l mj mk">logstash-central:<br/>  image: logstash:7.11.1<br/>  volumes:<br/>    - ./logstash-central:/etc/logstash<br/>  command: logstash -f /etc/logstash/logstash.conf<br/>  depends_on:<br/>    - elasticsearch</span></pre><p id="6593" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">配置文件<code class="du ko kp kq kr b">logstash.conf</code>安装在<code class="du ko kp kq kr b">logstash-central</code>目录中。</p><pre class="iy iz ja jb fd md kr me mf aw mg bi"><span id="2ce7" class="lp ky hi kr b fi mh mi l mj mk">input {<br/>  redis {<br/>    host =&gt; "redis-cache"<br/>    type =&gt; "redis-input"<br/>    data_type =&gt; "list"<br/>    key =&gt; "logstash"<br/>  }<br/>}</span><span id="6cb9" class="lp ky hi kr b fi ml mi l mj mk">output {<br/>  elasticsearch {<br/>    hosts =&gt; ["elasticsearch:9200"]<br/>  }<br/>}</span></pre><h2 id="f489" class="lp ky hi bd kz lq lr ls ld lt lu lv lh js lw lx lj jw ly lz ll ka ma mb ln mc bi translated">基巴纳</h2><p id="1028" class="pw-post-body-paragraph jj jk hi jl b jm mn ij jo jp mo im jr js mp ju jv jw mq jy jz ka mr kc kd ke hb bi translated">基巴纳只需要知道Elasticsearch在哪里。我们公开端口<code class="du ko kp kq kr b">5601</code>来访问web接口。</p><pre class="iy iz ja jb fd md kr me mf aw mg bi"><span id="79b4" class="lp ky hi kr b fi mh mi l mj mk">kibana:<br/>  image: kibana:7.11.1<br/>  ports:<br/>    - 5601:5601<br/>  environment:<br/>    - ELASTICSEARCH_HOSTS=http://elasticsearch:9200<br/>  depends_on:<br/>    - elasticsearch</span></pre></div><div class="ab cl ms mt gp mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="hb hc hd he hf"><p id="f2e1" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">完整的Docker-compose文件如下所示:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mz na l"/></div></figure><p id="6dd5" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们的目录结构如下:</p><pre class="iy iz ja jb fd md kr me mf aw mg bi"><span id="fcf0" class="lp ky hi kr b fi mh mi l mj mk">| elasticsearch_data/<br/>| logstash-agent/<br/>|     logstash.conf<br/>| logstash-central/<br/>|     logstash.conf<br/>| docker-compose.yml</span></pre><p id="0f72" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这里的一个<code class="du ko kp kq kr b">docker-compose up</code>应该可以做到这一点，旋转你自己的麋鹿堆，准备好吃掉你扔给它的任何木头！要访问Kibana仪表板，请在浏览器中转至<a class="ae mm" href="http://localhost:5601/" rel="noopener ugc nofollow" target="_blank"> http://localhost:5601/ </a>。但是，还没有任何日志可供查看。请注意，该服务可能需要一两分钟来初始化，所以如果网页上还没有任何内容，请不要担心。</p><p id="aa22" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们来解决这个问题——创建一个容器，放一些新鲜的日志。</p></div><div class="ab cl ms mt gp mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="hb hc hd he hf"><p id="c520" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们保持简单。我的服务将是一个有三个端点的小节点服务器。在这个上下文中，服务器做什么和端点做什么无关紧要。我们将考虑这个服务在一个单独的docker-compose环境中运行，它将通过暴露的端口<code class="du ko kp kq kr b">12201.</code>访问Logstash</p><p id="db03" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">docker-compose文件如下:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mz na l"/></div></figure><p id="2ca5" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">本质上，我们在与这个docker-compose文件相同的目录中构建一个Dockerfile，它在内部启动端口<code class="du ko kp kq kr b">9843</code>上的一个服务器，我们将它暴露给主机上的端口<code class="du ko kp kq kr b">9843</code>。有一些环境配置，作为读者，您不需要关心。我们的测井配置都在那个叫，请击鼓，<strong class="jl hj">测井</strong>的区块内。</p><pre class="iy iz ja jb fd md kr me mf aw mg bi"><span id="0d60" class="lp ky hi kr b fi mh mi l mj mk">logging:      <br/>  driver: gelf      <br/>  options:        <br/>    gelf-address: "udp://localhost:12201"        <br/>    tag: "myapp"</span></pre><p id="a829" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们告诉docker-compose使用“gelf”驱动程序，而不是默认的(我认为是“本地”驱动程序)。我们在选项块下配置驱动程序。我们指定需要将日志发送到的UDP端点，以及来自该服务的所有日志的标记，该标记将被添加到以GELF格式发送的日志中。</p><p id="4a47" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">实际上，您可以拥有任意数量的docker-compose服务，像这样配置它的日志驱动程序，并将所有服务的所有日志集中到一个位置。多牛逼啊！？</p></div><div class="ab cl ms mt gp mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="hb hc hd he hf"><h1 id="be28" class="kx ky hi bd kz la nb lc ld le nc lg lh io nd ip lj ir ne is ll iu nf iv ln lo bi translated">查看结果</h1><p id="59c0" class="pw-post-body-paragraph jj jk hi jl b jm mn ij jo jp mo im jr js mp ju jv jw mq jy jz ka mr kc kd ke hb bi translated">现在，进入Kibana，当您第一次进入Elasticsearch日志部分时，您必须指定一个默认索引。因为我们使用的是Logstash，所以索引的形式是<code class="du ko kp kq kr b">logstash-*</code>,除非你自己弄乱了logstash的配置(在这种情况下，你可能理解要指定的索引，对吗？).</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ng"><img src="../Images/71afdf5d7a4bbb79c268354ea6fd8768.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qs-FwaAUb-fUQlQ5H4MEdQ.png"/></div></div><figcaption class="nh ni et er es nj nk bd b be z dx">Specifying the default index</figcaption></figure><p id="7398" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">您还必须在下一步中指定时间字段。由于我们使用GELF输入，这将是<code class="du ko kp kq kr b">@ timestamp</code>字段。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ng"><img src="../Images/8615f3a41aff181bebc6bd89f090877d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VtPQXxbupnYl2n1okFEo7A.png"/></div></div><figcaption class="nh ni et er es nj nk bd b be z dx">Specifying the time field.</figcaption></figure><p id="3f8e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">点击<code class="du ko kp kq kr b">Create index pattern</code>，您现在应该能够转到<a class="ae mm" href="http://localhost:5601/app/discover/" rel="noopener ugc nofollow" target="_blank">http://localhost:5601/app/discover/</a>查看来自服务器应用程序的日志。如果您没有看到日志，请尝试调整持续时间过滤器，或者确保某些日志确实是由应用程序生成的。尝试向应用程序发送一些请求来获取一些日志。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ng"><img src="../Images/7d221eac06681718c300f810cdd10ba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g4p0_O0nUmF5N52hP9kLTA.png"/></div></div></figure><p id="4951" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这不是很好吗？在这里，您拥有所有的日志，并且可以随时进行分析。如果你是Logstash和Kibana的新手(像我一样)，试试看Kibana能为你做些什么是很好的。给定当前配置，您的应用程序创建的实际传入日志在“message”键中作为一个字符串提供。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ng"><img src="../Images/494c6d4c0c5419481fdde2b4cb3af778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0wIX94rU_zj2YIssZhgYlw.png"/></div></div><figcaption class="nh ni et er es nj nk bd b be z dx">A sample log</figcaption></figure><p id="0bbb" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我相信，可以对日志“消息”本身进行解析并使其可过滤。会给你最终的力量。或许试着解决这个问题。或许也让我知道。或者，一旦我搞清楚了，我会更新这篇文章。</p></div><div class="ab cl ms mt gp mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="hb hc hd he hf"><h1 id="c622" class="kx ky hi bd kz la nb lc ld le nc lg lh io nd ip lj ir ne is ll iu nf iv ln lo bi translated">关于可扩展性</h1><p id="a469" class="pw-post-body-paragraph jj jk hi jl b jm mn ij jo jp mo im jr js mp ju jv jw mq jy jz ka mr kc kd ke hb bi translated">这个ELK设置可以扩展吗？我认为在很大程度上是可能的。我们可以有多个中央Logstash实例从Redis数据库接收日志，该数据库本身可以通过复制扩展到多个节点。Elasticsearch本身可以设置为在多个节点的集群中运行，以帮助实现高可用性。Redis缓冲区确保对传入日志进行一定程度的速率限制，因为消费者Logstash实例可以按照自己的速度获取日志，从而让Elasticsearch引擎有足够的时间来索引数据。</p></div><div class="ab cl ms mt gp mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="hb hc hd he hf"><p id="db30" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">下次见，快乐学习。</p><p id="931e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">如果你想讨论一些关于这篇文章或一般技术的东西，请随时联系<a class="ae mm" href="https://www.linkedin.com/in/sharmarajdaksh/" rel="noopener ugc nofollow" target="_blank"> me </a>！</p></div></div>    
</body>
</html>