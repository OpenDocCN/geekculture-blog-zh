<html>
<head>
<title>Convolutional Neural Network With Tensorflow and Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有张量流和Keras的卷积神经网络</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/introduction-to-convolutional-neural-network-with-tensorflow-and-keras-cb52cdc66eaf?source=collection_archive---------1-----------------------#2021-03-12">https://medium.com/geekculture/introduction-to-convolutional-neural-network-with-tensorflow-and-keras-cb52cdc66eaf?source=collection_archive---------1-----------------------#2021-03-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/6895777bdae0b343da9848f8ca1df92a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AwajNAlAEAJCD1lFYN-5Xw.jpeg"/></div></div></figure><p id="6dd7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本指南中，我们将学习如何使用<strong class="is hj">卷积神经网络</strong>进行<em class="jo">图像分类和对象检测/识别</em>。用一种叫做计算机视觉的东西</p><p id="fc3a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们的卷积神经网络的目标将是分类和检测图像或图像中的特定对象。我们将使用图像数据作为我们的特征，并将这些图像的标签作为我们的标签或输出。</p><p id="ef73" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们已经知道神经网络是如何工作的，所以我们可以跳过基础知识，直接解释以下概念。</p><ul class=""><li id="f1dd" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">图像数据</li><li id="f502" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">卷积层</li><li id="f05c" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">汇集层</li><li id="60fb" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">CNN架构</li></ul><p id="fa40" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将要看到的这些类型的神经网络的主要区别是组成它们的层。</p><h1 id="a93a" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">图像数据</h1><p id="3966" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">现在我们将要处理通常由3维组成的图像数据。这三个维度如下:</p><ul class=""><li id="5b5a" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">图像高度</li><li id="628d" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">图像宽度</li><li id="b09d" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">颜色通道</li></ul><p id="b5c1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上面列表中唯一你可能不明白的是<strong class="is hj">颜色通道</strong>。颜色通道的数量代表图像的深度，并与图像中使用的颜色相关。例如，具有三个通道的图像可能由rgb(红、绿、蓝)像素组成。因此，对于每个像素，我们有三个数值在0-255的范围内定义它的颜色。对于颜色深度为1的图像，我们可能会有一个灰度图像，用一个值定义每个像素，也是在0–255的范围内。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/94aa9e5d24c7127a3390631386df90dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*VZ2D3BS9avtqzOMvj-9vbQ.png"/></div><figcaption class="ll lm et er es ln lo bd b be z dx">Keep this in mind as we discuss how our network works and the input/output of each layer.</figcaption></figure><h1 id="159f" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">卷积神经网络</h1><p id="ae53" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated"><strong class="is hj">注:</strong>我将互换使用术语<em class="jo"> convnet </em>和卷积神经网络。</p><p id="8de4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">每个卷积神经网络由一个或多个卷积层组成。这些层不同于我们之前看到的<em class="jo">密集</em>层。他们的目标是从图像中找到可以用来对图像或图像的一部分进行分类的模式。但这听起来可能与我们在上一节中密集连接的神经网络所做的事情很相似，因为确实如此。</p><p id="c3eb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">密集层和卷积层之间的根本区别在于，密集层检测全局模式，而卷积层检测局部模式。当我们有一个密集连接的层时，该层中的每个节点都可以看到前一层的所有数据。这意味着这一层查看所有的信息，并且只能在全局范围内分析数据。然而，我们的卷积层不会紧密连接，这意味着它可以使用该层的部分输入数据来检测局部模式。</p><p id="3747" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">让我们来看看密集连接层与卷积层对图像的看法。</em></p><p id="ab14" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是我们的形象；我们网络的目标将是确定这个图像是否是一只猫。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/8eae1c6aa5ebfeb2b08e741e63e16578.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*rAbCk0T4rksShBcPQjWC0A.gif"/></div></div></figure><p id="58c1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">密集层:</strong>密集层会考虑整个图像。它会查看所有像素，并使用这些信息来生成一些输出。</p><p id="5856" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">卷积层:</strong>卷积层会查看图像的特定部分。在这个例子中，假设它分析下面突出显示的部分并检测那里的模式。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/4d915c1f3cfd96d0cb77972e60220e46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o56wiQbp8HySiLGVXxqXQA.png"/></div></div></figure><p id="fa3f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你能看出为什么这会让这些网络更有用吗？</p><h1 id="b68c" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">它们是如何工作的</h1><p id="3579" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">密集的神经网络学习出现在图像的一个特定区域中的模式。这意味着，如果网络知道的模式出现在图像的不同区域，它必须在新的区域再次学习该模式，才能检测到它。</p><p id="9bfd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">让我们用一个例子来更好地说明这一点。</em></p><p id="e9be" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们会认为我们有一个密集的神经网络，它已经从狗的图像样本中学习了眼睛的样子。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/ffe385ab39800fa25e75e6b78c7d3b9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NYNnG1afCYYEXMQV_-g89A.png"/></div></div></figure><p id="6a5f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">比方说，如果在上面的图像中，有一只眼睛出现在被框住的位置，那么可以确定该图像可能是一只狗。</p><p id="9fc5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们翻转图像。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/ad7e24b5044cd8d071e3d1edf1ac4bdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pDLDlrLTcccO43NtNMBAJw.png"/></div></div></figure><p id="e5aa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于我们紧密相连的网络只能识别全球范围内的模式，因此它会寻找它认为眼睛应该出现的地方。显然，它没有在那里找到它们，因此可能会确定这个图像不是一只狗。尽管眼睛的模式是存在的，但它只是在不同的位置。</p><p id="eb47" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于卷积层从图像的不同区域学习和检测模式，它们在我们刚刚说明的例子中没有问题。他们知道眼睛是什么样的，通过分析图像的不同部分，可以找到眼睛的位置。</p><h1 id="6543" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">多重卷积层</h1><p id="38fb" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">在我们的模型中，有一个以上的卷积层是很常见的。甚至我们将在本指南中使用的基本示例也将由3个卷积层组成。这些层通过增加每个后续层的复杂性和抽象性来协同工作。第一层可能负责拾取边缘和短线，而第二层将这些线作为输入，并开始形成形状或多边形。最后，最后一层可能会采用这些形状，并确定哪些组合构成了特定的图像。</p><h1 id="b9ed" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">特征地图</h1><p id="98b5" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">你可能会看到我在整个教程中使用术语<em class="jo">特征映射</em>。这个术语简单地代表具有两个特殊轴(宽度和高度)和一个深度轴的3D张量。我们的卷积层将特征图作为它们的输入，并返回一个新的特征图，该新的特征图表示来自先前特征图的特定滤波器的存在。这些就是我们所说的<em class="jo">反应图</em>。</p><h1 id="94b8" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">层参数</h1><p id="e602" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">卷积层由两个关键参数定义。</p><h2 id="e553" class="lr ke hi bd kf ls lt lu kj lv lw lx kn jb ly lz kr jf ma mb kv jj mc md kz me bi translated">过滤</h2><p id="e1be" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">滤镜是我们在图像中寻找的m x n像素模式。卷积层中滤波器的数量代表了每一层寻找多少模式，以及我们的响应图的深度。如果我们正在寻找32种不同的模式/过滤器，那么我们的输出特征图(又名响应图)的深度将是32。32层深度中的每一层都将是某种大小的矩阵，包含指示过滤器是否存在于该位置的值。</p><p id="c06d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是Francois Chollet的书《用Python进行深度学习》中的一个很好的例子(第124页)。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/0397e0aed39d6c4f73e7a888ed427dcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bqDHVFg7VJgpwHe60zJIkA.png"/></div></div></figure><h2 id="41f0" class="lr ke hi bd kf ls lt lu kj lv lw lx kn jb ly lz kr jf ma mb kv jj mc md kz me bi translated">样本量</h2><p id="3ca8" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">这不是描述这一点的最佳术语，但每个卷积层将检查每个图像中的n x m个像素块。通常，我们会考虑3x3或5x5块。在上面的例子中，我们使用3x3的“样本大小”。这个尺寸将与我们的过滤器的尺寸相同。</p><p id="e050" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们的图层通过在图像中的每个可能位置上滑动这些n x m像素的过滤器，并填充新的特征图/响应图来指示过滤器是否出现在每个位置。</p><h1 id="dfb2" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">边框和填充</h1><p id="6dba" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">你可能已经意识到，如果我们在图像上滑动一个大小为3x3的滤镜，我们可以考虑比输入像素更少的滤镜位置。看看下面的例子。</p><p id="158f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">图片来自Francois Chollet的“用Python进行深度学习”(第126页)。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/1e52839cd584092f0f06e51659e342e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OOABoO6uP2K8kjWwpbeUDg.png"/></div></div></figure><p id="28dc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这意味着我们的响应图的宽度和高度将比原始图像略小。这很好，但有时我们希望我们的响应图有相同的维度。我们可以通过使用叫做<em class="jo">填充</em>的东西来完成这个任务。</p><p id="1700" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">填充</strong>是简单地将适当数量的行和/或列添加到您的输入数据中，这样每个像素都可以被过滤器居中。</p><h1 id="0a6d" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">大步</h1><p id="f753" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">在前面的部分中，我们假设过滤器将连续地滑过图像，从而覆盖每个可能的位置。这很常见，但有时我们会在卷积层引入一个<strong class="is hj">步长</strong>的概念。步长表示我们每次将移动过滤器多少行/列。这些不经常使用，所以我们将继续。</p><h1 id="013a" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">联营</h1><p id="e3e4" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">您可能还记得，我们的convnets是由卷积层和池层的堆栈组成的。</p><p id="0c0f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">池化图层背后的想法是对我们的要素地图进行向下采样并降低其维度。它们的工作方式类似于卷积层，从特征图中提取窗口，并返回每个通道的最大值、最小值或平均值的响应图。通常使用大小为2x2、跨度为2的窗口来完成池化。这将使特征图的大小减少一半，并返回一个小两倍的响应图。</p><h1 id="144e" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">更详细的外观</h1><p id="e2aa" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">请参考传奇人物安德鲁·吴的视频来了解这一切是如何在较低层次发生的！</p><h1 id="3003" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">创建一个通信网</h1><p id="fc0e" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">现在是时候创建我们的第一个convnet了！这个例子是为了熟悉CNN的架构，我们将在后面讨论如何提高它的性能。</p><p id="64a6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">本教程基于TensorFlow文档中的以下指南:</em><a class="ae mh" href="https://www.tensorflow.org/tutorials/images/cnn" rel="noopener ugc nofollow" target="_blank"><em class="jo">https://www.tensorflow.org/tutorials/images/cnn</em></a></p><h1 id="db03" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">资料组</h1><p id="1801" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">这里我们要考虑的问题是对10种不同的日常物品进行分类。我们将使用的数据集内置在tensorflow中，称为<a class="ae mh" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj"> CIFAR图像数据集。</strong> </a>包含60000张32x32的彩色图像，每类6000张。</p><p id="ee3c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该数据集中的标注如下:</p><ul class=""><li id="e0db" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">飞机</li><li id="6d3b" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">汽车</li><li id="d5af" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">伯德</li><li id="e9b4" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">猫</li><li id="8668" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">鹿</li><li id="6387" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">狗</li><li id="ed23" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">青蛙</li><li id="00a3" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">马</li><li id="b88b" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">船</li><li id="c380" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">卡车</li></ul><p id="c3bc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将加载数据集，看看下面的一些图像。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="9ba8" class="lr ke hi mj b fi mn mo l mp mq">%tensorflow_version 2.x  # this line is not required unless you are in a notebook</span><span id="399d" class="lr ke hi mj b fi mr mo l mp mq">import tensorflow as tf</span><span id="39b4" class="lr ke hi mj b fi mr mo l mp mq">from tensorflow.keras import datasets, layers, models</span><span id="6153" class="lr ke hi mj b fi mr mo l mp mq">import matplotlib.pyplot as plt</span><span id="6cba" class="lr ke hi mj b fi mr mo l mp mq">#  LOAD AND SPLIT DATASET</span><span id="8b9e" class="lr ke hi mj b fi mr mo l mp mq">(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()</span><span id="56d8" class="lr ke hi mj b fi mr mo l mp mq"># Normalize pixel values to be between 0 and 1</span><span id="2aa0" class="lr ke hi mj b fi mr mo l mp mq">train_images, test_images = train_images / 255.0, test_images / 255.0</span><span id="555b" class="lr ke hi mj b fi mr mo l mp mq">class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']<br/>IMG_INDEX = 7  # change this to look at other images</span><span id="0b2b" class="lr ke hi mj b fi mr mo l mp mq">plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)</span><span id="eea6" class="lr ke hi mj b fi mr mo l mp mq">plt.xlabel(class_names[train_labels[IMG_INDEX][0]])</span><span id="48a1" class="lr ke hi mj b fi mr mo l mp mq">plt.show()</span></pre><h1 id="d425" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">CNN架构</h1><p id="6224" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">CNN的常见架构是Conv2D和MaxPooling2D层的堆栈，后跟几个紧密连接的层。我们的想法是，卷积层和最大池层的堆栈从图像中提取特征。然后，这些特征被展平并馈送到密集连接的层，这些层基于特征的存在来确定图像的类别。</p><p id="fc99" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将从构建<strong class="is hj">卷积库</strong>开始。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="95c4" class="lr ke hi mj b fi mn mo l mp mq">model = models.Sequential()</span><span id="be03" class="lr ke hi mj b fi mr mo l mp mq">model.add(layers.Conv2D(32, (3, 3), activation=’relu’, input_shape=(32, 32, 3)))</span><span id="4581" class="lr ke hi mj b fi mr mo l mp mq">model.add(layers.MaxPooling2D((2, 2)))</span><span id="166b" class="lr ke hi mj b fi mr mo l mp mq">model.add(layers.Conv2D(64, (3, 3), activation=’relu’))</span><span id="0b7f" class="lr ke hi mj b fi mr mo l mp mq">model.add(layers.MaxPooling2D((2, 2)))</span><span id="fd75" class="lr ke hi mj b fi mr mo l mp mq">model.add(layers.Conv2D(64, (3, 3), activation=’relu’))</span></pre><p id="e8a9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第一层</strong></p><p id="54de" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们的数据的输入形状将是32，32，3，我们将在我们的输入数据上处理32个大小为3x3的过滤器。我们还将激活函数relu应用于每个卷积运算的输出。</p><p id="2c1c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第二层</strong></p><p id="0bbf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该层将使用2x2样本和2的跨距执行最大池化操作。</p><p id="8a38" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">其他图层</strong></p><p id="fac8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下一组图层执行非常相似的操作，但将前一图层的要素地图作为输入。他们还将过滤器的频率从32增加到64。我们可以这样做，因为我们的数据在通过各层时会在特殊维度上收缩，这意味着我们可以(在计算上)增加更多深度。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="ea1b" class="lr ke hi mj b fi mn mo l mp mq">model.summary() # let’s have a look at our model so far</span></pre><p id="56f9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">看完摘要后，你应该会注意到我们的图像深度增加了，但是特殊尺寸却大大减少了。</p><h1 id="ad17" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">添加密集层</h1><p id="9eed" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">至此，我们刚刚完成了<strong class="is hj">卷积基</strong>。现在，我们需要提取这些特征，并添加一种方法来对它们进行分类。这就是为什么我们在我们的模型中添加了下面的层。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="247f" class="lr ke hi mj b fi mn mo l mp mq">model.add(layers.Flatten())</span><span id="e66a" class="lr ke hi mj b fi mr mo l mp mq">model.add(layers.Dense(64, activation=’relu’))</span><span id="6108" class="lr ke hi mj b fi mr mo l mp mq">model.add(layers.Dense(10))<br/>model.summary()</span></pre><p id="9602" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以看到，flatten层改变了我们数据的形状，以便我们可以将它馈送到64节点密集层，然后是10个神经元的最终输出层(每个类一个)。</p><h1 id="47a8" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">培养</h1><p id="7abb" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">现在，我们将使用tensorflow推荐的超参数来训练和编译模型。</p><p id="4ba7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注意:这将比以前的型号花费更长的时间！</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="6041" class="lr ke hi mj b fi mn mo l mp mq">model.compile(optimizer=’adam’,</span><span id="ea77" class="lr ke hi mj b fi mr mo l mp mq">loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),</span><span id="5e78" class="lr ke hi mj b fi mr mo l mp mq">metrics=[‘accuracy’])</span><span id="59c0" class="lr ke hi mj b fi mr mo l mp mq">history = model.fit(train_images, train_labels, epochs=4,</span><span id="45c3" class="lr ke hi mj b fi mr mo l mp mq">validation_data=(test_images, test_labels))</span></pre><h1 id="a627" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">评估模型</h1><p id="94a8" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">我们可以通过查看模型在测试数据集上的表现来确定模型的表现</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="05e9" class="lr ke hi mj b fi mn mo l mp mq">est_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)</span><span id="6a5c" class="lr ke hi mj b fi mr mo l mp mq">print(test_acc)</span></pre><p id="c3cf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你应该得到大约70%的准确率。对于这样一个简单的模型来说，这并不坏，但我们将在下面探讨一些更好的计算机视觉方法。</p><h1 id="0547" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">使用小型数据集</h1><p id="adfa" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">在没有数百万张图片的情况下，很难从头开始训练一个表现良好的CNN。这就是为什么我们将学习一些技术，我们可以使用这些技术在只有几千张图片的小数据集上训练CNN。</p><h1 id="eda4" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">数据扩充</h1><p id="56cd" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">为了避免过度拟合并从较小的数据集创建较大的数据集，我们可以使用一种称为数据扩充的技术。这只是在我们的图像上执行随机变换，以便我们的模型可以更好地概括。这些变换可以是压缩、旋转、拉伸，甚至是颜色变化。</p><p id="ddac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">幸运的是，keras可以帮助我们做到这一点。请看下面的代码，这是一个数据扩充的例子。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="c0ba" class="lr ke hi mj b fi mn mo l mp mq">from keras.preprocessing import image</span><span id="9971" class="lr ke hi mj b fi mr mo l mp mq">from keras.preprocessing.image import ImageDataGenerator</span><span id="afc0" class="lr ke hi mj b fi mr mo l mp mq"># creates a data generator object that transforms images</span><span id="53df" class="lr ke hi mj b fi mr mo l mp mq">datagen = ImageDataGenerator(</span><span id="deca" class="lr ke hi mj b fi mr mo l mp mq">rotation_range=40,</span><span id="1ca8" class="lr ke hi mj b fi mr mo l mp mq">width_shift_range=0.2,</span><span id="5811" class="lr ke hi mj b fi mr mo l mp mq">height_shift_range=0.2,</span><span id="9865" class="lr ke hi mj b fi mr mo l mp mq">shear_range=0.2,</span><span id="cfb9" class="lr ke hi mj b fi mr mo l mp mq">zoom_range=0.2,</span><span id="d882" class="lr ke hi mj b fi mr mo l mp mq">horizontal_flip=True,</span><span id="74d4" class="lr ke hi mj b fi mr mo l mp mq">fill_mode=’nearest’)</span><span id="6a89" class="lr ke hi mj b fi mr mo l mp mq"># pick an image to transform</span><span id="2109" class="lr ke hi mj b fi mr mo l mp mq">test_img = train_images[20]</span><span id="2d91" class="lr ke hi mj b fi mr mo l mp mq">img = image.img_to_array(test_img) # convert image to numpy arry</span><span id="b7b7" class="lr ke hi mj b fi mr mo l mp mq">img = img.reshape((1,) + img.shape) # reshape image</span><span id="ea3a" class="lr ke hi mj b fi mr mo l mp mq">i = 0</span><span id="1066" class="lr ke hi mj b fi mr mo l mp mq">for batch in datagen.flow(img, save_prefix=’test’, save_format=’jpeg’): # this loops runs forever until we break, saving images to current directory with specified prefix</span><span id="ed2a" class="lr ke hi mj b fi mr mo l mp mq">plt.figure(i)</span><span id="82ea" class="lr ke hi mj b fi mr mo l mp mq">plot = plt.imshow(image.img_to_array(batch[0]))</span><span id="40fa" class="lr ke hi mj b fi mr mo l mp mq">i += 1</span><span id="a4fd" class="lr ke hi mj b fi mr mo l mp mq">if i &gt; 4: # show 4 images</span><span id="a48b" class="lr ke hi mj b fi mr mo l mp mq">break</span><span id="437b" class="lr ke hi mj b fi mr mo l mp mq">plt.show()</span></pre><h1 id="a198" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">迁移学习</h1><p id="42d4" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">您可能已经注意到，上面的模型需要几分钟来训练，并且只能给出大约70%的准确率。这没问题，但肯定有改进的方法。</p><p id="e0fd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本节中，我们将讨论使用预训练的CNN作为我们自定义网络的一部分，以提高我们模型的准确性。我们知道CNN本身(没有密集层)除了从我们的输入中映射特征的存在之外不做任何事情。这意味着我们可以使用一个预训练的CNN，一个在数百万张图像上训练过的CNN，作为我们模型的开始。这将使我们在最后添加自己的密集分层分类器之前，有一个非常好的卷积基础。事实上，通过使用这种技术，我们可以为相对较小的数据集(&lt; 10，000张图像)训练一个非常好的分类器。这是因为convnet已经非常清楚在图像中寻找什么特征，并且能够非常有效地找到它们。因此，如果我们可以确定特征的存在，那么模型的其余部分需要做的就是确定哪种特征组合构成了特定的图像。</p><h1 id="884a" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">微调</h1><p id="ecc2" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">当我们使用上面定义的技术时，我们经常想要调整卷积基础的最后几层，以便更好地解决我们的特定问题。这包括不接触或重新训练我们的卷积基中的早期层，而只调整最后几层。我们这样做是因为我们基层的第一层非常擅长提取低层次的特征李乐线和边缘，这对于任何类型的图像都是相似的。其中后面的层更擅长拾取非常特殊的特征，如形状甚至眼睛。如果我们调整最终层，那么我们可以只寻找与我们非常具体的问题相关的特征。</p><h1 id="f550" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">使用预训练模型</h1><p id="b999" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">在这一节中，我们将结合我们在上面学到的技术，使用一个预训练的模型和微调来使用一个小数据集对狗和猫的图像进行分类。</p><p id="af95" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">本教程基于TensorFlow文档中的以下指南:</em><a class="ae mh" href="https://www.tensorflow.org/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank"><em class="jo">https://www . tensor flow . org/tutorials/images/transfer _ learning</em></a></p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="bd6f" class="lr ke hi mj b fi mn mo l mp mq">#Imports</span><span id="7eb4" class="lr ke hi mj b fi mr mo l mp mq">import os</span><span id="994b" class="lr ke hi mj b fi mr mo l mp mq">import numpy as np</span><span id="3c72" class="lr ke hi mj b fi mr mo l mp mq">import matplotlib.pyplot as plt</span><span id="2261" class="lr ke hi mj b fi mr mo l mp mq">import tensorflow as tf</span><span id="b1e5" class="lr ke hi mj b fi mr mo l mp mq">keras = tf.keras</span></pre><h1 id="e041" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">资料组</h1><p id="dae6" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">我们将从modoule tensorflow_datatsets加载<em class="jo"> cats_vs_dogs </em>数据集。</p><p id="e5d6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该数据集包含(图像，标签)对，其中图像具有不同的维度和3个颜色通道。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="9a77" class="lr ke hi mj b fi mn mo l mp mq">import tensorflow_datasets as tfds</span><span id="5846" class="lr ke hi mj b fi mr mo l mp mq">tfds.disable_progress_bar()</span><span id="830d" class="lr ke hi mj b fi mr mo l mp mq"># split the data manually into 80% training, 10% testing, 10% validation</span><span id="1f09" class="lr ke hi mj b fi mr mo l mp mq">(raw_train, raw_validation, raw_test), metadata = tfds.load(</span><span id="373c" class="lr ke hi mj b fi mr mo l mp mq">‘cats_vs_dogs’,</span><span id="98c3" class="lr ke hi mj b fi mr mo l mp mq">split=[‘train[:80%]’, ‘train[80%:90%]’, ‘train[90%:]’],</span><span id="c008" class="lr ke hi mj b fi mr mo l mp mq">with_info=True,</span><span id="c299" class="lr ke hi mj b fi mr mo l mp mq">as_supervised=True,<br/>)</span><span id="faaa" class="lr ke hi mj b fi mr mo l mp mq">get_label_name = metadata.features['label'].int2str  # creates a function object that we can use to get labels</span><span id="8d5b" class="lr ke hi mj b fi mr mo l mp mq"># display 2 images from the dataset</span><span id="4455" class="lr ke hi mj b fi mr mo l mp mq">for image, label in raw_train.take(5):</span><span id="8ad0" class="lr ke hi mj b fi mr mo l mp mq">plt.figure()</span><span id="4daf" class="lr ke hi mj b fi mr mo l mp mq">plt.imshow(image)</span><span id="a702" class="lr ke hi mj b fi mr mo l mp mq">plt.title(get_label_name(label))</span></pre><h1 id="05e8" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">数据预处理</h1><p id="a999" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">由于我们的图像大小都不一样，我们需要将它们转换成相同的大小。我们可以在下面创建一个函数来完成这项工作。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="3641" class="lr ke hi mj b fi mn mo l mp mq">IMG_SIZE = 160 # All images will be resized to 160x160</span><span id="d5cc" class="lr ke hi mj b fi mr mo l mp mq">def format_example(image, label):</span><span id="d754" class="lr ke hi mj b fi mr mo l mp mq">“””</span><span id="9560" class="lr ke hi mj b fi mr mo l mp mq">returns an image that is reshaped to IMG_SIZE</span><span id="328c" class="lr ke hi mj b fi mr mo l mp mq">“””</span><span id="812d" class="lr ke hi mj b fi mr mo l mp mq">image = tf.cast(image, tf.float32)</span><span id="d1b2" class="lr ke hi mj b fi mr mo l mp mq">image = (image/127.5) — 1</span><span id="f4a2" class="lr ke hi mj b fi mr mo l mp mq">image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))</span><span id="17d9" class="lr ke hi mj b fi mr mo l mp mq">return image, label</span></pre><p id="e25c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们可以使用<code class="du ms mt mu mj b">.map()</code>将这个函数应用到我们所有的图像上。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="93b0" class="lr ke hi mj b fi mn mo l mp mq">train = raw_train.map(format_example)</span><span id="c2b2" class="lr ke hi mj b fi mr mo l mp mq">validation = raw_validation.map(format_example)</span><span id="67e5" class="lr ke hi mj b fi mr mo l mp mq">test = raw_test.map(format_example)</span></pre><p id="b64e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们来看看我们的图像。</p><p id="bce6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi">[ ]</p><p id="ffdd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于图像，在train.take(2)中标记:</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="ec72" class="lr ke hi mj b fi mn mo l mp mq">plt.figure()</span><span id="0486" class="lr ke hi mj b fi mr mo l mp mq">plt.imshow(image)</span><span id="27f2" class="lr ke hi mj b fi mr mo l mp mq">plt.title(get_label_name(label))</span><span id="38d9" class="lr ke hi mj b fi mr mo l mp mq">Finally we will shuffle and batch the images.</span><span id="3517" class="lr ke hi mj b fi mr mo l mp mq">[ ]</span><span id="99c1" class="lr ke hi mj b fi mr mo l mp mq">BATCH_SIZE = 32</span><span id="1811" class="lr ke hi mj b fi mr mo l mp mq">SHUFFLE_BUFFER_SIZE = 1000</span><span id="249a" class="lr ke hi mj b fi mr mo l mp mq">train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)</span><span id="60ba" class="lr ke hi mj b fi mr mo l mp mq">validation_batches = validation.batch(BATCH_SIZE)</span><span id="596c" class="lr ke hi mj b fi mr mo l mp mq">test_batches = test.batch(BATCH_SIZE)</span></pre><p id="2dd0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，如果我们观察原始图像与新图像的形状，我们会发现它已经发生了变化。</p><p id="06cb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi">[ ]</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="2f96" class="lr ke hi mj b fi mn mo l mp mq">for img, label in raw_train.take(2):</span><span id="4f4a" class="lr ke hi mj b fi mr mo l mp mq">print(“Original shape:”, img.shape)</span><span id="017f" class="lr ke hi mj b fi mr mo l mp mq">for img, label in train.take(2):</span><span id="0449" class="lr ke hi mj b fi mr mo l mp mq">print(“New shape:”, img.shape)</span></pre><h1 id="541e" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">选择预训练模型</h1><p id="a7bf" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">我们将用作我们模型卷积基础的模型是谷歌开发的<strong class="is hj">移动互联网V2 </strong>。这个模型在140万幅图像上进行训练，有1000个不同的类别。</p><p id="2095" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们想使用这个模型，但只是它的卷积基础。因此，当我们加载模型时，我们将指定我们不想加载顶层(分类)层。我们将告诉模型预期的输入形状，并使用来自<em class="jo"> imagenet </em>(谷歌数据集)的预定权重。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="cd60" class="lr ke hi mj b fi mn mo l mp mq">IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)</span><span id="e839" class="lr ke hi mj b fi mr mo l mp mq"># Create the base model from the pre-trained model MobileNet V2</span><span id="f635" class="lr ke hi mj b fi mr mo l mp mq">base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,</span><span id="0e54" class="lr ke hi mj b fi mr mo l mp mq">include_top=False,</span><span id="4fe8" class="lr ke hi mj b fi mr mo l mp mq">weights=’imagenet’)</span><span id="36d2" class="lr ke hi mj b fi mr mo l mp mq">base_model.summary()</span></pre><p id="199d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此时，这个<em class="jo"> base_model </em>将简单地输出一个形状(32，5，5，1280)张量，这是从我们的原始(1，160，160，3)图像中提取的特征。32意味着我们有32层不同的过滤器/特征。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="7345" class="lr ke hi mj b fi mn mo l mp mq">for image, _ in train_batches.take(1):</span><span id="a55d" class="lr ke hi mj b fi mr mo l mp mq">pass</span><span id="2a94" class="lr ke hi mj b fi mr mo l mp mq">feature_batch = base_model(image)</span><span id="b4f0" class="lr ke hi mj b fi mr mo l mp mq">print(feature_batch.shape)</span></pre><h1 id="1ad8" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">冻结底座</h1><p id="06c6" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">术语<strong class="is hj">冻结</strong>是指禁用一个层的训练属性。这仅仅意味着我们不会对训练期间冻结的任何层的权重进行任何更改。这很重要，因为我们不想改变已经学习了权重的卷积基。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="a61b" class="lr ke hi mj b fi mn mo l mp mq">base_model.trainable = False</span><span id="b093" class="lr ke hi mj b fi mr mo l mp mq">base_model.summary()</span></pre><h1 id="cb35" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">添加我们的分类器</h1><p id="3ccd" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">现在我们有了基础层设置，我们可以添加分类器了。我们将使用全局平均池层，而不是展平基础图层的要素地图，该池层将对每个2D要素地图的整个5x5区域进行平均，并为我们返回每个过滤器的单个1280元素矢量。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="f2a0" class="lr ke hi mj b fi mn mo l mp mq">global_average_layer = tf.keras.layers.GlobalAveragePooling2D()</span></pre><p id="23e8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，我们将添加预测层，这将是一个单一的密集神经元。我们可以这样做，因为我们只有两个类要预测。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="267d" class="lr ke hi mj b fi mn mo l mp mq">prediction_layer = keras.layers.Dense(1)</span></pre><p id="3b31" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们将把这些层组合在一个模型中。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="7a99" class="lr ke hi mj b fi mn mo l mp mq">model = tf.keras.Sequential([</span><span id="ad4c" class="lr ke hi mj b fi mr mo l mp mq">base_model,</span><span id="1fa6" class="lr ke hi mj b fi mr mo l mp mq">global_average_layer,</span><span id="8e9c" class="lr ke hi mj b fi mr mo l mp mq">prediction_layer</span><span id="6478" class="lr ke hi mj b fi mr mo l mp mq">])</span><span id="3e1a" class="lr ke hi mj b fi mr mo l mp mq">model.summary()</span></pre><h1 id="219d" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">训练模型</h1><p id="53c3" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">现在我们将训练和编译模型。我们将使用一个非常小的学习率来确保模型不会有任何大的改变。</p><pre class="lh li lj lk fd mi mj mk ml aw mm bi"><span id="e14c" class="lr ke hi mj b fi mn mo l mp mq">base_learning_rate = 0.0001</span><span id="baf6" class="lr ke hi mj b fi mr mo l mp mq">model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),</span><span id="7d62" class="lr ke hi mj b fi mr mo l mp mq">loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),</span><span id="2766" class="lr ke hi mj b fi mr mo l mp mq">metrics=[‘accuracy’])</span><span id="515d" class="lr ke hi mj b fi mr mo l mp mq"># We can evaluate the model right now to see how it does before training it on our new images</span><span id="42e9" class="lr ke hi mj b fi mr mo l mp mq">initial_epochs = 3</span><span id="3bd7" class="lr ke hi mj b fi mr mo l mp mq">validation_steps=20</span><span id="35ff" class="lr ke hi mj b fi mr mo l mp mq">loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)</span><span id="2a09" class="lr ke hi mj b fi mr mo l mp mq"># Now we can train it on our images</span><span id="626a" class="lr ke hi mj b fi mr mo l mp mq">history = model.fit(train_batches,</span><span id="ea3c" class="lr ke hi mj b fi mr mo l mp mq">epochs=initial_epochs,</span><span id="f9ea" class="lr ke hi mj b fi mr mo l mp mq">validation_data=validation_batches)</span><span id="f5f6" class="lr ke hi mj b fi mr mo l mp mq">acc = history.history[‘accuracy’]</span><span id="88e6" class="lr ke hi mj b fi mr mo l mp mq">print(acc)</span><span id="d0fb" class="lr ke hi mj b fi mr mo l mp mq">model.save(“dogs_vs_cats.h5”) # we can save the model and reload it at anytime in the future</span><span id="130a" class="lr ke hi mj b fi mr mo l mp mq">new_model = tf.keras.models.load_model(‘dogs_vs_cats.h5’)</span></pre><p id="1e24" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这就是计算机视觉部分的全部内容！</p><h1 id="d817" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">目标检测</h1><p id="bd5c" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">如果您想了解如何使用tensorflow进行物体检测和识别，请查看下面的指南。</p><p id="369b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae mh" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/models/tree/master/research/object _ detection</a></p><h1 id="fb05" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">来源</h1><ul class=""><li id="c32f" class="jp jq hi is b it lb ix lc jb mv jf mw jj mx jn ju jv jw jx bi translated">"卷积神经网络(CNN):张量流核心."张量流，【www.tensorflow.org/tutorials/images/cnn】T2。</li><li id="e11d" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">"用预训练的ConvNet进行迁移学习:TensorFlow核心."张量流，【www.tensorflow.org/tutorials/images/transfer_learning】的。</li><li id="29d5" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">乔莱·françois.用Python进行深度学习。曼宁出版公司，2018。</li></ul></div></div>    
</body>
</html>