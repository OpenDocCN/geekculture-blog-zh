<html>
<head>
<title>Review — Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation (Deep-ED &amp; Deep-Att)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">综述—用于神经机器翻译的具有快进连接的深度递归模型(Deep-ED &amp; Deep-Att)</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/review-deep-recurrent-models-with-fast-forward-connections-for-neural-machine-translation-e4881ffcf2d1?source=collection_archive---------16-----------------------#2021-11-23">https://medium.com/geekculture/review-deep-recurrent-models-with-fast-forward-connections-for-neural-machine-translation-e4881ffcf2d1?source=collection_archive---------16-----------------------#2021-11-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="3d97" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用快进连接，帮助渐变传播</h2></div><p id="30ca" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi jt translated"><span class="l ju jv jw bm jx jy jz ka kb di">在</span>这个故事里，回顾了百度研究院的<strong class="iz hj">深度递归模型与神经机器翻译的快进连接</strong>、(Deep-ED &amp; Deep-Att)。在本文中:</p><ul class=""><li id="756c" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated">介绍了一种基于深长短时记忆(LSTM)的新型线性连接，命名为<strong class="iz hj">快进(F-F)连接</strong>。</li><li id="1d79" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated">这些F-F连接有助于传播梯度并构建深度为16的深层拓扑。</li></ul><p id="d1a0" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是一篇发表在<strong class="iz hj"> 2016 TACL </strong>的论文，被引用超过<strong class="iz hj"> 180次</strong>，其中TACL<strong class="iz hj">影响力得分为6.43 </strong>。(<a class="kq kr ge" href="https://medium.com/u/aff72a0c1243?source=post_page-----e4881ffcf2d1--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="6d49" class="kz la hi bd lb lc ld le lf lg lh li lj io lk ip ll ir lm is ln iu lo iv lp lq bi translated">概述</h1><ol class=""><li id="f4a9" class="kc kd hi iz b ja lr jd ls jg lt jk lu jo lv js lw ki kj kk bi translated"><strong class="iz hj"> F-F连接</strong></li><li id="8275" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js lw ki kj kk bi translated"><strong class="iz hj"> Deep-ED和Deep-Att:网络架构</strong></li><li id="e43f" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js lw ki kj kk bi translated"><strong class="iz hj">实验结果</strong></li></ol></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="8576" class="kz la hi bd lb lc ld le lf lg lh li lj io lk ip ll ir lm is ln iu lo iv lp lq bi translated">1.F-F连接</h1><h2 id="4e78" class="lx la hi bd lb ly lz ma lf mb mc md lj jg me mf ll jk mg mh ln jo mi mj lp mk bi translated">1.1.RNN的F-F连接</h2><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es ml"><img src="../Images/5aa3fdbdb708072b5782747d5e5b23bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*VPCqMTbZSa5nZlKk-HASug.png"/></div><figcaption class="mt mu et er es mv mw bd b be z dx">RNN models. The recurrent use of a hidden</figcaption></figure><ul class=""><li id="3c82" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated"><strong class="iz hj"> (a):基本RNN: </strong>当一个输入序列{ <em class="mx"> x </em> 1，…，<em class="mx"> xm </em> }给一个递归层，<strong class="iz hj">在每个时间步<em class="mx"> t </em> </strong>的输出<em class="mx"> ht </em>可以计算为:</li></ul><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es my"><img src="../Images/2bb9e05f65c35876c466b5cd245c9a60.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*4oy1KnaoIcpyZJqFU96lDA.png"/></div></figure><ul class=""><li id="1706" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated"><strong class="iz hj"> (b):具有中间计算状态和加法运算(+)并随后激活的基本RNN。</strong>由“f”块和“r”块组成，<strong class="iz hj">等价于(a) </strong>。</li><li id="b928" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated">这个计算可以等效地分成两个连续的步骤:</li><li id="0745" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated"><strong class="iz hj">、【f】块</strong>、<strong class="iz hj">前馈计算、</strong>(b)中的左半部分:</li></ul><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es mz"><img src="../Images/15cc203cc01a89f4600e7c390e50418d.png" data-original-src="https://miro.medium.com/v2/resize:fit:194/format:webp/1*9AEDqRLOuwEULLTa-65lDw.png"/></div></figure><ul class=""><li id="3267" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated"><strong class="iz hj">“r”程序块，循环计算</strong>，右部分和求和运算(+)，然后在(b)中激活。</li></ul><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es na"><img src="../Images/674074bc15b33b1a61449cce3e976572.png" data-original-src="https://miro.medium.com/v2/resize:fit:314/format:webp/1*Rtq0KvEyCeFJirF-LOulKg.png"/></div></figure><ul class=""><li id="f963" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated"><strong class="iz hj"> (c):由红色虚线表示的具有F-F连接的两个堆叠的RNN层</strong>:</li></ul><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es nb"><img src="../Images/d9ec366a8bc3b2d86d932fec3698e1d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*U3aWhqryu-hOi45jAs_Ydw.png"/></div></figure><ul class=""><li id="b1ec" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated">其中<strong class="iz hj"> [，] </strong>表示<strong class="iz hj">串联</strong>。</li><li id="25ab" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated">F-F连接<strong class="iz hj">连接相邻递归层的两个前馈计算模块“F”。</strong></li><li id="ba6c" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated">F-F连接的路径既不包含非线性激活，也不包含递归计算。它为<strong class="iz hj">提供了信息传播</strong>的快速路径。</li></ul><h2 id="d2de" class="lx la hi bd lb ly lz ma lf mb mc md lj jg me mf ll jk mg mh ln jo mi mj lp mk bi translated">1.2.双向LSTM中的F-F连接</h2><ul class=""><li id="88f3" class="kc kd hi iz b ja lr jd ls jg lt jk lu jo lv js kh ki kj kk bi translated">类似地，带有F-F连接的<strong class="iz hj">深层双向LSTM模型</strong>的计算:</li></ul><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es nc"><img src="../Images/acb2f9007d21a80efc4ec3c2af12dd0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*SJRBveSGI6_pQEb9h1KyTw.png"/></div></figure><ul class=""><li id="d39d" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated">此外，<strong class="iz hj">在上述等式中引入了另外两个运算</strong>:</li></ul><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es nd"><img src="../Images/31de594f7be9a193a34882b7f2b04415.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*PnFtNudT13XgfRasvo9kXg.png"/></div></figure><ul class=""><li id="e70c" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated"><strong class="iz hj"> Half( <em class="mx"> f </em> ) </strong>表示<em class="mx"> f </em> 的<strong class="iz hj">前半部分元素，<strong class="iz hj"> Dr( <em class="mx"> h </em> ) </strong>是<a class="ae ne" href="https://sh-tsang.medium.com/paper-dropout-a-simple-way-to-prevent-neural-networks-from-overfitting-image-classification-a74b369b4b8e" rel="noopener"> <strong class="iz hj">的辍学</strong> </a> <strong class="iz hj"> </strong>操作。</strong></li><li id="3351" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated"><strong class="iz hj">使用Half()是为了减少参数大小</strong>并且不影响性能。</li></ul></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="4642" class="kz la hi bd lb lc ld le lf lg lh li lj io lk ip ll ir lm is ln iu lo iv lp lq bi translated">2.深度ED和深度Att:网络架构</h1><figure class="mm mn mo mp fd mq er es paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="er es nf"><img src="../Images/9fdd657bad951c380fa1a726c343855f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QuSLJ8pANDUZFhmjiBy9Bw.png"/></div></div><figcaption class="mt mu et er es mv mw bd b be z dx"><strong class="bd lb">Deep-ED and Deep-Att: Network Architecture</strong></figcaption></figure><h2 id="24e0" class="lx la hi bd lb ly lz ma lf mb mc md lj jg me mf ll jk mg mh ln jo mi mj lp mk bi translated"><strong class="ak"> 2.1。编码器</strong></h2><ul class=""><li id="8819" class="kc kd hi iz b ja lr jd ls jg lt jk lu jo lv js kh ki kj kk bi translated">LSTM层是堆叠的，所谓的交错双向编码器。</li></ul><h2 id="70da" class="lx la hi bd lb ly lz ma lf mb mc md lj jg me mf ll jk mg mh ln jo mi mj lp mk bi translated">2.2.连接</h2><ul class=""><li id="9463" class="kc kd hi iz b ja lr jd ls jg lt jk lu jo lv js kh ki kj kk bi translated">作为引入F-F连接的结果，我们有<strong class="iz hj"> 4个输出向量</strong>(两列的<em class="mx"> hnet </em>和<em class="mx"> fnet </em>)。</li><li id="ae8f" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated">对于<strong class="iz hj">深插</strong>，<strong class="iz hj"> <em class="mx"> et </em>为静态</strong>。</li><li id="b86e" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated">对于<strong class="iz hj"> Deep-Att </strong>，<strong class="iz hj">只将每个时间步的4个输出向量串接起来得到<em class="mx">et</em>T39】，并使用<a class="ae ne" href="https://sh-tsang.medium.com/review-neural-machine-translation-by-jointly-learning-to-align-and-translate-3b381fc032e3" rel="noopener">注意力解码器</a>中的软注意力机制从<em class="mx"> et </em>计算出最终表示<em class="mx"> ct </em>:</strong></li></ul><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es nk"><img src="../Images/ab7d42da474f9487c1ee1098527241ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*44oH6rd2kZoxB8gVOkt48A.png"/></div></figure><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es nl"><img src="../Images/3d5b47b80b609feb18b55f99bf9734ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*ZYTFCvqmnpPJelz5uzQiYw.png"/></div></figure><ul class=""><li id="6137" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated">其中:</li></ul><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es nm"><img src="../Images/104509a0639788b6c6015a346933c358.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*zFG6m_5WNUUSBI2sbg7b8w.png"/></div></figure><ul class=""><li id="9ffa" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated">对于<strong class="iz hj"> Deep-Att </strong>来说，为了减少内存开销，<strong class="iz hj">将<em class="mx"> et与<em class="mx"> Wp </em>线性投影成1/4维大小的矢量</em></strong>。</li><li id="4393" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated">(有兴趣请随意阅读<a class="ae ne" href="https://sh-tsang.medium.com/review-neural-machine-translation-by-jointly-learning-to-align-and-translate-3b381fc032e3" rel="noopener">注意解码器</a>。)</li></ul><h2 id="b3e0" class="lx la hi bd lb ly lz ma lf mb mc md lj jg me mf ll jk mg mh ln jo mi mj lp mk bi translated"><strong class="ak"> 2.3。解码器</strong></h2><ul class=""><li id="3591" class="kc kd hi iz b ja lr jd ls jg lt jk lu jo lv js kh ki kj kk bi translated">在softmax之前有一列<em class="mx">和</em>堆叠的LSTM层。也使用F-F连接。</li></ul><h2 id="e7b1" class="lx la hi bd lb ly lz ma lf mb mc md lj jg me mf ll jk mg mh ln jo mi mj lp mk bi translated">2.4.其他详细信息</h2><ul class=""><li id="0165" class="kc kd hi iz b ja lr jd ls jg lt jk lu jo lv js kh ki kj kk bi translated"><strong class="iz hj">源语言和目标语言的256维单词嵌入</strong>。</li><li id="3137" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated">所有<strong class="iz hj"> LSTM </strong>层都有<strong class="iz hj"> 512个存储单元</strong>。</li><li id="867c" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated"><strong class="iz hj">对于Deep-ED和Deep-Att，ct 的尺寸分别为5120和1280。</strong></li><li id="aaae" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated">使用波束搜索。</li><li id="216e" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated"><strong class="iz hj">运行<strong class="iz hj"> 10天</strong>的4到8个GPU机器</strong>(每个机器有4个K40 GPU卡)在数据批处理级别训练完整模型。每次通过需要将近1.5天。</li><li id="bd8d" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated"><a class="ae ne" href="https://sh-tsang.medium.com/paper-dropout-a-simple-way-to-prevent-neural-networks-from-overfitting-image-classification-a74b369b4b8e" rel="noopener">压差</a>比<em class="mx"> pd </em>为0.1。</li><li id="c58b" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated">每批有500~800个序列。</li></ul></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="7e34" class="kz la hi bd lb lc ld le lf lg lh li lj io lk ip ll ir lm is ln iu lo iv lp lq bi translated">3.实验结果</h1><h2 id="8d08" class="lx la hi bd lb ly lz ma lf mb mc md lj jg me mf ll jk mg mh ln jo mi mj lp mk bi translated">3.1.<strong class="ak">英语到法语</strong></h2><figure class="mm mn mo mp fd mq er es paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="er es nn"><img src="../Images/ad8e604054e2d08bef5399597b3e946f.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*O_3wP-wk5F1F4CFAPB3JdQ.png"/></div></div><figcaption class="mt mu et er es mv mw bd b be z dx"><strong class="bd lb">English-to-French task</strong></figcaption></figure><ul class=""><li id="5740" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated">具有六层的先前最佳单NMT编码器-解码器模型(Enc-Dec)实现BLEU=31.5。</li><li id="61a1" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated"><strong class="iz hj"> Deep-ED </strong>获得36.3 的<strong class="iz hj"> BLEU评分，领先Enc-Dec模型4.8 BLEU分，优于<a class="ae ne" href="https://sh-tsang.medium.com/review-neural-machine-translation-by-jointly-learning-to-align-and-translate-3b381fc032e3" rel="noopener">注意力解码器/RNNSearch </a>。</strong></li><li id="c446" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated">对于<strong class="iz hj"> Deep-Att </strong>，性能进一步提升至<strong class="iz hj"> 37.7 </strong>。</li><li id="ea0f" class="kc kd hi iz b ja kl jd km jg kn jk ko jo kp js kh ki kj kk bi translated">还列出了传统SMT系统之前的最先进性能(Durrani等人，2014年)，BLEU为37.0。</li></ul><blockquote class="no np nq"><p id="a7d2" class="ix iy mx iz b ja jb ij jc jd je im jf nr jh ji jj ns jl jm jn nt jp jq jr js hb bi translated">这是<strong class="iz hj">第一次</strong>以端到端形式<strong class="iz hj">训练的<strong class="iz hj">单NMT模型</strong>在这项任务中击败最好的常规系统</strong>。</p></blockquote><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es nu"><img src="../Images/c0751ede50f5a138dfea4913d56327f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*y7j1DRWKPOnVq2IbUMG7sA.png"/></div><figcaption class="mt mu et er es mv mw bd b be z dx"><strong class="bd lb">Effect of F-F Connections</strong></figcaption></figure><ul class=""><li id="85b5" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated">F-F连接带来了在BLEU上的改进。</li></ul><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es nv"><img src="../Images/83baa39cdea9a0535b6cc7ee1928992a.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*K6MEmdf1Yd30UKYuL6cd8g.png"/></div><figcaption class="mt mu et er es mv mw bd b be z dx"><strong class="bd lb">Different LSTM layer width in Deep-Att</strong></figcaption></figure><ul class=""><li id="8f33" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated">使用<strong class="iz hj">两倍大的LSTM层宽</strong>1024后，Deep-Att只能获得33.8的BLEU评分。与F-F 对应的Deep-Att后面还有<strong class="iz hj">。</strong></li></ul><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es nw"><img src="../Images/041100b43646255c5de6c4d50a7818b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*wCkPc1TbsRxU7Gx0poMHUw.png"/></div><figcaption class="mt mu et er es mv mw bd b be z dx"><strong class="bd lb">Effect of the interleaved bi-directional encoder</strong></figcaption></figure><ul class=""><li id="ddcc" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated"><strong class="iz hj">对于双向LSTM </strong>，对于Deep-Att和Deep-ED，这两个编码器之间有大约1.5点的间隙<strong class="iz hj"/></li></ul><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es nx"><img src="../Images/78a41b9a8cfdfa8d3de229fc89abe076.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*xNB5UejuSwHtBNtyidH7AQ.png"/></div><figcaption class="mt mu et er es mv mw bd b be z dx"><strong class="bd lb">Deep-Att with different model depths</strong></figcaption></figure><ul class=""><li id="8a52" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated"><strong class="iz hj">在<em class="mx"> ne </em> =9、<em class="mx"> nd </em> =7 </strong>的情况下，Deep-Att的<strong class="iz hj"> best </strong>得分为37.7。</li></ul><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es ny"><img src="../Images/4024229df0f786c267f645dfe6acff2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*XY8o_Vq97liAZMKYiFE7gw.png"/></div><figcaption class="mt mu et er es mv mw bd b be z dx"><strong class="bd lb">Encoders with different number of columns and LSTM layer width</strong></figcaption></figure><ul class=""><li id="0089" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated"><strong class="iz hj">发现带有<strong class="iz hj">单编码列</strong>的1.1 BLEU点退化</strong>。</li></ul><h2 id="974e" class="lx la hi bd lb ly lz ma lf mb mc md lj jg me mf ll jk mg mh ln jo mi mj lp mk bi translated">3.2.英语到德语</h2><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="er es nz"><img src="../Images/785fab33e5117b301a1f02ea310ce656.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*YFXbKVjy7itavhfDqvxN1w.png"/></div><figcaption class="mt mu et er es mv mw bd b be z dx"><strong class="bd lb">English-to-German task</strong></figcaption></figure><ul class=""><li id="2152" class="kc kd hi iz b ja jb jd je jg ke jk kf jo kg js kh ki kj kk bi translated">BLEU= <strong class="iz hj"> 20.6 </strong>的提议<strong class="iz hj">单模型</strong>结果<strong class="iz hj">类似于传统SMT结果20.7 </strong> (Buck et al .，2014)，并且优于<a class="ae ne" href="https://sh-tsang.medium.com/review-neural-machine-translation-by-jointly-learning-to-align-and-translate-3b381fc032e3" rel="noopener">注意力解码器/RNNSearch </a>。</li></ul></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><p id="d544" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">还有其他结果，如后处理和集成结果。如果感兴趣，请随意阅读该文件。</p></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h2 id="15de" class="lx la hi bd lb ly lz ma lf mb mc md lj jg me mf ll jk mg mh ln jo mi mj lp mk bi translated">参考</h2><p id="9d2c" class="pw-post-body-paragraph ix iy hi iz b ja lr ij jc jd ls im jf jg oa ji jj jk ob jm jn jo oc jq jr js hb bi translated">【2016 TACL】【Deep-ED &amp; Deep-Att】<br/><a class="ae ne" href="https://arxiv.org/abs/1606.04199" rel="noopener ugc nofollow" target="_blank">具有用于神经机器翻译的快进连接的深度递归模型</a></p><h2 id="311e" class="lx la hi bd lb ly lz ma lf mb mc md lj jg me mf ll jk mg mh ln jo mi mj lp mk bi translated">自然语言处理</h2><p id="c048" class="pw-post-body-paragraph ix iy hi iz b ja lr ij jc jd ls im jf jg oa ji jj jk ob jm jn jo oc jq jr js hb bi translated"><strong class="iz hj">序列模型:2014</strong>[<a class="ae ne" href="https://sh-tsang.medium.com/review-empirical-evaluation-of-gated-recurrent-neural-networks-on-sequence-modeling-gru-2adb86559257" rel="noopener">GRU</a>[<a class="ae ne" href="https://sh-tsang.medium.com/review-distributed-representations-of-sentences-and-documents-doc2vec-86ef911d4515" rel="noopener">doc 2 vec</a>]<br/><strong class="iz hj">语言模型:2007</strong>[<a class="ae ne" href="https://sh-tsang.medium.com/review-adaptive-importance-sampling-to-accelerate-training-of-a-neural-probabilistic-language-e71244001b13" rel="noopener">Bengio TNN’07</a>]<strong class="iz hj">2013</strong>[<a class="ae ne" href="https://sh-tsang.medium.com/review-word2vec-efficient-estimation-of-word-representations-in-vector-space-f9dbe2145afa" rel="noopener">word 2 vec</a>][<a class="ae ne" href="https://sh-tsang.medium.com/review-learning-word-embeddings-efficiently-with-noise-contrastive-estimation-nce-dba1c345c153" rel="noopener">NCE</a>][<a class="ae ne" href="https://sh-tsang.medium.com/review-distributed-representations-of-words-and-phrases-and-their-compositionality-negative-ab9ebfc3f041" rel="noopener">负采样</a><br/><strong class="iz hj">句子嵌入:2013 <strong class="iz hj">2015</strong><a class="ae ne" href="https://sh-tsang.medium.com/review-neural-machine-translation-by-jointly-learning-to-align-and-translate-3b381fc032e3" rel="noopener">注意力解码器/rnn search</a><strong class="iz hj">2016</strong><a class="ae ne" href="https://sh-tsang.medium.com/review-googles-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-518595d87226" rel="noopener">GNMT</a><a class="ae ne" href="https://sh-tsang.medium.com/review-neural-machine-translation-in-linear-time-bytenet-e5a50bfb462b" rel="noopener">ByteNet</a><a class="ae ne" href="https://sh-tsang.medium.com/review-deep-recurrent-models-with-fast-forward-connections-for-neural-machine-translation-e4881ffcf2d1" rel="noopener">Deep-ED&amp;Deep-Att</a><br/><strong class="iz hj">图片字幕:</strong><strong class="iz hj">2015</strong><a class="ae ne" href="https://sh-tsang.medium.com/review-deep-captioning-with-multimodal-recurrent-neural-networks-m-rnn-4417d82ef4f5" rel="noopener">m-RNN</a></strong></p><h2 id="06a4" class="lx la hi bd lb ly lz ma lf mb mc md lj jg me mf ll jk mg mh ln jo mi mj lp mk bi translated"><a class="ae ne" href="https://sh-tsang.medium.com/overview-my-reviewed-paper-lists-tutorials-946ce59fbf9e" rel="noopener">我以前的其他论文阅读材料</a></h2></div></div>    
</body>
</html>