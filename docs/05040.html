<html>
<head>
<title>Operationalizing Ethical AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">操作伦理人工智能</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/operationalizing-ethical-ai-8a8cd296a40a?source=collection_archive---------48-----------------------#2021-07-07">https://medium.com/geekculture/operationalizing-ethical-ai-8a8cd296a40a?source=collection_archive---------48-----------------------#2021-07-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/457005d4085df0f7a86d38e9997c0798.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hTLcqzc1TmxpPfHMGQWGEA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Photo by <a class="ae iu" href="https://unsplash.com/@markuswinkler?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Markus Winkler</a> on <a class="ae iu" href="https://unsplash.com/s/photos/artificial-intelligence?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="e8de" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">伦理人工智能的需要</h1><p id="a66d" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">鉴于日益扩大的<a class="ae iu" href="https://psu.pb.unizin.org/ist110/chapter/9-3-the-digital-divide/" rel="noopener ugc nofollow" target="_blank">数字鸿沟</a>，确保人工智能和一般技术以考虑系统差异的方式应用的道德准则的需求变得至关重要。当我们考虑人工智能的深远范围时，技术来源的任何<a class="ae iu" href="https://venturebeat.com/2020/09/24/in-facial-recognition-challenge-top-ranking-algorithms-show-bias-against-black-women/" rel="noopener ugc nofollow" target="_blank">偏差</a>都被放大了，这些偏差的<a class="ae iu" href="https://venturebeat.com/2020/11/12/why-ai-cant-move-forward-without-diversity-equity-and-inclusion/" rel="noopener ugc nofollow" target="_blank">影响</a>不能被低估。解决这些偏见的一种方法是通过伦理原则，确保人工智能不是由同质群体创造的或为同质群体创造的。</p><p id="7734" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">最近人工智能伦理白皮书的扩散阐明了一个全球共识，即人工智能必须以符合伦理的方式使用，并为人类造福。然而，关于操作伦理人工智能的实际指导还没有出现。一个通用的框架来操作，甚至可以想象执行，伦理人工智能可能是过于雄心勃勃。但作为一名从人权律师转向风投的人，我坚信，通过以下建议，人工智能可以被用来造福人类。</p><h1 id="9ed1" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">实现道德人工智能的5种方法</h1><h2 id="ba08" class="kw iw hi bd ix kx ky kz jb la lb lc jf ke ld le jj ki lf lg jn km lh li jr lj bi translated">1.以人为本</h2><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/2c30478a04c6fc23f99ef94f42a2a34a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U0GRwuOlCtEXOdzqHTfuoQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Photo by <a class="ae iu" href="https://unsplash.com/@pavement_special?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Riccardo Annandale</a> on <a class="ae iu" href="https://unsplash.com/s/photos/ethics?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="cf13" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">对人工智能最大的恐惧之一是这种“黑匣子”的感知，它将越来越多地控制我们的生活。作为一个“非技术人员”，我能理解这种对未知和无法解释的恐惧。然而，道德人工智能的普遍原则之一是透明和信任。为了让人工智能变得透明和可解释——它必须在设计中以人为中心。</p><p id="ab44" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">根据ISO标准，以人为本是一种允许系统提高我们作为人类的效率并改善我们福祉的方法。但是这到底意味着什么呢？这意味着在开发的每个阶段，都应该考虑到“用户”，即人。除了人工智能的承诺和宣传，以人为本还意味着对人工智能工具从长远来看可能带来的好处和危害保持透明。</p><p id="bf3d" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">总的来说，人工智能和技术永远不会取代人类；伦理人工智能通过增加我们的能力来放大和提升人类。同样，人工智能永远不应该是一个“黑匣子”，只有少数人才能理解或使用。以人为中心的人工智能应该能够被所有用户理解和解释——包括我们这些不太精通技术的人。</p><h2 id="b62d" class="kw iw hi bd ix kx ky kz jb la lb lc jf ke ld le jj ki lf lg jn km lh li jr lj bi translated">2.具有可操作性</h2><p id="002d" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">许多伦理人工智能已经理论化，但没有任何实际指导。但是，未能实施道德人工智能可能会威胁到底线，并使公司面临<a class="ae iu" href="https://hbr.org/2020/10/a-practical-guide-to-building-ethical-ai" rel="noopener ugc nofollow" target="_blank">监管、法律和声誉风险</a>——更不用说产品开发的低效率了。</p><p id="17aa" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">人工智能伦理仍然模糊不清，难以实施，有意义的行动往往被表面的承诺<a class="ae iu" href="https://www.technologyreview.com/2019/12/27/57/ai-ethics-washing-time-to-act/" rel="noopener ugc nofollow" target="_blank">所取代</a>。事实上，<a class="ae iu" href="https://venturebeat.com/2019/07/17/how-ai-companies-can-avoid-ethics-washing/" rel="noopener ugc nofollow" target="_blank">“道德清洗”</a>是科技社区中一个日益严重的问题。最近的一个例子是谷歌的人工智能道德委员会，该委员会没有否决权，其成员激起了强烈的反对，并立即导致其解散。</p><p id="e6f3" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">为了避免这种类型的争议，一些实用的建议包括成立道德委员会、任务组或某种包容计划，让各种利益相关者、主题专家和现有团队成员参与进来，以提供战略指导和组织监督。最重要的是，<a class="ae iu" href="https://venturebeat.com/2019/07/17/how-ai-companies-can-avoid-ethics-washing/" rel="noopener ugc nofollow" target="_blank">受影响方</a>必须包括在内，以确保决策不是由同质群体做出的。<a class="ae iu" href="https://www.forbes.com/sites/falonfatemi/2020/02/28/how-companies-should-answer-the-call-for-responsible-ai/?sh=471fbea813f5" rel="noopener ugc nofollow" target="_blank">高管和关键决策者</a>的参与对于建立组织意识和激励识别道德风险也至关重要。</p><h2 id="50db" class="kw iw hi bd ix kx ky kz jb la lb lc jf ke ld le jj ki lf lg jn km lh li jr lj bi translated">3.具有变革性</h2><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/4ff1dfa8cedc955fc676fb497c0d7c11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RXXmn6ooiRJNgoKn4IbZcQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Photo by <a class="ae iu" href="https://unsplash.com/@noahbuscher?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Noah Buscher</a> on <a class="ae iu" href="https://unsplash.com/s/photos/plant-in-hands?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="1a0c" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">尽管道德的本质是“灰色地带”，但有道德的人工智能可以成为强大的善的力量，实现技术成为伟大均衡器的潜力。但为了实现这一潜力，人工智能需要具有变革性，并超越公司“人工智能为善”倡议的营销策略。为了迎接实施道德人工智能的挑战，并利用人工智能的力量解决复杂的全球问题，公司内部需要进行深刻的转型变革。</p><p id="b67e" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">然而，这种变革性的变化需要不做作，诚实地面对技术的局限性；单靠一个人工智能工具无法解决困扰社会几十年的复杂问题。在我们与<a class="ae iu" href="https://www.wired.com/story/opinion-ai-for-good-is-often-bad/" rel="noopener ugc nofollow" target="_blank">当地专家和最接近问题的领导人接触时，需要一定程度的谦逊。解决全球问题需要那些懂技术的人，但更重要的是，需要那些站在问题前沿的人，包括非政府组织、政府和其他公共实体。</a></p><h2 id="f767" class="kw iw hi bd ix kx ky kz jb la lb lc jf ke ld le jj ki lf lg jn km lh li jr lj bi translated">4.让公共和私人领域都参与进来</h2><p id="3da1" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">通过人工智能和整体技术解决全球问题的复杂性，不仅需要一个变革的过程，还需要一个涉及公共和私营部门的多方面解决方案。事实上，安永会计师事务所最近的一项调查发现，公共部门和私营部门之间的脱节会导致<a class="ae iu" href="https://www.ey.com/en_gl/news/2020/07/ey-global-study-finds-disconnect-on-ethical-artificial-intelligence-priorities-between-public-and-private-sector" rel="noopener ugc nofollow" target="_blank">道德风险</a>增加。</p><p id="a242" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">此外，我们不应该将仅由私营部门领导的道德规范或人工智能治理合法化。为了创造既能支持新兴技术进步又能提供保护人权和社会价值观的正确护栏的创新治理解决方案，公私合作势在必行。</p><h2 id="c416" class="kw iw hi bd ix kx ky kz jb la lb lc jf ke ld le jj ki lf lg jn km lh li jr lj bi translated">5.公平</h2><p id="37b9" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">人工智能发展的加速步伐令人震惊，新的现实世界应用每天都在创造更多未解的问题。鉴于数字鸿沟，也有一种紧迫感，以确保最新的人工智能技术不只是由特权阶层获得。</p><p id="a530" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">政策制定者正在认识到确保技术不仅仅是由硅谷人设计并为他们服务所需的<a class="ae iu" rel="noopener" href="/berkman-klein-center/helping-global-policymakers-navigate-ais-challenges-and-opportunities-11b128687cad">包容战略</a>。人工智能和新兴技术需要反映全球人口和文化的多样性。毕竟，AI治理的许多挑战和机遇本来就是地方性的；一刀切的方法不适用于全球经验和现实的多样性。</p><p id="b0f0" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">确保那些负责创建人工智能工具的人不是同质的也很关键；多样化的人工智能团队可以帮助<a class="ae iu" href="https://venturebeat.com/2020/11/12/why-ai-cant-move-forward-without-diversity-equity-and-inclusion/" rel="noopener ugc nofollow" target="_blank">减轻不必要的人工智能偏见</a>。从根本上说，没有公平和包含不同的观点，人工智能就无法充分发挥其潜力来解决复杂的全球问题。</p><h1 id="0002" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">AI为好</h1><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/9e77c2e76391c1dd7938c8f1375f96ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XWxAfca8sqAutJ5d2mwKLQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Photo by <a class="ae iu" href="https://unsplash.com/@snowidesignz?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Elias Maurer</a> on <a class="ae iu" href="https://unsplash.com/s/photos/heart-hands?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="f362" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">随着我们不断实现技术突破的新高度，我们，尤其是我们这些在世界投资领域的人，应该让技术专家、创始人和企业家负起责任。愿我们确保正在创造的技术是合乎道德的，以人为本的，并且真诚地追求技术作为伟大均衡器的愿望。</p><p id="78e8" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">为了实现这一强大的愿望，实施道德人工智能可以发挥关键作用。如果有道德的人工智能可以操作化——通过以人为本、可操作、具有变革性、公共和私营部门的参与以及公平——那么技术就可以真正成为差距的拉平器。通过确保人工智能是道德的，我们可以永远释放人工智能的力量。</p></div></div>    
</body>
</html>