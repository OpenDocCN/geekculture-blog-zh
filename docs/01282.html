<html>
<head>
<title>Let’s Deep Dive into Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让我们深入研究逻辑回归</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/lets-deep-dive-into-logistic-regression-91fc0806e54b?source=collection_archive---------16-----------------------#2021-04-04">https://medium.com/geekculture/lets-deep-dive-into-logistic-regression-91fc0806e54b?source=collection_archive---------16-----------------------#2021-04-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="c38c" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">逻辑回归是一种机器学习分类算法，用于预测分类因变量的概率<strong class="il hj">。这是分类问题的线性回归模型的扩展。与输出连续数值的线性回归不同，逻辑回归使用<strong class="il hj">逻辑sigmoid </strong>函数转换其输出，以返回<strong class="il hj">一个概率值</strong>，该概率值可以映射到两个或更多个<strong class="il hj">离散类。</strong></strong></p></blockquote><p id="e32f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">在本节中，我们将尝试了解更多信息:</p><ol class=""><li id="b4e6" class="jk jl hi il b im in iq ir jh jm ji jn jj jo jg jp jq jr js bi translated"><strong class="il hj">逻辑回归系数</strong></li><li id="1ed2" class="jk jl hi il b im jt iq ju jh jv ji jw jj jx jg jp jq jr js bi translated"><strong class="il hj">逻辑回归的最大似然</strong></li></ol><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es jy"><img src="../Images/0e9d869c794cb420852f97d401a2225c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7rny5XVMxgtGnYR7.png"/></div></div></figure><h2 id="955c" class="kk kl hi bd km kn ko kp kq kr ks kt ku jh kv kw kx ji ky kz la jj lb lc ld le bi translated"><strong class="ak">逻辑回归和线性回归的比较</strong></h2><p id="2194" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jh lh iw ix ji li ja jb jj lj je jf jg hb bi translated">给出学习时间和考试分数的数据。线性回归和逻辑回归可以预测不同的事情:</p><ul class=""><li id="4f8a" class="jk jl hi il b im in iq ir jh jm ji jn jj jo jg lk jq jr js bi translated">线性回归可以帮助我们在0-100的范围内预测学生的考试成绩。线性回归预测是连续的(一个范围内的数字)。在线性回归中，<strong class="il hj">我们使用“最小二乘法”拟合直线。我们找到最小化残差平方和的线。</strong></li><li id="08b3" class="jk jl hi il b im jt iq ju jh jv ji jw jj jx jg lk jq jr js bi translated">逻辑回归分析可以帮助我们预测学生是通过还是失败。逻辑回归预测是离散的。我们还可以查看模型分类下的概率得分。</li></ul><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es ll"><img src="../Images/9e1ff9a0eb687a29745273e1e072b309.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*JWpgU5T5ffvFVvbiiR6SFA.png"/></div></figure><ul class=""><li id="1276" class="jk jl hi il b im in iq ir jh jm ji jn jj jo jg lk jq jr js bi translated">逻辑回归预测某事物是<strong class="il hj"> <em class="ik">真</em> </strong>还是<strong class="il hj"> <em class="ik">假</em></strong>而不是预测某事物连续像<strong class="il hj"> <em class="ik">大小</em>。</strong></li><li id="0ed0" class="jk jl hi il b im jt iq ju jh jv ji jw jj jx jg lk jq jr js bi translated">此外，逻辑回归拟合的不是数据的直线，而是“S”形的“逻辑函数”。曲线从0到1，这意味着，曲线告诉我们<strong class="il hj">上图中的物体根据其重量肥胖与否的概率</strong>。</li><li id="597d" class="jk jl hi il b im jt iq ju jh jv ji jw jj jx jg lk jq jr js bi translated">虽然逻辑回归告诉一个对象是否肥胖的概率，但它通常用于分类。举个例子，如果一个物体的概率&gt; 50%，那么我们就把它归类为肥胖，否则我们就把它归类为“不肥胖”。</li></ul><p id="939e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj">逻辑回归的步骤</strong></p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es lm"><img src="../Images/856c6cea7deeca81b07de9f64187837a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mkFC-waSbVxWPIYF"/></div></div></figure><h1 id="4805" class="ln kl hi bd km lo lp lq kq lr ls lt ku lu lv lw kx lx ly lz la ma mb mc ld md bi translated"><strong class="ak"> 1。逻辑回归:系数(连续变量)</strong></h1><p id="d1ad" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jh lh iw ix ji li ja jb jj lj je jf jg hb bi translated">第1部分，当我们使用一个<strong class="il hj">连续变量</strong>(如体重)预测肥胖时，我们将从谈论<strong class="il hj">逻辑回归</strong>开始。逻辑回归中的y轴限于0到1之间的概率值。逻辑回归中的y轴从“肥胖概率”转换为“log(肥胖几率)”，因此，就像线性回归中的y轴一样，它可以从<strong class="il hj">-无穷大</strong>到<strong class="il hj">+无穷大</strong>。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es me"><img src="../Images/22e5e8a4ffabba2786e184efee97a98b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cwKrrt-2llDrVVTBxKz_qw.png"/></div></div></figure><p id="37d1" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">让我们将y轴从“肥胖概率”标度转换为“肥胖几率”标度，如下所示:</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es mf"><img src="../Images/0fe1987c2363d1d53b3d692263320994.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*I87RCF0OVsufzKtYeqT3NQ.png"/></div></figure><p id="3d5d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj"> p，</strong>在这种情况下，是对象肥胖的概率，并且对应于旧y轴上0和1之间的值。</p><p id="f10e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">如果我们将<strong class="il hj"> <em class="ik"> p=0.88 </em> </strong>代入logit函数并计算，我们在新的y轴上得到2。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es mg"><img src="../Images/2d8134946f287c2c206a13d0f4d8a754.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KaH9uhG1J7xKODcRKnKKWQ.png"/></div></div></figure><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es mh"><img src="../Images/a903387e0f278d9e7828139d7619b9fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QuMy1JeWsZnREmBkGBijug.png"/></div></div></figure><p id="5b4d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">新的y轴将曲线转换为直线。</p><p id="90f4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">重要的是要知道，尽管带有<strong class="il hj">曲线</strong>的图表是我们与逻辑回归相关联的，<strong class="il hj">系数</strong>是以<strong class="il hj">对数(概率)图的形式呈现的。</strong></p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es mi"><img src="../Images/922ea4083ba4f09670ca902bb906890f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*az9QW-5nBTti27XlorjZ8w.png"/></div></div></figure><p id="749c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">第一个系数，<strong class="il hj">估计截距= -3.48 </strong>是体重= 0时的y轴截距，它表示体重= 0时，log(肥胖的几率)为-3.48。<strong class="il hj">估计截距的标准误差= 2.364 </strong>。</p><p id="ccd6" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj"> Z值= -1.471 </strong>是估计截距除以标准误差。换句话说，它是标准正态曲线上估计截距偏离0的标准差的数量。因为估计值离零小于两个标准偏差。我们知道这在统计上并不显著。</p><p id="7f16" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">第二个系数是<strong class="il hj">斜率= 1.83 </strong>。这意味着体重每增加一个单位，患肥胖症的几率增加1.825 ~ 1.83。<strong class="il hj">斜率的标准误差= 1.088 </strong>。</p><p id="3756" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj"> Z值= 1.678 </strong>是标准正态曲线上估计值从0开始的标准偏差数，从该结果我们知道估计值是否小于从0开始的2个标准偏差，因此<strong class="il hj">在统计上不显著</strong>。(样本量如此之小，这并不奇怪)。</p><p id="7cec" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">并且这是用大的<strong class="il hj"> <em class="ik"> p值来证实的。</em> </strong></p><h1 id="dcac" class="ln kl hi bd km lo lp lq kq lr ls lt ku lu lv lw kx lx ly lz la ma mb mc ld md bi translated">2.逻辑回归:系数(离散变量)</h1><p id="8f08" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jh lh iw ix ji li ja jb jj lj je jf jg hb bi translated">现在，让我们在测试一个<strong class="il hj">离散变量</strong>如“一个物体是否有突变基因”是否与肥胖有关的背景下，讨论一下<strong class="il hj">逻辑回归</strong>系数。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es mj"><img src="../Images/6c7f4c2deffc2ba9f035099cf6520cda.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*kiU-IiMJ2EGygQFaXHzgdg.png"/></div></figure><p id="ee39" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">这种逻辑回归非常类似于使用线性模型进行的t检验。</p><p id="5f41" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">我们做的第一件事是<strong class="il hj">将y轴的</strong>从<strong class="il hj">肥胖概率</strong>转换为<strong class="il hj">log(肥胖几率)</strong>。现在我们用两条线来拟合数据。对于第一行，我们获取<strong class="il hj">“正常基因”</strong>数据，并使用它来计算具有正常基因的对象的log(肥胖几率)。</p><p id="2326" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">因此，第一条(橙色)线代表具有正常基因的小鼠的对数(肥胖几率)。我们姑且称之为<strong class="il hj">日志(赔率基因正常)。</strong></p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es mk"><img src="../Images/67b1b71ae9d8e381d95d8b6279246c0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fRjVfNRcpkdF5xr0GcpYeg.png"/></div></div></figure><p id="aa5a" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">然后我们计算了带有突变基因的老鼠的log(肥胖几率)。因此，第二条(绿色)线代表带有突变基因的对象的对数(肥胖几率)。姑且称此为<strong class="il hj">日志(赔率基因突变)。</strong></p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es ml"><img src="../Images/8363d5b2600b8f1147f5a14349bdeb9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VIUQT2XM-tl0V3Yi3a2tRg.png"/></div></div></figure><p id="3097" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">这两条线合在一起构成该等式中的系数:</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es mm"><img src="../Images/696f1b7e4301b1b0f891b3f06d7c53d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*GOODKCMTFzMHsVPNvJ72Yw.png"/></div></figure><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es mk"><img src="../Images/6baef5175a1634634d3ea4bb1059ee92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FOUgD_dhwrJZCODvyNn6EQ.png"/></div></div></figure><p id="bc82" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">由于一个对数减去另一个对数可以转化为除法，这个术语就是<strong class="il hj">对数(比值比)。</strong></p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es mn"><img src="../Images/2ed7ed6a05b31cd829387d770801b04e.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*ZA23bQm8FXBb0WrBVSXkBw.png"/></div></figure><p id="bbd1" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">它告诉我们，在对数尺度上，突变基因增加(或减少)了一个物体肥胖的几率。让我们代入数字:</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es mo"><img src="../Images/eb24281710d2f45698856d909e678899.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*dNWKXAPmJzz8WiEzVkjqbA.png"/></div></figure><p id="4bae" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">这给了我们这些系数:</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es mp"><img src="../Images/74c0a512c1c31575bececf0d8df61ab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IAnjrfLh7uXtJFX4Pvk0nQ.png"/></div></div></figure><p id="e601" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">第一个系数，<strong class="il hj">估计截距= -1.50 </strong>是<strong class="il hj">对数(正常优势基因)</strong>和<strong class="il hj">基因突变</strong>项<strong class="il hj"> = 2.35 </strong>是<strong class="il hj">对数(优势比)</strong>，它告诉你，在对数尺度上，有多少突变基因增加或减少了肥胖的几率。</p><p id="3834" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">估计截距的标准误差= <strong class="il hj"> 0.7817 </strong>，基因突变体的标准误差= <strong class="il hj"> 1.0427 </strong>。</p><p id="9d2e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj"> Z值= -1.924 </strong>(用于估计截距)告诉我们，截距的估计值<strong class="il hj"> -1.5 </strong>小于0的2个标准差，因此<strong class="il hj">与0没有显著的</strong>差异，这由大于0.05的<em class="ik"> </em> <strong class="il hj"> <em class="ik"> p值</em> </strong>所证实。</p><p id="e8fd" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj"> Z值= 2.255 </strong>(对于基因突变型)，描述具有突变基因如何增加肥胖几率的对数(比值比)大于2，表明其具有<strong class="il hj">统计显著性</strong>，这通过一个<em class="ik"> </em> <strong class="il hj"> <em class="ik"> p值</em> </strong>小于<strong class="il hj"/>0.05得到证实。</p><h1 id="3981" class="ln kl hi bd km lo lp lq kq lr ls lt ku lu lv lw kx lx ly lz la ma mb mc ld md bi translated">3.逻辑回归:用最大似然拟合直线</h1><p id="dfa2" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jh lh iw ix ji li ja jb jj lj je jf jg hb bi translated">我们的目标是为这些数据绘制“最佳拟合”曲线。正如我们所知，在逻辑回归中，我们将y轴从肥胖的概率转换为对数(肥胖的几率)，参见前面的第1点和第2点。</p><p id="35c0" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">唯一的问题是，转换将原始数据推向正负无穷大，这意味着残差(从数据点到线的距离)也等于正负无穷大，这意味着<strong class="il hj">我们不能使用最小二乘法</strong>来找到最佳拟合线。</p><p id="5beb" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">相反，我们使用<strong class="il hj">最大可能性。</strong></p><p id="bdc1" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">我们做的第一件事是将原始数据点投影到候选线上。然后，我们使用这个看起来很奇特的公式将候选对数(赔率)转换成候选概率。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es mq"><img src="../Images/cc91d239a9650aba3a3a7854af15cdd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uljmjEpZC8COsjHh_BT7_Q.png"/></div></div></figure><p id="2c55" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">对于在家记账的人来说，下面是如何把以概率为输入输出log(odds)的方程，转换成以log(odds)为输入输出概率的方程。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es mr"><img src="../Images/fd9d6f5c6497843f348dd5d7f7d517d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hy4EE1V0uHRGaLGiR5qyLg.png"/></div></div></figure><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es ms"><img src="../Images/7872e54072eaf6fab4a5a3390e977f92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*swH0y_tZazChqF4Jdh8xyg.png"/></div></div></figure><p id="9f01" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">现在让我们来看看这个奇特的等式在起作用。例如，我们使用点= -2.1(从右侧)。我们用-2.1代替对数(赔率)。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es mt"><img src="../Images/856e4f1da33f3226bde60cf01b2bffd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:316/format:webp/1*pQ52H0r-rmq1zvVMZ8O56Q.png"/></div></figure><p id="32a3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">这给了我们曲线上的y坐标。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es mu"><img src="../Images/67d96ecc324e6ffc49f372ae37f5f6d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*VW6qer7wpl5rY6OXv1SjtA.png"/></div></figure><p id="94c4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">我们对所有的点做同样的事情。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es mv"><img src="../Images/51e5e75097122ca7f2b40ebeb8e1bda6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cym71up0oS7cMWAvMQP12Q.png"/></div></div></figure><p id="9ac0" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">现在我们使用观察到的状态(肥胖或不肥胖)来计算他们的可能性，给出曲线的形状。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es mw"><img src="../Images/de4e156d9031bf96cede7bec4f594a20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8ScxIdCQiHZoM72l0r2cmA.png"/></div></div></figure><p id="eb22" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">虽然可以将可能性计算为个体可能性的乘积，但统计学家更喜欢用<strong class="il hj">计算可能性的对数</strong>(因为最大化可能性的曲线就是最大化可能性的对数的曲线)。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es mi"><img src="../Images/41ad2f90343771bd5dffda9c6622a9d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MpfVEeyX9YnwyG_jI5wrgg.png"/></div></div></figure><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es mx"><img src="../Images/bf366e0a079ec31582aeaa6b6ba9bca4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*wYYcnBSNeK9yRqabMdUDYg.png"/></div></figure><p id="14bd" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">这意味着原始线的对数似然为<strong class="il hj"> -3.77 </strong>。现在，我们旋转这条线，通过将数据投影到这条线上，将对数(几率)转换为概率，来计算它的对数似然性。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es my"><img src="../Images/1a21812569a5cdc4c3239f050d9a6ba9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0wDlCtBA2qH6LArsQ3rZCg.png"/></div></div></figure><p id="420b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">旋转线条:</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es mz"><img src="../Images/d121ef4f1dc824baf8081bb65205a690.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rEZZ8PXqteOnG3PiNct0pQ.png"/></div></div></figure><p id="16c2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">通过将数据投影到它上面并将对数(赔率)转换为概率来计算它的对数似然性:</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es na"><img src="../Images/af64735c02678717f97f084d4c401b80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BsiJWsQddwhFq-HMNCotTA.png"/></div></div></figure><p id="36ad" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">然后计算对数似然</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es mh"><img src="../Images/006b22c876174d8e2131c6763815d072.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9it77OiuInNBj852P31uqQ.png"/></div></div></figure><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es nb"><img src="../Images/2717197bc86a6d7a7773736cd30da6ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*ypkUYDCczCXLSzi4rJMRPw.png"/></div></figure><p id="71b3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj">我们只是不断旋转对数(赔率)线，将数据投影到上面，将其转换为概率，并计算对数似然性</strong></p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es nc"><img src="../Images/71680228ae4d0cdc44ca6ad8c725f580.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xE10bGotmq5jX8-GZPrvIQ.png"/></div></div></figure><p id="34a8" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj">注意:</strong>每次旋转线条时，寻找最大似然线的算法非常聪明，它以增加对数似然的方式这样做。因此，该算法可以在几次旋转后找到最佳拟合。</p><p id="f58a" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">最终我们得到一条最大化可能性的线，这是选择的最适合的线。</p><h1 id="6186" class="ln kl hi bd km lo lp lq kq lr ls lt ku lu lv lw kx lx ly lz la ma mb mc ld md bi translated">参考资料:</h1><div class="nd ne ez fb nf ng"><a href="https://onezero.blog/modelling-binary-logistic-regression-using-python-research-oriented-modelling-and-interpretation/" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hj fi z dy nl ea eb nm ed ef hh bi translated">使用Python建模二元逻辑回归——One Zero博客</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">在有监督的机器学习世界中，有两种类型的算法任务经常被执行。一个叫…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">onezero .博客</p></div></div><div class="np l"><div class="nq l nr ns nt np nu ki ng"/></div></div></a></div><div class="nd ne ez fb nf ng"><a href="https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc" rel="noopener follow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hj fi z dy nl ea eb nm ed ef hh bi translated">逻辑回归—详细概述</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">逻辑回归在二十世纪早期被用于生物科学。它后来被用于许多社会…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">towardsdatascience.com</p></div></div><div class="np l"><div class="nv l nr ns nt np nu ki ng"/></div></div></a></div><div class="nd ne ez fb nf ng"><a href="https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hj fi z dy nl ea eb nm ed ef hh bi translated">逻辑回归— ML词汇表文档</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">假设我们得到了学生考试成绩的数据，我们的目标是基于以下因素来预测学生是否会通过考试…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">ml-cheatsheet.readthedocs.io</p></div></div><div class="np l"><div class="nw l nr ns nt np nu ki ng"/></div></div></a></div><figure class="jz ka kb kc fd kd"><div class="bz dy l di"><div class="nx ny l"/></div></figure><figure class="jz ka kb kc fd kd"><div class="bz dy l di"><div class="nx ny l"/></div></figure><p id="320e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">如果您想了解更多关于逻辑回归的R2和p值的信息，可以观看此视频！</p><figure class="jz ka kb kc fd kd"><div class="bz dy l di"><div class="nx ny l"/></div></figure></div></div>    
</body>
</html>