<html>
<head>
<title>Stochastic Gradient Descent (SGD) With PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch随机梯度下降法</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/stochastic-gradient-descent-sgd-with-pytorch-1187651da108?source=collection_archive---------4-----------------------#2022-07-30">https://medium.com/geekculture/stochastic-gradient-descent-sgd-with-pytorch-1187651da108?source=collection_archive---------4-----------------------#2022-07-30</a></blockquote><div><div class="ds hc hd he hf hg"/><div class="hh hi hj hk hl"><div class=""/><figure class="ev ex im in io ip er es paragraph-image"><div class="er es il"><img src="../Images/2dd4f1bf9d8e3be5866b9d19b9797f5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*wMup5xjI-LKXh5Dd1trNpQ.png"/></div></figure><p id="8450" class="pw-post-body-paragraph is it ho iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hh bi translated">深度学习网络学习和改进的方法之一是通过梯度下降(SGD)优化算法。该算法的工作原理是沿着曲线的每一步计算实际值和预测值之间的最低损失。</p><p id="1052" class="pw-post-body-paragraph is it ho iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hh bi translated">深度学习算法的典型SGD过程由以下步骤组成:</p><ol class=""><li id="d026" class="jq jr ho iu b iv iw iz ja jd js jh jt jl ju jp jv jw jx jy bi translated">首先，随机值沿着…</li></ol></div></div>    
</body>
</html>