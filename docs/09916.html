<html>
<head>
<title>Neural Image Style Transfer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经图像风格转移</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/neural-image-style-transfer-515fe09f1c0c?source=collection_archive---------11-----------------------#2022-01-04">https://medium.com/geekculture/neural-image-style-transfer-515fe09f1c0c?source=collection_archive---------11-----------------------#2022-01-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ed161ee6d6a6eab477c32a1f5f63a691.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SfGh9KVd9rnlSmyqGq2hSw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Claude Monet Painting</figcaption></figure><p id="9c4d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">你从相机胶卷里拿出一张照片，然后选择一个设计。然后你得到一个新的图像，它包含了你的输入图像的内容和设计图像的风格。我们从棱镜中了解到这一点，但是这种技术是如何工作的呢？在机器学习中，我们把这个算法叫做“<strong class="iw hj">风格转移</strong>”。</p><blockquote class="js"><p id="f8aa" class="jt ju hi bd jv jw jx jy jz ka kb jr dx translated">风格转移是将一幅图像的风格结合到另一幅图像中。</p></blockquote><p id="9365" class="pw-post-body-paragraph iu iv hi iw b ix kc iz ja jb kd jd je jf ke jh ji jj kf jl jm jn kg jp jq jr hb bi translated">风格转移使用预先训练好的CNN(卷积神经网络)来寻找一幅图像的<strong class="iw hj">内容</strong>特征——物体——和另一幅图像的<strong class="iw hj">风格</strong>特征——笔刷、纹理、颜色——来混合它们。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kh"><img src="../Images/5be8400decc0b4cd3278dd7a9d3ba9ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vSnDYgz9ilbN2B5SY49oOA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">I spent minutes on end absorbing wave cat | Source: Intro to Deep learning with Pytorch on Udacity</figcaption></figure><p id="aa02" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">最好的风格转换模型可以保持图像的特征，同时改变图像的风格属性。</p><blockquote class="js"><p id="ba04" class="jt ju hi bd jv jw jx jy jz ka kb jr dx translated">在本文中，我们将探索这种算法背后的技术过程。</p></blockquote><h1 id="3070" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">TL；速度三角形定位法(dead reckoning)</h1><ul class=""><li id="6673" class="lk ll hi iw b ix lm jb ln jf lo jj lp jn lq jr lr ls lt lu bi translated">内容和风格表示:机器如何理解和存储图像的各个方面？什么是VGG 19有线电视新闻网？什么是克矩阵？</li><li id="71c8" class="lk ll hi iw b ix lv jb lw jf lx jj ly jn lz jr lr ls lt lu bi translated">损失函数:我们优化什么？我们如何把风格和内容形象结合起来？什么是风格转移？</li></ul><h1 id="f2da" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ma kz la lb mb ld le lf mc lh li lj bi translated">风格转移过程(待进一步解释)</h1><ul class=""><li id="5ef5" class="lk ll hi iw b ix lm jb ln jf lo jj lp jn lq jr lr ls lt lu bi translated"><strong class="iw hj">内容图像</strong>通过VGG-19网络，在此<strong class="iw hj">提取内容表示</strong>。</li><li id="e9b4" class="lk ll hi iw b ix lv jb lw jf lx jj ly jn lz jr lr ls lt lu bi translated"><strong class="iw hj">风格图像</strong>通过VGG-19网络，其中<strong class="iw hj">风格表示</strong>被提取并使用gram矩阵存储。</li><li id="241b" class="lk ll hi iw b ix lv jb lw jf lx jj ly jn lz jr lr ls lt lu bi translated">然后，利用梯度下降和先前计算的内容和样式表示来迭代优化<strong class="iw hj">原始内容图像</strong>。</li></ul><h1 id="aaac" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ma kz la lb mb ld le lf mc lh li lj bi translated">捕获内容和样式表示</h1><p id="5af3" class="pw-post-body-paragraph iu iv hi iw b ix lm iz ja jb ln jd je jf md jh ji jj me jl jm jn mf jp jq jr hb bi translated">风格转换的两个主要任务是捕获一个图像的<strong class="iw hj">内容表示</strong>和另一个图像的<strong class="iw hj">风格</strong>来组合它们。</p><p id="7a53" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们分别使用CNN——在我们的例子中是VGG 19——和gram矩阵来捕捉这些表示</p><h2 id="ef16" class="mg kn hi bd ko mh mi mj ks mk ml mm kw jf mn mo la jj mp mq le jn mr ms li mt bi translated">CNN综述</h2><blockquote class="mu mv mw"><p id="85c1" class="iu iv mx iw b ix iy iz ja jb jc jd je my jg jh ji mz jk jl jm na jo jp jq jr hb bi translated">在这一节中，我回顾了CNN的基础知识以及它们是如何工作的。如果你知道基本知识，请随意跳过<em class="hi">🙂。</em>如果你不熟悉它，请阅读<a class="ae nb" href="https://e2eml.school/how_convolutional_neural_networks_work.html" rel="noopener ugc nofollow" target="_blank">这个深入的来源</a>来了解更多关于卷积、层和过滤器的知识。</p></blockquote><p id="b326" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">卷积神经网络(ConvNet/CNN) </strong>是一种深度学习算法，可以接受输入图像，为图像中的各个方面/对象分配重要性(可学习的权重和偏差)，并能够区分彼此。</p><p id="1183" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">虽然CNN的架构可以因其子类型而异——VGG-19、亚历克斯-Net等——但它运行的工作过程是相同的。所有CNN都有两个部分:</p><ul class=""><li id="3cbb" class="lk ll hi iw b ix iy jb jc jf nc jj nd jn ne jr lr ls lt lu bi translated">卷积层</li><li id="37cc" class="lk ll hi iw b ix lv jb lw jf lx jj ly jn lz jr lr ls lt lu bi translated">最大池层数</li></ul><p id="3f88" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">卷积层</strong>(蓝色)是“特征图”的容器。它们将检测到的特征(或卷积图像)存储在输入中。图层越深，要素地图或存储的要素就越多。</p><p id="4eda" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">池化</strong> <strong class="iw hj">层</strong>(橙色)用于降低维度，简化卷积层。因此，要学习的参数数量将会减少。</p><blockquote class="js"><p id="92e1" class="jt ju hi bd jv jw jx jy jz ka kb jr dx translated">当输入通过卷积层和池层时，会生成内容的更全面、更详细的表示。</p></blockquote><figure class="ng nh ni nj nk ij er es paragraph-image"><div class="er es nf"><img src="../Images/8b4a0c7a9787e8a8fee5d8cdbb516c11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*ZvQFlpK5IpCW5BALpBQRXA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">notice including convolution and pooling layers there are also fully connected layers. as style transfer does not require any prediction these fully connected layers are not included in our architecture further in the blog. | VGG-19 CNN 👆</figcaption></figure><p id="a04d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在我们的风格转换模型中，我们使用VGG-19 CNN框架。这个CNN有19个加权层，包括我们移除的3个密集层。</p><blockquote class="js"><p id="cee0" class="jt ju hi bd jv jw jx jy jz ka kb jr dx translated">在我们的风格转换项目中，使用VGG-19模型对于彻底理解风格和内容图像至关重要。</p></blockquote><h2 id="66a5" class="mg kn hi bd ko mh nl mj ks mk nm mm kw jf nn mo la jj no mq le jn np ms li mt bi translated">内容表示</h2><p id="ca2c" class="pw-post-body-paragraph iu iv hi iw b ix lm iz ja jb ln jd je jf md jh ji jj me jl jm jn mf jp jq jr hb bi translated">如你所知，VGG-19 CNN的后续层更好地捕捉了图像的内容，因此被称为内容表示。内容表示识别线条和亮度以描绘图像对象的轮廓</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nq"><img src="../Images/c4e3a69026f2e68ab8244b236e8539ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ca9CzOXgezpdHhI_9nwWAw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">content representation being created | notice the three input channels stand for the colour channels (R, G, B)</figcaption></figure><p id="8ea5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">请注意，内容表示丢弃了所有不相关的细节，包括<strong class="iw hj">样式</strong>，以保留图像中的主要对象。</p><p id="2fd4" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在我们的VGG-19 CNN中，我们提取第四个卷积堆栈的<strong class="iw hj">第二个卷积中的内容表示——正如Gatys L在他的论文中所使用的。这确保了全面但不太精简的表示。</strong></p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es nf"><img src="../Images/8b4a0c7a9787e8a8fee5d8cdbb516c11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*ZvQFlpK5IpCW5BALpBQRXA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">the purple rectangle represents the content representation of the image as said in the ‘Neural Style Transfer’ paper</figcaption></figure><h2 id="4b29" class="mg kn hi bd ko mh mi mj ks mk ml mm kw jf mn mo la jj mp mq le jn mr ms li mt bi translated">格拉姆矩阵</h2><p id="302b" class="pw-post-body-paragraph iu iv hi iw b ix lm iz ja jb ln jd je jf md jh ji jj me jl jm jn mf jp jq jr hb bi translated">正如我们所知，为了获得内容表示，我们通过CNN传递内容图像，在本例中是VGG19，其中后面的层具有更好的内容表示。</p><p id="a837" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">提取样式出乎意料的简单。</strong></p><p id="8c67" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">图像的“风格”是颜色、纹理和情感的总体主题。或者，从更理论的角度来看，《星夜》中柏树的纹理与月亮的纹理有什么关系？如果有，有何异同？</p><blockquote class="js"><p id="3807" class="jt ju hi bd jv jw jx jy jz ka kb jr dx translated">风格是一幅画的各个方面如何相互联系</p></blockquote><figure class="ng nh ni nj nk ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nr"><img src="../Images/e996a6f97ef63d0a8cee2c15e3006e44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UURZ9unZudgovZB9.jpg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">how does the texture in the cypress tree of starry night relate with the texture of the moon?</figcaption></figure><p id="541e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了找到风格，我们首先通过VGG-19 CNN输入风格图像，以观察卷积层中特征图之间的相关性。<strong class="iw hj">换句话说，我们正在查看图像中特征之间的相似性。</strong>这些相似点就是图像的<strong class="iw hj">风格</strong>。</p><blockquote class="js"><p id="71f4" class="jt ju hi bd jv jw jx jy jz ka kb jr dx translated">我们可以用<strong class="ak"> Gram矩阵</strong>将这些相似性存储为<strong class="ak">样式表示</strong>。</p></blockquote><p id="5f7b" class="pw-post-body-paragraph iu iv hi iw b ix kc iz ja jb kd jd je jf ke jh ji jj kf jl jm jn kg jp jq jr hb bi translated">格拉姆矩阵是通过取卷积层的展开中间表示及其转置的点积来计算的。用程序员更简单的话来说，我们用它的转置点一个卷积层中的展平特征图列表。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ns"><img src="../Images/be0d7170b5fa65aec3ac72d5c3129b36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*EoRizTzMDs2IOWrwNFsYOQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">and thus the Gram Matrix storing the style features in one convolutional layer is made</figcaption></figure><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es nt"><img src="../Images/a78df14c8eccbe47e7d5917f665c99a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/0*YQZWWPmveBqzXmyk.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">a flattened feature map, the random numbers represent pixel values</figcaption></figure><p id="c649" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">正如Leon Gatys的论文中所建议的，我们计算了VGG-19网络中所有卷积栈中每个第一卷积层的gram矩阵。<strong class="iw hj">图像的风格表示是VGG-19网络</strong>中的gram矩阵列表。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es nu"><img src="../Images/5a361be33d5f0514f1e0de66188b7f56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*2mV7Fk3u9PI121fPxWnIyA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">calculating the gram matrix at every first layer of each stack</figcaption></figure><p id="5b46" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">—因此我们知道如何计算图像的内容和样式表示！</p><h1 id="6c7d" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ma kz la lb mb ld le lf mc lh li lj bi translated">损失函数</h1><p id="dfce" class="pw-post-body-paragraph iu iv hi iw b ix lm iz ja jb ln jd je jf md jh ji jj me jl jm jn mf jp jq jr hb bi translated">获得内容和样式表示后，我们的下一步是创建目标图像——计算表示的组合。我们使用损失函数和<a class="ae nb" rel="noopener" href="/geekculture/gradient-descent-simplified-631a7ce38cb6">梯度下降</a>来实现这一点。</p><blockquote class="js"><p id="0247" class="jt ju hi bd jv jw jx jy jz ka kb jr dx translated">损失函数告知模型的准确性。损耗越低，精度越高。</p></blockquote><p id="f743" class="pw-post-body-paragraph iu iv hi iw b ix kc iz ja jb kd jd je jf ke jh ji jj kf jl jm jn kg jp jq jr hb bi translated">使用的损失函数是风格损失和内容损失。简单地说，他们分别找到目标图像与风格和内容图像之间的错误。目标图像首先被初始化为原始内容图像，并被迭代优化为具有最少样式和内容损失的混合图像。</p><h2 id="cdc3" class="mg kn hi bd ko mh mi mj ks mk ml mm kw jf mn mo la jj mp mq le jn mr ms li mt bi translated">内容损失</h2><p id="90fd" class="pw-post-body-paragraph iu iv hi iw b ix lm iz ja jb ln jd je jf md jh ji jj me jl jm jn mf jp jq jr hb bi translated">当我们形成目标图像时，我们比较目标图像和内容图像的内容表示。一个更好的风格转换模型使这两种表现尽可能接近，即使我们的目标图像改变了它的风格。</p><p id="f0ed" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们定义了一个内容损失来寻找表示之间的差异。或者计算内容和目标图像内容表示之间的对比度的损失。这里，我们使用均方差(MSE)作为损失函数。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es nv"><img src="../Images/71912c0de0dd6b02c9b348d5183d6447.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*XQmX2HTfNN3NULQ2PECc7g.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">T_C is target image content representation and C_C is content image content representation</figcaption></figure><p id="f5c2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了逐步生成更好的目标图像，我们的目标是尽量减少这种损失。虽然这个过程类似于在优化中使用损失来确定CNN的权重，但是这里我们的目的不是最小化分类误差。</p><p id="5497" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们的目标是只改变目标图像，更新它的外观，直到它的内容表示与内容图像的表示相匹配。我们没有使用传统意义上的VGG 19网络，而是仅用于特征提取— <a class="ae nb" href="http://google.com" rel="noopener ugc nofollow" target="_blank">梯度下降</a>用于降低目标和内容图像之间的损失。</p><blockquote class="js"><p id="c0c9" class="jt ju hi bd jv jw jx jy jz ka kb jr dx translated">我们不使用VGG-19进行分类，而仅用于特征提取</p></blockquote><h2 id="9630" class="mg kn hi bd ko mh nl mj ks mk nm mm kw jf nn mo la jj no mq le jn np ms li mt bi translated">风格丧失</h2><p id="d7d3" class="pw-post-body-paragraph iu iv hi iw b ix lm iz ja jb ln jd je jf md jh ji jj me jl jm jn mf jp jq jr hb bi translated">以同样的方式，我们计算目标图像和具有风格损失的风格图像之间的差异。该功能类似于内容丢失，试图使内容和目标图像<strong class="iw hj">的样式表示</strong>尽可能接近。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es nw"><img src="../Images/5f711515a4102a8f5b772c2bd4fc4160.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*dmNm2117qsGWmV15zV89eA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">T_s is the target image style representation, while S_s is the style image style representation, a is the number of values in each layer</figcaption></figure><p id="6ed0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们找到了风格和目标图像风格表示之间的均方距离。回想一下，这两种样式表示都包含五个gram矩阵，它们是在VGG-19网络中每个卷积堆栈的每个第一层计算的。</p><p id="2dd8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在上面的等式中，我们称<strong class="iw hj"> <em class="mx"> Ss </em> </strong>和<strong class="iw hj"> <em class="mx"> Ts </em> </strong>，<strong class="iw hj"> <em class="mx"> A </em> </strong>是一个常数，表示每一层中值的个数。我们将这五个计算的距离乘以我们指定的一些样式权重<strong class="iw hj"> <em class="mx"> w </em> </strong>，最终求和。</p><blockquote class="js"><p id="675d" class="jt ju hi bd jv jw jx jy jz ka kb jr dx translated">样式权重是改变目标图像上的样式表示的效果的值。重量越大，效果越好。</p></blockquote><p id="ccff" class="pw-post-body-paragraph iu iv hi iw b ix kc iz ja jb kd jd je jf ke jh ji jj kf jl jm jn kg jp jq jr hb bi translated"><strong class="iw hj">我们只改变目标图像的样式表示，因为我们通过多次迭代来最小化这种损失。</strong></p><h2 id="4a74" class="mg kn hi bd ko mh mi mj ks mk ml mm kw jf mn mo la jj mp mq le jn mr ms li mt bi translated">优化和后续步骤</h2><p id="b01e" class="pw-post-body-paragraph iu iv hi iw b ix lm iz ja jb ln jd je jf md jh ji jj me jl jm jn mf jp jq jr hb bi translated">既然我们理解了<strong class="iw hj">表示</strong>和<strong class="iw hj">损失</strong>的概念，下一步就是减少总损失。</p><blockquote class="mu mv mw"><p id="13e1" class="iu iv mx iw b ix iy iz ja jb jc jd je my jg jh ji mz jk jl jm na jo jp jq jr hb bi translated">全损简单来说就是风格损失和内容损失的相加。</p></blockquote><p id="ce2a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们使用典型的梯度下降和反向传播，通过迭代地改变目标图像来匹配我们想要的内容和风格，从而减少总损失。</p><p id="2f81" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">阅读<a class="ae nb" rel="noopener" href="/geekculture/gradient-descent-simplified-631a7ce38cb6">这篇</a>文章，了解更多关于梯度下降和优化算法的工作，阅读<a class="ae nb" href="https://www.tensorflow.org/tutorials/generative/style_transfer" rel="noopener ugc nofollow" target="_blank">这篇</a>文章，了解如何使用TensorFlow编写自己的代码。</p><p id="0d28" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">希望你有一个blast编码自己的风格转换算法！希望您学到了一些新东西，并对自己编写这个模型感到兴奋。干杯🍻！</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nx"><img src="../Images/9e11b27bf4fb0fe44b15ac62b5d96f5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kdWvERHfdwdQf9BJGIXDpA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Some Inspiration 🙌 | Made by <a class="ae nb" href="https://thushv89.medium.com/" rel="noopener">Thushan Ganegedara</a></figcaption></figure><h1 id="0717" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ma kz la lb mb ld le lf mc lh li lj bi translated">在你走之前…</h1><blockquote class="mu mv mw"><p id="73a5" class="iu iv mx iw b ix iy iz ja jb jc jd je my jg jh ji mz jk jl jm na jo jp jq jr hb bi translated">通过这篇文章，你已经了解了风格转换的基本原理。🎉🎊我们探讨了特征提取、损失函数以及风格转换优化是如何工作的！祝你的机器学习之旅好运！</p><p id="0b18" class="iu iv mx iw b ix iy iz ja jb jc jd je my jg jh ji mz jk jl jm na jo jp jq jr hb bi translated">机器学习一直是我的研究热点。无论是在snapchat过滤器还是垃圾邮件分类器中，到处都在使用<strong class="iw hj"><em class="hi"/></strong><em class="hi">。今天，它更像是一种生活方式，而不是流行语。</em></p><p id="e414" class="iu iv mx iw b ix iy iz ja jb jc jd je my jg jh ji mz jk jl jm na jo jp jq jr hb bi translated">这就是我进入数据科学领域的原因。从一开始，我就上瘾了，我希望我会一直上瘾。</p><p id="6dc7" class="iu iv mx iw b ix iy iz ja jb jc jd je my jg jh ji mz jk jl jm na jo jp jq jr hb bi translated">如果你喜欢阅读这篇文章，请联系我的社交网站🤗<br/><a class="ae nb" href="https://www.linkedin.com/in/arjun-mahes-a46200220/" rel="noopener ugc nofollow" target="_blank"><em class="hi">LinkedIn</em></a><em class="hi">|</em><a class="ae nb" href="https://arjunmahes.substack.com/" rel="noopener ugc nofollow" target="_blank"><em class="hi">快讯</em></a>|<a class="ae nb" href="https://twitter.com/mahes_arjun" rel="noopener ugc nofollow" target="_blank"><em class="hi">推特</em> </a></p></blockquote></div></div>    
</body>
</html>