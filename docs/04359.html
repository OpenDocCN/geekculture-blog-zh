<html>
<head>
<title>Insurance claims — Fraud detection using machine learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">保险索赔-使用机器学习进行欺诈检测</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/insurance-claims-fraud-detection-using-machine-learning-78f04913097?source=collection_archive---------0-----------------------#2021-06-25">https://medium.com/geekculture/insurance-claims-fraud-detection-using-machine-learning-78f04913097?source=collection_archive---------0-----------------------#2021-06-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/8b48347ecc7f29972b7fec1657736d75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*TAcSy7z14N0dxv_gI-ipZw.jpeg"/></div></figure><p id="a05b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi jk translated">raud是保险公司面临的最大、最广为人知的问题之一。本文关注一家汽车保险公司的索赔数据。欺诈性索赔对每个保险公司来说都是非常昂贵的。因此，重要的是要知道哪些主张是正确的，哪些是错误的。保险公司亲自检查所有的索赔是不可行的，因为这将花费太多的时间和金钱。在本文中，我们将利用保险公司在反欺诈斗争中拥有的最大资产:数据。我们采用关于索赔、被保险人和其他情况的各种属性，这些属性由保险公司包含在数据中。区分不同的索赔组和这些组中相应的欺诈率提供了新的见解。</p><p id="635c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">此外，我们使用机器学习来预测哪些索赔可能是欺诈性的。这些信息可以缩小需要进一步检查的索赔列表。它使保险公司能够发现更多的欺诈性索赔。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="933a" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">问题定义</h1><p id="62bb" class="pw-post-body-paragraph im in hi io b ip ky ir is it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj hb bi translated">这个项目的目标是建立一个可以检测汽车保险欺诈的模型。机器学习中欺诈检测背后的挑战是，与合法的保险索赔相比，欺诈远不常见。</p><p id="bb10" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">鉴于欺诈模式的多样性和典型样本中已知欺诈的相对较小比例，保险欺诈检测是一个具有挑战性的问题。在构建检测模型时，损失预防带来的节约需要与错误警报的成本相平衡。机器学习技术允许提高预测准确性，使损失控制单元能够以低误报率实现更高的覆盖率。</p><p id="eae7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">保险欺诈包括个人为了从保险公司获得有利结果而可能实施的一系列不当活动。这可能包括策划事件、歪曲情况(包括相关行为者和事件原因)以及最终造成的损害程度。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="c405" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">数据分析</h1><p id="7390" class="pw-post-body-paragraph im in hi io b ip ky ir is it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj hb bi translated">在这个项目中，我们有一个数据集，其中包含保险单的详细信息以及客户的详细信息。它还有据以提出索赔的事故细节。</p><p id="d908" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">给定的数据集包含1000行和40列。列名，如保单号、保单绑定日期、保单年度保费、事故严重性、事故位置、汽车型号等。</p><p id="2970" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这个数据集的明显缺点是样本量小。但是，仍然有很多公司没有大数据集。对于任何希望转型到利用数据科学的公司来说，利用可用资源的能力至关重要。</p><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/a7d4932b1fc27fc86a1414371845b9f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/0*iKO5mxNDsVFvAgyy"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Description of the data</figcaption></figure><p id="a5be" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">与等待拥有庞大数据集的那一天的公司相比，从小型数据集开始并处理它的公司更有可能在数据科学之旅中更早成功并获得回报。</p><p id="84db" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">有些变量包含空值字符“？”。下面给出了空值的数量。</p><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/39dcdb493a38cd48bd51e02abed74544.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/0*A58_2lXNWYvqNTs5"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Unique values</figcaption></figure></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="d9ff" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">探索性数据分析</h1><ul class=""><li id="70b1" class="ln lo hi io b ip ky it kz ix lp jb lq jf lr jj ls lt lu lv bi translated"><strong class="io hj">因变量:</strong>从因变量Fraud_reported开始进行探索性数据分析。有247起欺诈事件，753起非欺诈事件。24.7%的数据是欺诈性的，而75.3%是非欺诈性的索赔。</li></ul><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/64c9568d8354b6645478457efd3a6746.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/0*FJ2zNQwJpup-BBvy"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Reported frauds</figcaption></figure><ul class=""><li id="23b7" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj ls lt lu lv bi translated"><strong class="io hj">变量之间的相关性:</strong>为Pearson相关系数至少为0.3的变量绘制热图，包括DV。客户的月份和年龄的相关系数为0.92。可能是因为司机在拥有一辆车时购买了汽车保险，而这一时间尺度只会随着年龄的增长而增加。除此之外，数据中似乎没有太多的相关性。似乎没有多重共线性的问题，除了可能所有的索赔都是相关的，不知何故总索赔已经考虑了它们。但是，其他声明提供了一些粒度，否则总声明将无法捕获这些粒度。因此，这些变量被保留下来。</li><li id="185d" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj ls lt lu lv bi translated"><strong class="io hj">可视化变量:</strong>报告的欺诈价值因客户的爱好而异。看起来棋手和交叉对手有更高的欺诈倾向。</li></ul><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es mf"><img src="../Images/8728ab590418662f024106651a0c8460.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/0*8Zz79w_VoCtOvRQB"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Hobbies of customers with respect to frauds committed</figcaption></figure><blockquote class="mg mh mi"><p id="315c" class="im in mj io b ip iq ir is it iu iv iw mk iy iz ja ml jc jd je mm jg jh ji jj hb bi translated">重大事件的严重性似乎是欺诈案件最高，超过了非欺诈案件。</p></blockquote><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/2c3102b21080dfdb1dc91605279c8745.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/0*kHcbTcnqUtJm5x4g"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Damage analysis</figcaption></figure><blockquote class="mg mh mi"><p id="624e" class="im in mj io b ip iq ir is it iu iv iw mk iy iz ja ml jc jd je mm jg jh ji jj hb bi translated">萨博和斯巴鲁auto_make的total_claim_amount较高。</p></blockquote><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es mo"><img src="../Images/2d692989fbe05d067eee626fa475aa50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/0*_oXxKfuEgu0M0t3u"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Total insurance claims with respect to car brands</figcaption></figure><blockquote class="mg mh mi"><p id="6aeb" class="im in mj io b ip iq ir is it iu iv iw mk iy iz ja ml jc jd je mm jg jh ji jj hb bi translated">日产汽车的伤害索赔最高。</p></blockquote><figure class="le lf lg lh fd ij er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es mp"><img src="../Images/51e1fdc5220a229faa76ec83e6bd4ca0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KGVAzgWCR4CmRVAd"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx">Injury claims with respect to car brands</figcaption></figure><p id="6f55" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">检验因变量和自变量之间的相关性。</p><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es mu"><img src="../Images/545f32fd18eb69172ca0a8eaba84b083.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/0*g9PiWs332Zd_rktZ"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Correlation</figcaption></figure><h2 id="4aed" class="mv kb hi bd kc mw mx my kg mz na nb kk ix nc nd ko jb ne nf ks jf ng nh kw ni bi translated">预处理流水线</h2><p id="f1e8" class="pw-post-body-paragraph im in hi io b ip ky ir is it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj hb bi translated">数据预处理是机器学习中产生高度准确和深刻结果的主要步骤。数据质量越高，产生的结果越可靠。<strong class="io hj">不完整、有噪声和不一致的数据</strong>是真实世界数据集的固有特性。数据预处理有助于通过填充缺失的不完整数据、平滑噪声和解决不一致来提高数据质量。</p><ul class=""><li id="f0df" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj ls lt lu lv bi translated"><strong class="io hj">数据不完整</strong>可能是由多种原因造成的。由于误解或仪器缺陷和故障，可能无法保存适当的数据。</li><li id="63e5" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj ls lt lu lv bi translated"><strong class="io hj">噪声数据</strong>可能因多种原因出现(具有不正确的特征值)。用于数据收集的仪器可能有故障。数据输入可能包含人为或仪器错误。也可能发生数据传输错误。</li></ul><p id="d7a4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">数据预处理涉及许多阶段。</p><ul class=""><li id="a5f3" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj ls lt lu lv bi translated"><strong class="io hj">数据清理</strong>试图估算缺失值，从数据集中移除异常值。</li><li id="0671" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj ls lt lu lv bi translated"><strong class="io hj">数据集成</strong>将来自多个来源的数据集成到一个数据仓库中。</li><li id="6152" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj ls lt lu lv bi translated"><strong class="io hj">可应用数据转换</strong>，如标准化。例如，归一化可以提高涉及距离测量的挖掘算法的准确性和效率。</li><li id="f39f" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj ls lt lu lv bi translated"><strong class="io hj">数据缩减</strong>可以通过删除冗余特征来缩减数据大小。可以使用特征选择和特征提取技术。</li></ul><p id="1271" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">处理空值</strong></p><p id="8841" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">有时，某些列包含空值，用于指示缺少或未知的值，或者该值可能不存在。在我们的数据集中，空值出现在collision_type、property_damage、police_report_available和_c39列中，有178、360、343和1000个空值。</p><p id="7989" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">有不同的方法来替换数据集中的空值，但是我们使用fillna来替换数据中的空值。</p><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es nj"><img src="../Images/b34276ef4a131d8be006dd6cbe9ec831.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/0*h9UqkWe6nFyeszs3"/></div></figure><p id="d0d2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">将标签转换成数字</strong></p><p id="1c82" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在机器学习中，我们通常处理在一列或多列中包含多个标签的数据集。这些标签可以是单词或数字的形式。为了使数据可理解或以人类可读的形式，训练数据通常用文字标记。</p><p id="4c4f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在我们的数据中，有包含分类值的列。像事件严重程度、事件状态、事件类型、被保险人爱好、联系机构、事件城市、警察报告可用、汽车制造、碰撞类型、汽车型号、被保险人职业、被保险人教育水平、财产损失、被保险人关系、政策状态、被保险人性别、欺诈报告等列。这些列必须用一个热编码或标签编码器来处理。目标变量fraud_reported必须仅使用标签编码器进行转换。</p><p id="ebc8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">标签编码器</strong>是将标签转换成数字形式，从而转换成机器可读的形式。然后，机器学习算法可以以更好的方式决定这些标签必须如何操作。这是监督学习中结构化数据集的一个重要预处理步骤。</p><p id="6922" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">python中的标签编码可以从Sklearn库中导入。Sklearn提供了一个非常高效的编码工具。标签编码器使用0和n_classes-1之间的值对标签进行编码。</p><blockquote class="mg mh mi"><p id="7571" class="im in mj io b ip iq ir is it iu iv iw mk iy iz ja ml jc jd je mm jg jh ji jj hb bi translated"><strong class="io hj">离群值</strong>是远离其他相似点的数据点。它们可能是由于测量中的可变性或可能表明实验误差。如果可能，离群值应该从数据集中排除。然而，检测这种异常情况可能非常困难，而且并不总是可能的。</p></blockquote><p id="c266" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">去除异常值的方法:</p><ul class=""><li id="9393" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj ls lt lu lv bi translated"><strong class="io hj"> Z-score — </strong>调用scipy.stats.zscore()，将给定的数据帧作为其参数，以获取包含数据帧中每个值的Z-score的numpy数组。使用前面的结果调用numpy.abs()将dataframe中的每个元素转换为其绝对值。使用语法(数组&lt; 3)。all(axis=1)以array作为前一个结果来创建一个布尔数组。</li><li id="58b3" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj ls lt lu lv bi translated"><strong class="io hj">四分位数范围</strong> —四分位数范围可用于检测数据框架中存在的异常值。</li><li id="fbf7" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj ls lt lu lv bi translated">使用scipy.stats.iqr模块计算数据的四分位间距。</li><li id="2b89" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj ls lt lu lv bi translated">将四分位间距乘以1.5。</li><li id="4c0a" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj ls lt lu lv bi translated">第三个四分位数加上1.5倍的四分位数间距。任何大于这个值的数字都是可疑的异常值。</li><li id="fb05" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj ls lt lu lv bi translated">从第一个四分位数减去1.5倍四分位数间距。任何小于这个值的数字都是可疑的异常值。</li></ul><p id="2339" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">平衡我们不平衡的数据</strong></p><p id="8685" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">有不同的算法来平衡目标变量。我们使用SMOTE()算法来平衡数据。</p><blockquote class="mg mh mi"><p id="17b4" class="im in mj io b ip iq ir is it iu iv iw mk iy iz ja ml jc jd je mm jg jh ji jj hb bi translated"><strong class="io hj">注意:</strong> SMOTE(合成少数过采样技术)的工作原理是从少数类中随机选取一个点，并计算该点的k近邻。合成点被添加到所选点及其相邻点之间。</p></blockquote><p id="a6d5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">SMOTE算法在4个简单的步骤中工作:</p><ol class=""><li id="edac" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj nk lt lu lv bi translated">选择一个少数类作为输入向量。</li><li id="4452" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj nk lt lu lv bi translated">找到它的k个最近邻。</li><li id="76e8" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj nk lt lu lv bi translated">选择这些邻居中的一个，并将合成点放置在连接考虑中的点及其选择的邻居的线上的任何位置。</li><li id="cf91" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj nk lt lu lv bi translated">重复该步骤，直到数据平衡。</li></ol><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es nl"><img src="../Images/e02168ed0eef4229c86250f476c7a21e.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/0*pSgLV2XOoN8zudhv"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Balancing the data</figcaption></figure><p id="9522" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们数据的原始形状是753代表欺诈_无价值报告，247代表有。SMOTE算法将我们的数据与其中存在的最大数量的值进行平衡。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="4399" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated"><strong class="ak">建立机器学习模型</strong></h1><p id="2f28" class="pw-post-body-paragraph im in hi io b ip ky ir is it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj hb bi translated">为了构建机器学习模型，Sklearn模块中有几个模型。</p><p id="70aa" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Sklearn提供回归和分类两种模型。我们数据集的目标变量是预测欺诈是否被举报。因此，对于这类问题，我们使用分类模型。</p><p id="4870" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">但在将数据集拟合到其模型之前，我们首先必须分离预测变量和目标变量，然后将该变量传递给train_test_split方法，以创建随机测试和训练子集。</p><blockquote class="mg mh mi"><p id="3e90" class="im in mj io b ip iq ir is it iu iv iw mk iy iz ja ml jc jd je mm jg jh ji jj hb bi translated"><strong class="io hj">什么是train_test_split </strong>，it <strong class="io hj"> </strong>是sklearn模型选择中的一个函数，用于将数据组拆分为训练数据和测试数据两个子集。有了这个函数，就不需要手动划分数据集了。默认情况下，sklearn train_test_split会对这两个子集进行随机分区。但是，您也可以为操作指定随机状态。它给出四个输出x_train、x_test、y_train和y_test。x_train和x_test包含训练和测试预测变量，而y_train和y_test包含训练和测试目标变量。</p></blockquote><p id="6e0c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在执行train_test_split之后，我们必须选择模型来传递训练变量。</p><p id="7ebf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们可以建立尽可能多的模型来比较这些模型给出的精度，并从中选择最佳模型。</p><p id="726b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我选择了5种型号:</p><ul class=""><li id="4d71" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj ls lt lu lv bi translated"><strong class="io hj">来自sklearn.linear_model的Logistic回归:</strong> Logistic回归是一种监督学习分类算法，用于预测目标变量的概率。目标或因变量的性质是二元的，这意味着只有两种可能的类别1(代表成功/是)或0(代表失败/否)。在数学上，逻辑回归模型预测P(Y=1)为x的函数。这是最简单的ML算法之一，可用于各种分类问题，如垃圾邮件检测、糖尿病预测、癌症检测等。</li></ul><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es nm"><img src="../Images/62ca5755ea3b76ff39dbbf549bc58af7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/0*pfqOWff1OAC4pgFG"/></div></figure><ul class=""><li id="0ea8" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj ls lt lu lv bi translated"><strong class="io hj">来自sklearn.tree的决策树分类器:</strong>决策树可以通过一种算法方法来构建，这种算法方法可以基于不同的条件以不同的方式分割数据集。树的两个主要实体是决策节点，数据在这里被分割，树叶在这里我们得到结果。</li></ul><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es nn"><img src="../Images/a45281b6dcacecd0fa655e7d62584af5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/0*fTv8BRM7zNLqEta6"/></div></figure><ul class=""><li id="e17f" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj ls lt lu lv bi translated"><strong class="io hj">来自sklearn.ensemble的RandomForestClassifier】众所周知，森林是由树木组成的，更多的树木意味着更健壮的森林。类似地，随机森林算法在数据样本上创建决策树，然后从每个样本中获得预测，最后通过投票选择最佳解决方案。这是一种比单一决策树更好的集成方法，因为它通过平均结果来减少过拟合。</strong></li></ul><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es no"><img src="../Images/6077bbe3b644873696b6f4345663900f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/0*LCwLhGGXHqGwbpm9"/></div></figure><ul class=""><li id="d267" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj ls lt lu lv bi translated"><strong class="io hj">XGBoost的XGBClassifier:</strong>XGBoost是“极端梯度增强”的缩写。“极致”是指并行计算和缓存感知等速度增强，使XGBoost比传统的梯度提升快大约10倍。此外，XGBoost包括一个独特的分裂查找算法来优化树，以及内置的正则化来减少过度拟合。一般来说，XGBoost是一个更快、更精确的渐变增强版本。</li></ul><figure class="le lf lg lh fd ij er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es np"><img src="../Images/cc571a22523f7168e5ca5fb1ee54e3a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WuZgyxaEAVjRHxs_"/></div></div></figure><ul class=""><li id="d2de" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj ls lt lu lv bi translated"><strong class="io hj">来自sklearn.naive_bayes的GaussianNB:</strong>Naive bayes算法是一种基于应用Bayes定理的分类技术，它强烈假设所有预测器都是相互独立的。简而言之，假设一个类中某个特性的存在独立于同一个类中任何其他特性的存在。它是最简单的朴素贝叶斯分类器，假设来自每个标签的数据来自简单的高斯分布。</li></ul><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es nq"><img src="../Images/ffcb692236839dfbc985ece271e61b1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/0*G9Dbspa11PXd9o4T"/></div></figure></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="47a5" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated"><strong class="ak">从模型中得出的结论</strong></h1><p id="ff4a" class="pw-post-body-paragraph im in hi io b ip ky ir is it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj hb bi translated">我们得到了我们最好的模型，即RandomForestClassifier，准确率达到85.39%。这里，我们的模型预测218个阳性病例中的196个真阳性病例和234个真阴性病例中的190个真阴性病例。它预测218个阳性病例中的22个假阳性病例和234个病例中的44个假阴性病例。它给出了85.20%的f1分数。</p><p id="f9c4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">了解精确回忆和f1分数和准确度的作用</strong></p><ul class=""><li id="0ffe" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj ls lt lu lv bi translated"><strong class="io hj"> F1得分</strong>:这是精确度和召回率的调和平均值，比精确度矩阵更能衡量错误分类的情况。</li></ul><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es nr"><img src="../Images/09dd957c58cb2e54b6264397169e4384.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/0*SBF4_7A0xXlIwlvq"/></div></figure><ul class=""><li id="c203" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj ls lt lu lv bi translated"><strong class="io hj">精度:</strong>隐含为从所有预测阳性病例中正确识别出阳性病例的度量。因此，当假阳性的成本很高时，它是有用的。</li></ul><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es ns"><img src="../Images/e31de94a5cf639f7528bae32d895a3ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/0*6dsP8opk38XO3PiU"/></div></figure><ul class=""><li id="06f7" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj ls lt lu lv bi translated"><strong class="io hj">召回:</strong>是从所有实际阳性病例中正确识别出阳性病例的度量。当假阴性的成本很高时，这一点很重要。</li></ul><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es nt"><img src="../Images/fda02673fce32acdc0e11626a4592515.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/0*X9ijCGKu8cE0iQx1"/></div></figure><ul class=""><li id="a6ee" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj ls lt lu lv bi translated"><strong class="io hj">准确性:</strong>更明显的度量之一，它是所有正确识别的案例的度量。当所有的类都同等重要时，它最常用。</li></ul><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es nr"><img src="../Images/134628db4e9f0674a82d76f2ab7620fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/0*O960GxAFX6onX_ak"/></div></figure><p id="4793" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">混淆矩阵</strong></p><p id="31af" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一种表格，通常用于描述分类模型(或“分类器”)对一组已知真实值的测试数据的性能。</p><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es nu"><img src="../Images/512780db71d0c6b552bebd23e2f53b20.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/0*LWcK7qbflSMcZ7qo"/></div></figure><blockquote class="mg mh mi"><p id="c49b" class="im in mj io b ip iq ir is it iu iv iw mk iy iz ja ml jc jd je mm jg jh ji jj hb bi translated"><strong class="io hj">注:</strong></p><p id="0caf" class="im in mj io b ip iq ir is it iu iv iw mk iy iz ja ml jc jd je mm jg jh ji jj hb bi translated"><strong class="io hj">TN/真阴性:</strong>病例阴性，预测阴性。</p><p id="c5b8" class="im in mj io b ip iq ir is it iu iv iw mk iy iz ja ml jc jd je mm jg jh ji jj hb bi translated"><strong class="io hj">TP/真阳性:</strong>病例阳性，预测阳性。</p><p id="3a23" class="im in mj io b ip iq ir is it iu iv iw mk iy iz ja ml jc jd je mm jg jh ji jj hb bi translated"><strong class="io hj">FN/假阴性:</strong>病例呈阳性但预测为阴性。</p><p id="d28c" class="im in mj io b ip iq ir is it iu iv iw mk iy iz ja ml jc jd je mm jg jh ji jj hb bi translated"><strong class="io hj">TN/真阴性:</strong>病例为阴性但预测为阳性。</p></blockquote></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="5217" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated"><strong class="ak">超参数调谐</strong></h1><p id="d8e6" class="pw-post-body-paragraph im in hi io b ip ky ir is it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj hb bi translated">机器学习中的超参数优化旨在找到给定机器学习算法的超参数，这些参数在验证集上测量时提供最佳性能。与模型参数相反，超参数由机器学习工程师在训练之前设置。随机森林中的树的数量是超参数，而神经网络中的权重是在训练期间学习的模型参数。我喜欢将超参数视为要调整的模型设置，以便模型可以最优地解决机器学习问题。</p><p id="98d2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将使用GridSearchCV进行超参数调优。</p><p id="d2a1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> GridSearchCV </strong></p><p id="13ba" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在GridSearchCV方法中，针对一系列超参数值来评估机器学习模型。这种方法被称为GridSearchCV，因为它从超参数值的网格中搜索最佳超参数集。</p><figure class="le lf lg lh fd ij er es paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="er es nv"><img src="../Images/16c406cea4669fb9d050ca78069a3128.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*r7nb_Bl7VCISEK5e"/></div></div></figure><p id="ee02" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> ROC曲线:</strong> It <strong class="io hj">ROC是概率曲线，AUC代表可分性的程度或度量。它告诉我们这个模型在多大程度上能够区分不同的类。AUC越高，模型预测0为0和1为1的能力越强。以此类推，AUC越高，模型在区分患病和未患病患者方面就越好。</strong></p><p id="a4e2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">用TPR对FPR绘制ROC曲线，其中TPR在y轴上，FPR在x轴上。</p><figure class="le lf lg lh fd ij er es paragraph-image"><div class="er es nw"><img src="../Images/f26547b4885658bdb43c4f8852f85c30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/0*WNpkR4npcAAD5AQJ"/></div><figcaption class="li lj et er es lk ll bd b be z dx">Comparing ROC curves for all the models</figcaption></figure></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="f2e2" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated"><strong class="ak">备注</strong></h1><p id="e5ff" class="pw-post-body-paragraph im in hi io b ip ky ir is it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj hb bi translated">这个项目建立了一个可以检测汽车保险欺诈的模型。这样做，该模型可以减少保险公司的损失。机器学习中欺诈检测背后的挑战是，与合法的保险索赔相比，欺诈远不常见。</p><p id="1081" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这个项目中使用了五种不同的分类器:逻辑回归、K-最近邻、随机森林、决策树、高斯神经网络。用这五个分类器测试了处理不平衡类的四种不同方式:类加权模型、SMOTE过采样、超参数调整和绘制模型的roc曲线。</p><p id="1059" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">最佳和最终拟合的模型是加权的<strong class="io hj"> <em class="mj">随机森林</em> </strong>，其F1值为<em class="mj"> 0.85 </em>，ROC AUC为<em class="mj"> 0.95 </em>。该模型表现出色。该模型的F1评分和ROC AUC评分是其他模型中最高的。总之，该模型能够以较高的准确度正确区分欺诈索赔和合法索赔。</p><p id="8809" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这项研究并非没有局限性。首先，本研究受到样本量小的限制。数据集越大，统计模型越稳定。它也更容易概括，因为它占实际人口的比例更大。此外，该数据仅涵盖3个州的事故索赔。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="67e2" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated"><strong class="ak">参考文献</strong></h1><ul class=""><li id="62b4" class="ln lo hi io b ip ky it kz ix lp jb lq jf lr jj ls lt lu lv bi translated"><a class="ae nx" href="https://www.youtube.com/watch?v=UaiRkUuzcPI" rel="noopener ugc nofollow" target="_blank"> XGBClassifier </a></li><li id="3a33" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj ls lt lu lv bi translated"><a class="ae nx" href="https://www.youtube.com/watch?v=SctFnD_puQI" rel="noopener ugc nofollow" target="_blank">超参数调谐</a></li><li id="9ffc" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj ls lt lu lv bi translated"><a class="ae nx" href="https://www.youtube.com/watch?v=YMPMZmlH5Bo" rel="noopener ugc nofollow" target="_blank">重击</a></li><li id="1e95" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj ls lt lu lv bi translated"><a class="ae nx" href="https://towardsdatascience.com/getting-started-with-xgboost-in-scikit-learn-f69f5f470a97" rel="noopener" target="_blank">XGBoost入门</a></li><li id="8e73" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj ls lt lu lv bi translated">GridSearchCV优化&amp;T21:</li></ul><ol class=""><li id="7b0f" class="ln lo hi io b ip iq it iu ix lx jb ly jf lz jj nk lt lu lv bi translated">Sebastian Raschka和Vahid Mirjalili的Python机器学习</li><li id="87dd" class="ln lo hi io b ip ma it mb ix mc jb md jf me jj nk lt lu lv bi translated">伊莎贝尔·盖恩的《变量和特征选择导论》</li></ol></div></div>    
</body>
</html>