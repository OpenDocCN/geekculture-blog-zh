<html>
<head>
<title>Classification and Regression Evaluation Metrics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分类和回归评估指标</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/classification-and-regression-evaluation-metrics-c7cc843b3486?source=collection_archive---------3-----------------------#2021-03-01">https://medium.com/geekculture/classification-and-regression-evaluation-metrics-c7cc843b3486?source=collection_archive---------3-----------------------#2021-03-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9664" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在选择机器学习模型时，谨慎选择性能指标是极其重要的。不这样做将导致模型部署后的结果受到损害。评估指标给出了我们的机器学习模型有多好以及我们的算法执行得有多好的定量测量。</p><h2 id="d24c" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">分类指标</h2><p id="2d8a" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated">1.准确性-它等于正确预测的数量/总预测的数量。拆分数据，拟合出需要的模型后，简单使用来自sklearn的score方法就可以找到精度。范围从0到1。</p><p id="275c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Model_name.score(测试数据)</p><p id="6e68" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">准确性度量仅仅告诉我们的模型有多好或多坏，但是没有给出关于它有什么问题或者它在哪里出错的信息。只有当我们有一个平衡的数据集时，它才是可靠或合适的。</p><p id="60fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这可以使用混淆矩阵来完成。</p><p id="943d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.混淆矩阵是一个表格，它让我们了解我们的模型做出了多少正确的预测。它将实际输出值和预测输出值关联起来。也可以对多类问题作图。</p><blockquote class="kd ke kf"><p id="b18f" class="if ig kg ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc hb bi translated">真正(TP)值是那些被正确预测为正的值。</p><p id="8033" class="if ig kg ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc hb bi translated">假阳性(FP)值被错误地预测为阳性。</p><p id="3dd5" class="if ig kg ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc hb bi translated">假阴性(FN)值应该被预测为阳性，但没有。</p><p id="0a2f" class="if ig kg ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc hb bi translated">最后，真阴性(TN)值被正确地预测为阴性。</p></blockquote><p id="31a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要使用混淆矩阵，您可以从sklearn.metric导入它，并使用以下语法:</p><p id="c928" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">混淆矩阵(实际值，预测值)</p><p id="b239" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，在下面的示例中，正确的预测=126+60=186</p><p id="90d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">错误预测=24+13=37</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es kk"><img src="../Images/1338677be4e03dd7b6922600c2713d77.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*FvArRxQVnBXvh07_A4BF_g.png"/></div></figure><blockquote class="kd ke kf"><p id="6db7" class="if ig kg ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc hb bi translated">注:类型1误差=FP速率= FP/FP+TN</p><p id="a146" class="if ig kg ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc hb bi translated">类型2误差= FN速率=FN/FN+TP</p><p id="68a6" class="if ig kg ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc hb bi translated">在这些术语中，我们可以说精确度= TN+TP / (TP+TN+FP+FN)</p></blockquote><p id="76a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们的数据集是不平衡的，建议使用召回率和精确度，而不是仅仅依靠精确度。</p><p id="a5b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.精度-它也被称为正预测值。它是真阳性与总阳性的比率。例如，如果我们的模型将患有癌症(1)或未患癌症(0)的患者进行分类。这里的精确度是已经被正确识别为患有癌症的患者与已经被检测出患有癌症的患者总数的比率。</p><p id="4aeb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">精度= TP/TP+FP</p><p id="35a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们想要减少误报时，通常会考虑到这一点。</p><p id="c54a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.召回率——它是真阳性与真阳性和假阴性之和的比率。简单来说，就是正确预测值与实际正值总数的比值。在癌症的例子中，它会给我们正确识别出患有该疾病的患者与实际患有该疾病的患者进行比较。它也被称为TPR(真阳性率)或灵敏度。</p><p id="d23e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">召回= TP/TP+FN</p><p id="6e73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们想要减少假阴性时，通常会将它考虑在内。</p><blockquote class="kd ke kf"><p id="06da" class="if ig kg ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc hb bi translated">注意-在我们的癌症例子的情况下，如果一个人患有癌症，但被预测为没有癌症(假阴性)。这将是我们最坏的情况，并可能带来灾难性的后果。在这种情况下，我们应该专注于回忆。</p></blockquote><p id="45b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.这是精确度和召回率的调和平均值。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es ks"><img src="../Images/b7a681fae0fef15f614a2d7fbd67a9b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*TKL6AgyBv85-CFSZY1mfKQ.png"/></div></figure><p id="4bb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果β值= 1，则称为F1分。如果是2，就叫F2分，以此类推。当FP和FN同等重要时，β值选择为1。如果FP更本质，β值就减少到0到1之间。如果FN更重要，则将β值增加到大于1(1到10之间)。</p><p id="4eb0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">6.F1得分- F1得分= 2 *(精确度*召回率/精确度+召回率)</p><p id="00f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">=2*TP/2* TP+FP+FN</p><p id="de32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它考虑了真阳性、假阳性和假阴性，但不考虑真阴性。一个好的F1分数表明一个好的精确度和召回率，这样，我们不需要单独关注其中任何一个。</p><blockquote class="kd ke kf"><p id="9cb7" class="if ig kg ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc hb bi translated">注意-在多类问题的情况下，我们也可以计算精度和回忆，但是找到四个关键元素TP，FP，TN，FN的过程会有一点不同。</p></blockquote><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es kt"><img src="../Images/009e07dfbeb030f5b8aafc9059601ec8.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*CR41UnW5UDPnp7QNMjq2Qg.png"/></div></figure><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es ku"><img src="../Images/ba7d7eb42be9c7dad99ccc0268e7f248.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*xwNF98SHxLY-xZoyWdD3aw.png"/></div></figure><p id="961a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">微精度= 5/(5+4)=5/9</p><p id="c096" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">宏精度-计算每个类的精度:Precision(A)= 1；精度(B)= 3/6 = 0.5；精度(C)= 1/2=0.5</p><p id="6523" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在取这些的平均值，宏精度= (1+0.5+0.5)/3=0.667</p><p id="91cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">加权平均值——乘以各精度下的各类样本数，除以总样本数=(2 * 1+3 * 0.5+4 * 0.5)/(2+4+3)= 0.61</p><p id="c80e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.马修斯相关系数-这使用了混淆矩阵的所有四个类别。</p><p id="3a13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">MCC = TP * TN-FP * FN/sqrt((TP+FP)(TP+FN)(TN+FP)(TN+FN))</p><p id="5ae2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请记住，如果某些为零，MCC可能会作为未定义返回。如果我们翻转正值和负值，F1分数将会改变，但您可能会观察到MCC保持不变。这是因为F1分数对哪个类是正的和负的很敏感。</p><p id="b4d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">8.ROC(受试者工作特性)曲线——这是一种更简单的方法来总结我们从混淆矩阵中得到的信息。它们在y轴上有真阳性率，在x轴上有假阳性率。</p><p id="2349" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">真实阳性率(回忆或敏感度)=TP/ TP+FN</p><p id="4981" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假阳性率= 1-特异性(或真阴性率)= FP/FP+TN</p><p id="c871" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">9.曲线下面积。这样更容易比较多个ROC曲线和ML模型。曲线下的面积越大，模型越好。</p><p id="eb33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">10.精度/召回曲线</p><p id="b409" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">x轴表示精确度，y轴表示召回率。</p><p id="b290" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">11.原木损失</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es kv"><img src="../Images/2df176a51cc0f5d40fe98aa3356e515e.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*C2Vck_gtEHNOKenN-lIhzQ.png"/></div></figure><p id="bd37" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它将模型预测的不确定性考虑在内，并评估给定类别的概率预测。随着预测概率偏离实际标签，测井曲线损失增加。因此，对数损失越小，模型越好。如果我们将实际标签设为1，预测值设为0.9，我们将会有非常小的对数损失。另一方面，0.2的对数损失将呈现高得多的对数损失值。</p><p id="9291" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还可以计算多类日志损失。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es kw"><img src="../Images/953ef611f839cee2aa83ca4b6398efd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*iGEUW6WO_la5qDSOQOqebg.png"/></div></figure><blockquote class="kd ke kf"><p id="365c" class="if ig kg ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc hb bi translated">分类报告提供准确度、精确度、召回率、f1分数和支持。</p></blockquote><h2 id="77ab" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">回归评估度量</h2><p id="87b3" class="pw-post-body-paragraph if ig hi ih b ii jy ik il im jz io ip iq ka is it iu kb iw ix iy kc ja jb jc hb bi translated">1.r平方(决定系数)-它给出了数据与拟合回归线接近程度的度量(拟合优度)。它决定了因变量中可以用自变量解释的方差的比例。它利用了实际值和预测值之间的差异，以及实际值和实际值的平均值之间的差异。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es kx"><img src="../Images/fda4202c6ad201a933291b66ae192a32.png" data-original-src="https://miro.medium.com/v2/resize:fit:468/format:webp/1*IsaawFFsLDCCxfDWST0Rkg.png"/></div></figure><p id="6570" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">= (1-RSS(残差平方和))/TSS(总平方和)</p><p id="bbc7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ky" href="https://neptune.ai/blog/performance-metrics-in-machine-learning-complete-guide" rel="noopener ugc nofollow" target="_blank">这里的</a>是一篇关于评估指标和使用调整后的R平方来克服R平方缺陷的深刻文章。</p><p id="8618" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">sklearn中回归变量的评分方法给出了R的平方值。然而，R的平方不能给我们任何关于误差的信息。</p><p id="b460" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我们可以使用平均绝对误差(MAE)。</p><p id="80c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.MAE-它是真实值和预测值之间总差值的平均值。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es kz"><img src="../Images/c01f10112842109ae8997ef159409d90.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*F9zCDdqotV9Zh5uQTSu5TQ.png"/></div></figure><p id="79ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.均方误差(MSE)-它测量误差平方的平均值(观察值和预测值之间的差异)。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es la"><img src="../Images/13840098f98c79ec5ded3e77cf0c036c.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*4HpgRiDxCYowUbWt64taHw.png"/></div></figure><p id="22fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">= RSS(残差平方和)/数据点数</p><p id="fad5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.RMSE(均方根误差)-它是MSE的根</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es lb"><img src="../Images/17ad78698a407c5555a1d775b2a44db4.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*_bKrCczaLO7axj0VBwCaPQ.png"/></div></figure><p id="93fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.均方根对数误差</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es lc"><img src="../Images/39a942095c5995e84d4202f5b25ac7cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*nJjMVRleGUBCEfRJCI_7eQ.png"/></div></figure></div></div>    
</body>
</html>