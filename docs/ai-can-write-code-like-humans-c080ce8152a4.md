# AI 可以像人类一样写代码

> 原文：<https://medium.com/geekculture/ai-can-write-code-like-humans-c080ce8152a4?source=collection_archive---------14----------------------->

去年 6 月，微软的子公司 GitHub 提供托管和协作代码的工具，发布了一个使用人工智能协助程序员的程序的测试版。开始输入命令、数据库查询或对 API 的请求，这个名为 [Copilot](https://copilot.github.com/) 的程序会猜测你的意图并写出其余的内容。

[Alex Naka](https://twitter.com/gottapatchemall?lang=en) ，一家生物技术公司的数据科学家，注册测试 Copilot，他说这个程序非常有帮助，它改变了他的工作方式。“它让我花更少的时间跳转到浏览器来查找 API 文档或堆栈溢出的例子，”他说。“感觉确实有点像我的工作已经从代码的生成者变成了代码的鉴别者。”

但是 Naka 发现错误可以以不同的方式潜入他的代码。“当我接受它的一个提议时，有几次我错过了一些微妙的错误，”他说。“要找到这一点真的很难，也许是因为它犯的错误似乎与我犯的错误有所不同。”

人工智能产生错误代码的风险可能高得惊人。NYU[的研究人员最近分析了由 Copilot](https://arxiv.org/pdf/2108.09293.pdf) 生成的代码，发现对于某些安全性至关重要的任务，代码在大约 40%的时间里包含安全缺陷。

参与分析的 NYU 大学教授布伦丹·多兰-加维特说，这个数字“比我预期的要高一点”。“但 Copilot 接受训练的方式实际上并不是为了写出好的代码——它只是为了产生一种能遵循给定提示的文本。”

尽管存在这些缺陷，Copilot 和类似的人工智能工具可能预示着软件开发人员编写代码的方式将发生巨大变化。人们对使用人工智能来帮助自动化更普通的工作越来越感兴趣。但 Copilot 也强调了当今人工智能技术的一些缺陷。

“看起来它犯的错误与我犯的错误有所不同。”

亚历克斯 DATA，数据科学家

在分析 Copilot 插件的可用代码时，Dolan-Gavitt [发现](https://twitter.com/moyix/status/1433254293352730628)它包含了一个受限短语列表。这些显然是为了防止系统脱口而出攻击性的信息或复制他人编写的著名代码。

GitHub 的研究副总裁、Copilot 的开发者之一 Oege de Moor 表示，安全性从一开始就是一个问题。他说，NYU 研究人员引用的有缺陷代码的百分比只与更有可能出现安全缺陷的代码子集相关。

De Moor 发明了 [CodeQL](https://securitylab.github.com/tools/codeql/) ，这是 NYU 研究人员使用的一种工具，可以自动识别代码中的错误。他说 GitHub 建议开发者将 Copilot 与 CodeQL 结合使用，以确保他们的工作是安全的。

GitHub 程序建立在由 [OpenAI](https://www.wired.com/tag/openai/) 开发的人工智能模型之上，OpenAI 是一家在机器学习领域从事前沿工作的著名人工智能公司。该模型名为 Codex，由一个大型人工神经网络组成，该网络经过训练可以预测文本和计算机代码中的下一个字符。该算法消化了 GitHub 上存储的数十亿行代码——并非所有代码都完美无缺——以学习如何编写代码。

在 Codex 之上，OpenAI 创建了自己的人工智能编码工具，能够完成一些令人惊叹的编码壮举。它可以将书面指令转换为许多编程语言的可执行代码，例如“创建一个 1 到 100 之间的随机变量数组，然后返回其中最大的一个。”

同样的 OpenAI 算法的另一个迭代，称为 GPT-3，能够产生关于特定主题的可理解的写作，但它也可能重复从网络上不太美味的部分学到的攻击性或偏见的单词。

Copilot 和 Codex 让一些开发人员想知道人工智能是否会让他们自动失业。事实上，Naka 的经验表明，开发人员需要相当的技能来使用程序，因为他们经常必须审查或调整它的建议。

NYU 大学从事 Copilot 代码检查的博士后研究员 Hammond Pearce 说，该算法偶尔会生成错误的代码，因为它没有完全理解一段代码试图做什么。

据他所说，缺少开发人员需要了解的上下文经常会导致漏洞。

一些软件工程师担心人工智能已经养成了不良习惯。

软件开发人员马克西姆·凯洛(Maxim Khailo)曾尝试利用人工智能来产生代码，但没有使用过 Copilot，他声称该行业一直在努力摆脱复制粘贴解决方案。

根据 Khailo 的说法，黑客可以篡改像 Copilot 这样的程序。

在 GitHub 上创建易受攻击的代码项目，通过在黑市上购买 GitHub 明星来人为提高其知名度，然后希望它会被纳入即将到来的培训周期的语料库，这是一个糟糕的演员会做的事情。

相反，根据 GitHub 和 OpenAI 的说法，他们的 AI 编码工具只会变得更不容易出错。

根据 OpenAI 的说法，它使用手动和自动技术来审查代码和项目。

GitHub 的 De Moor 表示，最近的 Copilot 补丁应该已经减少了安全问题的发生。

然而，他补充说，他的团队正在寻找提高 Copilot 产量的其他选择。

一个是消除底层人工智能模型学习的不良实例。

另一种选择是使用强化学习自动检测低于标准的输出，包括以前未观察到的例子，强化学习是一种人工智能技术，已经在游戏和其他领域取得了一些惊人的成果。

他声称“巨大的进步”正在发生。

"一年后它会是什么样子几乎是无法想象的。"