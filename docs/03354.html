<html>
<head>
<title>It’s time to ditch Apache Spark and adopt Dask</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">是时候抛弃阿帕奇火花，采用达斯克了</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/its-time-to-ditch-apache-spark-and-love-dask-ad799a2cdf24?source=collection_archive---------6-----------------------#2021-06-07">https://medium.com/geekculture/its-time-to-ditch-apache-spark-and-love-dask-ad799a2cdf24?source=collection_archive---------6-----------------------#2021-06-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d597" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这不是Apache Spark和Dask之间的比较。但是如果你对此感兴趣的话，Dask会谦虚地把它包含在他们的官方文档中。这篇博客讲述了我使用这两种框架构建应用程序的经历。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/28ccd59a46020051e80692bbdc09bafc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v9rc2_4Chbj8j0LXmoP-eg.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">apache spark &amp; dask</figcaption></figure><h2 id="b523" class="ju jv hi bd jw jx jy jz ka kb kc kd ke iq kf kg kh iu ki kj kk iy kl km kn ko bi translated">火花很棒，但是…</h2><p id="1d9d" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">在<a class="ae jd" href="https://www.quartic.ai/" rel="noopener ugc nofollow" target="_blank"> Quartic.ai </a>我们已经使用Apache Spark构建了多个作业，这些作业对不同类型的数据执行入口/出口、ETL、评分模型等操作，这些数据具有流和批处理的性质。如果数据帧和rdd分布在集群中的多个节点上，Spark丰富的API集将使您的工作变得容易。但是问题在于构建所需的数据帧，以便我们可以利用Spark提供的API。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ku"><img src="../Images/fe2647708c17ab266111ddb2a4e37f00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9vm23AT3IASqWCRBIwjbnQ.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">dataengineers assemble</figcaption></figure><p id="a57f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们有来自多个物联网传感器的高频率数据流。现在想象使用Apache Spark在这些数据的基础上构建管道来服务成千上万的机器学习模型。这里有一个由康纳尔·梅菲撰写的很好的<a class="ae jd" href="https://databricks.com/blog/2020/05/19/manage-and-scale-machine-learning-models-for-iot-devices.html" rel="noopener ugc nofollow" target="_blank">博客，解释了关于大规模培训和部署多个模型。这很好，但在实践中，我们不只是为每台设备部署一种型号。每个传感器可以有多个模型，也存在预测被用作其他模型的特征的情况。但是，要为这样的用例生成流数据集而不引入管道偏斜，需要仔细选择分区策略(是否使用device-id、model-id或其他什么作为kafka主题的分区键)。</a></p><h2 id="1dd5" class="ju jv hi bd jw jx jy jz ka kb kc kd ke iq kf kg kh iu ki kj kk iy kl km kn ko bi translated">成功了吗？嗯…</h2><p id="dc59" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">在经历了构建管道来对数据流执行清理、ETL和反规范化的所有麻烦之后，我们意识到我们不能超越极限。我们要么扩展集群，要么将作业的微批处理间隔增加到30秒以上。我们可以在集群中部署的最大型号数量也少得惊人——在24个内核和24个kafka分区上部署600个型号。</p><p id="d173" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的问题不仅涉及ML模型，还涉及用户编写的必须在流数据上执行的定制代码，这些代码可以在多个ML模型中用作特性。所以我们的挑战是找到解决这种依赖性的实现。在Spark中，这不是一项简单的任务。我们必须创建不同的管道和回环来完成，如果资源已经不足，这不是一个非常有效的解决方案。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kv"><img src="../Images/d0d450fe77ee193b4b95b2c6c8b1175e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nk1crUIrBTO_HQaTHTtrfA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">ETL pipeline with loopback</figcaption></figure><h2 id="cb0e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke iq kf kg kh iu ki kj kk iy kl km kn ko bi translated">从小处着眼</h2><p id="ee00" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">我们很清楚，如果我们能够自己构建DAG，就有可能避免一些重复工作。Spark在执行作业之前构建Dag，但是我们找不到任何可以使用的高级API。我们之前使用了一个名为<a class="ae jd" href="https://github.com/yahoo/graphkit" rel="noopener ugc nofollow" target="_blank"> Graphkit </a>的小python库来构建应用程序。所以我们再次转向它，忽略了python的GIL不允许节点并行执行的事实。而Graphkit最终成为了我们解决依序解决依赖问题的解决方案。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kw"><img src="../Images/fc544e4addec6948614c3856b49490e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aOCBENsK99TUoHPaP-GvVw.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">graphkit graph</figcaption></figure><p id="9361" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它适用于小型应用程序和玩具项目/概念验证，但扩展是一个挑战。</p><h2 id="08d5" class="ju jv hi bd jw jx jy jz ka kb kc kd ke iq kf kg kh iu ki kj kk iy kl km kn ko bi translated">见见类固醇上的Graphkit，Dask</h2><p id="6cf7" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">在我们的一次头脑风暴中，<a class="ae jd" rel="noopener" href="/@dineshkumaryelluri09">迪内什</a>(我的队友)推荐了达斯克。我一直认为这是为了大规模处理熊猫数据帧，这是Spark已经擅长的事情。但我从来不知道他们的其他API。而Dask的<a class="ae jd" href="https://docs.dask.org/en/latest/delayed.html" rel="noopener ugc nofollow" target="_blank">延迟API </a>正是我们所需要的！它不仅允许我们使用低级API构建所需的DAG，还允许graph以分布式方式大规模执行。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kx"><img src="../Images/af14636c05e134980620ca36c61421bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TH3aj_8v5LtWlmrH95TqmA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">Dask graph</figcaption></figure><p id="6858" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该API功能强大，我们能够通过组合Graphkit和Dask来快速构建解决方案，以便在同一24核上服务数千个模型，同时还能动态解析依赖关系。看到数千个节点在几秒钟内被处理是一件令人高兴的事情。</p><h2 id="426a" class="ju jv hi bd jw jx jy jz ka kb kc kd ke iq kf kg kh iu ki kj kk iy kl km kn ko bi translated">结论</h2><p id="8f0a" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">初创公司经常发现自己没有太多时间进行研发。为了满足交付期限，他们不得不使用他们知道会起作用的工具。尽管这涉及到实施变通办法，但解决方案可能不是最好的。对于我们在Quartic.ai的人来说，我们总是在寻找改进我们平台的解决方案；我们对Dask为我们所做的努力感到高兴。</p></div></div>    
</body>
</html>