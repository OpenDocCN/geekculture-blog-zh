<html>
<head>
<title>Stroke Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">中风预测</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/stroke-prediction-d26c15f9d1?source=collection_archive---------1-----------------------#2021-03-08">https://medium.com/geekculture/stroke-prediction-d26c15f9d1?source=collection_archive---------1-----------------------#2021-03-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="401f" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">构建脑卒中风险预测模型</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/35429b79335bc75fd82cd2f51b5e4203.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KXyefoMEyCTb4fkf"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@austriannationallibrary?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Austrian National Library</a> on <a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="4741" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">1.介绍</h2><p id="cb3e" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">根据世界卫生组织(世卫组织)的数据，中风是全球第二大死亡原因和第三大残疾原因。中风是由于大脑动脉阻塞或破裂导致大脑血流减少时，由于缺氧而导致一些脑细胞突然死亡，它也是痴呆症和抑郁症的主要原因。</p><p id="a392" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">美国每年有近80万人患有中风，其中约四分之三是首次中风。80%的情况下这些中风是可以预防的，因此对中风的征兆进行适当的教育是非常重要的。</p><p id="df9d" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">本研究的目的是构建一个预测中风的预测模型，并评估该模型的准确性。我们将探索七种不同的模型，看看哪种模型能产生可靠且可重复的结果。这些模型是:决策树、逻辑回归、随机森林、支持向量机、K近邻、朴素贝叶斯和K均值聚类。根据模型的预测结果，最佳性能模型将经历交叉验证过程，以评估其可重复性。</p><h2 id="0f7b" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">2.数据源</h2><p id="d2f0" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">本研究涉及5110人，其中女性2995人，男性2115人。本研究的数据集提取自Kaggle数据仓库(https://www.kaggle.com/datasets ),用于根据以下属性信息预测患者是否可能患中风:</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="ce60" class="jo jp hi ll b fi lp lq l lr ls">1.  id                : unique identifier<br/>2.  gender            : "Male", "Female" or "Other"<br/>3.  age               : age of the patient<br/>4.  hypertension      : 0 if the patient doesn't have hypertension, 1 if the patient has hypertension<br/>5.  heart_disease     : 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease<br/>6.  ever_married      : "No" or "Yes"<br/>7.  work_type         : "children", "Govt_jov", "Never_worked", "Private" or "Self-employed"<br/>8.  Residence_type    : "Rural" or "Urban"<br/>9.  avg_glucose_level : average glucose level in blood<br/>10. bmi               : body mass index<br/>11. smoking_status    : "formerly smoked", "never smoked", "smokes" or "Unknown"<br/>12. stroke            : 1 if the patient had a stroke, 0 the patient do not have a stroke</span></pre><h2 id="6fa0" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">3.导入库和数据</h2><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="15b0" class="jo jp hi ll b fi lp lq l lr ls">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>%matplotlib inline<br/>import warnings<br/>warnings.filterwarnings(action='ignore')</span><span id="6c97" class="jo jp hi ll b fi lt lq l lr ls">data = pd.read_csv('healthcare-dataset-stroke-data.csv')<br/>data.head(3)</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lu"><img src="../Images/bda709e7e983d165508c05213a2e8c55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7kK7ZxNPAFenMCSOPiCGLA.png"/></div></div></figure><h2 id="6997" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">4.数据清理</h2><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="e913" class="jo jp hi ll b fi lp lq l lr ls">data_row_count, data_column_count = data.shape<br/>print('Row Count:', data_row_count)<br/>print('Column Count:', data_column_count)</span><span id="ad53" class="jo jp hi ll b fi lt lq l lr ls">Row Count: 5110<br/>Column Count: 12</span><span id="cf2b" class="jo jp hi ll b fi lt lq l lr ls">data.info()</span><span id="dc2d" class="jo jp hi ll b fi lt lq l lr ls">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 5110 entries, 0 to 5109<br/>Data columns (total 12 columns):<br/> #   Column             Non-Null Count  Dtype  <br/>---  ------             --------------  -----  <br/> 0   id                 5110 non-null   int64  <br/> 1   gender             5110 non-null   object <br/> 2   age                5110 non-null   float64<br/> 3   hypertension       5110 non-null   int64  <br/> 4   heart_disease      5110 non-null   int64  <br/> 5   ever_married       5110 non-null   object <br/> 6   work_type          5110 non-null   object <br/> 7   Residence_type     5110 non-null   object <br/> 8   avg_glucose_level  5110 non-null   float64<br/> 9   bmi                4909 non-null   float64<br/> 10  smoking_status     5110 non-null   object <br/> 11  stroke             5110 non-null   int64  <br/>dtypes: float64(3), int64(4), object(5)<br/>memory usage: 479.2+ KB</span><span id="f68a" class="jo jp hi ll b fi lt lq l lr ls">data.isna().sum()</span><span id="dcae" class="jo jp hi ll b fi lt lq l lr ls">id                     0<br/>gender                 0<br/>age                    0<br/>hypertension           0<br/>heart_disease          0<br/>ever_married           0<br/>work_type              0<br/>Residence_type         0<br/>avg_glucose_level      0<br/>bmi                  201<br/>smoking_status         0<br/>stroke                 0<br/>dtype: int64</span></pre><p id="59e9" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">身体质量指数要素中有201个缺失值。处理缺失值的一个简单方法是删除具有空值的行，但是这可能会删除不为空的数据。因此，我们将用bmi的平均值替代缺失值，并检查是否完成了插补。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="0dbc" class="jo jp hi ll b fi lp lq l lr ls">data['bmi'] = data['bmi'].fillna(data['bmi'].mean())<br/>data.info()</span><span id="b562" class="jo jp hi ll b fi lt lq l lr ls">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 5110 entries, 0 to 5109<br/>Data columns (total 12 columns):<br/> #   Column             Non-Null Count  Dtype  <br/>---  ------             --------------  -----  <br/> 0   id                 5110 non-null   int64  <br/> 1   gender             5110 non-null   object <br/> 2   age                5110 non-null   float64<br/> 3   hypertension       5110 non-null   int64  <br/> 4   heart_disease      5110 non-null   int64  <br/> 5   ever_married       5110 non-null   object <br/> 6   work_type          5110 non-null   object <br/> 7   Residence_type     5110 non-null   object <br/> 8   avg_glucose_level  5110 non-null   float64<br/> 9   bmi                5110 non-null   float64<br/> 10  smoking_status     5110 non-null   object <br/> 11  stroke             5110 non-null   int64  <br/>dtypes: float64(3), int64(4), object(5)<br/>memory usage: 479.2+ KB</span><span id="eec1" class="jo jp hi ll b fi lt lq l lr ls">data.describe()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lv"><img src="../Images/ab57bb7da4958447a5618f52e99879d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aFYyknHuKRyzqHzDAkoCBg.png"/></div></div></figure><h2 id="8155" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">4.1身份证</h2><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="0a0c" class="jo jp hi ll b fi lp lq l lr ls">data.id.nunique()</span><span id="a52b" class="jo jp hi ll b fi lt lq l lr ls">5110</span></pre><p id="b20d" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">唯一id的总数与行数相同。我们不需要另一个标识符。因此，我们将删除该列。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="d9df" class="jo jp hi ll b fi lp lq l lr ls">data = data.drop(columns ='id')</span><span id="8921" class="jo jp hi ll b fi lt lq l lr ls">data.shape</span><span id="39d4" class="jo jp hi ll b fi lt lq l lr ls">(5110, 11)</span></pre><h2 id="bb4b" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">4.2性别</h2><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="047a" class="jo jp hi ll b fi lp lq l lr ls">data.gender.value_counts()</span><span id="6854" class="jo jp hi ll b fi lt lq l lr ls">Female    2994<br/>Male      2115<br/>Other        1<br/>Name: gender, dtype: int64</span></pre><p id="fbbd" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">性别需要被归类为二元变量。从分析的角度来看，为一个行值创建另一个变量(' Others ')会很繁琐。因此，我们将在这一列中用mode估算这个值。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="cc64" class="jo jp hi ll b fi lp lq l lr ls">data['gender'] = data['gender'].replace('Other', list(data.gender.mode().values)[0])<br/>data.gender.value_counts()</span><span id="f2a1" class="jo jp hi ll b fi lt lq l lr ls">Female    2995<br/>Male      2115<br/>Name: gender, dtype: int64</span></pre><h2 id="f67f" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">5.探索性数据分析</h2><h2 id="3a4b" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">5.1分类特征分析</h2><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="8e7e" class="jo jp hi ll b fi lp lq l lr ls">df_cat = ['gender','hypertension','heart_disease','ever_married','work_type','Residence_type','smoking_status', 'stroke']<br/><br/>fig, axs = plt.subplots(4, 2, figsize=(14,20))<br/>axs = axs.flatten()<br/><br/># iterate through each column of df_catd and plot<br/>for i, col_name in enumerate(df_cat):<br/>    sns.countplot(x=col_name, data=data, ax=axs[i], hue =data['stroke'], palette = 'flare')<br/>    plt.title("Bar chart of")<br/>    axs[i].set_xlabel(f"{col_name}", weight = 'bold')<br/>    axs[i].set_ylabel('Count', weight='bold')</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lw"><img src="../Images/247661a8aaaf73596c9db62a5e0c2ad7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xLW2KmMoJUX6E-_RQ8WXVQ.png"/></div></div></figure><p id="4a1d" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">从上面的计数图中，可以得出一些观察结果:</p><ul class=""><li id="07c9" class="lx ly hi ko b kp lf ks lg jz lz kd ma kh mb le mc md me mf bi translated">高血压:先前诊断为高血压的受试者有很高的中风风险。</li><li id="57f3" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">心脏病:先前诊断患有心脏病的受试者有很高的中风风险。</li><li id="ad87" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">曾经结过婚:曾经结过婚的受试者患中风的风险很高。</li><li id="9638" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">工作类型:有工作经验和从事政府相关工作的受试者患中风的风险很高，而没有工作经验的受试者几乎没有经历过中风。</li><li id="f4f3" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">居住类型:与发生中风的可能性无明显关系。</li><li id="9b57" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">吸烟状况:吸烟或曾经吸烟会增加患中风的风险。</li></ul><h2 id="26d1" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">5.2数值特征分析</h2><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="4dbc" class="jo jp hi ll b fi lp lq l lr ls">df_num = ['age', 'avg_glucose_level', 'bmi']<br/><br/>fig, axs = plt.subplots(1, 3, figsize=(16,5))<br/>axs = axs.flatten()<br/><br/># iterate through each column in df_num and plot<br/>for i, col_name in enumerate(df_num):<br/>    sns.boxplot(x="stroke", y=col_name, data=data, ax=axs[i],  palette = 'Set1')<br/>    axs[i].set_xlabel("Stroke", weight = 'bold')<br/>    axs[i].set_ylabel(f"{col_name}", weight='bold')</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ml"><img src="../Images/4d47b83d7a69b569f1dc3066b6249036.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eWqyhfOR5lTu94tOnaqC1w.png"/></div></div></figure><p id="efbc" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">从上面的箱线图中，可以得出一些观察结果:</p><ul class=""><li id="43ba" class="lx ly hi ko b kp lf ks lg jz lz kd ma kh mb le mc md me mf bi translated">年龄:中风患者的平均年龄更高。</li><li id="41ed" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">平均血糖水平:中风患者的平均血糖水平往往较高。</li><li id="9c75" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">身体质量指数:身体质量指数并不能说明患中风的可能性。超级肥胖的bmi指数是50。此功能中的异常值应被替换到其最高限制(50)。</li></ul><p id="0f2d" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">总共检测到79个异常值。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="7e6f" class="jo jp hi ll b fi lp lq l lr ls">bmi_outliers=data.loc[data['bmi']&gt;50]<br/>bmi_outliers['bmi'].shape</span><span id="05a5" class="jo jp hi ll b fi lt lq l lr ls">(79,)</span></pre><p id="def7" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">将bmi列中大于50的值替换为50。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="0615" class="jo jp hi ll b fi lp lq l lr ls">data["bmi"] = pd.to_numeric(data["bmi"])<br/>data["bmi"] = data["bmi"].apply(lambda x: 50 if x&gt;50 else x)</span></pre><p id="8b3f" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">通过绘制bmi列的箱线图来确认所做的更改。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="6254" class="jo jp hi ll b fi lp lq l lr ls">sns.boxplot(data=data,x=data["bmi"],color='green')<br/>plt.title("Boxplot of BMI Distribution");</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mm"><img src="../Images/e0049a3b76b29b726d8a5ce1efa3d301.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*lyFrP-de1_1unXnIP9gPIQ.png"/></div></figure><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="715a" class="jo jp hi ll b fi lp lq l lr ls">plt.figure(figsize=(4,4))<br/>data['stroke'].value_counts().plot.pie(autopct='%1.1f%%', colors = ['#66b3ff','#99ff99'])<br/>plt.title("Pie Chart of Stroke Status", fontdict={'fontsize': 14})<br/>plt.tight_layout()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mn"><img src="../Images/a23cae6c51e7f689e1c9142a93f8faae.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*B4gaM5Vl47HjOJ9XzNNFug.png"/></div></figure><p id="18cd" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">该数据集中4.9%的人口被诊断患有中风</p><h2 id="1072" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">5.3多重共线性分析</h2><p id="6943" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">由于相关性检查只接受数字变量，预处理分类变量成为一个必要的步骤，我们需要将这些分类变量转换成编码为0或1的数字。我们使用sklearn.preprocessing的labelEncoder，因为如果需要的话，在预测之后可以很容易地将特定的标签解码回来。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="8f5b" class="jo jp hi ll b fi lp lq l lr ls">from sklearn.preprocessing import LabelEncoder</span><span id="7207" class="jo jp hi ll b fi lt lq l lr ls">le = LabelEncoder()<br/><br/>data['gender'] = le.fit_transform(data['gender'])<br/>data['ever_married'] = le.fit_transform(data['ever_married'])<br/>data['work_type'] = le.fit_transform(data['work_type'])<br/>data['Residence_type'] = le.fit_transform(data['Residence_type'])<br/>data['smoking_status'] = le.fit_transform(data['smoking_status'])<br/><br/>df_en = data</span><span id="72b8" class="jo jp hi ll b fi lt lq l lr ls">df_en.head()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="ab fe cl mo"><img src="../Images/19632ca8025985bc79ea30b1787ec363.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Hu8hX7dEP8Lx-E-v2ZkbDQ.png"/></div></figure><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="0c68" class="jo jp hi ll b fi lp lq l lr ls">corr = df_en.corr().round(2)<br/>plt.figure(figsize=(10,7))<br/>sns.heatmap(corr, annot = True, cmap = 'RdYlGn');</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mp"><img src="../Images/19fa49a564d61a498719d8211d3ed4d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*pro5SIxDudJik9pbtSB4QA.png"/></div></div></figure><p id="d414" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">从上面的相关矩阵中，我们可以验证某些变量之间存在多重共线性。例如，ever_married和age列的相关性为0.68。在这两个属性中，年龄包含了关于一个人是否易患中风的更多信息。因此，我们将删除曾经结婚一栏。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="30ca" class="jo jp hi ll b fi lp lq l lr ls">df_en = df_en.drop(['ever_married'], axis = 1)</span><span id="63bf" class="jo jp hi ll b fi lt lq l lr ls">df_en.head(3)</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/d86a2a9efb5d8417f1080c0e07aae689.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DNhhTVAE0HXdZ2mDwmM4Rg.png"/></div></div></figure><h2 id="a106" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">5.4最终预处理</h2><p id="d91e" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">不同尺度下测量的变量对模型拟合的贡献不同，最终可能会产生偏差。因此，为了处理这个潜在的问题，通常在模型拟合之前使用特征标准化(μ=0，σ=1)。我们创建了一个StandardScaler()对象，然后应用fit_transform()函数对“avg_glucose_level”、“bmi”和“age”列应用标准化。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="f4ea" class="jo jp hi ll b fi lp lq l lr ls">from sklearn.preprocessing import StandardScaler<br/>s = StandardScaler()</span><span id="d9e6" class="jo jp hi ll b fi lt lq l lr ls">columns = ['avg_glucose_level','bmi','age']<br/>stand_scaled = s.fit_transform(df_en[['avg_glucose_level','bmi','age']])<br/>stand_scaled = pd.DataFrame(stand_scaled,columns=columns)<br/><br/>df_en=df_en.drop(columns=columns,axis=1)</span><span id="98d9" class="jo jp hi ll b fi lt lq l lr ls">stand_scaled.head()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/561f7d07a2014ef98048b794a92b432f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hCNl0iM1uM35TW0DaQHcwg.png"/></div></div></figure><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="602e" class="jo jp hi ll b fi lp lq l lr ls">df = pd.concat([df_en, stand_scaled], axis=1)<br/>df.head(3)</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/4bbc76ee25cb1f4e968194dbadb3b815.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QntOpAlCMr80HCX8vK9M3Q.png"/></div></div></figure><h2 id="527b" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">6.系统模型化</h2><p id="99c8" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">所有预测变量将映射到数组x，目标变量映射到数组y。目标变量是“stroke”列。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="f578" class="jo jp hi ll b fi lp lq l lr ls">x=df.drop(['stroke'], axis=1)<br/>y=df['stroke']</span><span id="aefe" class="jo jp hi ll b fi lt lq l lr ls"># Models<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.svm import SVC<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.naive_bayes import GaussianNB<br/>from sklearn.cluster import KMeans<br/><br/># Evaluation<br/>from sklearn.metrics import confusion_matrix, accuracy_score, classification_report<br/><br/>x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state= 124)</span></pre><p id="fc46" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">用它们的参数建立模型并将它们存储到字典中。我们将探讨7种算法，看看哪种算法能产生可靠且可重复的结果。这7种算法是:</p><ul class=""><li id="ad6e" class="lx ly hi ko b kp lf ks lg jz lz kd ma kh mb le mc md me mf bi translated">决策图表</li><li id="8b3a" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">逻辑回归</li><li id="a42d" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">随机森林</li><li id="a3d8" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">支持向量机</li><li id="260e" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">k最近邻</li><li id="f132" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">朴素贝叶斯</li><li id="ec2b" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">k均值聚类</li></ul><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="3434" class="jo jp hi ll b fi lp lq l lr ls">models = dict()<br/>models['Decision Tree'] = DecisionTreeClassifier()<br/>models['Logreg'] = LogisticRegression()<br/>models['Random Forest'] = RandomForestClassifier()<br/>models['Support Vector Machine'] = SVC(kernel = 'sigmoid', gamma='scale')<br/>models['kNN'] = KNeighborsClassifier()<br/>models['Naive Bayes'] = GaussianNB()<br/>models['KMeans'] = KMeans(n_clusters=2, n_init=10, random_state=42)</span><span id="e6cb" class="jo jp hi ll b fi lt lq l lr ls">for model in models:<br/>    <br/>    models[model].fit(x_train, y_train)<br/>    print(model + " model fitting completed.")</span><span id="03a4" class="jo jp hi ll b fi lt lq l lr ls">Decision Tree model fitting completed.<br/>Logreg model fitting completed.<br/>Random Forest model fitting completed.<br/>Support Vector Machine model fitting completed.<br/>kNN model fitting completed.<br/>Naive Bayes model fitting completed.<br/>KMeans model fitting completed.</span><span id="58fe" class="jo jp hi ll b fi lt lq l lr ls">print("Test Set Prediction:\n")<br/><br/>for x in models:<br/><br/>    print('-'*20+x+'-'*20)<br/>    model = models[x]<br/>    y_pred = model.predict(x_test)<br/>    arg_test = {'y_true':y_test, 'y_pred':y_pred}<br/>    print(confusion_matrix(**arg_test))<br/>    print(classification_report(**arg_test))</span><span id="dd44" class="jo jp hi ll b fi lt lq l lr ls">Test Set Prediction:<br/><br/>--------------------Decision Tree--------------------<br/>[[1398   66]<br/> [  63    6]]<br/>              precision    recall  f1-score   support<br/><br/>           0       0.96      0.95      0.96      1464<br/>           1       0.08      0.09      0.09        69<br/><br/>    accuracy                           0.92      1533<br/>   macro avg       0.52      0.52      0.52      1533<br/>weighted avg       0.92      0.92      0.92      1533<br/><br/>--------------------Logreg--------------------<br/>[[1464    0]<br/> [  69    0]]<br/>              precision    recall  f1-score   support<br/><br/>           0       0.95      1.00      0.98      1464<br/>           1       0.00      0.00      0.00        69<br/><br/>    accuracy                           0.95      1533<br/>   macro avg       0.48      0.50      0.49      1533<br/>weighted avg       0.91      0.95      0.93      1533<br/><br/>--------------------Random Forest--------------------<br/>[[1463    1]<br/> [  69    0]]<br/>              precision    recall  f1-score   support<br/><br/>           0       0.95      1.00      0.98      1464<br/>           1       0.00      0.00      0.00        69<br/><br/>    accuracy                           0.95      1533<br/>   macro avg       0.48      0.50      0.49      1533<br/>weighted avg       0.91      0.95      0.93      1533<br/><br/>--------------------Support Vector Machine--------------------<br/>[[1412   52]<br/> [  64    5]]<br/>              precision    recall  f1-score   support<br/><br/>           0       0.96      0.96      0.96      1464<br/>           1       0.09      0.07      0.08        69<br/><br/>    accuracy                           0.92      1533<br/>   macro avg       0.52      0.52      0.52      1533<br/>weighted avg       0.92      0.92      0.92      1533<br/><br/>--------------------kNN--------------------<br/>[[1457    7]<br/> [  66    3]]<br/>              precision    recall  f1-score   support<br/><br/>           0       0.96      1.00      0.98      1464<br/>           1       0.30      0.04      0.08        69<br/><br/>    accuracy                           0.95      1533<br/>   macro avg       0.63      0.52      0.53      1533<br/>weighted avg       0.93      0.95      0.94      1533<br/><br/>--------------------Naive Bayes--------------------<br/>[[1310  154]<br/> [  41   28]]<br/>              precision    recall  f1-score   support<br/><br/>           0       0.97      0.89      0.93      1464<br/>           1       0.15      0.41      0.22        69<br/><br/>    accuracy                           0.87      1533<br/>   macro avg       0.56      0.65      0.58      1533<br/>weighted avg       0.93      0.87      0.90      1533<br/><br/>--------------------KMeans--------------------<br/>[[ 266 1198]<br/> [   2   67]]<br/>              precision    recall  f1-score   support<br/><br/>           0       0.99      0.18      0.31      1464<br/>           1       0.05      0.97      0.10        69<br/><br/>    accuracy                           0.22      1533<br/>   macro avg       0.52      0.58      0.20      1533<br/>weighted avg       0.95      0.22      0.30      1533</span></pre><p id="4682" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">注意，召回可以被认为是分类器完整性的度量。中风(1)的低召回率表示许多假阴性。</p><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="13d5" class="jo jp hi ll b fi lp lq l lr ls">print('Summary of Accuracy Score\n\n')<br/>for i in models:<br/>    model = models[i]<br/>    print(i + ' Model: ',accuracy_score(y_test, model.predict(x_test)).round(4))</span><span id="de76" class="jo jp hi ll b fi lt lq l lr ls">Summary of Accuracy Score<br/><br/><br/>Decision Tree Model:  0.9159<br/>Logreg Model:  0.955<br/>Random Forest Model:  0.9543<br/>Support Vector Machine Model:  0.9243<br/>kNN Model:  0.9524<br/>Naive Bayes Model:  0.8728<br/>KMeans Model:  0.2172</span></pre><p id="9eed" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">从以上准确度总结来看，逻辑回归、随机森林和KNN模型都给出了0.95的高准确度分数。但是，考虑每个模型的错误类型和召回值也很重要。如混淆矩阵所示，准确度分数为0.95的模型通常具有较高的假阴性。高假阴性表示2型错误。对于我们的中风预测研究，我们希望避免2型错误，因为这意味着我们无法识别患有中风的受试者，而是认为他们没有中风。从上面的分类报告来看，朴素贝叶斯模型符合我们的目标，虽然准确率为0.87。</p><h2 id="0e3c" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">7.交互效度分析</h2><pre class="iy iz ja jb fd lk ll lm ln aw lo bi"><span id="e9cc" class="jo jp hi ll b fi lp lq l lr ls">from sklearn.model_selection import cross_val_score<br/><br/>gnb = GaussianNB()<br/><br/>scores = cross_val_score(gnb, x_train, y_train, cv = 10, scoring='accuracy')<br/><br/>print('Cross-validation scores:{}'.format(scores))</span><span id="d8da" class="jo jp hi ll b fi lt lq l lr ls">Cross-validation scores:[0.87430168 0.84916201 0.88826816 0.87709497 0.89944134 0.88547486<br/> 0.86592179 0.86554622 0.86834734 0.85714286]</span><span id="5739" class="jo jp hi ll b fi lt lq l lr ls">print('Average cross-validation score: {:.4f}'.format(scores.mean()))</span><span id="5132" class="jo jp hi ll b fi lt lq l lr ls">Average cross-validation score: 0.8731</span></pre><ul class=""><li id="2b90" class="lx ly hi ko b kp lf ks lg jz lz kd ma kh mb le mc md me mf bi translated">使用平均交叉验证，我们可以得出结论，我们预计该模型的平均准确率约为87.31%。</li><li id="0fbf" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">如果我们观察由10倍交叉验证产生的所有10个分数，我们也可以得出结论，在各倍之间的准确度存在相对较小的方差，范围从84.91%准确度到89.94%准确度。因此，我们可以得出结论，该模型独立于用于训练的特定褶皱。</li><li id="9d4c" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mc md me mf bi translated">我们的原始模型精度是0.8728，但是平均交叉验证精度是0.8731。因此，10倍的交叉验证准确性确实提高了该模型的性能。</li></ul><h2 id="ef5b" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">8.结论</h2><ol class=""><li id="ca94" class="lx ly hi ko b kp kq ks kt jz mr kd ms kh mt le mu md me mf bi translated">使用各种模型来预测一个人是否遭受中风。朴素贝叶斯模型产生了非常好的性能，如通过发现的87.28%的模型准确度所表明的。</li><li id="367d" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mu md me mf bi translated">使用平均交叉验证，我们可以得出结论，我们预计该模型的平均准确率约为87.31%。</li><li id="0873" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mu md me mf bi translated">如果我们观察由10倍交叉验证产生的所有10个分数，我们也可以得出结论，折叠之间的准确性存在相对小的差异，因此该模型独立于用于训练的特定折叠。</li><li id="b6e4" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mu md me mf bi translated">我们的原始模型准确率为87.28%，平均交叉验证准确率为87.31%。因此，10倍的交叉验证准确性确实提高了该模型的性能。</li><li id="5966" class="lx ly hi ko b kp mg ks mh jz mi kd mj kh mk le mu md me mf bi translated">朴素贝叶斯模型可以通过调整超参数得到更好的结果或调整概率阈值来改善其性能。</li></ol></div></div>    
</body>
</html>