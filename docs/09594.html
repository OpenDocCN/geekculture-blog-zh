<html>
<head>
<title>A Lightweight PyTorch Implementation of Neural Style Transfer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经风格转换的轻量级PyTorch实现</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/a-lightweight-pytorch-implementation-of-neural-style-transfer-86603e5eb551?source=collection_archive---------5-----------------------#2021-12-18">https://medium.com/geekculture/a-lightweight-pytorch-implementation-of-neural-style-transfer-86603e5eb551?source=collection_archive---------5-----------------------#2021-12-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="6867" class="hg hh hi bd b fp hj hk hl hm hn ho dx hp translated" aria-label="kicker paragraph">人工智能过道</h2><div class=""/><div class=""><h2 id="8645" class="pw-subtitle-paragraph io hr hi bd b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf dx translated">用卷积神经网络创建您自己的数字艺术，只需简单的五个步骤！</h2></div><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es jg"><img src="../Images/aa6d8f7505d424a1c6b421e3d138c289.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wif1a4KqFHzVI40QOzbQKQ.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx">Image by author</figcaption></figure><p id="1704" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">艺术超越了人类的存在。我们看到它在整个历史进程中的重要性——从史前时代，通过一些最伟大的河谷文明，君主的堡垒和宫廷，一直到现代技术时代。艺术一直是表达一个人对世界的看法的手段。传奇人物巴勃罗·毕加索曾经说过:</p><blockquote class="ks"><p id="8257" class="kt ku hi bd kv kw kx ky kz la lb kr dx translated">“我花了四年时间画出拉斐尔的样子，却花了一辈子时间画出一个孩子的样子。”</p><p id="601e" class="kt ku hi bd kv kw kx ky kz la lb kr dx translated"><em class="lc"> —巴勃罗·毕加索</em></p></blockquote><p id="2e9d" class="pw-post-body-paragraph jw jx hi jy b jz ld is kb kc le iv ke kf lf kh ki kj lg kl km kn lh kp kq kr hb bi translated">大多数艺术都遵循一种模式——一种令人愉悦并刺激我们大脑的模式。下次你看到一幅作品时，试着注意它的颜色主题，或者其中的笔触。你会看到一个模式从中浮现出来。我们人类擅长潜意识地识别这些模式。现在，在神经网络的帮助下，这种识别和人工再造模式的能力也得到发展。</p><h2 id="01ec" class="li lj hi bd lk ll lm ln lo lp lq lr ls kf lt lu lv kj lw lx ly kn lz ma mb ho bi translated">Gatys等人的研究论文。</h2><p id="d691" class="pw-post-body-paragraph jw jx hi jy b jz mc is kb kc md iv ke kf me kh ki kj mf kl km kn mg kp kq kr hb bi translated">由<em class="mi"> Gatys等人</em>撰写的一篇<a class="ae mh" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">研究论文</a>，标题为<strong class="jy hs"> </strong>“艺术风格的神经算法”(最初于2015年发布给ArXiv，随后于2016年被CVPR会议接受)，是神经风格转移的第一篇论文，至今仍被认为是该领域最具开创性的工作。</p><p id="2c9c" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">在本文中，我们将构建一个轻量级的PyTorch实现，如这篇专题论文中所讨论的那样，并学习如何通过五个简单的步骤将流行的艺术风格转移到任何图像上。我们走吧！</p></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><h1 id="08f7" class="mq lj hi bd lk mr ms mt lo mu mv mw ls ix mx iy lv ja my jb ly jd mz je mb na bi translated">目录</h1><ol class=""><li id="86fc" class="nb nc hi jy b jz mc kc md kf nd kj ne kn nf kr ng nh ni nj bi translated">概观</li><li id="a77a" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr ng nh ni nj bi translated">它是如何工作的？</li><li id="d8f9" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr ng nh ni nj bi translated">入门<br/>–文件描述<br/>–依赖关系<br/>–如何在自己的映像上使用NST？</li><li id="760d" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr ng nh ni nj bi translated">获得的产量</li><li id="c160" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr ng nh ni nj bi translated">NST的应用</li><li id="cf2b" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr ng nh ni nj bi translated">承认</li></ol><h1 id="2a2c" class="mq lj hi bd lk mr np mt lo mu nq mw ls ix nr iy lv ja ns jb ly jd nt je mb na bi translated">概观</h1><p id="4463" class="pw-post-body-paragraph jw jx hi jy b jz mc is kb kc md iv ke kf me kh ki kj mf kl km kn mg kp kq kr hb bi translated">神经样式转移(NST)是一种获取两个图像(内容图像和样式参考图像)并将它们混合在一起的技术，以便输出看起来像内容图像，但以样式参考图像的样式绘制。</p><p id="5e86" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">它是<strong class="jy hs">非真实感渲染</strong>更广泛领域内的图像风格化(一种图像处理和操作技术)的一个例子。</p><h1 id="568b" class="mq lj hi bd lk mr np mt lo mu nq mw ls ix nr iy lv ja ns jb ly jd nt je mb na bi translated">它是如何工作的？</h1><ul class=""><li id="47ea" class="nb nc hi jy b jz mc kc md kf nd kj ne kn nf kr nu nh ni nj bi translated">我们利用预先训练的卷积神经网络(在我们的例子中是VGG19)来提取图像细节。<br/>–从网络的输入层开始，<strong class="jy hs">最初的几个层激活</strong>代表低级特征，如颜色和纹理(<strong class="jy hs">“样式”</strong>)。<br/>——当我们在网络中穿行时，<strong class="jy hs">最后几层</strong>代表更高层次的特征(即<strong class="jy hs">‘内容’</strong>)—例如本例中的猫的眼睛和耳朵。</li><li id="c1fd" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr nu nh ni nj bi translated">这就是为什么我们从获取内容图像开始，通过VGG19，并在后期卷积层<code class="du nv nw nx ny b">(conv4_2)</code>对网络激活进行采样。</li><li id="6dd2" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr nu nh ni nj bi translated">然后，我们获取我们的风格图像，通过相同的网络馈送，并在早期到中期卷积层(<code class="du nv nw nx ny b">conv1_1</code>、<code class="du nv nw nx ny b">conv2_1</code>、<code class="du nv nw nx ny b">conv3_1</code>、<code class="du nv nw nx ny b">conv4_1</code>、<code class="du nv nw nx ny b">conv5_1</code>)对网络激活进行采样。</li></ul><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es nz"><img src="../Images/585e5c09388dd659df0ff73c227ab80e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tobu4DVYO2MY9ZxVgPacGQ.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx">VGG 19 architecture (image by author)</figcaption></figure><ul class=""><li id="b1d7" class="nb nc hi jy b jz ka kc kd kf oa kj ob kn oc kr nu nh ni nj bi translated">这些激活被编码成一个<strong class="jy hs"> Gram矩阵表示</strong>，用来表示图像的“风格”。</li><li id="f5ec" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr nu nh ni nj bi translated">我们的目标是合成一个输出图像，它展示了一个图像的内容和另一个图像的风格。为此，我们计算以下损失:<br/>–<strong class="jy hs">内容损失</strong>，即内容图像与生成图像<strong class="jy hs">、<br/></strong>–<strong class="jy hs">风格损失</strong>，即从VGG19、<br/>–<strong class="jy hs">不同层提取的内容图像和风格图像表示的格拉姆矩阵之间的L2距离之和</strong>， 其用于所生成图像的像素之间的空间连续性，从而对其去噪并赋予其视觉连贯性；以及<br/>–<strong class="jy hs">总损失</strong>，其是所有上述损失的总和乘以它们各自的权重。</li><li id="d83e" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr nu nh ni nj bi translated">然后采用迭代<strong class="jy hs">优化技术</strong>(在我们的例子中是L-BFGS)来逐渐最小化这些损失，以达到期望的结果。</li></ul><h1 id="88bc" class="mq lj hi bd lk mr np mt lo mu nq mw ls ix nr iy lv ja ns jb ly jd nt je mb na bi translated">入门指南</h1><h2 id="4a0d" class="li lj hi bd lk ll lm ln lo lp lq lr ls kf lt lu lv kj lw lx ly kn lz ma mb ho bi translated">➡ <strong class="ak">文件描述</strong></h2><p id="1766" class="pw-post-body-paragraph jw jx hi jy b jz mc is kb kc md iv ke kf me kh ki kj mf kl km kn mg kp kq kr hb bi translated">你可以在GitHub上我的<a class="ae mh" href="https://github.com/nazianafis/Neural-Style-Transfer" rel="noopener ugc nofollow" target="_blank">库</a>里看看神经风格转移的代码。</p><ul class=""><li id="c8d1" class="nb nc hi jy b jz ka kc kd kf oa kj ob kn oc kr nu nh ni nj bi translated"><strong class="jy hs"> vgg19.py </strong>包含vgg19模型定义，指定哪个图层用于样式表示，哪个图层用于内容。</li><li id="5636" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr nu nh ni nj bi translated"><strong class="jy hs"> NST.py </strong>是包含最终输出图像的操作、生成、优化、调整和保存等步骤的文件。</li></ul><pre class="jh ji jj jk fd od ny oe of aw og bi"><span id="d068" class="li lj hi ny b fi oh oi l oj ok">Neural-Style-Transfer<br/>    ├── data<br/>    |   ├── content-images<br/>    |   ├── style-images<br/>    ├── models/definitions     <br/>    │   ├── <strong class="ny hs">vgg19.py</strong>         # VGG19 model definition<br/>    ├── <strong class="ny hs">NST.py</strong>               # The main python file<br/>    ├── LICENSE<br/>    └── README.md</span></pre><h2 id="5eda" class="li lj hi bd lk ll lm ln lo lp lq lr ls kf lt lu lv kj lw lx ly kn lz ma mb ho bi translated">➡ <strong class="ak">依赖</strong></h2><ul class=""><li id="203f" class="nb nc hi jy b jz mc kc md kf nd kj ne kn nf kr nu nh ni nj bi translated">Python 3.9以上版本</li><li id="6a1c" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr nu nh ni nj bi translated">框架:PyTorch</li><li id="5a34" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr nu nh ni nj bi translated">库:os、numpy、cv2、matplotlib、torchvision</li></ul><h2 id="582d" class="li lj hi bd lk ll lm ln lo lp lq lr ls kf lt lu lv kj lw lx ly kn lz ma mb ho bi translated">➡ <em class="lc">如何在自己的图像上使用NST？</em></h2><ol class=""><li id="6f2f" class="nb nc hi jy b jz mc kc md kf nd kj ne kn nf kr ng nh ni nj bi translated">克隆<a class="ae mh" href="https://github.com/nazianafis/Neural-Style-Transfer" rel="noopener ugc nofollow" target="_blank">库</a>并移动到下载的文件夹:</li></ol><pre class="jh ji jj jk fd od ny oe of aw og bi"><span id="53d4" class="li lj hi ny b fi oh oi l oj ok">$ git clone https://github.com/nazianafis/Neural-Style-Transfer<!-- --> </span><span id="d2e5" class="li lj hi ny b fi ol oi l oj ok">$ cd Neural-Style-Transfer</span></pre><p id="40fd" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">2.将您的内容/风格图像移动到<code class="du nv nw nx ny b">data</code>文件夹中各自的文件夹中。</p><p id="3dba" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">3.转到<code class="du nv nw nx ny b">NST.py</code>，在其中，将<code class="du nv nw nx ny b">PATH</code>变量设置为您下载的文件夹。还可以将<code class="du nv nw nx ny b">CONTENT_IMAGE</code>、<code class="du nv nw nx ny b">STYLE_IMAGE</code>变量设置为您想要的图像</p><pre class="jh ji jj jk fd od ny oe of aw og bi"><span id="9745" class="li lj hi ny b fi oh oi l oj ok">$ PATH = &lt;your_path&gt;<br/>   <br/>$ CONTENT_IMAGE = &lt;your_content_image_name&gt;<br/>$ STYLE_IMAGE = &lt;your_style_image_name&gt;</span></pre><p id="6679" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">4.跑<code class="du nv nw nx ny b">NST.py</code>:</p><pre class="jh ji jj jk fd od ny oe of aw og bi"><span id="c1b7" class="li lj hi ny b fi oh oi l oj ok">$ python NST.py</span></pre><p id="7766" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">5.就是这样！在<code class="du nv nw nx ny b">data</code>内的<code class="du nv nw nx ny b">output-images</code>文件夹中找到您生成的图像。</p><h1 id="28b2" class="mq lj hi bd lk mr np mt lo mu nq mw ls ix nr iy lv ja ns jb ly jd nt je mb na bi translated"><strong class="ak">获得的输出</strong></h1><p id="0c0a" class="pw-post-body-paragraph jw jx hi jy b jz mc is kb kc md iv ke kf me kh ki kj mf kl km kn mg kp kq kr hb bi translated">除了本文描述的代码之外，下面的输出图像没有使用任何图像处理程序生成。我鼓励你尝试一下！</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es om"><img src="../Images/1970be1c9d2068f10a376e0235b53130.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wM6yZ3YRSE0rnIZFpU5_1w.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx">📷 — All output images by author</figcaption></figure><h1 id="d018" class="mq lj hi bd lk mr np mt lo mu nq mw ls ix nr iy lv ja ns jb ly jd nt je mb na bi translated">实际应用</h1><p id="fe13" class="pw-post-body-paragraph jw jx hi jy b jz mc is kb kc md iv ke kf me kh ki kj mf kl km kn mg kp kq kr hb bi translated">NST有许多真实的使用案例。一份非详尽的清单将包括:</p><ul class=""><li id="881a" class="nb nc hi jy b jz ka kc kd kf oa kj ob kn oc kr nu nh ni nj bi translated"><strong class="jy hs">照片和视频编辑:</strong>随着风格转移的最新进展，任何人(艺术家或非艺术家)都可以创作自己的艺术杰作，并与世界分享。这一趋势也从著名的终端用户应用程序如DeepArt和Prisma的兴起中显而易见。</li><li id="f0c1" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr nu nh ni nj bi translated"><strong class="jy hs">商业艺术:</strong>随着人们对NFT(不可替代的代币)的强烈好奇心，艺术创作和消费市场的规模只会越来越大。艺术家们现在可以把他们的艺术风格借给/卖给其他人，允许他们的风格的新的和创新的表现与原始的杰作共存。</li><li id="dfaa" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr nu nh ni nj bi translated">游戏和虚拟现实:元宇宙是最新的流行语。通过增强现实(AR)和虚拟现实(VR)服务的结合，我们正在迅速走向现实世界的数字化，视觉计算(图像和视频处理、计算机图形、计算机视觉)技能被吹捧为在不久的将来需求量很大。</li></ul><p id="6610" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">如果你想进入视觉计算领域，现在正是时候！😊</p><h1 id="b68b" class="mq lj hi bd lk mr np mt lo mu nq mw ls ix nr iy lv ja ns jb ly jd nt je mb na bi translated">承认</h1><p id="7d6f" class="pw-post-body-paragraph jw jx hi jy b jz mc is kb kc md iv ke kf me kh ki kj mf kl km kn mg kp kq kr hb bi translated">这些是我在做这个项目时参考的一些资源。你可能想去看看。</p><ul class=""><li id="dabf" class="nb nc hi jy b jz ka kc kd kf oa kj ob kn oc kr nu nh ni nj bi translated">PyTorch关于NST的<a class="ae mh" href="https://pytorch.org/tutorials/advanced/neural_style_tutorial.html" rel="noopener ugc nofollow" target="_blank">教程</a></li><li id="9ec7" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr nu nh ni nj bi translated">阿列克萨·戈尔迪奇的<a class="ae mh" href="https://github.com/gordicaleksa/pytorch-neural-style-transfer" rel="noopener ugc nofollow" target="_blank">实施</a></li><li id="317c" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr nu nh ni nj bi translated">关于神经风格转移的原始论文由<a class="ae mh" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mi"> Gatys等人</em> </a>完成。</li><li id="ca21" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr nu nh ni nj bi translated">原论文关于<a class="ae mh" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank"> VGG19 </a></li><li id="ee8f" class="nb nc hi jy b jz nk kc nl kf nm kj nn kn no kr nu nh ni nj bi translated"><a class="ae mh" href="https://commons.wikimedia.org/wiki/Category:Images" rel="noopener ugc nofollow" target="_blank"> Wikimedia </a>，<a class="ae mh" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>所有的内容和风格图片</li></ul></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><p id="fb9e" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">在接下来的日子里，我计划通过机器学习来学习更多关于图像生成/处理的知识。我还打算用人工智能创造更多的艺术(我对分形着迷已经有一段时间了！).如果你发现bugs(🕷)/have的建议，请随时联系我。</p><div class="on oo ez fb op oq"><a href="https://github.com/nazianafis/Neural-Style-Transfer" rel="noopener  ugc nofollow" target="_blank"><div class="or ab dw"><div class="os ab ot cl cj ou"><h2 class="bd hs fi z dy ov ea eb ow ed ef hr bi translated">GitHub-nazianafis/神经类型转移</h2><div class="ox l"><h3 class="bd b fi z dy ov ea eb ow ed ef dx translated">神经风格转移是基于两个输入图像创建一个新图像(称为仿作)的能力…</h3></div><div class="oy l"><p class="bd b fp z dy ov ea eb ow ed ef dx translated">github.com</p></div></div><div class="oz l"><div class="pa l pb pc pd oz pe jq oq"/></div></div></a></div></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><p id="5eb5" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated"><em class="mi">我希望这篇文章对你有用。可以在LinkedIn </em>  <em class="mi">上和我</em> <a class="ae mh" href="http://linkedin.com/in/nazianafis" rel="noopener ugc nofollow" target="_blank"> <em class="mi">联系，或者关注我的著作</em> </a><a class="ae mh" href="https://nazianafis.medium.com/" rel="noopener"> <em class="mi">这里</em> </a> <em class="mi">。</em></p><p id="7666" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated"><em class="mi">下次见！</em>(∫･‿･)ﾉ゛</p></div></div>    
</body>
</html>