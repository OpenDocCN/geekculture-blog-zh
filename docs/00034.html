<html>
<head>
<title>Beyond “Hello World”: Modern, Asynchronous Python in Kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超越“Hello World”:Kubernetes中的现代异步Python</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/beyond-hello-world-modern-asynchronous-python-in-kubernetes-f2c4ecd4a38d?source=collection_archive---------0-----------------------#2019-07-22">https://medium.com/geekculture/beyond-hello-world-modern-asynchronous-python-in-kubernetes-f2c4ecd4a38d?source=collection_archive---------0-----------------------#2019-07-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="025b" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">在Kubernetes上用Python 3部署可伸缩的、生产就绪的Web服务</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/5ff330987be6f35a51f1f23fd87fcfaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IXFYidSqho_VliwABIUYMw.png"/></div></div></figure><p id="7769" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在过去的几年里，Python经历了某种进化。从Python 3.4到3.7我们已经看到了<code class="du kf kg kh ki b"><a class="ae kj" href="https://docs.python.org/3/library/asyncio.html" rel="noopener ugc nofollow" target="_blank">asyncio</a></code>的引入、<code class="du kf kg kh ki b"><a class="ae kj" href="https://docs.python.org/3/library/asyncio-task.html#coroutines" rel="noopener ugc nofollow" target="_blank">async/await</a></code>关键词的引入和形式化，以及对<code class="du kf kg kh ki b">asyncio</code>性能的再投资。用Python编写异步代码从未像现在这样简单、高效或高效。</p><p id="9e49" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">除了对stdlib的改进，Python的开源社区也进入了某种复兴。开源社区已经接受了async/await的潜力，而<code class="du kf kg kh ki b">asyncio</code>库的灵活性已经被证明是一个巨大的福利。<code class="du kf kg kh ki b">asyncio</code>的可扩展API很容易鼓励替代的事件循环实现，我们现在有了像<code class="du kf kg kh ki b"><a class="ae kj" href="https://uvloop.readthedocs.io/" rel="noopener ugc nofollow" target="_blank">uvloop</a></code>这样的库，它是一个使用<code class="du kf kg kh ki b"><a class="ae kj" href="https://github.com/libuv/libuv" rel="noopener ugc nofollow" target="_blank">libuv</a></code>的事件循环的<code class="du kf kg kh ki b">asyncio</code>兼容实现。此外，当谈到web框架时，没有更多的选项可供选择，而且有<a class="ae kj" href="https://www.techempower.com/benchmarks/#section=data-r17&amp;hw=cl&amp;test=fortune&amp;l=zijzen-1" rel="noopener ugc nofollow" target="_blank">个决定性的基准</a>在那里对它们进行正面交锋。</p><p id="f1c1" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">然而，当构建一个新的应用程序时，很少有人谈论这些基准在如何部署应用程序的上下文中对您意味着什么。它将通过基于云的虚拟机部署吗？直接连接到服务器？那Kubernetes或者Docker Swarm呢？</p><h1 id="9bce" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">假设</h1><p id="d37f" class="pw-post-body-paragraph jj jk hi jl b jm lc ij jo jp ld im jr js le ju jv jw lf jy jz ka lg kc kd ke hb bi translated">这篇文章假设:</p><ol class=""><li id="1a5e" class="lh li hi jl b jm jn jp jq js lj jw lk ka ll ke lm ln lo lp bi translated">您已经做出了(明智的)决定，为您的web服务使用异步框架</li><li id="4786" class="lh li hi jl b jm lq jp lr js ls jw lt ka lu ke lm ln lo lp bi translated">您正在寻找Kubernetes部署您的服务。</li></ol><p id="0226" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">出于本文的目的，我选择了aiohttp框架，因为它成熟且稳定，但是这里提供的一般规则应该适用于当今市场上的任何开源框架。</p><h1 id="c088" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">这都是关于缩放</h1><p id="ff45" class="pw-post-body-paragraph jj jk hi jl b jm lc ij jo jp ld im jr js le ju jv jw lf jy jz ka lg kc kd ke hb bi translated">当我们谈论<em class="lv">扩展</em>时，我们通常指两种主要方法之一:</p><ol class=""><li id="18f5" class="lh li hi jl b jm jn jp jq js lj jw lk ka ll ke lm ln lo lp bi translated">水平扩展—跨机器和/或环境扩展</li><li id="9e3a" class="lh li hi jl b jm lq jp lr js ls jw lt ka lu ke lm ln lo lp bi translated">垂直扩展—在给定机器的资源上进行扩展。</li></ol><h1 id="a08f" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">我们正在测试的</h1><p id="a7fe" class="pw-post-body-paragraph jj jk hi jl b jm lc ij jo jp ld im jr js le ju jv jw lf jy jz ka lg kc kd ke hb bi translated">更传统的部署需要垂直和水平扩展的混合，重点是<em class="lv">垂直</em> —通过最大限度地利用机器上可用的CPU内核。对于Python web服务来说，这通常意味着在<a class="ae kj" href="http://docs.gunicorn.org/en/stable/index.html" rel="noopener ugc nofollow" target="_blank"> Gunicorn </a>或另一个类似的生产解决方案之后运行你的应用程序。我同意，对于这些环境，这绝对是合适的策略。</p><p id="c5ea" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">当您的应用程序部署在Kubernetes上时，它在前台的小型Docker容器上运行，这些容器被安排在Pods中，只占用一小部分CPU和最小的内存。Kubernetes利用了<em class="lv">水平</em>缩放。您不是增加单个Pod上的线程或工作进程的数量，而是扩展Pod的数量以满足需求。</p><p id="3372" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">如果处理得当，用Docker进行开发和部署可以为我们提供非常有力的保证:</p><ul class=""><li id="a42e" class="lh li hi jl b jm jn jp jq js lj jw lk ka ll ke lw ln lo lp bi translated"><strong class="jl hj">您开发和调试的应用程序运行时就是您部署的应用程序运行时。</strong></li></ul><p id="4ade" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">考虑到这一点，我着手确定以下问题:</p><ul class=""><li id="d776" class="lh li hi jl b jm jn jp jq js lj jw lk ka ll ke lw ln lo lp bi translated"><strong class="jl hj">在Kubernetes的环境中，增加部署的运行时依赖是否值得额外的开销和/或风险？</strong></li></ul><h1 id="a353" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">应用实施和设计</h1><p id="1936" class="pw-post-body-paragraph jj jk hi jl b jm lc ij jo jp ld im jr js le ju jv jw lf jy jz ka lg kc kd ke hb bi translated">我使用以下库实现了一个简单的RESTful API，支持GET/PUT/POST/DELETE:</p><ol class=""><li id="347e" class="lh li hi jl b jm jn jp jq js lj jw lk ka ll ke lm ln lo lp bi translated">服务器:<a class="ae kj" href="https://aiohttp.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> aiohttp </a></li><li id="4dbb" class="lh li hi jl b jm lq jp lr js ls jw lt ka lu ke lm ln lo lp bi translated">数据库:<a class="ae kj" href="https://www.postgresql.org/" rel="noopener ugc nofollow" target="_blank"> PostgreSQL </a></li><li id="c02c" class="lh li hi jl b jm lq jp lr js ls jw lt ka lu ke lm ln lo lp bi translated">数据库客户端:<a class="ae kj" href="https://github.com/MagicStack/asyncpg" rel="noopener ugc nofollow" target="_blank"> asyncpg </a></li></ol><p id="1abb" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">此外，我安装了以下库来提高整体性能:</p><ol class=""><li id="77b1" class="lh li hi jl b jm jn jp jq js lj jw lk ka ll ke lm ln lo lp bi translated"><a class="ae kj" href="https://github.com/saghul/aiodns" rel="noopener ugc nofollow" target="_blank"> aiodns </a>(通过<code class="du kf kg kh ki b">aiohttp[fast]</code>)</li><li id="6efd" class="lh li hi jl b jm lq jp lr js ls jw lt ka lu ke lm ln lo lp bi translated"><a class="ae kj" href="https://github.com/PyYoshi/cChardet" rel="noopener ugc nofollow" target="_blank">卡特</a>(通过<code class="du kf kg kh ki b">aiohttp[fast]</code>)</li><li id="9a76" class="lh li hi jl b jm lq jp lr js ls jw lt ka lu ke lm ln lo lp bi translated"><a class="ae kj" href="https://uvloop.readthedocs.io/" rel="noopener ugc nofollow" target="_blank"> uvloop </a></li></ol><p id="adcd" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><code class="du kf kg kh ki b">aiodns</code> &amp; <code class="du kf kg kh ki b">cchardet</code>被<code class="du kf kg kh ki b">aiohttp</code>自动使用，如果它们可用的话，也是一个空操作。<code class="du kf kg kh ki b">uvloop</code>可以通过运行<code class="du kf kg kh ki b">app.py</code>顶部的<code class="du kf kg kh ki b">uvloop.install()</code>来调用(如果你愿意，也可以在<code class="du kf kg kh ki b">ifmain</code>下面)。在这样做之前，确保你没有为你的循环创建一个全局变量😄)!</p><h1 id="2f2d" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">应用程序运行时</h1><p id="6315" class="pw-post-body-paragraph jj jk hi jl b jm lc ij jo jp ld im jr js le ju jv jw lf jy jz ka lg kc kd ke hb bi translated">现在我们已经有了我们的应用程序，是时候弄清楚如何在生产中运行它了。出于本文的目的，我设置了两个应用程序入口点:</p><ol class=""><li id="f624" class="lh li hi jl b jm jn jp jq js lj jw lk ka ll ke lm ln lo lp bi translated">直接调用<code class="du kf kg kh ki b">python app.py</code>(使用<code class="du kf kg kh ki b">aiohttp.web.run_app</code>)，或者…</li><li id="57ab" class="lh li hi jl b jm lq jp lr js ls jw lt ka lu ke lm ln lo lp bi translated">通过<a class="ae kj" href="https://gunicorn.org/" rel="noopener ugc nofollow" target="_blank"> Gunicorn </a>，通过调用<code class="du kf kg kh ki b">gunicorn --config=guniconfig app_wsgi:app</code></li></ol><ul class=""><li id="981f" class="lh li hi jl b jm jn jp jq js lj jw lk ka ll ke lw ln lo lp bi translated">Gunicorn被配置为使用单个<code class="du kf kg kh ki b">aiohttp.GunicornUVLoopWebWorker</code></li><li id="cd1d" class="lh li hi jl b jm lq jp lr js ls jw lt ka lu ke lw ln lo lp bi translated">Gunicorn还配置了1000个请求的最大工作生命周期，以应对长期工作人员可能出现的<a class="ae kj" href="https://www.google.com/search?q=gunicorn+memory+leak" rel="noopener ugc nofollow" target="_blank">详细记录的</a>内存泄漏问题。</li></ul><p id="577b" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">应用程序本身构建在Docker映像上，使用Python/Alpine-Linux基础映像的多阶段构建，以确保映像尽可能小。</p><p id="9059" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><em class="lv">需要注意的是，aiohttp在</em> <a class="ae kj" href="https://www.google.com/search?q=gunicorn+memory+leak" rel="noopener ugc nofollow" target="_blank"> <em class="lv">其文档</em> </a> <em class="lv">中提到，在Gunicorn后面运行aiohttp服务器会导致性能变慢。</em></p><h1 id="e3ca" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">应用程序部署</h1><p id="838a" class="pw-post-body-paragraph jj jk hi jl b jm lc ij jo jp ld im jr js le ju jv jw lf jy jz ka lg kc kd ke hb bi translated">这两个应用都是使用Nginx入口后的<a class="ae kj" href="https://github.com/appnexus/ankh" rel="noopener ugc nofollow" target="_blank"> ankh </a>部署的，具有相同的服务定义和以下资源配置文件:</p><pre class="iy iz ja jb fd lx ki ly lz aw ma bi"><span id="6ab6" class="mb kl hi ki b fi mc md l me mf">replicas: 10<br/>limits:<br/>  cpu: 1<br/>  memory: 512Mi<br/>requests:<br/>  cpu: .1<br/>  memory: 256Mi</span></pre><h1 id="ee94" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">系统地</h1><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mg mh l"/></div></figure><p id="b493" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">随着我的应用程序的部署和错误的消除，现在是时候感受一下这两个服务将如何运行了。</p><h2 id="b6a7" class="mb kl hi bd km mi mj mk kq ml mm mn ku js mo mp kw jw mq mr ky ka ms mt la mu bi translated">应用程序性能</h2><p id="3285" class="pw-post-body-paragraph jj jk hi jl b jm lc ij jo jp ld im jr js le ju jv jw lf jy jz ka lg kc kd ke hb bi translated">以下所有基准测试都是使用<a class="ae kj" href="https://github.com/rakyll/hey" rel="noopener ugc nofollow" target="_blank"> hey </a>运行的，设置为200个并发连接，持续30秒。没有实施速率限制，因为我们的目标是确定在高压力和充分利用资源的情况下的部署性能。</p><p id="f92e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们为我们的服务器设置了以下服务级别协议。得到:100 ms以下99.9%<br/>2。岗位:150 ms以下99.9%<br/>3。PUT: 99.9%在200毫秒以下</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mv"><img src="../Images/7c1ae13387b25635a48e4645ec0345db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mkluu8V4ja8CMqGUokqO8Q.png"/></div><figcaption class="mw mx et er es my mz bd b be z dx"><a class="ae kj" href="https://plot.ly/~seandstewart/6" rel="noopener ugc nofollow" target="_blank">Requests Per Second — Head to Head</a></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mv"><img src="../Images/cc98e0524c4ca59b03c8bdc0be250bd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NeVt1O6Yl4-IvL3rditbqA.png"/></div><figcaption class="mw mx et er es my mz bd b be z dx"><a class="ae kj" href="https://plot.ly/~seandstewart/8" rel="noopener ugc nofollow" target="_blank">Response Time Distribution within 99.9% — GET — 1ms Buckets</a></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mv"><img src="../Images/e45c524ce8e19bf0414e7c0697b92f12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mWr4b3XbkxG7d1Pe7JFGzQ.png"/></div><figcaption class="mw mx et er es my mz bd b be z dx"><a class="ae kj" href="https://plot.ly/~seandstewart/16" rel="noopener ugc nofollow" target="_blank">Response Time Distribution within 99.9% — POST — 1ms Buckets</a></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mv"><img src="../Images/f82fa207471158528577635744eef532.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*raj0Wtz94wM4fQwwO4zeLw.png"/></div><figcaption class="mw mx et er es my mz bd b be z dx"><a class="ae kj" href="https://plot.ly/~seandstewart/14" rel="noopener ugc nofollow" target="_blank">Response Time Distribution within 99.9% — PUT — 1ms Buckets</a></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mv"><img src="../Images/bf787030e83240a129c5c3a356035793.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u6K7-IFAcnNLW6lw__6XFQ.png"/></div><figcaption class="mw mx et er es my mz bd b be z dx"><a class="ae kj" href="https://plot.ly/~seandstewart/22" rel="noopener ugc nofollow" target="_blank">Head-to-Head Distribution, All Quantiles. Click through to play around!</a></figcaption></figure><h2 id="af2b" class="mb kl hi bd km mi mj mk kq ml mm mn ku js mo mp kw jw mq mr ky ka ms mt la mu bi translated">资源利用</h2><p id="395f" class="pw-post-body-paragraph jj jk hi jl b jm lc ij jo jp ld im jr js le ju jv jw lf jy jz ka lg kc kd ke hb bi translated">对于简单的<code class="du kf kg kh ki b">aiohttp</code>部署，副本集以大约1.15Gi内存和&lt;0.01 CPU整体运行(大约115Mi内存和大约0 CPU/pod)。在负载情况下，CPU的利用率限制在90 %- 100%之间(大约90%用于GET测试，100%用于PUT)，但是内存使用从未超过1.5Gi，远低于我们的5Gi限制。</p><p id="b292" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">Gunicorn部署始终使用大约30%以上的内存，CPU利用率略高，约为95%-105% <strong class="jl hj"> * </strong>。</p><p id="0c79" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> <em class="lv"> * </em> </strong> <em class="lv"> Kubernetes通过节流来强制执行CPU限制，而不是像内存限制那样通过杀死容器。这意味着您可能会看到偶尔的峰值略高于您配置的限制。我发现</em> <a class="ae kj" rel="noopener" href="/@betz.mark/understanding-resource-limits-in-kubernetes-cpu-time-9eff74d3161b"> <em class="lv">这篇文章</em> </a> <em class="lv">对理解这个机制很有帮助。</em></p><h2 id="64e0" class="mb kl hi bd km mi mj mk kq ml mm mn ku js mo mp kw jw mq mr ky ka ms mt la mu bi translated">初步评估</h2><p id="291a" class="pw-post-body-paragraph jj jk hi jl b jm lc ij jo jp ld im jr js le ju jv jw lf jy jz ka lg kc kd ke hb bi translated">总而言之，两种部署的性能几乎是相同的，Gunicorn带来的轻微服务降级不一定是交易的破坏者，这取决于您的特定应用程序必须满足的SLA。然而，如果Gunicorn实际上妨碍了这个部署架构中应用程序的性能和可靠性，那么是否应该使用它呢？</p><h1 id="601d" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">附加基准</h1><p id="6f34" class="pw-post-body-paragraph jj jk hi jl b jm lc ij jo jp ld im jr js le ju jv jw lf jy jz ka lg kc kd ke hb bi translated">有了这些数据，我决定试试能否测试一个更“标准”的Gunicorn式部署，以便利用Gunicorn的垂直扩展能力，遵循<a class="ae kj" href="http://docs.gunicorn.org/en/stable/settings.html#workers" rel="noopener ugc nofollow" target="_blank"> Gunicorn文档</a>中提到的古老经验法则。</p><p id="ae39" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我登陆了以下Gunicorn部署的资源配置文件:</p><pre class="iy iz ja jb fd lx ki ly lz aw ma bi"><span id="3325" class="mb kl hi ki b fi mc md l me mf">replicas: 2<br/>limits:<br/>  cpu: 5<br/>  memory: 3Gi<br/>requests:<br/>  cpu: 5<br/>  memory: 2Gi</span></pre><p id="7785" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">每个Pod有11个工作线程，因此副本集总共有10个CPU、6Gi内存和22个工作线程。</p><h2 id="83a1" class="mb kl hi bd km mi mj mk kq ml mm mn ku js mo mp kw jw mq mr ky ka ms mt la mu bi translated">应用程序性能</h2><p id="6f04" class="pw-post-body-paragraph jj jk hi jl b jm lc ij jo jp ld im jr js le ju jv jw lf jy jz ka lg kc kd ke hb bi translated">这是我们在上面看到的图表，混合了这种部署…</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mv"><img src="../Images/b5d678382b352d00f07d01451421f46b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bAbulIW3sxZaJ96PWOQ6aQ.png"/></div><figcaption class="mw mx et er es my mz bd b be z dx"><a class="ae kj" href="https://plot.ly/~seandstewart/33" rel="noopener ugc nofollow" target="_blank">Response Time Distributions within 99.9% — GET — 1 ms Buckets</a></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mv"><img src="../Images/e22923735748ad4ffc923ff14f5e1014.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wLpbbxXwHXYqgm-9OiuiRQ.png"/></div><figcaption class="mw mx et er es my mz bd b be z dx"><a class="ae kj" href="https://plot.ly/~seandstewart/31" rel="noopener ugc nofollow" target="_blank">Response Time Distributions within 99.9% — POST — 1 ms Buckets</a></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mv"><img src="../Images/a663aa8df3e2aff39c01cd7abe06b52e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m_WhghciXUjQm42GvREDKA.png"/></div><figcaption class="mw mx et er es my mz bd b be z dx"><a class="ae kj" href="https://plot.ly/~seandstewart/29" rel="noopener ugc nofollow" target="_blank">Response Time Distributions within 99.9% — PUT — 1 ms Buckets</a></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mv"><img src="../Images/f978c2089d126b177186008b05116524.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ZSa-xqJNJWyrHXfbadP_Q.png"/></div><figcaption class="mw mx et er es my mz bd b be z dx"><a class="ae kj" href="https://plot.ly/~seandstewart/27" rel="noopener ugc nofollow" target="_blank">Head-to-Head Distribution, All Quantiles. Click through to play around!</a></figcaption></figure><p id="a5dd" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">副本集中共有22个工作线程，超过2个pod，该部署超出了10个CPU的限制，并始终以大约3.5Gi的内存运行。这大约增加了43%的CPU和2倍的⅓内存。</p><p id="66c2" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">不仅如此，就性能和可靠性而言，这一部署甚至无法与前两者相提并论，而且远远超出了我们针对所有运营的服务级别协议。有人可能会说，扩大每个Pod或扩展副本集会改善这种情况，他们是对的。然而，在这一点上，我们已经使用了大量的资源来实现低于标准的结果，并且为了满足替代部署的性能而向上或向外扩展违背了Kubernetes部署的核心思想:可以按需向外扩展的小型轻量级容器。</p><h1 id="3559" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">最终评估</h1><p id="588c" class="pw-post-body-paragraph jj jk hi jl b jm lc ij jo jp ld im jr js le ju jv jw lf jy jz ka lg kc kd ke hb bi translated">虽然没有一个应用程序是相同的，但我相信上面的数据显示了基于历史解决方案假设部署策略的谬误。虽然Gunicorn在正确部署的情况下不一定会妨碍我们应用程序的性能，但它的使用是以下列成本为代价的:</p><ol class=""><li id="14f6" class="lh li hi jl b jm jn jp jq js lj jw lk ka ll ke lm ln lo lp bi translated">这是一个额外的依赖项，它改变了应用程序在生产环境中的运行时间和在开发环境中的运行时间。</li><li id="1dc6" class="lh li hi jl b jm lq jp lr js ls jw lt ka lu ke lm ln lo lp bi translated">还有一层需要学习和调试，并确保您的同事也很熟悉。</li><li id="4f0e" class="lh li hi jl b jm lq jp lr js ls jw lt ka lu ke lm ln lo lp bi translated">如果配置不正确，至少会多出~ <strong class="jl hj"> 43% </strong>的CPU和<strong class="jl hj"> 2⅓x </strong>的内存，如果配置正确，大约会多出<strong class="jl hj"> ~20% </strong>的内存。</li></ol><p id="84af" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我的建议(如果你还没猜到的话)是完全放弃这种生产依赖。在Gunicorn之后的Kubernetes上部署web服务，在性能或稳定性方面并没有带来额外的好处，代价是需要更多的资源。</p></div></div>    
</body>
</html>