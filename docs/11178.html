<html>
<head>
<title>Build Android app for custom object detection (TensorFlow 2.x)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建用于自定义对象检测的Android应用程序(TensorFlow 2.x)</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/build-android-app-for-custom-object-detection-tf-2-x-53904a08cfa2?source=collection_archive---------0-----------------------#2022-03-09">https://medium.com/geekculture/build-android-app-for-custom-object-detection-tf-2-x-53904a08cfa2?source=collection_archive---------0-----------------------#2022-03-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/7f5a8bebe412be1c408a308fc2ae288f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F6aVw8Scz_PqTuWRPLO1yA.png"/></div></div></figure><div class=""/><div class=""><h2 id="3595" class="pw-subtitle-paragraph iq hs ht bd b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh dx translated">使用TensorFlow对象检测API(用于旧版本TF应用程序)</h2></div><p id="62dd" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">使用Google Colab中的<strong class="jk hu"> TensorFlow 2.x </strong>训练一个用于自定义对象检测的深度学习模型，并使用TensorFlow的GitHub中的样本TFLite <a class="ae ke" href="https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection" rel="noopener ugc nofollow" target="_blank">对象检测应用</a>将其转换为TFLite模型，以部署在Android、iOS、Raspberry Pi、物联网设备等移动设备上。</p><h2 id="3427" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated"><strong class="ak">重要:</strong></h2><p id="866f" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">本教程针对使用TensorFlow对象检测API的TensorFlow 2.5。</p><p id="d2c0" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这是针对旧的java版本的。在GitHub中可以切换到以前的版本。对本教程中使用的java版本参考应用程序使用以下版本:</p><p id="12e2" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><a class="ae ke" href="https://github.com/tensorflow/examples/tree/demo/lite/examples/object_detection/android" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/examples/tree/demo/lite/examples/object _ detection/Android</a></p><h2 id="2744" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">路标</h2><ul class=""><li id="d8e8" class="lf lg ht jk b jl la jo lb jr lh jv li jz lj kd lk ll lm ln bi translated">收集图像数据集，并对它们进行标记，以获得它们的XML文件。</li><li id="caf6" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated">安装TensorFlow对象检测API。</li><li id="e619" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated">生成培训所需的TFRecord文件。(为此需要生成_tfrecord.py脚本和CSV文件)</li><li id="71f4" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated">编辑模型管道配置文件，并下载预先训练的模型检查点。</li><li id="8182" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated">训练和评估模型。</li><li id="6f7e" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated">将模型导出并转换为TFlite(TensorFlow Lite)格式。</li><li id="18bb" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated">使用来自TensorFlow的GitHub的样本TFLite <a class="ae ke" href="https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection" rel="noopener ugc nofollow" target="_blank">对象检测应用</a>在Android / iOS / IoT设备上部署TFlite模型。</li></ul></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="1aad" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">目标:为自定义对象检测构建Android应用程序</h1><p id="eea0" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">在本文中，我将为自定义对象训练一个对象检测模型，并将其转换为TFlite模型，以便它可以部署在Android、iOS和物联网设备上。遵循下面提到的21个步骤。(前16个步骤和我上一篇关于用TF 2训练一个ML模型的文章是一样的。由于TFLite目前只支持SSD型号，我们将在这里使用SSD型号)</p><p id="2045" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">(但首先✅Subscribe到我的YouTube频道👉🏻<a class="ae ke" href="https://bit.ly/3Ap3sdi" rel="noopener ugc nofollow" target="_blank">https://bit.ly/3Ap3sdi</a>😁😜)</p><ol class=""><li id="2dea" class="lf lg ht jk b jl jm jo jp jr ml jv mm jz mn kd mo ll lm ln bi translated"><a class="ae ke" href="#1854" rel="noopener ugc nofollow"> <strong class="jk hu">导入库</strong> </a></li><li id="63ff" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#5c39" rel="noopener ugc nofollow"> <strong class="jk hu">在google drive中创建customTF2、training和data文件夹</strong> </a></li><li id="3694" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#1f9c" rel="noopener ugc nofollow"> <strong class="jk hu">创建并上传您的图片文件和XML文件</strong> </a></li><li id="e873" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#fedc" rel="noopener ugc nofollow"> <strong class="jk hu">将generate_tfrecord.py文件上传到您的驱动器</strong> </a>中的customTF2文件夹</li><li id="7d02" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#dac7" rel="noopener ugc nofollow"> <strong class="jk hu">挂载驱动器并链接你的文件夹</strong> </a></li><li id="ffd4" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#6931" rel="noopener ugc nofollow"> <strong class="jk hu">克隆TensorFlow模型git库&amp;安装TensorFlow对象检测API </strong> </a></li><li id="9a04" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#dbf4" rel="noopener ugc nofollow"> <strong class="jk hu">测试模型构建器</strong> </a></li><li id="9dc6" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#26e9" rel="noopener ugc nofollow"> <strong class="jk hu">导航到<em class="mp">/my drive/custom tf2/data/</em>，将images.zip和annotations.zip文件解压到数据文件夹</strong> </a></li><li id="7703" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#f157" rel="noopener ugc nofollow">T19】创建测试_标签&amp;训练_标签T21】</a></li><li id="f651" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#e0a2" rel="noopener ugc nofollow"> <strong class="jk hu">创建CSV和“label_map.pbtxt”文件</strong> </a></li><li id="03e6" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#63f4" rel="noopener ugc nofollow"> <strong class="jk hu">创建‘train . record’&amp;【test . record】文件</strong> </a></li><li id="e845" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#fd78" rel="noopener ugc nofollow"> <strong class="jk hu">下载预训练模型检查点</strong> </a></li><li id="0469" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#3675" rel="noopener ugc nofollow"> <strong class="jk hu">获取模型管线配置文件，对其进行修改，并将其放入数据文件夹</strong> </a></li><li id="3e2f" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#33e6" rel="noopener ugc nofollow"> <strong class="jk hu">加载张量板</strong> </a></li><li id="1275" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#b148" rel="noopener ugc nofollow"> <strong class="jk hu">训练模型</strong> </a></li><li id="f19c" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#e928" rel="noopener ugc nofollow"> <strong class="jk hu">测试你训练过的模型</strong> </a></li><li id="26c8" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#eb05" rel="noopener ugc nofollow"> <strong class="jk hu">安装TensorFlow-nightly </strong> </a></li><li id="4502" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#5a2d" rel="noopener ugc nofollow"> <strong class="jk hu">导出SSD TFlite图</strong> </a></li><li id="3115" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#6cac" rel="noopener ugc nofollow"> <strong class="jk hu">将保存的模型转换为TFlite模型</strong> </a></li><li id="2eb5" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#9aef" rel="noopener ugc nofollow"> <strong class="jk hu">创建TFLite元数据</strong> </a></li><li id="fceb" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd mo ll lm ln bi translated"><a class="ae ke" href="#fb5e" rel="noopener ugc nofollow"> <strong class="jk hu">下载带有元数据的TFLite模型，并将其部署在移动设备上</strong> </a></li></ol></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="052d" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">如何开始？</h1><ul class=""><li id="324d" class="lf lg ht jk b jl la jo lb jr lh jv li jz lj kd lk ll lm ln bi translated">在你的浏览器上打开我的<a class="ae ke" href="https://colab.research.google.com/drive/13SPNsogGr8o4KQvBAxJBBCIonUx5Xad8?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab笔记本</a>。</li><li id="4e88" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated">点击菜单栏中的<strong class="jk hu">文件</strong>并点击<strong class="jk hu">在驱动器</strong>中保存一份副本。这将在您的浏览器上打开我的Colab笔记本的副本，您现在可以使用它了。</li><li id="c9b0" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated">接下来，一旦你打开了我的笔记本，并连接到谷歌Colab虚拟机，点击菜单栏中的<strong class="jk hu">运行时</strong>，并点击<strong class="jk hu">改变运行时类型</strong>。选择<strong class="jk hu"> GPU </strong>，点击保存。</li></ul></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="2993" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">我们开始吧！！</h1><figure class="mr ms mt mu fd hk er es paragraph-image"><div class="er es mq"><img src="../Images/4fd7df0e1bd482fee63df259bc026d1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*5_zyJ9pZGQcqrxvE4A376w.gif"/></div></figure><h1 id="1854" class="ma kg ht bd kh mb mv md kl me mw mg kp iz mx ja ks jc my jd kv jf mz jg ky mk bi translated">1)导入库</h1><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="389e" class="kf kg ht nb b fi nf ng l nh ni">import os<br/>import glob<br/>import xml.etree.ElementTree as ET<br/>import pandas as pd<br/>import tensorflow as tf</span></pre></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="5c39" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">2)在google drive中创建customTF2、training和data文件夹</h1><p id="018d" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">在google drive中创建一个名为<strong class="jk hu"> <em class="mp"> customTF2 </em> </strong>的文件夹。</p><p id="e9ec" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在<strong class="jk hu"> <em class="mp"> customTF2 </em> </strong>文件夹中再创建一个文件夹，名为<em class="mp">training</em>(<strong class="jk hu"><em class="mp">training</em></strong>文件夹是训练时保存检查点的地方)。</p><p id="daa0" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在<strong class="jk hu"> <em class="mp"> customTF2 </em> </strong>文件夹内创建另一个名为<strong class="jk hu"> <em class="mp"> data </em> </strong>的文件夹。</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="1f9c" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">3)创建并上传您的图像文件及其相应的带标签的XML文件。</h1><p id="ae6c" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">为您的自定义数据集图像创建一个名为<strong class="jk hu"> <em class="mp"> images </em> </strong>的文件夹，并为其对应的PASCAL_VOC格式的XML文件创建另一个名为<strong class="jk hu"> <em class="mp"> annotations </em> </strong>的文件夹。</p><p id="4901" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">接下来，创建他们的zip文件并上传到你的驱动器中的<strong class="jk hu"> <em class="mp"> customTF2 </em> </strong>文件夹。</p><blockquote class="nj nk nl"><p id="68a6" class="ji jj mp jk b jl jm iu jn jo jp ix jq nm js jt ju nn jw jx jy no ka kb kc kd hb bi translated"><strong class="jk hu"> <em class="ht">使</em> </strong> <em class="ht"> </em> <strong class="jk hu"> <em class="ht">确定所有的图像文件都有它们的扩展名为”。仅jpg”。</em>T51】</strong></p><p id="55c6" class="ji jj mp jk b jl jm iu jn jo jp ix jq nm js jt ju nn jw jx jy no ka kb kc kd hb bi translated"><em class="ht">其他格式如</em> <strong class="jk hu"> <em class="ht"> &lt;。png&gt;</em></strong><em class="ht"/><strong class="jk hu"><em class="ht">&lt;。jpeg &gt; </em> </strong> <em class="ht">甚至&lt;。</em><strong class="jk hu"><em class="ht">【JPG】</em><em class="ht">&gt;会给出错误自</em><strong class="jk hu">generate _ TF record</strong><em class="ht">和<strong class="jk hu">【XML _ to _ CSV</strong><em class="ht">脚本这里只有</em> <strong class="jk hu"> <em class="ht"> &lt;。jpg &gt; </em> </strong> <em class="ht">在其中。如果您有其他格式的图像，则相应地在脚本中进行更改。</em></em></strong></p></blockquote><p id="8f73" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">对于数据集，您可以在本文底部的致谢部分查看我的数据集来源。</p><h2 id="5d2e" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">收集图像数据集并标记它们以获得它们的PASCAL_VOC XML注释。</h2><h2 id="4392" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">标注数据集</h2><p id="8f4e" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">输入图像示例(<strong class="jk hu">Image1.jpg</strong>)</p><figure class="mr ms mt mu fd hk er es paragraph-image"><div class="er es np"><img src="../Images/25efb624bec73d21ad3bc5b0f6547abd.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/0*sgZW9n7nZEf50SYr.jpeg"/></div></figure></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><p id="60bb" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">您可以使用任何软件进行贴标，如<a class="ae ke" href="https://github.com/tzutalin/labelImg#labelimg" rel="noopener ugc nofollow" target="_blank"> <strong class="jk hu">贴标机</strong> </a>工具。</p><figure class="mr ms mt mu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nq"><img src="../Images/2088015c9b9f7abfff4c24cad7b1721f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-LHXVon8COqfIZoR.png"/></div></div></figure></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><p id="fc65" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">我使用一个叫做<strong class="jk hu"> OpenLabeling </strong>的开源标签工具，它有一个非常简单的UI。</p><figure class="mr ms mt mu fd hk er es paragraph-image"><div class="er es mq"><img src="../Images/d5363804f5249364f0c2789cbcd1aef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*o17q_iVOUyJd3GhR.gif"/></div></figure></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><p id="70a2" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">点击下面的链接，了解更多关于贴标过程和其他软件的信息:</p><ul class=""><li id="2b37" class="lf lg ht jk b jl jm jo jp jr ml jv mm jz mn kd lk ll lm ln bi translated"><a class="ae ke" href="https://techzizou.com/dataset-labeling-annotation-tutorial-for-beginners/" rel="noopener ugc nofollow" target="_blank"> <strong class="jk hu">影像数据集标注条</strong> </a></li></ul><p id="7464" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">注:</strong>垃圾进=垃圾出。选择和标记图像是最重要的部分。尽量找质量好的图片。数据的质量在很大程度上决定了结果的质量。</p><p id="4efc" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">输出的PASCAL_VOC标记的XML文件如下所示:</p><figure class="mr ms mt mu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nr"><img src="../Images/232e6f543d3430169c2d0210b6a5539a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*olN4RBNs_TI4QLez.png"/></div></div></figure></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="fedc" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">4)将generate_tfrecord.py文件上传到驱动器中的customTF2文件夹。</h1><p id="33d5" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">你可以在这里找到generate_tfrecord.py文件<a class="ae ke" href="https://github.com/techzizou/Train-Object-Detection-Model-TF-2.x" rel="noopener ugc nofollow" target="_blank"/></p><figure class="mr ms mt mu fd hk"><div class="bz dy l di"><div class="ns nt l"/></div></figure></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="dac7" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">5)安装驱动器并链接您的文件夹</h1><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="c141" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu">#mount drive</strong></span><span id="2557" class="kf kg ht nb b fi nu ng l nh ni">from google.colab import drive<br/>drive.mount('/content/gdrive')</span><span id="6f46" class="kf kg ht nb b fi nu ng l nh ni"><strong class="nb hu"># this creates a symbolic link so that now the path /content/gdrive/My Drive/ is equal to /mydrive</strong></span><span id="0aac" class="kf kg ht nb b fi nu ng l nh ni">!ln -s /content/gdrive/My Drive/ /mydrive<br/>!ls /mydrive</span></pre></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="6931" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">6)克隆TensorFlow模型git存储库并安装TensorFlow对象检测API</h1><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="9feb" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu"># clone the tensorflow models on the colab cloud vm</strong></span><span id="ed3f" class="kf kg ht nb b fi nu ng l nh ni">!git clone --q https://github.com/tensorflow/models.git</span><span id="46ec" class="kf kg ht nb b fi nu ng l nh ni"><strong class="nb hu"># navigate to /models/research folder to compile protos</strong></span><span id="6800" class="kf kg ht nb b fi nu ng l nh ni">%cd models/research</span><span id="a5f6" class="kf kg ht nb b fi nu ng l nh ni"><strong class="nb hu"># Compile protos.</strong></span><span id="f0e6" class="kf kg ht nb b fi nu ng l nh ni">!protoc object_detection/protos/*.proto --python_out=.</span><span id="0ddb" class="kf kg ht nb b fi nu ng l nh ni"><strong class="nb hu"># Install TensorFlow Object Detection API.</strong></span><span id="f2a6" class="kf kg ht nb b fi nu ng l nh ni">!cp object_detection/packages/tf2/setup.py .<br/>!python -m pip install .</span></pre></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="dbf4" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">7)测试模型构建器</h1><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="6210" class="kf kg ht nb b fi nf ng l nh ni">!python object_detection/builders/model_builder_tf2_test.py</span></pre></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="26e9" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">8)导航到/mydrive/customTF2/data/</h1><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="b7df" class="kf kg ht nb b fi nf ng l nh ni">%cd /mydrive/customTF2/data/</span><span id="e55f" class="kf kg ht nb b fi nu ng l nh ni"><strong class="nb hu"># unzip the datasets and their contents so that they are now in /mydrive/customTF2/data/ folder</strong></span><span id="34dc" class="kf kg ht nb b fi nu ng l nh ni">!unzip /mydrive/customTF2/images.zip -d .<br/>!unzip /mydrive/customTF2/annotations.zip -d .</span></pre></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="f157" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">9)创建测试标签和训练标签</h1><p id="3377" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">当前工作目录为<strong class="jk hu"><em class="mp">/my drive/custom tf2/data/</em></strong></p><p id="34cd" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">将标注分为test_labels(20%)和train_labels(80%)。</p><figure class="mr ms mt mu fd hk"><div class="bz dy l di"><div class="ns nt l"/></div></figure><figure class="mr ms mt mu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nr"><img src="../Images/58ca090badceeee33c722985dc9c4aab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Rcd1UwUwqNEzmuIt.png"/></div></div></figure></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="e0a2" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">10)创建CSV文件和“label_map.pbtxt”文件</h1><p id="afc8" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">当前工作目录为<strong class="jk hu"><em class="mp">/my drive/custom tf2/data/</em></strong></p><p id="43dc" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">运行下面的xml_to_csv脚本来创建<strong class="jk hu"><em class="mp">test _ labels . CSV</em></strong>和<strong class="jk hu"><em class="mp">train _ labels . CSV</em></strong></p><p id="9722" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">该脚本还使用xml文件中提到的类创建了<strong class="jk hu"><em class="mp">label _ map . Pb txt</em></strong>文件。</p><figure class="mr ms mt mu fd hk"><div class="bz dy l di"><div class="ns nt l"/></div></figure><figure class="mr ms mt mu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nr"><img src="../Images/5e8744f4b264dcd37a6553efe1bdae50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WR_hToy84cUO8gZD.png"/></div></div></figure><p id="45d0" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">创建的3个文件，即<strong class="jk hu"> train_labels.csv </strong>、<strong class="jk hu"> test_labels.csv </strong>和<strong class="jk hu"> label_map.pbtxt </strong>，如下图所示:</p><figure class="mr ms mt mu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nv"><img src="../Images/3f0d940130406242476e4dc933dae061.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*y4qrGCQ_daYZStCO"/></div></div></figure><figure class="mr ms mt mu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nw"><img src="../Images/eacec72b693939fba164ac7b003b1a94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*j6s4SBWRRuKQlplV"/></div></div></figure><figure class="mr ms mt mu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nx"><img src="../Images/a145ad8024465ccc68e43b10b8643df5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MbrfWO1TQ-wJO6Ex"/></div></div></figure><p id="f79c" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu"> train_labels.csv </strong>包含所有列车图像的名称、这些图像中的类及其注释。</p><p id="fa63" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu"> test_labels.csv </strong>包含所有测试图像的名称、这些图像中的类以及它们的注释。</p><p id="0f36" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu"> label_map.pbtxt </strong>文件包含来自您的带标签的XML文件的类名。</p><p id="461e" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">注:</strong>我有两个职业，分别是<strong class="jk hu"/><strong class="jk hu">【带_遮罩】</strong><strong class="jk hu"/><strong class="jk hu"/><strong class="jk hu">【不带_遮罩】</strong><strong class="jk hu">。</strong></p><blockquote class="nj nk nl"><p id="19e0" class="ji jj mp jk b jl jm iu jn jo jp ix jq nm js jt ju nn jw jx jy no ka kb kc kd hb bi translated"><strong class="jk hu"> <em class="ht">标签贴图id 0预留给背景标签</em> </strong> <em class="ht">。</em></p></blockquote></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="63f4" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">11)创建训练记录和测试记录文件</h1><p id="ae3c" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">当前工作目录为<strong class="jk hu"><em class="mp">/my drive/custom tf2/data/</em></strong></p><p id="c112" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">运行<strong class="jk hu"><em class="mp">generate _ TF record . py</em></strong>脚本，创建<strong class="jk hu"> <em class="mp"> train.record </em> </strong>和<strong class="jk hu"> <em class="mp"> test.record </em> </strong>文件</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="3fe7" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu">#Usage:</strong><br/>#!python generate_tfrecord.py output.csv output_pb.txt /path/to/images output.tfrecords</span><span id="40dd" class="kf kg ht nb b fi nu ng l nh ni"><strong class="nb hu">#For train.record</strong><br/>!python /mydrive/customTF2/generate_tfrecord.py train_labels.csv  label_map.pbtxt images/ train.record</span><span id="f913" class="kf kg ht nb b fi nu ng l nh ni"><strong class="nb hu">#For test.record</strong><br/>!python /mydrive/customTF2/generate_tfrecord.py test_labels.csv  label_map.pbtxt images/ test.record</span></pre><figure class="mr ms mt mu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nv"><img src="../Images/ab6cf517158b9cc7ef2f4a25ed5ad670.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*u1lCnYTBbGqKomRe.png"/></div></div></figure><p id="ac2f" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">图像文件的总数是1370。因为我们将标签分为两类，即。train_labels(80%)和test_labels(20%)，“<strong class="jk hu"> train.record </strong>的文件数为1096，“t <strong class="jk hu"> est.record </strong>的文件数为274。</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="fd78" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">12)下载预先训练的模型检查点</h1><p id="813b" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">当前工作目录为<strong class="jk hu"><em class="mp">/my drive/custom tf2/data/</em></strong></p><p id="4cf0" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">根据您的数据和要求，您可以选择任何模型进行培训。阅读<a class="ae ke" href="https://serokell.io/blog/how-to-choose-ml-technique" rel="noopener ugc nofollow" target="_blank">这篇</a>博客，了解更多关于这方面的信息。TensorFlow 2.x的检测模型检查点官方列表可以在<a class="ae ke" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="436d" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">然而，由于TFLite现在并不支持所有的模型，目前这方面的选择是有限的。TensorFlow正致力于添加更多支持TFLite的模型。点击阅读更多关于所有ML模块的TFLite兼容模型，如对象检测、图像分类、图像分割等<a class="ae ke" href="https://www.tensorflow.org/lite/guide/hosted_models" rel="noopener ugc nofollow" target="_blank">。</a></p><blockquote class="nj nk nl"><p id="1fd6" class="ji jj mp jk b jl jm iu jn jo jp ix jq nm js jt ju nn jw jx jy no ka kb kc kd hb bi translated"><strong class="jk hu"> <em class="ht">目前，TFLite仅支持SSD型号(不包括EfficientDet) </em> </strong></p></blockquote><p id="6ec9" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在本教程中，我将使用<strong class="jk hu">SSD _ mobilenet _ v2 _ fpnlite _ 320 x320 _ coco 17 _ TPU-8</strong>模型。</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="4f9e" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu"># Download the pre-trained model ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz into the <em class="mp">data</em> folder &amp; unzip it</strong></span><span id="53f9" class="kf kg ht nb b fi nu ng l nh ni">!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz</span><span id="c491" class="kf kg ht nb b fi nu ng l nh ni">!tar -xzvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz</span></pre></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="3675" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">13)获取模型管线配置文件，对其进行更改，并将其放入数据文件夹中</h1><p id="234a" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">当前工作目录为<strong class="jk hu">/my drive/custom tf2/data/</strong></p><p id="2ee3" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">从<strong class="jk hu"><em class="mp">/content/models/research/object _ detection/configs/tf2</em></strong>下载<strong class="jk hu">SSD _ mobilenet _ v2 _ fpnlite _ 320 x320 _ coco 17 _ TPU-8 . config</strong>。对其进行必要的修改，并上传到<strong class="jk hu"><em class="mp">/my drive/custom/data</em></strong>文件夹。</p><p id="8689" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">或</strong></p><p id="15b9" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在colab vm中编辑<strong class="jk hu"><em class="mp">/content/models/research/object _ detection/configs/tf2</em></strong>中的配置文件，并将编辑后的配置文件复制到<strong class="jk hu"><em class="mp">/my drive/custom tf2/data</em></strong>文件夹中。</p><p id="270e" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">您还可以在我们在上一步中刚刚下载的模型检查点文件夹中找到管道配置文件。</p><p id="488f" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">你需要做如下修改:</strong></p><ul class=""><li id="8c88" class="lf lg ht jk b jl jm jo jp jr ml jv mm jz mn kd lk ll lm ln bi translated">将<strong class="jk hu"> <em class="mp"> num_classes </em> </strong>更改为您的班级数。</li><li id="2524" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated">将<strong class="jk hu"> <em class="mp"> test.record </em> </strong> path、<strong class="jk hu"><em class="mp">train . record</em></strong>path&amp;<strong class="jk hu"><em class="mp">label map</em></strong>path更改为您创建这些文件的路径(训练时路径应相对于您当前的工作目录)。</li><li id="efd9" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated">将<strong class="jk hu"> <em class="mp">微调检查点</em> </strong>更改为步骤12下载的检查点所在目录的路径。</li><li id="c18a" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated">根据类型，用值<strong class="jk hu">分类</strong>或<strong class="jk hu">检测</strong>改变<strong class="jk hu"> <em class="mp">微调_检查点_类型</em> </strong>。</li><li id="10b6" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated">根据您的GPU能力，将<strong class="jk hu"> <em class="mp"> batch_size </em> </strong>更改为8的任意倍数。(例如:- 24，128，…，512)。GPU能力越好，你能走的越高。我的设置为64。我的设置为64。</li><li id="9f0f" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated">将<strong class="jk hu"> <em class="mp"> num_steps </em> </strong>更改为您希望探测器训练的步数。</li></ul><blockquote class="nj nk nl"><p id="f3b4" class="ji jj mp jk b jl jm iu jn jo jp ix jq nm js jt ju nn jw jx jy no ka kb kc kd hb bi translated">最大批量大小=可用GPU内存字节数/ 4 /(张量大小+可训练参数)</p></blockquote><p id="eee3" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">接下来，复制编辑过的配置文件</strong>。</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="b1ac" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu"># copy the edited config file from the configs/tf2 directory to the data/ folder in your drive</strong></span><span id="e9b3" class="kf kg ht nb b fi nu ng l nh ni">!cp /content/models/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config /mydrive/customTF2/data</span></pre><p id="9c1d" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">此时的工作区:</strong></p><figure class="mr ms mt mu fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ny"><img src="../Images/3cdd6ce08810627248afc2ab823075fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y1UCYmc_Wvuj95-jJ_jfLw.jpeg"/></div></div></figure><blockquote class="nj nk nl"><p id="bebe" class="ji jj mp jk b jl jm iu jn jo jp ix jq nm js jt ju nn jw jx jy no ka kb kc kd hb bi translated">您可以添加许多数据扩充选项。查看完整列表<a class="ae ke" href="https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto" rel="noopener ugc nofollow" target="_blank"> <em class="ht">此处</em> </a>。对于新手来说，以上改动就足够了。</p></blockquote><h1 id="fe65" class="ma kg ht bd kh mb mv md kl me mw mg kp iz mx ja ks jc my jd kv jf mz jg ky mk bi translated">数据扩充建议(可选)</h1><p id="094c" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">首先，您应该使用带有上述基本更改的示例配置文件来训练模型，并看看它做得如何。如果你过拟合，那么你可能想做一些更多的图像放大。</p><p id="4332" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在示例配置文件中:默认添加<code class="du nz oa ob nb b"><strong class="jk hu">random_horizontal_flip</strong></code> &amp; <code class="du nz oa ob nb b"><strong class="jk hu">ssd_random_crop</strong></code>。您也可以尝试添加以下内容:</p><p id="d816" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">(<strong class="jk hu">注</strong>:每次图像增强都会大幅增加训练时间)</p><ol class=""><li id="2d38" class="lf lg ht jk b jl jm jo jp jr ml jv mm jz mn kd mo ll lm ln bi translated">来自<strong class="jk hu">列车配置{}: </strong></li></ol><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="a218" class="kf kg ht nb b fi nf ng l nh ni">data_augmentation_options {<br/>    random_adjust_contrast {<br/>    }<br/>  }<br/>  data_augmentation_options {<br/>    random_rgb_to_gray {<br/>    }<br/>  }<br/>  data_augmentation_options {<br/>    random_vertical_flip {<br/>    }<br/>  }<br/>  data_augmentation_options {<br/>    random_rotation90 {<br/>    }<br/>  }<br/>  data_augmentation_options {<br/>    random_patch_gaussian {<br/>    }<br/>  }</span></pre><p id="9453" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">2.在<strong class="jk hu">型号{ }&gt;SSD { }&gt;box _ predictor { }:</strong>将<code class="du nz oa ob nb b"><strong class="jk hu">use_dropout</strong></code>设置为<code class="du nz oa ob nb b">true</code>这将帮助您应对过度拟合。</p><p id="06aa" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">3.在<strong class="jk hu"> eval_config : {} </strong>设置<code class="du nz oa ob nb b"><strong class="jk hu">num_examples</strong></code>中的<strong class="jk hu">测试</strong>图像的数量，并移除<code class="du nz oa ob nb b"><strong class="jk hu">max_eval</strong></code>以无限期评估</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="5986" class="kf kg ht nb b fi nf ng l nh ni">eval_config: {<br/>  num_examples: 274 # set this to the number of test images we divided earlier<br/>  num_visualizations: 20 # the number of visualization to see in tensorboard<br/>}</span></pre></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="33e6" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">14)加载张量板</h1><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="52c7" class="kf kg ht nb b fi nf ng l nh ni">%load_ext tensorboard<br/>%tensorboard --logdir '/content/gdrive/MyDrive/customTF2/training'</span></pre></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="b148" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">15)训练模型</h1><p id="dc51" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">导航到Colab VM中的<strong class="jk hu"><em class="mp">object _ detection</em></strong>文件夹</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="948d" class="kf kg ht nb b fi nf ng l nh ni">%cd /content/models/research/object_detection</span></pre></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="7a9f" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">15 (a)使用model_main_tf2.py进行培训</h1><p id="5294" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">这里<strong class="jk hu"> {PIPELINE_CONFIG_PATH} </strong>指向管道配置，<strong class="jk hu"> {MODEL_DIR} </strong>指向训练检查点和事件将被写入的目录。</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="7d3a" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu">#Run the command below from the content/models/research/object_detection directory</strong></span><span id="6295" class="kf kg ht nb b fi nu ng l nh ni"><strong class="nb hu">"""<br/>PIPELINE_CONFIG_PATH=path/to/pipeline.config<br/>MODEL_DIR=path to training checkpoints directory<br/>NUM_TRAIN_STEPS=50000<br/>SAMPLE_1_OF_N_EVAL_EXAMPLES=1</strong></span><span id="b014" class="kf kg ht nb b fi nu ng l nh ni"><strong class="nb hu">python model_main_tf2.py -- \<br/>--model_dir=$MODEL_DIR --num_train_steps=$NUM_TRAIN_STEPS \<br/>--sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \<br/>--pipeline_config_path=$PIPELINE_CONFIG_PATH \<br/>--alsologtostderr</strong></span><span id="1c2a" class="kf kg ht nb b fi nu ng l nh ni"><strong class="nb hu">"""</strong></span><span id="19ab" class="kf kg ht nb b fi nu ng l nh ni">!python model_main_tf2.py --pipeline_config_path=/mydrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --model_dir=/mydrive/customTF2/training --alsologtostderr</span></pre><p id="28b6" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">注:</strong></p><p id="367e" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">为了获得最佳结果，如果可能的话，应该在损失小于0.1时停止训练，否则训练模型，直到损失暂时没有任何显著变化。理想的损耗应该在0.05以下(在不过度拟合模型的情况下，尽量让损耗尽可能低。如果模型已经收敛，不要在训练步骤上走得太高，以试图降低损失。如果它不能进一步显著减少损失，并且需要一段时间才能下降。)</p><p id="cd23" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">理想情况下，我们希望损失尽可能低，但我们应该小心，以免模型过度拟合。您可以将步数设置为50000，并检查损失是否低于0.1，如果没有，则可以用更高的步数重新训练模型。</p><p id="b668" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">输出通常看起来像是“冻结”了，但不要急于取消该过程。默认情况下，训练仅每100步输出一次日志，因此，如果您等待一段时间，您应该会在第100步看到一个丢失日志。您应该等待的时间可能会有很大的不同，这取决于您是否使用GPU以及在配置文件中为<code class="du nz oa ob nb b">batch_size</code>选择的值，所以请耐心等待。</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="26bf" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">15 (b)使用model_main_tf2.py的评估(可选)</h1><p id="1bb0" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">您可以打开另一个colab笔记本，同时运行这个命令和上面的训练命令(不要忘记安装驱动器，克隆TF git repo，并在那里安装TF2对象检测API)。这将给你验证损失，地图等，所以你有一个更好的想法如何你的模型执行。</p><p id="cca0" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这里<strong class="jk hu"> {CHECKPOINT_DIR} </strong>指向包含由训练作业生成的检查点的目录。评估事件被写入<strong class="jk hu">{模型_目录/评估} </strong>。</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="14ec" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu"># Run the command below from the content/models/research/object_detection directory</strong></span><span id="86ed" class="kf kg ht nb b fi nu ng l nh ni"><strong class="nb hu">"""<br/>PIPELINE_CONFIG_PATH=path/to/pipeline.config<br/>MODEL_DIR=path to training checkpoints directory<br/>CHECKPOINT_DIR=${MODEL_DIR}<br/>NUM_TRAIN_STEPS=50000<br/>SAMPLE_1_OF_N_EVAL_EXAMPLES=1</strong></span><span id="4fba" class="kf kg ht nb b fi nu ng l nh ni"><strong class="nb hu">python model_main_tf2.py -- \<br/>--model_dir=$MODEL_DIR --num_train_steps=$NUM_TRAIN_STEPS \<br/>--checkpoint_dir=${CHECKPOINT_DIR} \<br/>--sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \<br/>--pipeline_config_path=$PIPELINE_CONFIG_PATH \<br/>--alsologtostderr<br/>"""</strong></span><span id="273d" class="kf kg ht nb b fi nu ng l nh ni">!python model_main_tf2.py --pipeline_config_path=/mydrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --model_dir=/mydrive/customTF2/training/ --checkpoint_dir=/mydrive/customTF2/training/ --alsologtostderr</span></pre></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="5e65" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">重新训练模型(以防断线)</h1><p id="ea0f" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">如果您在Colab VM上断开连接或丢失会话，您可以从您停止的地方开始培训，因为检查点保存在您的驱动器上的培训文件夹中。要重新开始训练，只需运行<strong class="jk hu">步骤1、5、6、7、14 </strong>、<strong class="jk hu">和15。</strong></p><p id="d5c5" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">请注意，由于我们拥有训练所需的所有文件，如记录文件、编辑过的管道配置文件、label_map文件和模型检查点文件夹，因此我们不需要再次创建这些文件。</p><p id="e754" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">【The model _ main _ tf2.py脚本每1000步保存一次检查点。训练会自动从上次保存的检查点重新开始。</p><p id="e611" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">但是，如果您发现它没有从最后一个检查点重新开始训练，您可以在管道配置文件中进行1处更改。将<strong class="jk hu"> fine_tune_checkpoint </strong>更改为您最新训练的检查点所在的位置，并使其指向最新的检查点，如下所示:</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="fc03" class="kf kg ht nb b fi nf ng l nh ni">fine_tune_checkpoint: "/mydrive/customTF2/training/ckpt-X" (where ckpt-X is the latest checkpoint)</span></pre><p id="ee68" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">阅读<a class="ae ke" href="https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#" rel="noopener ugc nofollow" target="_blank">这篇</a> TensorFlow物体探测API教程，了解更多关于TF2的训练过程。</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="e928" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">16)测试你训练好的模型</h1><h2 id="7658" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">导出推理图</h2><p id="1666" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">当前工作目录是<strong class="jk hu"><em class="mp">/内容/模型/研究/对象_检测</em> </strong></p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="1931" class="kf kg ht nb b fi nf ng l nh ni">!python exporter_main_v2.py --trained_checkpoint_dir=/mydrive/customTF2/training --pipeline_config_path=/content/gdrive/MyDrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --output_directory /mydrive/customTF2/data/inference_graph</span></pre><p id="8001" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">注意</strong>:上述命令中的<em class="mp"> trained_checkpoint_dir </em>参数需要训练目录的路径。有一个名为“检查点”的文件，其中保存了所有的模型路径和最新的模型检查点路径。因此它会自动使用最新的检查点。在我的例子中，检查点文件中为最新的model_checkpoint_path写入了ckpt-36。</p><p id="950e" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">对于<em class="mp"> pipeline_config_path </em>，给出我们用来训练上述模型的已编辑配置文件的路径。</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h2 id="9efe" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">在图像上测试您训练的对象检测模型</h2><p id="e704" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">当前工作目录为<strong class="jk hu"><em class="mp">/内容/模型/研究/对象_检测</em> </strong></p><p id="32bf" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这一步是可选的。</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="3f3b" class="kf kg ht nb b fi nf ng l nh ni"># <strong class="nb hu">Different font-type and font-size for labels text</strong></span><span id="9441" class="kf kg ht nb b fi nu ng l nh ni">!wget https://freefontsdownload.net/download/160187/arial.zip<br/>!unzip arial.zip -d .</span><span id="040f" class="kf kg ht nb b fi nu ng l nh ni">%cd utils/<br/>!sed -i "s/font = ImageFont.truetype('arial.ttf', 24)/font = ImageFont.truetype('arial.ttf', 50)/" visualization_utils.py<br/>%cd ..</span></pre><h2 id="acc7" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">测试您训练好的模型</h2><figure class="mr ms mt mu fd hk"><div class="bz dy l di"><div class="ns nt l"/></div></figure><h2 id="80a5" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">对于网络摄像头捕捉或视频的测试，请使用这款colab 笔记本。</h2></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="ecda" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">将训练好的SSD模型转换为TFLITE模型</h1><h1 id="eb05" class="ma kg ht bd kh mb mv md kl me mw mg kp iz mx ja ks jc my jd kv jf mz jg ky mk bi translated">17)每夜安装tf</h1><p id="092e" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated"><strong class="jk hu"> (TFLite转换器与tf-nightly配合使用效果更好。建议使用tf-nightly。也可以尝试使用最新的TensorFlow稳定版。)</strong></p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="d8e7" class="kf kg ht nb b fi nf ng l nh ni">!pip install tf-nightly</span></pre><p id="4643" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">注意:</strong>如果运行上述命令要求您重新启动运行时，并且您丢失了colab VM中的所有局部变量，您必须再次运行步骤5 &amp; 6来挂载驱动器、克隆TF模型库并安装对象检测API。再次运行这些步骤后，运行下面的步骤18。</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="5a2d" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">18)导出SSD TFlite图形</h1><p id="5e7a" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">当前工作目录是<strong class="jk hu"><em class="mp">/内容/模型/研究/对象_检测</em> </strong></p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="8b4e" class="kf kg ht nb b fi nf ng l nh ni">%cd /content/models/research/object_detection</span><span id="3c50" class="kf kg ht nb b fi nu ng l nh ni">!python export_tflite_graph_tf2.py --pipeline_config_path /content/gdrive/MyDrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --trained_checkpoint_dir /mydrive/customTF2/training --output_directory /mydrive/customTF2/data/tflite</span></pre></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="6cac" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">19)将TensorFlow保存的模型转换为TFlite模型</h1><p id="46f6" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">检查输入和输出张量名称</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="6cec" class="kf kg ht nb b fi nf ng l nh ni">!saved_model_cli show --dir /mydrive/customTF2/data/tflite/saved_model --tag_set serve --all</span></pre><h1 id="8c81" class="ma kg ht bd kh mb mv md kl me mw mg kp iz mx ja ks jc my jd kv jf mz jg ky mk bi translated">转换为TFlite</h1><p id="d95d" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated"><strong class="jk hu">使用方法(a)或方法(b)转换为TFLite </strong>。</p><p id="4c10" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">方法(a):- </strong>使用命令行工具</p><p id="f62e" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">使用<em class="mp"> tflite_convert </em>命令将保存的模型转换为TFLite。这是用于基本模型转换的简单方法。对于新手，我推荐先用这个方法。虽然第二种方法，即<em class="mp"> Python_API </em>，因为它有更多可用的支持和特性，所以在任何地方都被强烈推荐，但是您可以从使用第一种命令行工具方法开始进行测试，然后您可以稍后使用第二种方法，这也允许我们应用优化和训练后量化等。</p><p id="22b2" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">运行下面的代码块，使用<em class="mp"> tflite_convert </em>命令行工具<em class="mp">创建TFLite模型。</em></p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="bbcb" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu"># The default inference type is Floating-point. </strong></span><span id="7112" class="kf kg ht nb b fi nu ng l nh ni">%cd /mydrive/customTF2/data/</span><span id="1d02" class="kf kg ht nb b fi nu ng l nh ni">!tflite_convert --saved_model_dir=tflite/saved_model --output_file=tflite/detect.tflite</span></pre><p id="ce36" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">方法</strong> ( <strong class="jk hu"> b) </strong> :-使用Python API</p><p id="4460" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">使用Python API将保存的模型转换为TFLite。根据TensorFlow文档，这是更好的选择，因为我们可以应用其他功能和优化，如训练后量化，从而减少模型大小，并改善CPU和硬件加速器延迟。您可以根据自己的需求更改下面的代码。请阅读下面这些代码块下面的链接，以便更广泛地理解这一点以及为什么它更好，并且在理解了创建TFLite模型的整个过程的基础之后尝试一下。</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="d71b" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu"># Navigate to the data folder</strong></span><span id="58ff" class="kf kg ht nb b fi nu ng l nh ni">%cd /mydrive/customTF2/data/</span></pre><p id="e172" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">运行以下代码块，使用<em class="mp"> Python API创建TF lite<em class="mp">T13】模型。您可以使用任何推理类型或应用任何您想要的优化。</em></em></p><figure class="mr ms mt mu fd hk"><div class="bz dy l di"><div class="ns nt l"/></div></figure><p id="1cfc" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">要了解以上两种方法、优化、训练后量化以及我们为什么需要它们的更多信息，请查看下面的链接</strong>:</p><div class="hh hi ez fb hj oc"><a href="https://www.tensorflow.org/lite/convert" rel="noopener  ugc nofollow" target="_blank"><div class="od ab dw"><div class="oe ab of cl cj og"><h2 class="bd hu fi z dy oh ea eb oi ed ef hs bi translated">张量流Lite转换器</h2><div class="oj l"><h3 class="bd b fi z dy oh ea eb oi ed ef dx translated">TensorFlow Lite转换器采用TensorFlow模型并生成TensorFlow Lite模型(优化的FlatBuffer…</h3></div><div class="ok l"><p class="bd b fp z dy oh ea eb oi ed ef dx translated">www.tensorflow.org</p></div></div><div class="ol l"><div class="om l on oo op ol oq hp oc"/></div></div></a></div><div class="hh hi ez fb hj oc"><a href="https://www.tensorflow.org/lite/performance/post_training_quantization" rel="noopener  ugc nofollow" target="_blank"><div class="od ab dw"><div class="oe ab of cl cj og"><h2 class="bd hu fi z dy oh ea eb oi ed ef hs bi translated">训练后量化| TensorFlow Lite</h2><div class="oj l"><h3 class="bd b fi z dy oh ea eb oi ed ef dx translated">训练后量化是一种转换技术，可以减少模型大小，同时还可以改善CPU和硬件…</h3></div><div class="ok l"><p class="bd b fp z dy oh ea eb oi ed ef dx translated">www.tensorflow.org</p></div></div><div class="ol l"><div class="or l on oo op ol oq hp oc"/></div></div></a></div><div class="hh hi ez fb hj oc"><a href="https://www.tensorflow.org/lite/performance/model_optimization" rel="noopener  ugc nofollow" target="_blank"><div class="od ab dw"><div class="oe ab of cl cj og"><h2 class="bd hu fi z dy oh ea eb oi ed ef hs bi translated">模型优化| TensorFlow Lite</h2><div class="oj l"><h3 class="bd b fi z dy oh ea eb oi ed ef dx translated">边缘设备通常具有有限的内存或计算能力。可以对模型进行各种优化，以便…</h3></div><div class="ok l"><p class="bd b fp z dy oh ea eb oi ed ef dx translated">www.tensorflow.org</p></div></div><div class="ol l"><div class="os l on oo op ol oq hp oc"/></div></div></a></div><div class="hh hi ez fb hj oc"><a href="https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_integer_quant.ipynb#scrollTo=jPYZwgZTwJMT" rel="noopener  ugc nofollow" target="_blank"><div class="od ab dw"><div class="oe ab of cl cj og"><h2 class="bd hu fi z dy oh ea eb oi ed ef hs bi translated">训练后量化</h2><div class="oj l"><h3 class="bd b fi z dy oh ea eb oi ed ef dx translated">张量流</h3></div></div><div class="ol l"><div class="ot l on oo op ol oq hp oc"/></div></div></a></div><p id="971e" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">注:</strong>以上所有转换创建了“<strong class="jk hu"> detect.tflite </strong>模型。我已经使用了一个转换，并注释掉了其余的。如果运行所有命令，第二个命令将覆盖第一个命令。我的建议是首先运行其中一个转换，然后在下一步中使用元数据创建TFLite模型。一旦你有了带有一个模型的元数据的“<strong class="jk hu"> detect.tflite </strong>”，下载它，然后你就可以回来对另一个模型重新运行这一步，进行优化和训练后量化，然后也用元数据创建它的tflite模型。我为所有的转换编写了相同的名称，因为它也在下面的命令中使用。如果使用不同的名称，请在接下来的步骤中进行相应的更改。</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="9aef" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">20)将元数据附加到TFLite模型</h1><p id="ba3e" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">用于对象检测的新TensorFlow Lite示例要求最终的TFLite模型应附加元数据才能运行。你可以在TensorFlow官方网站<a class="ae ke" href="https://www.tensorflow.org/lite/convert/metadata" rel="noopener ugc nofollow" target="_blank">这里</a>了解更多信息。运行以下步骤来获取带有元数据的TFLite模型。</p><h2 id="3d4c" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">安装tflite_support_nightly软件包</h2><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="96ab" class="kf kg ht nb b fi nf ng l nh ni">pip install tflite_support_nightly</span></pre><h2 id="b4b6" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">在“tflite”文件夹中创建一个名为“tflite_with_metadata”的单独文件夹，以保存添加了元数据的最终tflite模型。</h2><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="651b" class="kf kg ht nb b fi nf ng l nh ni">%cd /mydrive/customTF2/data/<br/>%cd tflite/<br/>!mkdir tflite_with_metadata<br/>%cd ..</span></pre><h2 id="0667" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">创建并上传“labelmap.txt”文件</h2><p id="1a75" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">创建并上传“<strong class="jk hu"> labelmap.txt </strong>”文件，我们稍后也将在Android Studio中使用该文件。该文件不同于我们在步骤<strong class="jk hu"> 10 &amp; 11 </strong>中使用的“<strong class="jk hu"> label_map.pbtxt </strong>”。这个"<strong class="jk hu"> labelmap.txt </strong>"文件只有写在每一行中的类的名称，仅此而已。将此文件上传到<strong class="jk hu"><em class="mp">/my drive/custom tf2/data</em></strong>文件夹。<strong class="jk hu"> labelmap.txt </strong>文件如下所示:</p><figure class="mr ms mt mu fd hk er es paragraph-image"><div class="er es ou"><img src="../Images/302a8fe020a777e696bed0274b9f589a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/0*wCABaChfILnQfojA.png"/></div></figure><h2 id="ab4f" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">运行下面代码块中的代码，用元数据创建TFLite模型。</h2><p id="b9a3" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated"><strong class="jk hu">(注意:将下面代码块中第14、15 &amp; 16 &amp; 87行的路径改为您的路径。只有当你为你的文件使用不同的路径时。但是如果你正在遵循这个教程，你可以让它保持原样)</strong></p><ul class=""><li id="d411" class="lf lg ht jk b jl jm jo jp jr ml jv mm jz mn kd lk ll lm ln bi translated"><strong class="jk hu">第14行:</strong>在步骤19中创建的没有元数据的输入TFLite模型。</li><li id="5d6e" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><strong class="jk hu">第15行和第87行:</strong>label map . txt文件。</li><li id="6d9c" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><strong class="jk hu">第16行:</strong>添加了元数据的<strong class="jk hu"> </strong>最终TFLite模型输出的位置。</li></ul><figure class="mr ms mt mu fd hk"><div class="bz dy l di"><div class="ns nt l"/></div></figure><p id="26b4" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">注意:</strong>您可以为上面块中的元数据信息添加自己的名称和描述。我使用了通用的SSD_Detector名称和描述。</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="fb5e" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">21)下载带有元数据的TFLite模型，并调整TFLite对象检测示例应用程序</h1><p id="6ea2" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated"><strong class="jk hu">重要:</strong></p><p id="218e" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">使用<a class="ae ke" href="https://github.com/tensorflow/examples/tree/demo" rel="noopener ugc nofollow" target="_blank">这个链接</a>下载我在本教程中使用的旧版本TensorFlow档案。</p><p id="8d07" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu"> → </strong>接下来，打开Android Studio中的<strong class="jk hu"> <em class="mp">物体检测</em> </strong> app。</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="2110" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu"><em class="mp">C:Users\zizou\Downloads\examples-master\examples-master\lite\examples\object_detection</em></strong></span></pre><p id="c1d5" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu"> → </strong>接下来，将<strong class="jk hu"> detect.tflite </strong>模型连同元数据和<strong class="jk hu"> labelmap.txt </strong>文件复制到物体检测安卓app的<strong class="jk hu"> <em class="mp"> assets </em> </strong>文件夹内。</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="ef67" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu"><em class="mp">..\object_detection\android\app\src\main\assets</em></strong></span></pre><p id="a52d" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu"> → </strong>接下来，对代码进行如下修改。</p><ul class=""><li id="2175" class="lf lg ht jk b jl jm jo jp jr ml jv mm jz mn kd lk ll lm ln bi translated">首先，编辑gradle构建文件。打开<strong class="jk hu"> build.gradle </strong>文件<strong class="jk hu"><em class="mp">$ TF _ EXAMPLES/lite/EXAMPLES/object _ detection/Android/app/build . gradle</em></strong>注释掉<strong class="jk hu">apply from</strong>:'<strong class="jk hu">download _ model . gradle</strong>'，基本上是下载默认的对象检测应用TFLite模型并覆盖您的资产。</li></ul><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="14fd" class="kf kg ht nb b fi nf ng l nh ni">// apply from:'download_model.gradle'</span></pre><ul class=""><li id="faad" class="lf lg ht jk b jl jm jo jp jr ml jv mm jz mn kd lk ll lm ln bi translated">第二，如果您的模型被命名为<code class="du nz oa ob nb b"><strong class="jk hu">detect.tflite</strong></code>，并且您的标签文件被命名为<code class="du nz oa ob nb b"><strong class="jk hu">labelmap.txt</strong></code>，那么只要它们被正确地复制到基本资产目录中，示例就会自动使用它们。为了确认，在文本编辑器中或在Android Studio本身中打开<strong class="jk hu"><em class="mp">$ TF _ EXAMPLES/lite/EXAMPLES/object _ detection/Android/app/src/main/Java/org/tensor flow/demo/detector activity . Java</em></strong>文件，并找到<strong class="jk hu"> TF_OD_API_LABELS_FILE </strong>的定义。验证它指向你的标签映射文件:“<strong class="jk hu"> <em class="mp"> labelmap.txt </em> </strong>”。注意，如果你的模型是量化的，标志<strong class="jk hu">TF _ OD _ API _ IS _ quantified</strong>设置为<strong class="jk hu"> true </strong>，如果你的模型是浮点的，标志<strong class="jk hu">TF _ OD _ API _ IS _ quantified</strong>设置为<strong class="jk hu"> false </strong>。这个<strong class="jk hu"><em class="mp">DetectorActivity.java</em></strong>的新部分现在应该看起来如下。</li></ul><p id="3f5c" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">为一个</strong> <strong class="jk hu">量化模型</strong></p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="f5ab" class="kf kg ht nb b fi nf ng l nh ni">private static final boolean TF_OD_API_IS_QUANTIZED = true;<br/>private static final String TF_OD_API_MODEL_FILE = "detect.tflite";<br/>private static final String TF_OD_API_LABELS_FILE = "labelmap.txt";</span></pre><p id="2413" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">对于浮点模型</strong></p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="c3f4" class="kf kg ht nb b fi nf ng l nh ni">private static final boolean TF_OD_API_IS_QUANTIZED = false;<br/>private static final String TF_OD_API_MODEL_FILE = "detect.tflite";<br/>private static final String TF_OD_API_LABELS_FILE = "labelmap.txt";</span></pre><h2 id="1d16" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated"><strong class="ak">重要:</strong></h2><ul class=""><li id="b3ca" class="lf lg ht jk b jl la jo lb jr lh jv li jz lj kd lk ll lm ln bi translated">第三，将“DetectorActivity.java”文件中的输入大小更改为您正在使用的模型的输入数组形状。在这种情况下，将其设置为320，因为这是我们正在使用的模型的输入数组形状。当我们打印出输入&amp;输出张量细节时，我们在我们的colab笔记本上也看到了这个形状。您还可以使用Netron查看TFLite模型，以查看输入和输出张量的名称和形状。在“DetectorActivity.java”中进行以下调整:</li></ul><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="44ec" class="kf kg ht nb b fi nf ng l nh ni">private static final int <em class="mp">TF_OD_API_INPUT_SIZE </em>= 320;</span></pre><ul class=""><li id="fa94" class="lf lg ht jk b jl jm jo jp jr ml jv mm jz mn kd lk ll lm ln bi translated">最后，连接移动设备并运行应用程序。在进行任何其他新的改进或添加更多功能之前，请测试您的应用程序。现在您已经为此创建了一个基本的应用程序，您可以尝试对您的TFLite模型进行更改，正如我在本文前面提到的那样。我还提供了TensorFlow网站页面的链接，在那里你可以学习如何应用其他功能和优化，如训练后量化等。阅读下面在<strong class="jk hu">文档中的链接。玩得开心！</strong></li></ul></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="941c" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">实施解决方案</h1><p id="af3a" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">该对象检测Android参考应用程序演示了两种实施解决方案:</p><p id="797d" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">(1) <code class="du nz oa ob nb b"><a class="ae ke" href="https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android/lib_task_api" rel="noopener ugc nofollow" target="_blank">lib_task_api</a></code>利用来自<a class="ae ke" href="https://www.tensorflow.org/lite/inference_with_metadata/task_library/object_detector" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite任务库</a>的现成API</p><p id="e047" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">(2) <code class="du nz oa ob nb b"><a class="ae ke" href="https://github.com/tensorflow/examples/tree/master/lite/examples/text_classification/android/lib_interpreter" rel="noopener ugc nofollow" target="_blank">lib_interpreter</a></code>使用<a class="ae ke" href="https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_java" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite解释器Java API </a>创建自定义推理管道。</p><p id="06c3" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">对于新手来说，可以就这样吧。默认实现是lib_task_api。</p><h2 id="0e1c" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">重要事项:</h2><p id="ca47" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">您可以对使用上述教程训练的模型使用默认实现，即<strong class="jk hu"> lib_task_api </strong>，即使使用最新的TensorFlow版本也能很好地工作。然而，对于<strong class="jk hu"> lib_interpreter </strong>实现，对于TensorFlow 2.6和更高版本，如果您得到一个输出张量维度错误，您可能必须调整lib_interpreter文件中的代码。</p><p id="fc36" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">在lib_interpreter中更改“tfliteobjectdetectionapimodel . Java”文件中索引的顺序。</strong></p><p id="f9fc" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">将顺序从:</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="fc34" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu">outputMap.put(0, outputLocations);<br/>outputMap.put(1, outputClasses);<br/>outputMap.put(2, outputScores);<br/>outputMap.put(3, numDetections);</strong></span></pre><p id="7418" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">收件人:</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="edbd" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu">outputMap.put(0, outputScores);<br/>outputMap.put(1, outputLocations);<br/>outputMap.put(2, numDetections);<br/>outputMap.put(3, outputClasses);</strong></span></pre><ul class=""><li id="3f36" class="lf lg ht jk b jl jm jo jp jr ml jv mm jz mn kd lk ll lm ln bi translated">上述代码的文件位置:object _ detection \ Android \ lib _ interpreter \ src \ main \ Java \ org \ tensor flow \ lite \ examples \ detection \ TF lite \ tfliteobjectdetectionapimodel . Java</li></ul><p id="cd0d" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">要了解有关这些实现的更多信息，请阅读以下TensorFlow文档。</p><p id="490b" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><a class="ae ke" href="https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/lite/推论_ with _ metadata/task _ library/overview</a></p><p id="a03f" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><a class="ae ke" href="https://www.tensorflow.org/lite/inference_with_metadata/lite_support" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/lite/inference _ with _ metadata/lite _ support</a></p><p id="a03d" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在<code class="du nz oa ob nb b">app</code>文件夹中的<code class="du nz oa ob nb b"><a class="ae ke" href="https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/android/app/build.gradle" rel="noopener ugc nofollow" target="_blank">build.gradle</a></code>显示了如何改变<code class="du nz oa ob nb b">flavorDimensions "tfliteInference"</code>在两种解决方案之间切换。</p><p id="0d94" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在<strong class="jk hu"> Android Studio </strong>中，您可以将构建版本更改为您想要构建和运行的版本——只需转到<code class="du nz oa ob nb b">Build &gt; Select Build Variant</code>并从下拉菜单中选择一个即可。更多详情请参见<a class="ae ke" href="https://developer.android.com/studio/build/build-variants#product-flavors" rel="noopener ugc nofollow" target="_blank">在Android Studio </a>中配置产品口味。</p><figure class="mr ms mt mu fd hk er es paragraph-image"><div class="er es ov"><img src="../Images/690fa7e9cb775079dd0fae220de08b9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*sJgMidiCN8Bx95yYHirdOg.jpeg"/></div></figure><figure class="mr ms mt mu fd hk er es paragraph-image"><div class="er es ow"><img src="../Images/13f4d5173d4995a685cf4217f8e41ee4.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*H7EettRjllseVPqM1ik77g.jpeg"/></div></figure></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="1fc7" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">注意:</h1><p id="c999" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">我收集的用于遮罩检测的数据集主要包含特写图像。你可以在网上搜索更多的长镜头图片。有很多网站可以下载有标签和无标签的数据集。我在数据集来源下面给出了一些链接。我也给出了一些掩膜数据集的链接。其中一些有超过10，000张图片。</p><p id="0b64" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">虽然我们可以对我们的训练配置文件进行某些调整和更改，或者通过增强为每种类型的对象类向数据集添加更多图像，但我们必须小心，以免导致影响模型准确性的过度拟合。</p><p id="3586" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">对于初学者，你可以简单地使用我上传到GitHub上的配置文件。我还上传了我的掩模图像数据集以及PASCAL_VOC格式的文本文件，虽然这可能不是最好的，但将为您提供一个如何使用SSD模型训练您自己的自定义对象检测器的良好开端。你可以找到一个质量更好的带标签的数据集或者一个不带标签的数据集，以后自己标注。</p><p id="a4bb" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">我已经针对一个戴或没戴口罩的人的特定场景训练了这个应用程序，我的数据集主要有如上所述的特写图像。如果我们将这个应用程序用于其他场景，它可能会给出一些误报。您可以通过在正确的数据集上训练来为您的场景训练模型。此外，如果您想在您的场景中排除某些对象，您可以训练这些对象，然后在您的应用程序中编写代码来排除这些对象，只包括您想要的对象。</p><p id="9486" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">有许多方法可以定制这些ML应用程序，并处理这些应用程序中的误报。你可以在网上找到脚本。本教程向您展示了如何开始使用移动ML。玩得开心！</p><figure class="mr ms mt mu fd hk er es paragraph-image"><div class="er es mq"><img src="../Images/4fd7df0e1bd482fee63df259bc026d1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*5_zyJ9pZGQcqrxvE4A376w.gif"/></div></figure></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="4e7d" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">我的GitHub</h1><p id="19e5" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">培训文件</p><div class="hh hi ez fb hj oc"><a href="https://github.com/techzizou/Train-Object-Detection-Model-TF-2.x" rel="noopener  ugc nofollow" target="_blank"><div class="od ab dw"><div class="oe ab of cl cj og"><h2 class="bd hu fi z dy oh ea eb oi ed ef hs bi translated">GitHub-techzizou/Train-Object-Detection-Model-TF-2 . x:训练一个自定义的对象检测模型，使用…</h2><div class="ok l"><p class="bd b fp z dy oh ea eb oi ed ef dx translated">github.com</p></div></div><div class="ol l"><div class="ox l on oo op ol oq hp oc"/></div></div></a></div></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="23ae" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">我的掩膜数据集</h1><div class="hh hi ez fb hj oc"><a href="https://www.kaggle.com/techzizou/labeled-mask-dataset-pascal-voc-format" rel="noopener  ugc nofollow" target="_blank"><div class="od ab dw"><div class="oe ab of cl cj og"><h2 class="bd hu fi z dy oh ea eb oi ed ef hs bi translated">带标签的掩膜数据集(PASCAL_VOC)</h2><div class="oj l"><h3 class="bd b fi z dy oh ea eb oi ed ef dx translated">PASCAL_VOC格式XML注释</h3></div><div class="ok l"><p class="bd b fp z dy oh ea eb oi ed ef dx translated">www.kaggle.com</p></div></div><div class="ol l"><div class="oy l on oo op ol oq hp oc"/></div></div></a></div></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="1f4c" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">我的Colab笔记本</h1><div class="hh hi ez fb hj oc"><a href="https://colab.research.google.com/drive/13SPNsogGr8o4KQvBAxJBBCIonUx5Xad8?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="od ab dw"><div class="oe ab of cl cj og"><h2 class="bd hu fi z dy oh ea eb oi ed ef hs bi translated">谷歌协作笔记本</h2><div class="oj l"><h3 class="bd b fi z dy oh ea eb oi ed ef dx translated">构建对象检测应用程序tf2</h3></div></div><div class="ol l"><div class="oz l on oo op ol oq hp oc"/></div></div></a></div></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="1a53" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">看看我在Youtube上的视频</h1><h2 id="0dec" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">第一部分</h2><figure class="mr ms mt mu fd hk"><div class="bz dy l di"><div class="pa nt l"/></div></figure><h2 id="ad45" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">第二部分</h2><figure class="mr ms mt mu fd hk"><div class="bz dy l di"><div class="pa nt l"/></div></figure></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="1f3a" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">如果你觉得这篇文章有帮助，请订阅我的YouTube频道，并考虑在YouTube、Medium或以下任何🖖上支持我</h1><div class="hh hi ez fb hj oc"><a href="https://www.youtube.com/techzizou" rel="noopener  ugc nofollow" target="_blank"><div class="od ab dw"><div class="oe ab of cl cj og"><h2 class="bd hu fi z dy oh ea eb oi ed ef hs bi translated">泰克齐祖</h2><div class="oj l"><h3 class="bd b fi z dy oh ea eb oi ed ef dx translated">创建人工智能、机器学习、深度学习、计算机视觉、物体检测、图像等方面的视频教程</h3></div><div class="ok l"><p class="bd b fp z dy oh ea eb oi ed ef dx translated">www.youtube.com/techzizouizichtech</p></div></div><div class="ol l"><div class="pb l on oo op ol oq hp oc"/></div></div></a></div><div class="hh hi ez fb hj oc"><a href="https://www.buymeacoffee.com/techzizou" rel="noopener  ugc nofollow" target="_blank"><div class="od ab dw"><div class="oe ab of cl cj og"><h2 class="bd hu fi z dy oh ea eb oi ed ef hs bi translated">给我买杯咖啡！</h2><div class="oj l"><h3 class="bd b fi z dy oh ea eb oi ed ef dx translated">嘿，👋我正在创建技术博客和视频。你现在可以给我买杯咖啡来支持我的频道了！</h3></div><div class="ok l"><p class="bd b fp z dy oh ea eb oi ed ef dx translated">www.buymeacoffee.com/techzizou</p></div></div></div></a></div><div class="hh hi ez fb hj oc"><a href="https://www.patreon.com/techzizou" rel="noopener  ugc nofollow" target="_blank"><div class="od ab dw"><div class="oe ab of cl cj og"><h2 class="bd hu fi z dy oh ea eb oi ed ef hs bi translated">订阅模式</h2><div class="oj l"><h3 class="bd b fi z dy oh ea eb oi ed ef dx translated">立即成为TechZizou的赞助人:获得世界上最大的会员的独家内容和体验…</h3></div><div class="ok l"><p class="bd b fp z dy oh ea eb oi ed ef dx translated">www.patreon.com/techzizou</p></div></div><div class="ol l"><div class="pc l on oo op ol oq hp oc"/></div></div></a></div></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="ef19" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">信用</h1><h2 id="9ec4" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">文件/参考资料</h2><ul class=""><li id="4c66" class="lf lg ht jk b jl la jo lb jr lh jv li jz lj kd lk ll lm ln bi translated"><a class="ae ke" href="https://github.com/tensorflow/tensorflow" rel="noopener ugc nofollow" target="_blank"> Tensorflow简介</a></li><li id="5441" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://github.com/tensorflow/models" rel="noopener ugc nofollow" target="_blank"> Tensorflow模型Git库</a></li><li id="8712" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank"> TensorFlow对象检测API库</a></li><li id="d2ae" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#" rel="noopener ugc nofollow" target="_blank"> TensorFlow物体检测API教程</a></li><li id="62f1" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://github.com/tensorflow/models/tree/master/research/object_detection/g3doc" rel="noopener ugc nofollow" target="_blank"> TF对象检测文档</a></li><li id="92de" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md" rel="noopener ugc nofollow" target="_blank"> TF2安装指南</a></li><li id="fbbd" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md" rel="noopener ugc nofollow" target="_blank"> TensorFlow 2检测模型动物园</a></li><li id="a673" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_classification_zoo.md" rel="noopener ugc nofollow" target="_blank"> TensorFlow 2分类模型动物园</a></li><li id="9c54" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_training_and_evaluation.md" rel="noopener ugc nofollow" target="_blank">使用TensorFlow 2进行培训和评估</a></li><li id="a501" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite物体检测Android演示</a></li><li id="01f6" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md" rel="noopener ugc nofollow" target="_blank">在手机上运行TF2检测API模型</a></li><li id="a4f4" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://www.tensorflow.org/lite/convert#using_the_interpreter_from_a_model_file" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite转换器文档</a></li><li id="9147" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://github.com/techzizou/examples/tree/master/lite" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite示例应用</a></li><li id="18c1" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://www.tensorflow.org/tutorials" rel="noopener ugc nofollow" target="_blank">张量流教程</a></li><li id="d9d9" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://www.tensorflow.org/lite/models/object_detection/overview" rel="noopener ugc nofollow" target="_blank">面向移动和物联网设备的物体检测</a></li><li id="14fb" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://tfhub.dev/" rel="noopener ugc nofollow" target="_blank">张量流枢纽</a></li><li id="6660" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://github.com/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb" rel="noopener ugc nofollow" target="_blank"> TensorFlow Hub对象检测Colab </a></li><li id="aa7f" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://www.tensorflow.org/lite/convert" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite转换器</a></li><li id="3b8b" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://www.tensorflow.org/lite/performance/post_training_quantization" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite训练后量化</a></li><li id="ea6f" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://www.tensorflow.org/lite/convert/metadata" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite元数据</a></li><li id="ed4a" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://www.tensorflow.org/lite/guide/hosted_models" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite托管模型</a></li><li id="26fd" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite任务库</a></li><li id="f5d2" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://www.tensorflow.org/lite/inference_with_metadata/lite_support" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite支持库</a></li><li id="a6ba" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://www.tensorflow.org/lite/inference_with_metadata/task_library/object_detector" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite任务库—集成对象检测器</a></li><li id="0a75" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_java" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite解释器Java API </a></li><li id="e40c" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://towardsdatascience.com/detailed-tutorial-build-your-custom-real-time-object-detector-5ade1017fd2d" rel="noopener" target="_blank">物体探测器教程</a></li></ul><h2 id="44cc" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">数据集源</h2><p id="9fba" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">您可以从下面提到的网站下载许多对象的数据集。这些网站还包含许多种类的对象的图像以及它们的多种格式的注释/标签，例如YOLO_DARKNET txt文件和PASCAL_VOC xml文件。</p><ul class=""><li id="3878" class="lf lg ht jk b jl jm jo jp jr ml jv mm jz mn kd lk ll lm ln bi translated"><a class="ae ke" href="https://storage.googleapis.com/openimages/web/index.html" rel="noopener ugc nofollow" target="_blank">通过谷歌打开图像数据集</a></li><li id="734f" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://www.kaggle.com/datasets" rel="noopener ugc nofollow" target="_blank"> Kaggle数据集</a></li><li id="aaa6" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://public.roboflow.com/" rel="noopener ugc nofollow" target="_blank"> Roboflow公共数据集</a></li><li id="9adf" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://www.visualdata.io/discovery" rel="noopener ugc nofollow" target="_blank">可视化数据数据集</a></li></ul><h2 id="b42c" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">屏蔽数据集源</h2><ul class=""><li id="2686" class="lf lg ht jk b jl la jo lb jr lh jv li jz lj kd lk ll lm ln bi translated"><a class="ae ke" href="https://github.com/prajnasb/observations" rel="noopener ugc nofollow" target="_blank">般若Github </a></li><li id="0cab" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://www.kaggle.com/andrewmvd/face-mask-detection" rel="noopener ugc nofollow" target="_blank">安德鲁·默德·卡格尔</a></li><li id="10d1" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated"><a class="ae ke" href="https://github.com/X-zhangyang/Real-World-Masked-Face-Dataset" rel="noopener ugc nofollow" target="_blank">X-张洋Github </a></li></ul><h2 id="a113" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">更多掩膜数据集</h2><ul class=""><li id="c0be" class="lf lg ht jk b jl la jo lb jr lh jv li jz lj kd lk ll lm ln bi translated">Prasoonkottarathil ka ggle(20000张图片)</li><li id="c806" class="lf lg ht jk b jl lo jo lp jr lq jv lr jz ls kd lk ll lm ln bi translated">ashishjangra 27 ka ggle(12000张图片)</li></ul></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="d837" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">故障排除:</h1><h2 id="c5fc" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">错误1) ANDROID错误:索引0处的输出张量应该有3个维度，但找到2个。</h2><p id="69ee" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">lib_task_api实现与TensorFlow 2的最新版本配合得很好。</p><p id="8ca5" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">然而，对于lib_interpreter实现，您必须在代码中进行一些更改，以便它能够与使用Tensorflow 2.6和更高版本创建的TFLite模型一起工作。进行以下更改，它将正常工作:</p><p id="3634" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">在lib_interpreter中更改“tfliteobjectdetectionapimodel . Java”文件中索引的顺序。</strong></p><p id="01a9" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">将顺序从:</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="9208" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu">outputMap.put(0, outputLocations);<br/>outputMap.put(1, outputClasses);<br/>outputMap.put(2, outputScores);<br/>outputMap.put(3, numDetections);</strong></span></pre><p id="d960" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">收件人:</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="60dd" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu">outputMap.put(0, outputScores);<br/>outputMap.put(1, outputLocations);<br/>outputMap.put(2, numDetections);<br/>outputMap.put(3, outputClasses);</strong></span></pre><p id="5a88" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">注意:上述文件位于object _ detection \ Android \ lib _ interpreter \ src \ main \ Java \ org \ tensor flow \ lite \ examples \ detection \ TF lite \ tfliteobjectdetectionapimodel . Java</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h2 id="b953" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">错误2) OPENCV错误</h2><p id="8573" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">如果上面的_registerMatType cv2出现错误，这可能是因为Colab中的OpenCV版本不匹配。运行<code class="du nz oa ob nb b">!pip list|grep opencv</code>查看安装的OpenCV包版本，即<code class="du nz oa ob nb b">opencv-python</code>、<code class="du nz oa ob nb b">opencv-contrib-python</code>、&amp;、<code class="du nz oa ob nb b">opencv-python-headless</code>。版本会有所不同，这导致了这个错误。当colab更新其支持的版本时，此错误将会消失。现在，您可以通过简单地卸载和安装OpenCV包来解决这个问题。</p><p id="3510" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">检查版本:</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="dddc" class="kf kg ht nb b fi nf ng l nh ni">!pip list|grep opencv</span></pre><p id="acb3" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">如果只有opencv-python-headless是不同的版本，请使用以下两个命令:</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="ec96" class="kf kg ht nb b fi nf ng l nh ni">!pip uninstall opencv-python-headless --y</span><span id="bba5" class="kf kg ht nb b fi nu ng l nh ni">!pip install opencv-python-headless==4.1.2.30</span></pre><p id="eb3b" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">或者，如果其他opencv包是不同的版本，则使用以下命令。卸载并安装所有相同版本的<strong class="jk hu">。</strong></p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="b422" class="kf kg ht nb b fi nf ng l nh ni">!pip uninstall opencv-python --y<br/>!pip uninstall opencv-contrib-python --y<br/>!pip uninstall opencv-python-headless --y</span><span id="5dc7" class="kf kg ht nb b fi nu ng l nh ni">!pip install opencv-python==4.5.4.60<br/>!pip install opencv-contrib-python==4.5.4.60<br/>!pip install opencv-python-headless==4.5.4.60</span></pre></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="9c8e" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">误差3) DNN误差</h1><h2 id="8add" class="kf kg ht bd kh ki kj kk kl km kn ko kp jr kq kr ks jv kt ku kv jz kw kx ky kz bi translated">没有找到DNN图书馆</h2><p id="8d6d" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">此错误是由于Google Colab环境中的版本不匹配造成的。这可能是由于两个原因。第一，到目前为止，由于Google Colab中的默认TensorFlow版本是2.8(截至目前)，但我们在步骤6中安装的对象检测API的默认TensorFlow版本是2.9.0，这导致了一个错误。</p><p id="ee00" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">第二，Google Colab的默认cuDNN版本是8.0.5，但是对于TF 2.8和更高版本，它应该是8.1.0。这也会导致版本不匹配。</p><p id="20d3" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">当Colab更新它的包时，这个错误将会消失。但是对于临时解决方案，在搜索了许多在线论坛并查看了Google Colab团队成员的回复后，我可以推荐以下两个可能的解决方案:</p><p id="1053" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">解决方案1) </strong></p><p id="470b" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这是最简单的修复方法，但是根据Google Colab团队成员在论坛上的评论，这不是最佳实践，也不安全。这也可能导致与其他包或库的不匹配，但是作为一个临时的解决方法，这将会起作用。</p><p id="5af5" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在训练步骤之前运行以下命令。这将更新cudnn版本，之后您将不会有任何错误。</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="738a" class="kf kg ht nb b fi nf ng l nh ni">!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2</span></pre><p id="a7bc" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">解决方案2) </strong></p><p id="67b6" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">在此方法中，您可以编辑要安装在TensorFlow对象检测API中的包版本，使其与Colab的默认版本相同。</p><p id="42b6" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">我们将步骤6分成两个部分。</p><p id="9533" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">第一节:</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="5a45" class="kf kg ht nb b fi nf ng l nh ni"># clone the tensorflow models on the colab cloud vm<br/>!git clone --q <a class="ae ke" href="https://github.com/tensorflow/models.git" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/models.git</a></span><span id="1484" class="kf kg ht nb b fi nu ng l nh ni">#navigate to /models/research folder to compile protos<br/>%cd models/research</span><span id="9138" class="kf kg ht nb b fi nu ng l nh ni"># Compile protos.<br/>!protoc object_detection/protos/*.proto --python_out=.</span></pre><p id="8605" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">上面的第1节将克隆TF模型git存储库。</p><p id="7dfa" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">之后可以在<strong class="jk hu"><em class="mp">object _ detection/packages/tf2/setup . py</em></strong>编辑文件。<br/>更改所需包中的代码，在pandas包行后包括以下4行:</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="8e27" class="kf kg ht nb b fi nf ng l nh ni">    'tensorflow==2.8.0',<br/>    'tf-models-official==2.8.0',<br/>    'tensorflow_io==0.23.1',<br/>    'keras==2.8.0'</span></pre><p id="fd72" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated"><strong class="jk hu">注意</strong>:我在上面写了TensorFlow 2.8.0，因为它是目前默认的Google colab版本。</p><p id="4584" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">接下来，在这之后，您可以运行下面所示的步骤6的第2部分，用更新后的<strong class="jk hu"> <em class="mp"> setup.py </em> </strong>文件安装TF2 OD API。</p><p id="3f1a" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">第二节:</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="0f6c" class="kf kg ht nb b fi nf ng l nh ni"># Install TensorFlow Object Detection API.</span><span id="8b19" class="kf kg ht nb b fi nu ng l nh ni">!cp object_detection/packages/tf2/setup.py .<br/>!python -m pip install .</span></pre><p id="8b34" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">这将安装TensorFlow 2.8.0的TensorFlow对象检测API和其他所需的包，以及我们在<strong class="jk hu"> <em class="mp"> setup.py </em> </strong>文件中指定的更新版本。</p><p id="f4e5" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">现在，您将能够正确无误地运行培训步骤。</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="8390" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">错误4) TypeError: EndVector()缺少1个必需的位置参数:“vectorNumElems”</h1><p id="72bb" class="pw-post-body-paragraph ji jj ht jk b jl la iu jn jo lb ix jq jr lc jt ju jv ld jx jy jz le kb kc kd hb bi translated">该错误是由于flatbuffers版本不匹配造成的。将flatbuffers版本从2.0降级到1.12，它将修复此错误。</p><pre class="mr ms mt mu fd na nb nc nd aw ne bi"><span id="1321" class="kf kg ht nb b fi nf ng l nh ni"><strong class="nb hu">!pip install flatbuffers==1.12</strong></span></pre></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><h1 id="5e6c" class="ma kg ht bd kh mb mc md kl me mf mg kp iz mh ja ks jc mi jd kv jf mj jg ky mk bi translated">别忘了留下👏</h1><h1 id="75aa" class="ma kg ht bd kh mb mv md kl me mw mg kp iz mx ja ks jc my jd kv jf mz jg ky mk bi translated">祝您愉快！！！✌</h1><h1 id="28fa" class="ma kg ht bd kh mb mv md kl me mw mg kp iz mx ja ks jc my jd kv jf mz jg ky mk bi translated">♕·特奇佐·♕</h1></div></div>    
</body>
</html>