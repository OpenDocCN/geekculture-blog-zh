# 什么是机器学习中的数据泄露，有什么影响？

> 原文：<https://medium.com/geekculture/what-is-data-leakage-in-machine-learning-and-what-are-its-effects-811d58be7ccd?source=collection_archive---------10----------------------->

![](img/b106e6ac1e0cfa0a9b51d49b60fbc3a3.png)

Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

本文将阐述机器学习中的**数据泄露**现象、其原因、影响以及一些现实生活中的用例，以便更好地理解。

## **数据泄露**

**数据泄漏**(或**泄漏**)发生在训练数据包含关于目标的信息时，但当模型用于预测时，类似的数据将不可用。这导致**在**训练数据集**(甚至可能是**验证数据**)上的高性能**，但是该模型在生产中的性能将会很差。

简而言之，数据泄漏导致任何机器学习模型看起来都很准确，直到使用该模型进行预测，而该模型显示不正确的结果。

泄漏主要有两种类型:**目标泄漏**和**列车测试污染。**

## 目标泄漏

**目标泄漏**发生在预测器包含预测时不可用的数据时。

例如，有人想预测谁会得肺炎。人们在得了肺炎后服用抗生素药物以便康复，但如果没有肺炎就不会服药。

数据在那些列之间具有**强关系**，但是在确定值`got_pneumonia`之后频繁改变`took_antibiotic_medicine`。这是目标泄漏。

这个模型将会看到任何一个`False`值为`took_antibiotic_medicine`的人都没有患肺炎。由于验证数据与训练数据来自相同的来源，因此模式将总是在验证中重复自身，并且模型将具有很高的验证(或交叉验证)分数。

但是，当随后在现实世界中部署时，该模型将会非常不准确，因为当我们需要预测他们未来的健康状况时，即使是患肺炎的病人也不会接受抗生素治疗。

为了防止这种类型的**数据泄露**，任何在目标值实现后更新(或创建)的变量**都应该被排除。**

## 列车测试污染

当用户没有足够小心来**区分训练数据和验证数据时，就会发生不同类型的泄漏。**

**验证**是衡量模型如何处理以前没有考虑的数据。如果验证数据影响预处理行为，它可能会被微妙地破坏。这有时被称为**列车测试污染**。

例如，想象在调用`[train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)`之前运行一个预处理(比如**为缺失值拟合一个估算器**)。下一步什么？创建的模型可能会得到**良好的验证分数**，给予其极大的信心，但在部署进行决策时，表现**不佳。**

毕竟，用户将来自**验证或测试数据**的数据合并到如何进行预测中，所以他们可能在特定数据上做得很好，即使它**不能推广到新数据**。当一个人做更多复杂的特征工程时，这个问题变得更加微妙(也更加危险)。

如果验证基于**简单列车测试分割**，从任何类型的拟合中排除验证数据，包括预处理步骤的拟合。如果使用 **scikit-learn 管道**，这就更容易了。当使用交叉验证时，预处理在管道内部完成就更加重要了！

## **数据泄露用例**

1.  需要多少根鞋带？

耐克希望在鞋材上省钱。因此，耐克需要审查一个他们的员工建立的模型，以预测他们每个月需要多少根鞋带。进入机器学习模型的**功能**有:

*   当月(一月、二月等)
*   上个月的广告支出
*   截至本月初的各种宏观经济特征(如失业率)
*   当月他们最终使用的皮革数量

结果显示，如果使用**皮革量**的特征，模型几乎**完全准确**。但是如果不考虑这个特征的话，这仅仅是适度准确的，因为他们使用的皮革数量是他们生产多少鞋子的完美指标，这反过来又告诉他们需要多少鞋带。

您认为**使用的皮革量**特征是否构成数据泄露的来源？如果你的答案是“**视情况而定，**”取决于什么？

这很棘手，而且取决于数据收集的细节(在考虑泄漏时这很常见)。有人会在月初决定那个月要用多少皮革吗？如果是这样，这是可以的。但是，如果这是在当月确定的，那么当用户做出预测时，用户将无法访问它。如果你在月初的**有一个猜测，并且是**随后在该月内改变**，则该月内的实际使用量不能作为一个特性(因为它会造成泄漏)。**

让我们用一个新的想法。我们可以在鞋带模型中使用**耐克订购的皮革**数量(而不是他们实际使用的数量)作为预测。

这可能没问题，但这取决于他们是先订购鞋带还是先订购皮革。如果他们先订购鞋带，当你预测他们的鞋带需求时，你不会知道他们订购了多少皮革。如果他们先订购皮革，然后**当你下**鞋带订单**时，你就有那个号码**了，你应该没问题。

## **预防患者感染**

一家提供医疗保健的机构希望预测**哪些罕见手术的患者**有感染**的风险**，这样它就可以提醒护士在随访这些患者时要更加小心。

假设我们想要建立一个模型。建模数据集中的每一行将是接受手术的单个患者，而**预测目标**将是**他们是否受到感染**。

一些外科医生可能会以提高或降低感染风险的方式进行手术。但是如何才能最好地将外科医生的信息整合到模型中呢？

以下几点可以考虑。

1.  取每个外科医生的所有手术，并**计算这些外科医生的感染率**。
2.  对于数据中的每个患者，找出外科医生是谁，并将该外科医生的平均感染率作为一个特征插入。

这是否会造成任何目标泄漏问题？它会造成任何列车测试污染问题吗？

这造成了**目标泄漏和列车测试污染的风险。**

如果给定患者的结果对其外科医生的**感染率有影响，则存在目标泄漏，然后将其插回到该患者是否被感染的预测模型中。如果**外科医生的感染率**仅通过使用我们预测的患者之前的手术来计算，就可以避免目标泄露。在训练数据中为每个手术计算这个可能有点棘手。**

如果一个外科医生执行的所有**手术**都计算在内，包括那些来自测试集的手术，那么还有一个**训练测试污染**的问题。结果将是**模型在测试集**上看起来非常准确，即使在模型部署后**不会很好地推广到新患者**。这是因为外科医生风险特征考虑了测试集中的数据。测试集用于评估模型在看到新数据时的表现。所以这种污染违背了测试设备的目的。

## **学期考试准备**

我认为这个例子与**数据泄露**的情况有关，如果这种情况发生在现实生活中，它也会被证明是灾难性的。假设有一个学生正在准备他的学期考试。他期中考试考得很好，所以他了解课程内容和问题模式。到现在都很好。现在让我们假设一种情况，他以某种方式得到了**泄露的学期试卷(泄露的数据)**并出现在**学期期末考试**中。由于显而易见的原因，他在**学期的期末考试**中得了**高分**。现在，由于课程与工业项目直接相关，这意味着如果一个**在课程**中取得好成绩，这意味着候选人能够**在完成任何现实生活中的工业项目**中表现出色(基本上，考试的目的与创造现实生活中的工业经验是一致的)。现在的候选人**在行业环境** ( **部署环境**)中不能很好的表现 **，因为他使用了不正当的手段通过考试。在这里，不公平的做法与**数据泄露问题**直接相关，尽管模型在培训和测试环境中表现良好，但**在现实生产环境中会失败**。**

总的来说，这就是现实生活中的数据泄露现象。还可以有其他的用例。我在这里从 [**得到了**](https://www.kaggle.com/code/alexisbcook/data-leakage/tutorial) **的帮助。**

我将在不久的将来继续上传更多的**网络抓取、Python 自动化、数据分析、机器学习、NLP、深度学习、使用云部署的端到端 ML 和 DL 项目，以及相关教程**，因为我一直在努力学习、提升自己并分享我的工作。敬请期待，直到那时，请查看我的其他 [**文章**](/@abhi2652254) ，说 [**嗨**](https://www.linkedin.com/in/obhinaba17/) ，，让我知道你是否想要一个技术作家为你写作，我们可以通过一个简短的电话讨论。

此外，如果你喜欢我的工作，你可以捐赠给我几杯 [**咖啡**](https://ko-fi.com/abhinababanerjee) ，我可以在这个旅程中不断提高内容的质量。