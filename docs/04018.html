<html>
<head>
<title>Deploying PyTorch Model as a Serverless Service</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将PyTorch模型部署为无服务器服务</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/deploying-pytorch-model-as-a-serverless-service-339b4b93e517?source=collection_archive---------5-----------------------#2021-06-20">https://medium.com/geekculture/deploying-pytorch-model-as-a-serverless-service-339b4b93e517?source=collection_archive---------5-----------------------#2021-06-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/c28e6c9f3d00d27b2f55f1f3242a2ad2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HHlsE3qQ1fvkDpaI"/></div></div><figcaption class="iq ir et er es is it bd b be z dx"><a class="ae iu" href="https://unsplash.com/photos/JT1AI1nKWhg" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/JT1AI1nKWhg</a></figcaption></figure><p id="8688" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于深度学习生态系统中的最新进展，如改进的框架、生产就绪型架构、预训练模型...等等。现在，构建一个像样的模型很容易(并不真的😅)，但之后出现的最大问题是<strong class="ix hj"> <em class="jt">“我已经建立了一个模型，下一个是什么？”</em>T3】</strong></p><p id="f955" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一个模型的好坏取决于它能为客户提供什么样的用途，所以为了使一个模型有用，它应该以一种非常经济有效的方式服务于数百万用户。现在，我们如何向用户提供或部署模型呢？<br/>很简单，我们可以利用任何常见的云平台，如AWS、GCP、Azure等，按需获取数据存储和计算能力。对于本教程，我们将使用AWS云平台。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ju"><img src="../Images/64bd9e785fb5e97d690b16dc76bae7ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xPt57xzfnMstXpqVnrHXMA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">silicon valley series S4E4</figcaption></figure></div><div class="ab cl jz ka gp kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="hb hc hd he hf"><p id="e65d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">生活中最好的东西是免费的，但AWS资源却不是。云定价即使非常有竞争力，也可能成为工程师构建可扩展和资源密集型产品的障碍。<strong class="ix hj">在构建具有人工智能功能的MVP时，建立一个专用的实例基础设施是一项自杀任务</strong>，因为我们不知道用户保留率、产品在市场中的接受度以及产品带来的收入..等等。由于几个原因，使用专用云基础架构从头构建这些堆栈是一项昂贵的任务，我们将很快讨论这些原因<strong class="ix hj">。<br/> </strong>所以一个典型的深度学习API栈会是这样的:</strong></p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/bb1e9d1fe862d09d14ebea18c843708c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Oct_atdl8U_i_Ziw.gif"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">credit: AWS</figcaption></figure><p id="c349" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如我们所看到的，这是一个非常复杂的堆栈，这种基础设施的缺点是:<br/> 1。我们必须管理集群—其规模、类型和扩展逻辑<br/> 2。客户端必须为未使用的服务器电源付费<br/> 3。我们必须管理容器逻辑——日志记录、多个请求的处理等。需要大量云架构方面的专业知识</p><p id="ac82" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了解决专用云基础设施的缺点，云提供商提出了无服务器服务(例如:AWS Lambda)，其主要吸引力在于，<strong class="ix hj">我们不必管理任何服务器，并且我们按功能执行的数量而不是按小时计费</strong>(每月100万个免费请求)。<br/>由于无服务器(AWS Lambda)生态系统的最新进展，如容器支持、内存改进...等等，为所有深度学习实践者利用Lambda stack将模型部署为推理API开辟了许多机会。<br/> <strong class="ix hj">所以今天我们将部署一个PyTorch模型，作为利用Lambda、ECR和无服务器框架的无服务器API。</strong></p><p id="eca6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt">这是我的第一个故事，我非常兴奋地谈论所有的利基细节</em> </strong>😅<strong class="ix hj"> <em class="jt">。所以如果你们想直接进入代码，请查看我的</em></strong><a class="ae iu" href="https://github.com/anandsm7/BERT_as_serverless_service" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj"><em class="jt">GitHub repo</em></strong></a></p><div class="kg kh ez fb ki kj"><a href="https://github.com/anandsm7/BERT_as_serverless_service" rel="noopener  ugc nofollow" target="_blank"><div class="kk ab dw"><div class="kl ab km cl cj kn"><h2 class="bd hj fi z dy ko ea eb kp ed ef hh bi translated">Anand sm 7/BERT _ as _ server less _ service</h2><div class="kq l"><h3 class="bd b fi z dy ko ea eb kp ed ef dx translated">BAAS - BERT即服务，我们将使用无服务器基础架构部署经过培训的BERT模型。以上…</h3></div><div class="kr l"><p class="bd b fp z dy ko ea eb kp ed ef dx translated">github.com</p></div></div><div class="ks l"><div class="kt l ku kv kw ks kx io kj"/></div></div></a></div><p id="37ae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在本教程中，<strong class="ix hj">我们将使用BERT部署一个简单的文本分类模型🤗它将日常用户交易日志分类为“食物”、“交通”、“账单”等类别..并将其作为一个API </strong>。我将详细介绍以下主题:<br/> 1 .关于所有正在使用的资源的简要说明<br/> 2。构建我们的模型推理管道。使用无服务器框架创建Lambda函数<br/> 4。将我们的推理管道与lambda函数<br/> 5结合起来。构建一个docker映像并在本地测试我们的API<br/>6。标记图像并将其部署到AWS ECR <br/> 7。使用AWS ECR <br/> 8中部署的映像部署lambda函数。最后，使用无服务器API进行模型推理</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ky"><img src="../Images/9ae8c05f167a4e5b75140fac81c0b60d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*OHP7L4tKqnOkbKIfTHGGuA.gif"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">That’s too much work 😖 — giphy</figcaption></figure><ul class=""><li id="02b7" class="kz la hi ix b iy iz jc jd jg lb jk lc jo ld js le lf lg lh bi translated"><strong class="ix hj"> AWS Lambda服务</strong> —“能力越大，责任越小”<br/> <a class="ae iu" href="https://docs.aws.amazon.com/lambda/latest/dg/welcome.html" rel="noopener ugc nofollow" target="_blank"> AWS Lambda </a>基本上是一种让你在云服务器上运行功能而无需实际管理任何服务器的服务。如前所述，管理服务器从来都不是一件容易的事情。有了无服务器，我们就不必考虑基础设施的可伸缩性和健壮性，因为AWS会替我们处理。<br/>与ECR等AWS资源沟通..etc编程时我们需要安装AWS CLI，请按照<a class="ae iu" href="https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html" rel="noopener ugc nofollow" target="_blank">说明</a>进行操作</li><li id="8498" class="kz la hi ix b iy li jc lj jg lk jk ll jo lm js le lf lg lh bi translated"><strong class="ix hj">无服务器框架<br/> </strong> <a class="ae iu" href="https://www.serverless.com/" rel="noopener ugc nofollow" target="_blank">无服务器</a>框架让你使用<a class="ae iu" href="https://aws.amazon.com/lambda/" rel="noopener ugc nofollow" target="_blank"> AWS Lambda、</a> <a class="ae iu" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank"> S3 </a>、<a class="ae iu" href="https://aws.amazon.com/api-gateway/" rel="noopener ugc nofollow" target="_blank">亚马逊API网关</a>…等服务快速构建和部署无服务器应用。这个框架利用<a class="ae iu" href="https://aws.amazon.com/cloudformation/" rel="noopener ugc nofollow" target="_blank"> AWS cloudformation </a>来使用YAML配置文件启动构建我们的推理API所需的所有资源。<br/>要安装无服务器框架，请遵循此<a class="ae iu" href="https://www.serverless.com/framework/docs/providers/aws/guide/installation/" rel="noopener ugc nofollow" target="_blank">说明</a>，并确保遵循<a class="ae iu" href="https://www.serverless.com/framework/docs/providers/aws/cli-reference/config-credentials/" rel="noopener ugc nofollow" target="_blank">指南</a>使用您的AWS秘密访问密钥配置无服务器。</li><li id="ea1f" class="kz la hi ix b iy li jc lj jg lk jk ll jo lm js le lf lg lh bi translated"><strong class="ix hj"> AWS ECR — </strong> Docker🐳这就是你所需要的一切<strong class="ix hj"><br/></strong><a class="ae iu" href="https://aws.amazon.com/ecr/" rel="noopener ugc nofollow" target="_blank">Amazon Elastic Container Registry</a>(ECR)是一个完全托管的容器注册中心，可以方便地在任何地方存储、管理、共享和部署你的容器映像和工件。因此，我们基本上构建了分类器管道的docker映像，并将其存储在AWS ECR中。</li></ul><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/2663145b84c9f9b3816b62418d9b1240.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GnSmGMUCiN69cnIKZjRK-A.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">API stack infrastructure</figcaption></figure><p id="f9a7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们完整的API架构如上所示，这里用户用他的一个日常事务日志发出一个API请求，这个日志通过AWS API网关传递，这个请求将启动Lambda函数。对于我们的初始请求，lambda启动一个10GB的pod，并从ECR获取docker映像来启动我们的分类器容器。docker映像由模型+推理脚本组成，<strong class="ix hj">将模型保存在对象存储中是一种更好的方法，但为了简单起见，现在我们可以采用这种方法</strong>。因此，基于用户查询，lambda函数执行模型推断并返回最终的事务类，如下所示:</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/f42533fe4aaed87926f68eb0be521282.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AaQwMMTVMsbhllQXubbrbg.png"/></div></div></figure><p id="b05c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">既然我已经解释了整个过程，现在我们可以用代码弄脏我们的手了。我不会解释整个BERT分类器模型训练管道，因为这不是这篇博客的目的。可以查看我的<a class="ae iu" href="https://colab.research.google.com/drive/1IAJrx15szXsGDjKx1qihrvzAWqp2exz5?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> colab笔记本</strong> </a> <strong class="ix hj"> </strong>来训练用户日志分类模型。训练过程完成后，您将获得一个<strong class="ix hj"> pytorch_model.bin </strong>文件，我们将使用它作为构建无服务器API的模型。</p><p id="ae9b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们将使用无服务器CLI命令创建一个python lambda函数</p><pre class="jv jw jx jy fd lo lp lq lr aw ls bi"><span id="f9d6" class="lt lu hi lp b fi lv lw l lx ly">serverless create — template aws-python3 — path serverless-logbert</span></pre><p id="04e3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面的命令将使用一个基本的python处理程序脚本创建一个简单的样板文件，serverless.yml，requirements.txt..等等。因为我们正在使用pytorch框架构建深度学习文本分类模型，所以我们需要一些需要安装的包，所以让我们将它们添加到requirements.txt中。因为我们没有利用GPU进行推理，所以我们可以使用最小化的pytorch cpu版本来节省存储。</p><figure class="jv jw jx jy fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="b975" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在让我们直接跳到我们的处理函数，Lambda函数<em class="jt">处理函数</em>是您的函数代码中处理事件的方法。当您的函数被调用时，Lambda运行处理程序方法。当处理程序退出或返回响应时，它就可以处理另一个事件了。我们的处理程序代码如下:</p><figure class="jv jw jx jy fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="4741" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上面的代码中，sentence_prediction()方法接受用户输入，进行预处理、标记化并传递给经过训练的BERT模型，该模型又返回最终的预测。当前，该函数返回具有最高置信度得分的预测类。你可以在这里检查推理代码<a class="ae iu" href="https://github.com/anandsm7/BERT_as_serverless_service/blob/main/inference.py" rel="noopener ugc nofollow" target="_blank"/></p><p id="13ce" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们已经准备好使用docker在本地测试我们的推理API。确保docker安装在您的本地机器上以测试API，请查看<a class="ae iu" href="https://docs.docker.com/engine/install/" rel="noopener ugc nofollow" target="_blank"> docker安装指南</a>。Dockerfile如下:</p><figure class="jv jw jx jy fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="4023" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在让我们构建docker映像并运行容器进行测试</p><pre class="jv jw jx jy fd lo lp lq lr aw ls bi"><span id="8855" class="lt lu hi lp b fi lv lw l lx ly">docker build -t logbert-lambda .<br/>docker run -p 8080:8080 logbert-lambda</span></pre><p id="a8e5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在准备在本地测试我们的API。<br/>URL端点应该采用以下格式。{主机名}/{ lambda-API-version }/函数/函数/调用</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/60c11cb105ce1c479645dead8d1a4289.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Su5Gk8iMScM-INV33kfmOg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">local API testing</figcaption></figure><p id="83c4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果它在docker中工作，那么它应该在其他任何地方工作，所以我们的大部分工作已经完成。为了让Lambda函数获取这个图像，它应该被部署到AWS ECR(弹性容器注册中心)。作为第一步，我们需要创建一个repo来保存我们的docker映像，这可以使用AWS CLI以编程方式完成，如下所示:</p><pre class="jv jw jx jy fd lo lp lq lr aw ls bi"><span id="d95c" class="lt lu hi lp b fi lv lw l lx ly">aws ecr create-repository — repository-name logbert-lambda</span></pre><p id="818c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了推送我们的图像，我们应该首先需要从我们的机器登录到ECR，这需要一些标识符，如AWS区域和AWS帐户id，我们可以从AWS IAM获得。</p><p id="50ee" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在可以使用以下命令登录ECR:</p><pre class="jv jw jx jy fd lo lp lq lr aw ls bi"><span id="91be" class="lt lu hi lp b fi lv lw l lx ly">aws_region=ap-south-1<br/>aws_account_id=&lt;12 digit id&gt;</span><span id="6ced" class="lt lu hi lp b fi mc lw l lx ly">aws ecr get_login-password \<br/> — region $aws_region \<br/>| docker login \<br/> — username AWS \<br/> — password-stdin $aws_account_id.dkr.ecr.$aws_region.amazonaws.com</span></pre><p id="af84" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在将我们的图像推送到ECR之前，我们需要记住，默认情况下，所有docker图像都被推送到Docker Hub，但这里我们需要将其推送到AWS ECR，以便lambda函数获取我们的图像。为此，我们需要将其标记或重命名为一种格式，以便将其推送到相应的ECR repo。其格式如下:<br/> <code class="du md me mf lp b">{AccountID}.dkr.ecr.{region}.amazonaws.com/{repository-name}</code></p><pre class="jv jw jx jy fd lo lp lq lr aw ls bi"><span id="9e5e" class="lt lu hi lp b fi lv lw l lx ly">docker tag logbert-lambda $aws_account_id.dkr.ecr.$aws_region.amazonaws.com/logbert-lambda</span></pre><p id="aaf9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们使用"<em class="jt"> docker image ls" </em>命令来检查我们的docker image列表，我们将能够看到具有上述格式标签的docker image。现在，我们已经准备好将我们的形象推向ECR。</p><pre class="jv jw jx jy fd lo lp lq lr aw ls bi"><span id="bdcd" class="lt lu hi lp b fi lv lw l lx ly">docker push $aws_account_id.dkr.ecr.$aws_region.amazonaws.com/logbert-lambda</span></pre><p id="50f7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们已经到了教程的最后阶段，那就是<strong class="ix hj">使用我们的自定义映像</strong>部署AWS Lambda。现在我们必须编辑我们的serverless.yml文件，它是在我们创建lambda函数时作为样板文件创建的。下面的yml文件让您配置在部署lambda函数时需要启动的AWS资源。</p><figure class="jv jw jx jy fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="40dd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">ECR让我们的生活变得超级简单，因为我们只需要传递url路径和摘要路径，这样lambda就可以在启动服务时提取我们本地测试的图像。<strong class="ix hj">我们可以使用AWS CLI获取URL路径，也可以直接从ECR控制台</strong>中复制，在新创建的repo 中可以找到<strong class="ix hj">摘要。确保用我们各自的URL路径和摘要替换图像路径。</strong></p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/2f7bfd1885a83706a50be46fccd45fd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XH5-5zLAcurQ-n6YOlADnw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">ECR repo url</figcaption></figure><p id="6376" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们已经准备好使用以下命令部署lambda函数:</p><pre class="jv jw jx jy fd lo lp lq lr aw ls bi"><span id="df86" class="lt lu hi lp b fi lv lw l lx ly">serverless deploy</span></pre><p id="f99c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面的命令将启动所有资源，如AWS API网关、lambda函数、s3 bucket..使用API运行所需的AWS cloudformation。一旦部署过程完成，我们将得到如下所示的一些日志</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/613030d25de2b67c747ec2590296ce63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pKyUgO-bHrA7J7G7HeaiJw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">serverless deployment process</figcaption></figure><p id="1715" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们差不多完成了<a class="ae iu" href="https://apps.timwhitlock.info/emoji/tables/unicode#emoji-modal" rel="noopener ugc nofollow" target="_blank">😁</a>现在让我们做有趣的部分，是的，测试我们新构建的API。让我们再次回到postman，使用我们从上面的无服务器部署日志中获得的URL，并对其进行测试。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mi"><img src="../Images/26558e163afcf1f1e5b1595b5ae949db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mi4P6V80szTIDNshex91IQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Its working <a class="ae iu" href="https://apps.timwhitlock.info/emoji/tables/unicode#emoji-modal" rel="noopener ugc nofollow" target="_blank">😅</a></figcaption></figure><p id="06ec" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">是啊。，它像预期的那样工作，只花了半秒钟就得到响应，这也是CPU的推断。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ky"><img src="../Images/c6eb9494665f60987d67318b382f32c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*OR6PnWX5RW5XWPU2JxmSPA.gif"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">It ‘s working <a class="ae iu" href="https://apps.timwhitlock.info/emoji/tables/unicode#emoji-modal" rel="noopener ugc nofollow" target="_blank">😄</a>— GIFY</figcaption></figure><p id="10ae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这种无服务器的API基础设施有利有弊，最大的好处是它可以自动扩展到数千个并行请求，而不会出现任何问题。因此，我们不必担心自己构建一个可扩展且健壮的架构(这意味着没有人会在半夜打电话给你来解决服务器过载问题😴 🤯).<br/>同时，由于冷启动问题，它<strong class="ix hj">不太适合构建生产就绪的任务关键型API，但这可以在一定程度上通过使用AWS CloudWatch来保持我们的lambda服务温暖来纠正。<strong class="ix hj">GPU目前无法用于AWS lambda </strong>，这令人非常失望😞对于所有深度学习的人来说，我们可以希望在未来的迭代中看到这样的功能。当谈到以一种非常经济有效的方式构建基于人工智能的MVP(最小可行产品)时，无服务器基础设施的未来看起来很光明。</strong></p><p id="3984" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">希望你们觉得这个故事有用。随时欢迎建议和批评。感谢<a class="ae iu" href="https://apps.timwhitlock.info/emoji/tables/unicode#emoji-modal" rel="noopener ugc nofollow" target="_blank">😁</a></p><p id="1b30" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">参考文献<br/><em class="jt">*</em></strong><a class="ae iu" href="https://www.philschmid.de/multilingual-serverless-xlm-roberta-with-huggingface" rel="noopener ugc nofollow" target="_blank"><em class="jt">https://www . philschmid . de/multilingual-server less-xlm-Roberta-with-hugging face</em></a><br/><em class="jt">*</em><a class="ae iu" href="https://aws.amazon.com/blogs/machine-learning/deploying-machine-learning-models-as-serverless-apis/" rel="noopener ugc nofollow" target="_blank"><em class="jt">https://AWS . Amazon . com/blogs/machine-learning/deploying-machine-learning-models-as-server less-APIs/</em></a></p></div></div>    
</body>
</html>