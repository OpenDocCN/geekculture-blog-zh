<html>
<head>
<title>Analyzing Customer Churn Data with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python分析客户流失数据</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/analyzing-customer-churn-data-with-python-ddfef75e8149?source=collection_archive---------2-----------------------#2022-05-24">https://medium.com/geekculture/analyzing-customer-churn-data-with-python-ddfef75e8149?source=collection_archive---------2-----------------------#2022-05-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="0990" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">什么是客户流失？</h1><p id="dae9" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">术语“客户流失”指的是客户的流失。也就是说，如果顾客或客户停止接受公司的服务，就说他/她已经离职。</p><p id="2df3" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">客户流失与公司的财务表现密切相关。一个人对买家的行为了解得越多，他就能赚更多的钱。分析客户流失也有助于发现和改进公司提供的服务的缺点。</p><h1 id="0797" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">收集和清理数据</h1><p id="b83f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在这个实验中，我使用了著名的电信客户流失数据。这些数据可以从不同的来源找到。您也可以从<a class="ae kg" href="https://github.com/AashiqReza/DataAnalysiswithPython/tree/main/Classification" rel="noopener ugc nofollow" target="_blank">这里</a>下载数据。</p><p id="9012" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">下载数据后，应该将其加载到python中，然后获得数据的概述。在此之前，应该将所有必需的库导入到环境中。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="4bb5" class="kq ig hi km b fi kr ks l kt ku"># Import libraries<br/>import sklearn as sk<br/>import pandas as pd<br/>import matplotlib as plt<br/>import xgboost as xgb<br/>import seaborn as sn<br/>import matplotlib.pyplot as plt<br/>import os<br/>import numpy as np# ML algorithmsfrom sklearn.model_selection import train_test_split, cross_val_score<br/>from sklearn.impute import SimpleImputer<br/>from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, plot_roc_curve, confusion_matrixfrom sklearn.linear_model import LogisticRegression<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.neural_network import MLPClassifier<br/>from sklearn.tree import DecisionTreeClassifier## For hyperperameter tuningfrom sklearn.model_selection import RepeatedStratifiedKFold<br/>from sklearn.model_selection import GridSearchCV</span></pre><p id="23c0" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">现在读数据，看一看。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="2fb0" class="kq ig hi km b fi kr ks l kt ku"># Reading data<br/>data = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv', sep=',')<br/># Overview of the data<br/>data.head()</span></pre><figure class="kh ki kj kk fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es kv"><img src="../Images/d6fdedea99e4c06b6b7059a7ff0067b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VuaOIHsXp-PtItAr.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">Data overview</figcaption></figure><p id="59b9" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">数据集有21个变量，7032个观察值。第一列代表customerID，我将考虑删除此列以进行进一步分析。我使用以下代码检查了该数据集中缺少的值和数据类型。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="c13c" class="kq ig hi km b fi kr ks l kt ku"># Checking the summary of missing values<br/>data.isnull().values.any() # The result false implies there is no missing values in the data<br/>FALSE<br/>data.dtypes</span></pre><figure class="kh ki kj kk fd kw er es paragraph-image"><div class="er es lh"><img src="../Images/b27f0f406810d21e2abedb5455190776.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/format:webp/0*QCk-49smqJl_LsDY.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">Data types</figcaption></figure><p id="2593" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">大多数变量都是对象类型的。正如我在分析中提到的，由于TotalCharges是一个对象，应该是浮动格式的，所以出现了一些问题。同样，即使上面的代码显示数据集没有任何丢失的值，我也注意到数据集中的空白区域出现了一些丢失的值。执行以下代码，将这些空格转换为NA，并省略包含NA的数据集的行，并将相关列转换为浮点类型。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="b26a" class="kq ig hi km b fi kr ks l kt ku"># Removing variables we are not interested in<br/>data.drop(data.columns[[0]], axis = 1, inplace = True)<br/>## Missing values occured in terms of blank spaces in this dataset<br/>print (data[pd.to_numeric(data.TotalCharges, errors='coerce').isnull()])## Replace all the blank spaces to NA's<br/>nan = float("NaN")<br/>data.replace(" ", nan, inplace=True)<br/>data.dropna(subset = ["TotalCharges", "MonthlyCharges"], inplace=True)<br/>data.MonthlyCharges = pd.to_numeric(data.MonthlyCharges)<br/>data.TotalCharges = pd.to_numeric(data.TotalCharges)</span></pre><h1 id="f9d6" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">数据可视化</h1><p id="baa6" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">既然我们已经完成了数据收集和初步的数据清理，现在是时候可视化数据集以从数据集获得有用的见解了。性别与流失的数字显示，男性和女性流失的客户数量几乎相等。下一个数字，老年人与流失率显示，从数量上看，年轻人更喜欢流失率，但如果我们考虑比率，那么老年人的流失率更高。可以说，从合同长度与流失率的数字来看，有逐月合同长度的人更有可能流失。与那些仍在考虑公司提供的服务的人相比，那些已经跳槽的人的任期更短。最后一张图显示了数据集中数值变量之间的关系。</p><div class="kh ki kj kk fd ab cb"><figure class="li kw lj lk ll lm ln paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/61233707487d64bd4d01df0b36a70e2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Ii5rX4I1aHzzjltzqpSk5w.png"/></div></figure><figure class="li kw lj lk ll lm ln paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/37f89814dea2d4c5c5f79ce2dd5b709f.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*BgcVad0WEDsm_0ER3wkJ6g.png"/></div></figure><figure class="li kw lj lk ll lm ln paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/b47f6ade9021c521ab8d97978595e6af.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*cOLoBBpaNOQ94DPw0VG-Xg.png"/></div></figure></div><div class="ab cb"><figure class="li kw lo lk ll lm ln paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/9ffe975a028285206241418939ffa388.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*Ym0Yv1ZDV2SNpgYiBH0Jjg.png"/></div></figure><figure class="li kw lp lk ll lm ln paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/f5c10916174232de946c6793c43a0e3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*dQB9hitD-fRF2_9Vfyb12w.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx lq di lr ls">Some visualizations</figcaption></figure></div><p id="58a5" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">生成上述图形的代码:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="bd18" class="kq ig hi km b fi kr ks l kt ku"># pairplots<br/>sn.pairplot(data = data, hue='Churn')<br/>plt.show()## Average time to churn<br/>sn.boxplot(data['Churn'], data['tenure'])<br/>plt.title('Tenure vs Churn')# Effect of Contract length on customer attrition<br/>counts = (data.groupby(['Contract'])['Churn']<br/>  .value_counts()<br/>  .rename('Count')<br/>  .reset_index())<br/>sn.barplot(x="Contract", y="Count", hue="Churn", data=counts)<br/>set_title('Contract length vs Churn')<br/>plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)# Effect of age on customer attrition<br/>counts = (data.groupby(['SeniorCitizen'])['Churn']<br/>  .value_counts()<br/>  .rename('Count')<br/>  .reset_index())<br/>sn.barplot(x="SeniorCitizen", y="Count", hue="Churn", data=counts)<br/>set_title('SeniorCitizen vs Churn')<br/>plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)<br/>plt.savefig('fig4.png')# Effect of Contract length on customer attrition<br/>counts = (data.groupby(['gender'])['Churn']<br/>  .value_counts()<br/>  .rename('Count')<br/>  .reset_index())sn.barplot(x="gender", y="Count", hue="Churn", data=counts).set_title('Gender vs Churn')<br/>plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)<br/>plt.savefig('fig5.png')</span></pre><h1 id="6776" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">建模和准确性测试</h1><p id="e7a6" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在这一节中，我将展示一些对数据集进行预测的模型，并测试它们的准确性。为此，首先，数据集将被分为训练和测试部分，数据集的30%的观察值将被视为测试数据，其余数据将用于训练模型。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="1253" class="kq ig hi km b fi kr ks l kt ku"># Splitting into test and train sets<br/>x = data.drop('Churn', axis=1)<br/>y = data['Churn']<br/>x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=1)<br/>x_train = pd.get_dummies(x_train)<br/>x_test = pd.get_dummies(x_test)</span></pre><p id="35a3" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">所有需要的库和算法都已经在代码的开头加载了。在这个实验中，我考虑使用逻辑回归、随机森林、决策树和MLP分类器来进行预测。在训练数据中训练模型，并在测试数据集上评估性能指标。</p><ul class=""><li id="b672" class="lt lu hi jf b jg kb jk kc jo lv js lw jw lx ka ly lz ma mb bi translated">首先，在数据集中训练了逻辑回归模型，我们在测试集上获得了80%的准确度。</li></ul><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="390a" class="kq ig hi km b fi kr ks l kt ku">logmodel = LogisticRegression()<br/>logmodel.fit(x_train, y_train)predictions = logmodel.predict(x_test)<br/>print(classification_report(y_test, predictions))<br/>print(confusion_matrix(y_test, predictions))<br/>print(accuracy_score(y_test, predictions))</span></pre><figure class="kh ki kj kk fd kw er es paragraph-image"><div class="er es mc"><img src="../Images/9b0839a7fdc00fc46e106836c22884b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/0*Y7ijndZknAdtKIpW.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">Results from logistic regression</figcaption></figure><ul class=""><li id="63fe" class="lt lu hi jf b jg kb jk kc jo lv js lw jw lx ka ly lz ma mb bi translated">接下来，我训练了MLP分类器，混淆矩阵显示，该模型在测试集上的准确率也是80%。</li></ul><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="3630" class="kq ig hi km b fi kr ks l kt ku">mlp = MLPClassifier()<br/>mlp.fit(x_train, y_train)<br/>predictions = mlp.predict(x_test)<br/>print(classification_report(y_test, predictions))<br/>print(confusion_matrix(y_test, predictions))<br/>print(accuracy_score(y_test, predictions))</span></pre><figure class="kh ki kj kk fd kw er es paragraph-image"><div class="er es md"><img src="../Images/047428fc20d4f01f87cf6fc53786e513.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/0*0gL2s7A3h1KPCUt6.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">Results from MLP classifier</figcaption></figure><ul class=""><li id="fec2" class="lt lu hi jf b jg kb jk kc jo lv js lw jw lx ka ly lz ma mb bi translated">决策树在测试集上显示了72%的准确率。</li></ul><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="04fd" class="kq ig hi km b fi kr ks l kt ku">dtree = DecisionTreeClassifier()<br/>dtree.fit(x_train, y_train)<br/>predictions = dtree.predict(x_test)<br/>print(classification_report(y_test, predictions))<br/>print(confusion_matrix(y_test, predictions))<br/>print(accuracy_score(y_test, predictions))</span></pre><figure class="kh ki kj kk fd kw er es paragraph-image"><div class="er es me"><img src="../Images/d9dc2eaba2ac27f04d92ce3dbe7d9aef.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/0*mcD2xoETWNIgBaQ-.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">Results from the decision tree</figcaption></figure><ul class=""><li id="4e84" class="lt lu hi jf b jg kb jk kc jo lv js lw jw lx ka ly lz ma mb bi translated">最后，对随机森林模型进行了训练，我发现这个模型在测试集上有大约79%的准确率。</li></ul><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="f173" class="kq ig hi km b fi kr ks l kt ku">rand = RandomForestClassifier()<br/>rand.fit(x_train, y_train)<br/>predictions = rand.predict(x_test)<br/>print(classification_report(y_test, predictions))<br/>print(confusion_matrix(y_test, predictions))<br/>print(accuracy_score(y_test, predictions))</span></pre><figure class="kh ki kj kk fd kw er es paragraph-image"><div class="er es md"><img src="../Images/4f816184caa5256aacea278b6a256db1.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/0*C4_3MmhaeEFOgmtM.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx">Results from random forest</figcaption></figure><h1 id="8a16" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">超参数调谐</h1><p id="3456" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">超参数调整对于提高模型的预测能力非常重要。超参数是其值影响学习过程并影响学习算法学习的模型参数的参数。并且这些超参数的调整意味着选择超参数值的最佳集合。有许多不同的方法来调整超参数。网格搜索是最简单的调优方法之一。以下代码可用于调整任何模型的超参数。对于不同的模型，只需要改变参数列表。每个模型都有许多不同的参数。要调整的参数的选择取决于使用情况和问题。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="bb32" class="kq ig hi km b fi kr ks l kt ku">solvers = ['newton-cg', 'lbfgs', 'liblinear']<br/>penalty = ['l2']<br/>c_values = np.logspace(-4, 4, 50)<br/># define grid search<br/>grid = dict(solver=solvers,penalty=penalty,C=c_values, max_iter = [1000])<br/>cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)<br/>grid_search = GridSearchCV(estimator=logmodel, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)<br/>grid_result = grid_search.fit(x_train, y_train)<br/># summarize results<br/>print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_)Result:<br/>Best: 0.807123 using {'C': 0.013257113655901081, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}</span></pre><p id="40ae" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在这种情况下，提高的精度并不多。在这种情况下，采用了一种非常简单的方法来调整超参数。这可以进一步发展，准确率应该提高到90–95%。</p><h1 id="9703" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结论</h1><ul class=""><li id="da76" class="lt lu hi jf b jg jh jk jl jo mf js mg jw mh ka ly lz ma mb bi translated">在本文中，我展示了如何使用python中的电信客户流失数据来分析客户流失。</li><li id="228f" class="lt lu hi jf b jg mi jk mj jo mk js ml jw mm ka ly lz ma mb bi translated">可视化可以从数据中显示一些有用的见解。比如我们可以借助可视化找到客户流失背后的影响因素。</li><li id="9336" class="lt lu hi jf b jg mi jk mj jo mk js ml jw mm ka ly lz ma mb bi translated">已经进行了预测分析，并且已经比较了不同的机器学习算法来解决这个特定的问题。</li><li id="7f75" class="lt lu hi jf b jg mi jk mj jo mk js ml jw mm ka ly lz ma mb bi translated">最后，超参数调整显示了如何优化学习模型的参数值，以获得最佳预测准确性。</li></ul><p id="52c8" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">注意:完整的代码可以从<a class="ae kg" href="https://github.com/AashiqReza/DataAnalysiswithPython/tree/main/Classification" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p></div></div>    
</body>
</html>