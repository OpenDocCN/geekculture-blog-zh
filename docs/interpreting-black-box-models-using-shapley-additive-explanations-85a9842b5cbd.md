# 这个可解释的人工智能(XAI)包可以解决你的业务问题

> 原文：<https://medium.com/geekculture/interpreting-black-box-models-using-shapley-additive-explanations-85a9842b5cbd?source=collection_archive---------8----------------------->

## Shap

## 解释你的黑盒模型的算法

![](img/01b5faa440db6f5215c23908606e51cd.png)

Photo by [Clarisse Croset](https://unsplash.com/@herfrenchness?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

开发机器学习应用需要很多步骤。收集数据，进行数据清理，通过探索性数据分析、特征工程、特征选择、建模、评估和解释来探索数据。**解释**是开发机器学习应用的关键部分之一。由于业务流程的原因，这个过程需要很多关注。机器学习工程师需要向非技术专家/利益相关者解释机器学习模型如何对数据做出特定预测。

想象一下，如果你使用一个具有复杂特征的神经网络模型来开发你的机器学习应用程序，**非技术专家会相信你的模型预测吗？绝对没有**。对于技术专家和利益相关者来说，由于对模型的误解，使用机器学习来加速业务流程将是一个大问题。因此，在对数据进行特定预测时，解释模型的能力是让非技术专家信任我们的机器学习模型的必要知识。

**Shap(Shapley Additive exPlanations)**是最具可解释性的人工智能(XAI)工具之一，用来解释机器学习模型为什么会对数据实例做出特定的预测。Shapley Additive exPlanations 使用 shap 值来解释机器学习模型所做的预测。Shap 值是基于博弈论的方法做出的预测。

想象一下，你和你的团队(由 4 名成员组成)正在参加一场机器学习黑客马拉松。为了解决黑客马拉松中给出的问题，每个人都有自己独特的能力。如果你的团队赢得了黑客马拉松，你如何决定一个特定成员的贡献的公平支付。

为某个特定成员分配一部分奖金绝对是明智之举。这与 shap 如何根据我们在机器学习模型上训练的数据来解释我们的模型是一样的。从数学上讲，这是一件很难解释的事情。你可以查看 [**研究论文**](https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html) 中对这个可解释工具的数学解释，以及他们的 [**GitHub 库**](https://github.com/slundberg/shap) 中的更新特性。

> 我们将通过一个例子来实现电信客户流失数据集的 shap，我们可以在这里下载

[](https://www.kaggle.com/datasets/blastchar/telco-customer-churn) [## 电信客户流失

### 重点客户保留计划

www.kaggle.com](https://www.kaggle.com/datasets/blastchar/telco-customer-churn) 

该数据集包含 7043 个客户和 21 个基于数据实例预测客户是否会流失的特征。在这里，我们不会更深入地研究完整的机器学习过程。我只是做一个简单的探索性数据分析和数据预处理。

建议进行适当的探索性数据分析、数据清理、特性工程、特性选择、交叉验证和评估步骤，以便更好地预测数据实例。在本教程中，我们主要关注 Shap 的实现来解释模型。

你可以看看这个笔记本里的实现，供你参考。

[](https://deepnote.com/workspace/josua-naiborhu-6357636c-7a32-47a2-9932-f929b2448e11/project/Interpreting-black-box-models-1bc2c841-e6bf-4fd7-9ba8-536abd8d71ce) [## 深度笔记

### 面向数据科学家和研究人员的托管笔记本电脑。

deepnote.com](https://deepnote.com/workspace/josua-naiborhu-6357636c-7a32-47a2-9932-f929b2448e11/project/Interpreting-black-box-models-1bc2c841-e6bf-4fd7-9ba8-536abd8d71ce) 

# **翻译结果**

> 在解释结果之前，我们需要做的第一件事是在训练数据上训练我们的机器学习模型。在这个数据集上，我们使用 XGBoostClassifier 来解决这个分类问题，以如下方式研究流失或未流失的客户。

Shap 作为一个代理模型，使用 shap 值来解释我们的机器学习模型预测。我们必须使用下面的代码来获得这个值。我们实例化 shap 对象，并用我们的测试数据测试 shap 算法。

Shap 框架能够基于两种方法解释数据，即局部可解释性和全局可解释性。局部可解释性是 shap 根据特定数据实例解释数据的方式，而全局可解释性则根据我们拥有的整体特征和数据来解释数据。通常，由于不同的解释和结果，基于特定的数据实例对所有数据进行预测会更好。我们将为我们自己的用例可视化全局可解释性和本地可解释性。

# 具有特征重要性的全局可解释性

前面的条形图显示了每个特征如何影响我们根据我们使用的机器学习模型对训练数据进行的预测。我们可以看到，合同特征对预测目标结果的影响最大，其次是月费用和任期。

# 热图的全球可解释性

热图显示了所有功能对模型的影响。我们可以看到，增加合同功能也将增加红色区域的任期和总费用，因为这些功能的 shap 值更高。顶部的 f(x)曲线显示了随着数据实例的增加，预测的流失情况。我们可以看到客户流失预测如何影响数据实例的增长。

# 分层的全局可解释性

该图显示了功能使用权和总费用形成一组，在线安全性和乘数形成另一组。这个过程称为层次聚类。此图还显示了一些特性如何根据子组进行交互，这可能是我们可以在 EDA 中检测到的特性，以便进行进一步分析。

# SHAP 汇总图的全球可解释性

violin 图显示了该特性对于某些数据点的积极或消极影响。由于红色渐变，TotalCharges 与目标结果呈正相关。然而，它与合同、任期和总费用不同，后者的低值表示流失。

# 具有特征依赖图的全局可解释性

特征独立性图就像一个散点图，我们可以从中看到两个变量的相关性。可视化显示总费用的增加也将增加合同。

# 使用瀑布图的局部可解释性

我们可以从数据实例对第一和第二观察上的特征的推断中看出，示出了不同的结果，其中在第一观察上，合同特征对模型预测有负贡献，而在第二观察上，合同特征对模型预测有正贡献。

# 决策图的局部可解释性

决策图有助于解释处理数据集中的许多要素。我们可以从前面的图中看到每个当前局部预测如何高于或低于平均预测结果，以及特征值如何影响模型结果。在所示的两个示例中，合同给技术支持的案例功能对模型产生负面影响，而第二次观察的大多数功能对模型预测产生正面影响。

你也可以阅读另一篇关于可解释人工智能(XAI)的文章

[](https://www.freecodecamp.org/news/interpret-black-box-model-using-lime/) [## 如何使用 LIME 解释黑盒模型(本地可解释的模型不可知解释)

### 机器学习模型是黑盒模型。通过给这些模型输入，我们可以根据特定的…

www.freecodecamp.org](https://www.freecodecamp.org/news/interpret-black-box-model-using-lime/) 

参考资料:

[1].斯科特·伦德伯格。“[解释模型预测的统一方法](https://arxiv.org/abs/1705.07874v2)”。(2017).

[2].斯科特·伦德伯格。”[沙普利加解释](https://paperswithcode.com/method/shap)。(2017).

# 感谢您的阅读！

*我真的很感激！*🤗*如果你喜欢这个帖子并想看更多，可以考虑* [***关注我***](https://naiborhujosua.medium.com/) *。我发布与机器学习和深度学习相关的主题。我尽量让我的帖子简单而精确，总是提供可视化和模拟。*

![](img/6945da5ee6c6b62bca14b0e84906ad30.png)

**Josua Naiborhu** 是一名业务发展分析师，后来成为一名自学成才的机器学习工程师。他的兴趣包括**统计学习、预测建模和可解释机器学习**。他喜欢跑步，这教会他不要放弃做任何事情，即使是在实施**机器学习生命周期(MLOps)** 的时候。除了追求他对机器学习的热情，他还热衷于投资印度尼西亚证券交易所和加密货币。他一直在跑 2015 年**雅加达马拉松和 2019 年**大阪马拉松的全程马拉松。他的下一个梦想是参加波士顿马拉松、TCS 纽约市马拉松和 Virgin Money 伦敦马拉松。

*你可以在****LinkedIn****，****Twitter****，G****ithub****，***上和他联系或者直接在他的* ***个人网站上联系他。****