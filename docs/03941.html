<html>
<head>
<title>ML algorithms 1.03: K Nearest Neighbors</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML算法1.03: K个最近邻</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/ml-algorithms-1-03-k-nearest-neighbors-5f54470b5e30?source=collection_archive---------51-----------------------#2021-06-17">https://medium.com/geekculture/ml-algorithms-1-03-k-nearest-neighbors-5f54470b5e30?source=collection_archive---------51-----------------------#2021-06-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/29ba6215bc8308b0e23e1cf13ce15c9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SVkPJ28ZKDc4Uig7xzz_fQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx"><a class="ae iu" href="https://unsplash.com/photos/fIMqGvVaATk?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditShareLink" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><h1 id="21fa" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">介绍</h1><p id="7f20" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">k近邻是一个懒惰的学习者。它并不构建这样的模型。当要素具有不同的范围时，在计算距离之前有必要对要素进行缩放。</p><h1 id="7faf" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">优势</h1><ol class=""><li id="1c66" class="kr ks hi jv b jw jx ka kb ke kt ki ku km kv kq kw kx ky kz bi translated">无需培训。</li><li id="6143" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq kw kx ky kz bi translated">非常容易解读。</li></ol><h1 id="b555" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">不足之处</h1><ol class=""><li id="ba7e" class="kr ks hi jv b jw jx ka kb ke kt ki ku km kv kq kw kx ky kz bi translated">需要找到最佳K(邻居的数量)。随着新数据的添加，这种情况可能会发生变化。</li><li id="6eac" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq kw kx ky kz bi translated">当数据非常大或者维数很大时，问题就出现了。这可以通过使用kd树和球树算法来解决。</li><li id="a32c" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq kw kx ky kz bi translated">它对噪声数据很敏感。</li></ol><h1 id="92fd" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">距离度量</h1><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lf"><img src="../Images/e33f6dbb6e23a83538ffd0dadb08bab8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1pwwxo7Dr66gyVWs.png"/></div></div></figure><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/9427603c0ece636563151d9deac66d47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*G72g3I75o-JMz-9E.png"/></div></div></figure><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/d0f31f8ddae75ad589ed663903241a59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tR4kWLkKPonDgIkZ.png"/></div></div></figure><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/741ae11ef19c1638246b1acd38cc6797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/0*70ayB4oLOY4mooch.png"/></div></figure><h1 id="dee5" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">模型结构</h1><p id="466c" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">需要注意的要点:</p><ol class=""><li id="fea6" class="kr ks hi jv b jw ln ka lo ke lp ki lq km lr kq kw kx ky kz bi translated">我们需要规范化/标准化数字特征，并将分类特征编码为虚拟特征。</li><li id="371e" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq kw kx ky kz bi translated">如果预测数据是数字和分类特征的混合，我们只能对数字数据进行最小最大缩放。这是为了将值限制在与分类编码变量相同的范围内的[0，1]内。</li><li id="10fc" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq kw kx ky kz bi translated">如果预测值都是数字，我们可以使用欧几里得距离、曼哈顿距离、米诺斯基距离或马哈拉诺比斯距离。</li><li id="9949" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq kw kx ky kz bi translated">如果预测值只是绝对的，我们可以使用海明距离。</li><li id="bfbb" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq kw kx ky kz bi translated">如果预测因子是数字和分类的混合，我们必须非常小心地选择距离度量。</li><li id="764b" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq kw kx ky kz bi translated">当数据具有非常高的维度时，我们会遭受维数灾难。在这种情况下，我们限制在闵可夫斯基距离中使用较低的功率。我们也可以求助于降维技术和特征选择。</li><li id="287a" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq kw kx ky kz bi translated">K的最佳值可以通过绘制误差和K来找出。</li></ol><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/9ed1de94d2d157d99c84deb65ed558b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*zWUjktVuZoF4nfbmTkuIqw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">Image by author</figcaption></figure><h1 id="d8ec" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">预言；预测；预告</h1><p id="3008" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">新的观察结果被放置在训练数据的特征空间中。</p><h2 id="cd3d" class="lt iw hi bd ix lu lv lw jb lx ly lz jf ke ma mb jj ki mc md jn km me mf jr mg bi translated">分类</h2><p id="6da6" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">输出类是n个邻居的模态类。</p><h2 id="f80e" class="lt iw hi bd ix lu lv lw jb lx ly lz jf ke ma mb jj ki mc md jn km me mf jr mg bi translated">回归</h2><p id="6418" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">输出估计值是n个邻居的平均值。</p><blockquote class="mh mi mj"><p id="d3dd" class="jt ju mk jv b jw ln jy jz ka lo kc kd ml mm kg kh mn mo kk kl mp mq ko kp kq hb bi translated">当类的数量是偶数时，你应该保持邻居的数量为奇数，反之亦然，以避免混淆。</p></blockquote><h1 id="88ab" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">超参数调谐</h1><ul class=""><li id="c280" class="kr ks hi jv b jw jx ka kb ke kt ki ku km kv kq mr kx ky kz bi translated"><strong class="jv hj"> n_neighbors </strong>:设置邻居数量</li><li id="0743" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq mr kx ky kz bi translated"><strong class="jv hj">砝码</strong>:统一；距离:<br/>一致:所有点的权重一致<br/>距离:越近的点的权重越大，与它们的距离成反比</li><li id="d49d" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq mr kx ky kz bi translated"><strong class="jv hj">算法</strong>:算法构造的类型。<br/> kd-tree:将形成K维树(轴平行超平面)<br/> ball-tree:将空间划分为同心球体<br/>蛮力:将计算所有距离</li><li id="793a" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq mr kx ky kz bi translated"><strong class="jv hj">leaf _ size:</strong>KD树或ball树叶子中的点数</li><li id="992a" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq mr kx ky kz bi translated"><strong class="jv hj"> p: </strong>闵可夫斯基度规的功率参数</li><li id="565a" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq mr kx ky kz bi translated"><strong class="jv hj">度量:</strong>算法的距离度量</li><li id="326d" class="kr ks hi jv b jw la ka lb ke lc ki ld km le kq mr kx ky kz bi translated"><strong class="jv hj"> metric_params: </strong>附加度量参数；像马氏距离的协方差矩阵</li></ul><p id="ca59" class="pw-post-body-paragraph jt ju hi jv b jw ln jy jz ka lo kc kd ke mm kg kh ki mo kk kl km mq ko kp kq hb bi translated">* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *<em class="mk">示例代码:</em></p><p id="5873" class="pw-post-body-paragraph jt ju hi jv b jw ln jy jz ka lo kc kd ke mm kg kh ki mo kk kl km mq ko kp kq hb bi translated">从sklearn.neighbors导入KNeighborsRegressor作为K {或KNeighborsClassifier}</p><p id="32a6" class="pw-post-body-paragraph jt ju hi jv b jw ln jy jz ka lo kc kd ke mm kg kh ki mo kk kl km mq ko kp kq hb bi translated">knn =K(n_neighbors=5)</p><p id="ac35" class="pw-post-body-paragraph jt ju hi jv b jw ln jy jz ka lo kc kd ke mm kg kh ki mo kk kl km mq ko kp kq hb bi translated">KNN . fit(X _火车，y _火车)</p><p id="d4e3" class="pw-post-body-paragraph jt ju hi jv b jw ln jy jz ka lo kc kd ke mm kg kh ki mo kk kl km mq ko kp kq hb bi translated">y_hat = knn.predict(X_test)</p><p id="d7a7" class="pw-post-body-paragraph jt ju hi jv b jw ln jy jz ka lo kc kd ke mm kg kh ki mo kk kl km mq ko kp kq hb bi">******************************************************************</p><h1 id="914f" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">参考</h1><div class="ms mt ez fb mu mv"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier" rel="noopener  ugc nofollow" target="_blank"><div class="mw ab dw"><div class="mx ab my cl cj mz"><h2 class="bd hj fi z dy na ea eb nb ed ef hh bi translated">sk learn . neighbors . kneighborsclassifier-scikit-learn 0 . 24 . 2文档</h2><div class="nc l"><h3 class="bd b fi z dy na ea eb nb ed ef dx translated">实现k-最近邻投票的分类器。了解更多信息。参数n_neighborsint，默认值=5…</h3></div><div class="nd l"><p class="bd b fp z dy na ea eb nb ed ef dx translated">scikit-learn.org</p></div></div><div class="ne l"><div class="nf l ng nh ni ne nj io mv"/></div></div></a></div></div></div>    
</body>
</html>