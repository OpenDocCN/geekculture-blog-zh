<html>
<head>
<title>TableNet Implementation Using Resnet encoder for extraction of information from document images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Resnet编码器从文档图像中提取信息的TableNet实现</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/tablenet-implementation-using-resnet-encoder-for-extraction-of-information-from-document-images-3004c27bc7c7?source=collection_archive---------35-----------------------#2021-07-04">https://medium.com/geekculture/tablenet-implementation-using-resnet-encoder-for-extraction-of-information-from-document-images-3004c27bc7c7?source=collection_archive---------35-----------------------#2021-07-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="b47b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="82f8" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在过去的十年中，深度神经网络在模式识别问题上取得了巨大的成功，如计算机视觉、自然语言处理等。计算机视觉是计算机从数字图像和视频中获取高级信息的领域。计算机视觉已经应用于多个行业，从自动驾驶汽车的开发到取消细胞的检测。大多数计算机视觉应用的一个共同主题是图像分割。</p><p id="bca6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">图像分割是基于它们各自的类别将数字图像分割成多个片段的过程。在这篇文章中，我将解释一篇名为<a class="ae kg" href="https://arxiv.org/abs/2001.01469" rel="noopener ugc nofollow" target="_blank"> <strong class="jf hj"> TableNet </strong> </a>的研究论文，它使用图像分割深度学习模型从扫描图像中检测表格及其结构。虽然在表检测方面已经取得了一些进展，但是提取表内容仍然是一个挑战，因为这涉及到更细粒度的表结构识别。用Resnet模型代替VGG19，实现了对原模型的改进。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kh"><img src="../Images/c107ab2680c54c906cdd943cd44708fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1pmzcCdqiys4rIHNMJcNHA.png"/></div></div></figure><h1 id="c777" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">TableNet架构</h1><p id="6785" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">该模型基于FCN(全卷积网络)模型。它没有任何致密层。它由卷积层、池层和上采样层组成。该模型使用VGG 19层作为基础层。VGG-19的全连接层(池5之后的层)被替换为两个(1x1)卷积层。每个卷积层(conv6)都使用ReLU激活，后跟一个概率为0.8的漏失层(conv6+漏失，如图所示)。我已经用Resnet121层代替了VGG19。在我的实验中，Resnet层给出了更好的结果。</p><p id="1ebe" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">使用了“conv2_block6_concat”、“conv4_block9_0_relu”、“conv5_block1_0_relu”层。在这一层之后，附加了解码器网络的两个不同分支。(conv5_block1_0_relu + dropout)层的输出分配给两个解码器分支。在每个分支中，附加层被附加以过滤出相应的活动区域。在解码器网络的表分支中，在使用一系列分数步长卷积层来放大图像之前，使用一个额外的(1x1)卷积层，即conv7表。conv7表层的输出也使用分数步长卷积进行放大，并附加了相同维度的pool4池层。</p><p id="e223" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">类似地，组合的特征地图再次被放大，并且pool3池被附加到其上。最后，最终的特征图被放大以满足原始图像的尺寸。在用于检测列的另一个分支中，存在具有ReLU激活函数的附加卷积层(conv7列)和具有相同丢失概率的丢失层。在(1x1)卷积(conv8列)层之后，使用分数步长卷积对特征图进行上采样。向上采样的要素地图与pool4池层组合，并且组合的要素地图向上采样并与相同维度的pool3池层组合。在这一层之后，特征地图被放大到原始图像。在两个分支中，在转置层之前使用多个(1x1)卷积层。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kt"><img src="../Images/cd2be031dfe5400fcb928f56f0c69ead.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2gIjSUI3Qe9LcndCh_CHbg.png"/></div></div></figure><p id="a793" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">一个解码器分支用于进行<strong class="jf hj"> </strong>表格区域<strong class="jf hj"> </strong>的分割，另一个分支负责列区域的分割。检测到表格和列区域后，使用Tesseract OCR <strong class="jf hj">提取表格数据。</strong></p><h1 id="29ff" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">数据集</strong></h1><p id="93d8" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">该模型在Marmot数据集上进行训练。Marmot数据集由扫描的文档图像和指定表格位置的相应xml组成。表格列的注释由研究论文的作者完成，可通过以下链接获得。</p><div class="ku kv ez fb kw kx"><a href="https://drive.google.com/drive/folders/1QZiv5RKe3xlOBdTzuTVuYRxixemVIODp" rel="noopener  ugc nofollow" target="_blank"><div class="ky ab dw"><div class="kz ab la cl cj lb"><h2 class="bd hj fi z dy lc ea eb ld ed ef hh bi translated">数据集- Google Drive</h2><div class="le l"><h3 class="bd b fi z dy lc ea eb ld ed ef dx translated">标注的旱獭数据集</h3></div><div class="lf l"><p class="bd b fp z dy lc ea eb ld ed ef dx translated">drive.google.com</p></div></div><div class="lg l"><div class="lh l li lj lk lg ll kr kx"/></div></div></a></div><h1 id="5c44" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">问题陈述</h1><ul class=""><li id="9623" class="lm ln hi jf b jg jh jk jl jo lo js lp jw lq ka lr ls lt lu bi translated">给定扫描的文档图像，需要对表格及其列进行分割。</li><li id="5ca7" class="lm ln hi jf b jg lv jk lw jo lx js ly jw lz ka lr ls lt lu bi translated">一旦确定了区域，就必须从表中提取信息</li></ul><h1 id="1328" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">机器学习问题</h1><p id="c9c0" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于给定的文档图像，我们必须通过将每个像素分类为表格或不分类来进行语义分割。这是一个深度学习的语义切分问题。</p><p id="1878" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">绩效指标</strong></p><p id="06e0" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">由于这是一个分类问题，f1分数将用于衡量模型的效率。</p><h1 id="00a2" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">数据准备</h1><p id="847f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">数据集由bmp格式的图像和xml文件组成。我们必须首先使用xml文件中给出的信息为所有图像创建一个表和列掩码。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es ma"><img src="../Images/baf230598b73949ee6b0f70960923845.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_nt0g9mIKLDO8sgiI7QVYQ.jpeg"/></div></div><figcaption class="mb mc et er es md me bd b be z dx">Scanned image of document</figcaption></figure><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="mf mg l"/></div><figcaption class="mb mc et er es md me bd b be z dx">Sample xml file</figcaption></figure><p id="d837" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">每个xml文件由<bndbox>标签组成，这些标签指定了表格及其相应列的坐标。这些坐标将用于根据图像创建蒙版。下面给出了创建掩码的代码。</bndbox></p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="mf mg l"/></div></figure><p id="dc1b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">图像遮罩基本上是原始图像的一部分，其中只有yable及其列是白色的，而图像的其余部分是黑色的。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es ma"><img src="../Images/93da1756e32599739577020af9691bde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RkEppAdqMBsqO_wva2E_ZQ.jpeg"/></div></div><figcaption class="mb mc et er es md me bd b be z dx">Column mask</figcaption></figure><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es ma"><img src="../Images/5e86859e9763196b81cbb1f09cb4884a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BmAB3ghg8XWNF5wRQfIkwA.jpeg"/></div></div><figcaption class="mb mc et er es md me bd b be z dx">Table mask</figcaption></figure><p id="7dfa" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">接下来，对原始图像和两个掩模进行图像归一化。为了训练，图像和蒙版被分组以提供给模型。</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="mf mg l"/></div></figure><h1 id="9b2a" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">模型准备</h1><p id="216a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">数据准备完成后，按照体系结构部分的指定为tablenet创建模型。它由以下两部分组成。</p><ol class=""><li id="d535" class="lm ln hi jf b jg kb jk kc jo mh js mi jw mj ka mk ls lt lu bi translated">编码器部分</li><li id="dddc" class="lm ln hi jf b jg lv jk lw jo lx js ly jw lz ka mk ls lt lu bi translated">解码器部分</li></ol><p id="551e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">编码器部分:</strong></p><p id="aa62" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这里，Resnet模型与图像净重一起使用。图像尺寸调整为1024、1024、3维。三层Resnet被传递到解码器部分。编码器部分对图像进行降采样。</p><p id="936f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">解码器部分:</strong></p><p id="afaa" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在这个模型中有两个解码器。一个解码器用于检测表格位置，另一个解码器用于检测表格的列。经过两个conv2D层后的缩减采样图像，再次经过一个1x1 conv2D层处理。然后借助跳池技术，将解码器网络的低分辨率特征映射与编码器网络的高分辨率特征相结合。在向上采样之后，我们将得到形状(1024*1024*2)的输出表掩码。</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="mf mg l"/></div></figure><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es ml"><img src="../Images/ba18c938ffc264fc3e1fd5c98ffa3d63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tka_unG5F5ioDZ1FxJpsOw.jpeg"/></div></div><figcaption class="mb mc et er es md me bd b be z dx">Model loss</figcaption></figure><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es mm"><img src="../Images/6e90536eaff32c2bd6f6c4343eadeed6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*ZGT2mcg53S5SIvah2x6PLw.jpeg"/></div><figcaption class="mb mc et er es md me bd b be z dx">Model f1 score</figcaption></figure><h1 id="9d73" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">信息提取</h1><p id="ba40" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">一旦训练完成，就对原始图像进行预测。为了提取信息，在原始图像上施加表格掩模。这样做是为了根据预测来确定表的位置。在这一步之后，使用Tesseract ocr提取信息并保存到csv文件中。</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="mf mg l"/></div></figure><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es mn"><img src="../Images/730f82bf820e166bbfd694b1eb2b0654.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NehVKrmyim5AoRn2p-9owg.jpeg"/></div></div></figure><h1 id="dab6" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">进一步改进:</h1><p id="2a5b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们需要更多的数据来提高模型的性能。对高分辨率图像的训练也需要更好的计算能力。</p><h1 id="77c8" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">参考资料:</h1><p id="6df3" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">https://www.appliedaicourse.com<a class="ae kg" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank"/></p><div class="ku kv ez fb kw kx"><a href="https://arxiv.org/abs/2001.01469" rel="noopener  ugc nofollow" target="_blank"><div class="ky ab dw"><div class="kz ab la cl cj lb"><h2 class="bd hj fi z dy lc ea eb ld ed ef hh bi translated">TableNet:深度学习模型，用于端到端的表格检测和表格数据提取…</h2><div class="le l"><h3 class="bd b fi z dy lc ea eb ld ed ef dx translated">随着移动电话和扫描仪广泛用于拍摄和上传文档，提取文档的需求日益增加</h3></div><div class="lf l"><p class="bd b fp z dy lc ea eb ld ed ef dx translated">arxiv.org</p></div></div><div class="lg l"><div class="mo l li lj lk lg ll kr kx"/></div></div></a></div><p id="ebae" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><em class="mp">可以在</em><a class="ae kg" href="https://www.linkedin.com/in/durga-shankar-singh/" rel="noopener ugc nofollow" target="_blank"><strong class="jf hj"><em class="mp">Linkedin</em></strong></a><strong class="jf hj"><em class="mp">&amp;</em></strong><a class="ae kg" href="https://github.com/Rony75617/TABLENET_RESNET_IMPLEMENTATION/tree/master" rel="noopener ugc nofollow" target="_blank"><strong class="jf hj"><em class="mp">GITHUB</em></strong></a><strong class="jf hj"><em class="mp">上与我联系。</em>T25】</strong></p></div></div>    
</body>
</html>