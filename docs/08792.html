<html>
<head>
<title>Data Leakage in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的数据泄漏</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/data-leakage-in-machine-learning-30437a0a0a95?source=collection_archive---------16-----------------------#2021-11-14">https://medium.com/geekculture/data-leakage-in-machine-learning-30437a0a0a95?source=collection_archive---------16-----------------------#2021-11-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/66e6aa9c4095e6b8acee871cc1e1be6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9mOORxAoUeL6SpRnbh2YNQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Photo by <a class="ae iu" href="https://www.pexels.com/@jibarofoto?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">Luis Quintero</a> from <a class="ae iu" href="https://www.pexels.com/photo/photo-of-gray-faucet-2339722/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">Pexels</a></figcaption></figure><p id="47f8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在你的脑海中，想象这样一幅画面:你正在准备一场考试，这场考试将决定一个人有多聪明。<br/>在准备试用考试和真正的考试时，您将会用到一组问题。<br/>不幸或幸运的是，你的备考问题与预考问题结合在一起。你可以参加试用考试，并获得99分。你继续参加真正的考试，得了45%的分数。</p><figure class="jt ju jv jw fd ij"><div class="bz dy l di"><div class="jx jy l"/></div></figure><p id="8f22" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里发生了什么？<br/>从预试来看，每个人都可能认为你很聪明，这可能是真的，但实际情况是，你<strong class="ix hj">对你准备的问题有所了解</strong>，这就是为什么你得了99%的分数，但当面对你从未见过的问题时，你悲惨地失败了。在整篇文章中，这是一个你应该记住的场景。这是机器学习中单向数据泄漏的一个经典例子。</p><p id="32e9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你是否曾经训练过一个<a class="ae iu" href="https://en.wikipedia.org/wiki/Machine_learning" rel="noopener ugc nofollow" target="_blank">机器学习模型</a>，达到了很好的<a class="ae iu" href="https://www.datarobot.com/wiki/accuracy/" rel="noopener ugc nofollow" target="_blank">精度</a>而不幸的是这个模型在生产中表现很差？(真实数据)<br/>许多因素都可能导致这种情况，其中最有可能的是<strong class="ix hj">数据泄漏</strong>，这也是本文的重点。<br/>数据泄露是数据科学家和机器学习工程师，初学者和专家都会犯的最大错误之一。</p></div><div class="ab cl jz ka gp kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="hb hc hd he hf"><h2 id="1c5f" class="kg kh hi bd ki kj kk kl km kn ko kp kq jg kr ks kt jk ku kv kw jo kx ky kz la bi translated"><strong class="ak">什么是数据泄露？</strong></h2><p id="e8ad" class="pw-post-body-paragraph iv iw hi ix b iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo lf jq jr js hb bi translated">在训练机器学习模型时，我们有一个训练集和一个测试集。<br/>机器学习的最终目标是产生一个模型，根据看不见的数据进行准确预测。<br/>数据泄露是指训练集对目标或测试集有想法或一些信息的情况。基本上，训练测试之外的数据参与模型开发。<br/>这导致一个具有95%精确度的度量模型，但是在真实世界数据上表现不佳。还记得上面的考试场景吗？<br/>现在让我们申请吧。就像你知道了考试的题目一样，你通过了考试，因此被认为是聪明的。<br/>机器学习模型也一样。它的准确度很高，因此被认为是一个性能良好的模型。就像你在最初的考试中失败一样，机器学习模型在生产中也失败了，因为它的准确性只源于它对应该测试的数据有所了解。它现在失败了，因为它不是一个好的模型，从一开始，现实世界的数据只是暴露了这个模型有多糟糕。</p><h2 id="66ce" class="kg kh hi bd ki kj kk kl km kn ko kp kq jg kr ks kt jk ku kv kw jo kx ky kz la bi translated"><strong class="ak">数据泄露的类型和实例</strong></h2><p id="2d7b" class="pw-post-body-paragraph iv iw hi ix b iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo lf jq jr js hb bi translated">数据泄露以多种方式出现，然而，数据泄露有两种主要方式:</p><h1 id="2dea" class="lg kh hi bd ki lh li lj km lk ll lm kq ln lo lp kt lq lr ls kw lt lu lv kz lw bi translated"><strong class="ak">目标泄漏</strong></h1><p id="4701" class="pw-post-body-paragraph iv iw hi ix b iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo lf jq jr js hb bi translated">在机器学习中，我们有目标变量。目标变量是您试图预测的标签。<br/>当您在包含预测时不可用的要素的数据集上训练模型时，会出现目标泄漏。<br/>由于您的模型已经知道实际结果，因此对于训练数据来说，结果会不切实际地准确。</p><p id="4da8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">让我们来看一个例子:<br/> </strong>使用Kaggle的乳腺癌数据集，假设您想要预测谁被诊断患有乳腺癌。<br/>我将添加一个名为<strong class="ix hj"> had_surgery </strong>的新列，它与<strong class="ix hj"> diagnosis </strong>具有相同的值，以表明一旦您进行了手术，就意味着您被诊断患有乳腺癌。</p><figure class="jt ju jv jw fd ij"><div class="bz dy l di"><div class="jx jy l"/></div></figure><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/f5b940d64b8812ae4af81f3792bfe725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sQS9aWISlu94JqIwRlKPKw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">The output of the code above</figcaption></figure><p id="c9df" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果我们用上面的数据集开发一个机器学习模型，将包括<strong class="ix hj"> had_surgery </strong>在内的所有相关列作为特征，将诊断作为我们预测的标签，该模型将会看到<strong class="ix hj"> had_surgery </strong>的值为0的任何人都没有患乳腺癌。由于测试数据与训练数据来自同一个来源，所以模式会在测试中重复，模型会有很大的验证甚至交叉验证分数。<br/>但该模型在随后部署到现实世界中时将非常不准确，因为当我们需要对他们的诊断进行预测时，即使是将被诊断为乳腺癌的患者也不会进行手术。<br/> <strong class="ix hj">避免目标泄露的方法包括</strong>:</p><ol class=""><li id="8e0d" class="ly lz hi ix b iy iz jc jd jg ma jk mb jo mc js md me mf mg bi translated">从训练集中消除预测后可用的任何特征。在这种情况下，<strong class="ix hj"> had_surgery </strong>应该从训练集中删除。</li><li id="395a" class="ly lz hi ix b iy mh jc mi jg mj jk mk jo ml js md me mf mg bi translated">这是显而易见的，但请确保您没有将目标变量包含在用于预测的特征中。</li></ol><h1 id="127c" class="lg kh hi bd ki lh li lj km lk ll lm kq ln lo lp kt lq lr ls kw lt lu lv kz lw bi translated">列车测试泄漏</h1><p id="b09d" class="pw-post-body-paragraph iv iw hi ix b iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo lf jq jr js hb bi translated">这种类型的数据泄漏与我上面强调的考试场景相同。还记得通过试用考试是因为你在准备过程中接触到了问题吗？同样的情况也会发生。在这里，如果我们不小心区分训练数据和测试数据，就会导致模型在测试期间表现很好，而在生产期间失败。<br/> <strong class="ix hj">避免列车试验污染的方法包括:</strong></p><ol class=""><li id="a6eb" class="ly lz hi ix b iy iz jc jd jg ma jk mb jo mc js md me mf mg bi translated">如前所述，在训练机器学习模型时，我们将数据集分为训练集和测试集。尽管并非所有的机器学习模型都需要这样做，但建议考虑通过在训练集和测试集之外添加验证集来将数据集分成三组。为什么？验证集允许我们微调模型的参数。验证集所做的是模拟真实场景，其中模型将在新数据上进行测试。当我们这样做时，我们可以识别任何可能的过度拟合的情况，并且将帮助我们避免训练测试泄漏和部署将在生产中失败的模型的情况。</li><li id="39e0" class="ly lz hi ix b iy mh jc mi jg mj jk mk jo ml js md me mf mg bi translated">将数据分成训练、测试和验证集后，建议将数据准备技术和<a class="ae iu" href="https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15" rel="noopener" target="_blank">探索性数据分析(EDA) </a>仅应用于<strong class="ix hj">训练测试</strong>。在EDA过程中，对数据进行初步调查，以在汇总统计和图形表示的帮助下发现模式、发现异常、测试假设和检查假设。如果我们将预处理技术应用于整个数据集，EDA在测试和验证集上产生的额外特征代表了数据泄漏的实例。该模型将已经看到测试和验证数据可能会在准确性等指标上得分很高。</li></ol></div><div class="ab cl jz ka gp kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="hb hc hd he hf"><p id="e862" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于专家和初学者来说，理解像数据泄漏这样的概念是非常重要的，因为它们发生在数据科学的真实世界中。我希望在读完这篇文章后，你将能够发现你的机器学习模型中何时存在漏洞，以及如何避免它。<br/>如果读完这篇文章后，数据泄露听起来仍然很抽象，并且你想学得更实际，试试<a class="ae iu" href="https://www.kaggle.com/afiblebo/exercise-data-leakage/edit" rel="noopener ugc nofollow" target="_blank"> Kaggle的数据泄露练习</a>。请随意在评论中加入更多信息，尤其是关于数据泄露的书籍。<br/>在我的下一篇文章中，我将讨论数据清理，我们将看一个包含杂乱数据和源代码的真实例子。</p><p id="ef3b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你好，我是奎亚基！<br/>我的目标是撰写文章，以一种对绝对初学者来说清晰的方式解释Python、数据科学和机器学习的概念。<br/>在<a class="ae iu" href="https://www.linkedin.com/in/kweyakieblebo/" rel="noopener ugc nofollow" target="_blank"><em class="mm">LinkedIn</em></a><em class="mm">和</em><a class="ae iu" href="https://twitter.com/dede_codes" rel="noopener ugc nofollow" target="_blank"><em class="mm">Twitter</em></a><em class="mm">上跟我连线。</em></p><figure class="jt ju jv jw fd ij"><div class="bz dy l di"><div class="mn jy l"/></div></figure><p id="88c1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">推荐资源</strong></p><p id="0e49" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/" rel="noopener ugc nofollow" target="_blank">机器学习的特征工程。<br/> </a> <a class="ae iu" href="https://machinelearningmastery.com/data-leakage-machine-learning/" rel="noopener ugc nofollow" target="_blank">机器学习中的数据泄露。<br/> </a> <a class="ae iu" href="https://machinelearningmastery.com/data-preparation-without-data-leakage/" rel="noopener ugc nofollow" target="_blank">如何在进行数据预处理时避免数据泄露。</a></p></div></div>    
</body>
</html>