<html>
<head>
<title>What text clustering can tell us about text classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于文本分类，文本聚类能告诉我们什么</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/what-text-clustering-can-tell-us-about-text-classification-248ce1d5d1e3?source=collection_archive---------13-----------------------#2021-09-22">https://medium.com/geekculture/what-text-clustering-can-tell-us-about-text-classification-248ce1d5d1e3?source=collection_archive---------13-----------------------#2021-09-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/c679959e278452a8aacd58a41b4dd7b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EBwFocYS4hqPcbmwJ47iVw.jpeg"/></div></div></figure><p id="3486" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">之前，我使用监督学习在BBC新闻数据上训练多类<a class="ae jo" rel="noopener" href="/swlh/text-classification-using-scikit-learn-pytorch-and-tensorflow-a3350808f9f7">文本分类</a>模型，并针对测试数据实现了98%的准确率。根据训练数据的质量，当训练我们自己的文本分类数据时，我们可能会也可能不会用我们的测试数据集达到98%的准确率。我发现在分析训练数据时可能有帮助的一种方法是使用无监督学习将数据集聚类到不同的簇中(簇的数量等于类别的数量)，并比较来自不同类别的数据点如何被分配到不同的簇中。</p><p id="9c81" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我再次使用BBC新闻数据，来看看这些数据如何根据它们的类别进行分组。</p><p id="05b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我读取训练数据，并使用Scikit Learn的TfidfVectorizor将文本转换成数字表示。该步骤与之前描述的相同，因此请参考<a class="ae jo" rel="noopener" href="/swlh/text-classification-using-scikit-learn-pytorch-and-tensorflow-a3350808f9f7">文章</a>获取详细解释。</p><blockquote class="jp jq jr"><p id="5b10" class="iq ir js is b it iu iv iw ix iy iz ja jt jc jd je ju jg jh ji jv jk jl jm jn hb bi translated">源代码可从<a class="ae jo" href="https://github.com/donglinchen/text_classification/blob/master/text_clustering_and_visualization.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/陈东林/text _ classification/blob/master/text _ clustering _ and _ visualization . ipynb</a>获得</p></blockquote><h1 id="8287" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">收集数据</h1><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="925b" class="ld jx hi kz b fi le lf l lg lh">df = pd.read_csv('bbc-text.csv')<br/>print(df.shape, df['category'].nunique())<br/>df.head()</span></pre><p id="7680" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面显示了BBC新闻数据集中的5条记录:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/525b47310bd237980ac5b4ca585a8a1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7udV-zVn0ba3ij3TTqU17A.png"/></div></div></figure><p id="94d4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">检查新闻类别和每个类别的新闻文章数量</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="9001" class="ld jx hi kz b fi le lf l lg lh">df['category'].value_counts()</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lj"><img src="../Images/2a462353d5fbc8cdef239840f5463bfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZVz5u0zDUckZrVA6wZdDJg.png"/></div></div></figure><p id="69d3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在使用TfidfVectorizer将文本提取到TFIDF数字要素中:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="824b" class="ld jx hi kz b fi le lf l lg lh">vec = TfidfVectorizer()<br/>features= vec.fit_transform(df['text'])<br/>print("Input features shape:", features.shape)<br/>print(f"\nTake a look at the features extracted from the first news article:\n{features[0].toarray()}")</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/9b6845ede272af521dff6f486955d084.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CAd--3arBOa6hu85dXxlDg.png"/></div></div></figure><p id="600a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们看到TfidfVectorizer将文本中的特征提取到29421个特征维度中</p><h1 id="8cf5" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">k均值聚类</h1><p id="95f8" class="pw-post-body-paragraph iq ir hi is b it ll iv iw ix lm iz ja jb ln jd je jf lo jh ji jj lp jl jm jn hb bi translated">现在我们可以在特征向量上运行K-Means聚类算法。这里我选择5个聚类，因为我们知道文本有5个类别。</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="bf07" class="ld jx hi kz b fi le lf l lg lh">from sklearn.cluster import KMeans<br/>kmeans = KMeans(5, n_init=10, random_state=42)<br/>kmeans.fit(features)</span></pre><p id="56a9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">聚类后，向数据帧添加一个包含指定聚类标签的列，并将该列命名为“cluster”</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="c6d0" class="ld jx hi kz b fi le lf l lg lh">df[‘cluster’] = kmeans.labels_</span></pre><p id="1092" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">“聚类”列具有从0到4值，代表5个不同的聚类</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/f4ac2cbe212813ff0c35e830d3016e5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iINaS1t1_4GHYCEu9apqkQ.png"/></div></div></figure><h1 id="0384" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">根据大多数数据点被分配到的类别，将分类映射到类别</h1><p id="25dd" class="pw-post-body-paragraph iq ir hi is b it ll iv iw ix lm iz ja jb ln jd je jf lo jh ji jj lp jl jm jn hb bi translated">通过检查20个样本，我们可以看到每个聚类都可以很好地映射到一个类别，除了索引19映射到聚类4，它应该是“商业”，而不是“技术”。检查每个类别的数据是如何分类的，可以让我们找到每个类别最合适的分类编号:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="8524" class="ld jx hi kz b fi le lf l lg lh">for cat in df['category'].unique():<br/>    mark = df['category'] == cat<br/>    print(f"{cat}\n{df[mark]['cluster'].value_counts()}\n")</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/b906663f1ed8de34b3ebfb3bbff1ad07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CB_UKWcUnZj0iv-CjNM5oQ.png"/></div></div></figure><p id="fae0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上面所有属于“技术”类别的新闻文章中，有327篇被分配到第一组，只有19篇和12篇被分配到第三组和第四组，所以我们可以很确定第一组是属于“技术”类别的。同样，我们知道群集群集4是用于“业务”的。聚类3用于“体育”，然而对于体育，有135个样本被分配给聚类3，其应该对应于“娱乐”。我们可以创建一个字典来将分类映射到类别，如下所示:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="3dc8" class="ld jx hi kz b fi le lf l lg lh">{1: 'tech', 4: 'business', 0: 'sport', 3: 'entertainment', 2: 'politics'}</span></pre><p id="fcf0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用上面的映射，我可以创建一个clustered_category列，如下所示:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="4fda" class="ld jx hi kz b fi le lf l lg lh">df['clustered_category'] = df['cluster'].map(cluster_to_category)<br/>df.head(20)</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/51343e8b50fdc45e368c3d9ba30cb9cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f3pnGGjabG7mxfYuwT9F0Q.png"/></div></div></figure><p id="2e8c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我可以计算出新闻数据可以正确归类的程度:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="6329" class="ld jx hi kz b fi le lf l lg lh">print('Overall accuracy of clustered categories:', np.mean(df['category'] == df['clustered_category']))</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/6366978706d191b0dbe278cd22ea1ba5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FUyqQorVgLYF49Rncuterg.png"/></div></div></figure><p id="c616" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，如果仅使用K-Means聚类将新闻数据分组到类别组中，已经可以达到87%的正确率将新闻文章分配到相关类别中。</p><h1 id="c41c" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">将主成分分析应用于数据可视化</h1><p id="0ead" class="pw-post-body-paragraph iq ir hi is b it ll iv iw ix lm iz ja jb ln jd je jf lo jh ji jj lp jl jm jn hb bi translated">在应用PCA(主成分分析)将特征从29421维空间减少到仅2维空间，同时尽可能多地保留数据的变化之后，我们可以将数据如何分组到二维空间中进行可视化。我将制作两个图表，分别基于类别和集群来可视化数据:</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="8de8" class="ld jx hi kz b fi le lf l lg lh">from sklearn.decomposition import PCA<br/>pca = PCA(n_components=2)<br/>x_pca = pca.fit_transform(encoded_x.toarray())</span></pre><p id="7e41" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上面的代码将生成一个形状为(2225，2)的2D数组，代表2225篇新闻文章，每篇文章有2个主成分。我将把2225条新闻数据投射到与2个主成分相对应的2D空间上。然后并排比较两个用类别v.s .聚类着色的图</p><pre class="ku kv kw kx fd ky kz la lb aw lc bi"><span id="e4ad" class="ld jx hi kz b fi le lf l lg lh">fig, axes = plt.subplots(1, 2, sharey=True)<br/>fig.set_size_inches(20, 10)<br/>categories = df['category'].unique()<br/>colors = ['green','orange', 'blue', 'purple', 'red']<br/>for i, e in enumerate(categories):<br/>    mark = df['category'] == e<br/>    axes[0].scatter(x_pca[:, 0][mark], x_pca[:, 1][mark], color=colors[i], label=e, alpha=0.9)<br/>axes[0].legend();</span><span id="9dd6" class="ld jx hi kz b fi lu lf l lg lh"># use the same set of colors as above to compare side to side of the two graphs<br/>colors = ['blue', 'green', 'red', 'purple', 'orange']<br/>for e in set(kmeans.labels_):<br/>    mark = kmeans.labels_ == e<br/>    axes[1].scatter(x_pca[:, 0][mark], x_pca[:, 1][mark], color=colors[e], label=e, alpha=0.9)<br/>axes[1].legend()</span></pre><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/979674aad4441e25d68f25e06c3872ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MbPGTNjLRQ1iheZd-rqkyg.png"/></div></div></figure><p id="418e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如我所看到的，这两个图表是相似的，数据点按彩色类别v.s .集群分组。黄点(商业)和绿点(科技)彼此有一些重叠，这意味着它们可能具有相似的单词标记，而红点(政治)可以更容易地与其他类别/聚类区分开来。我们还可以看到，在右图中，许多紫色点属于左图中的蓝色(体育)类别，这表明许多体育新闻文章被聚集到紫色(娱乐)簇中，从上面的数据可以明显看出，358篇新闻文章被聚集到簇号0，135篇新闻文章被聚集到簇号3。总的来说，对于每个类别，大多数新闻文章都可以正确地归类到相应的类别中。</p><h1 id="03aa" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">摘要</h1><p id="f6c9" class="pw-post-body-paragraph iq ir hi is b it ll iv iw ix lm iz ja jb ln jd je jf lo jh ji jj lp jl jm jn hb bi translated">对新闻文章数据集应用K-Means聚类导致每篇新闻文章以87%的准确度被分配到相对类别。这意味着数据集非常干净，质量很好。使用干净和高质量的数据集训练模型通常可以实现高模型预测精度，正如我们看到的，当<a class="ae jo" rel="noopener" href="/swlh/text-classification-using-scikit-learn-pytorch-and-tensorflow-a3350808f9f7">训练BBC新闻分类模型</a>时，我们实现了超过98%的模型测试精度。</p><p id="5462" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">另一方面，我多次看到，我们的训练数据不太理想，数据不容易聚类和映射到相应的类别，属于相同类别的数据可能会非常均匀地分布到多个聚类中。用这些数据集训练分类模型可能导致相对较低准确度，如70%或80%，且可能难以达到90%以上的高准确度。</p></div></div>    
</body>
</html>