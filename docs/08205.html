<html>
<head>
<title>Self-Driving Car with YOLOv5 and Roboflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">拥有YOLOv5和Roboflow的自动驾驶汽车</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/self-driving-car-with-yolov5-and-roboflow-a5a2bf109c6?source=collection_archive---------1-----------------------#2021-10-19">https://medium.com/geekculture/self-driving-car-with-yolov5-and-roboflow-a5a2bf109c6?source=collection_archive---------1-----------------------#2021-10-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="e7f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你是否对自动驾驶汽车及其背后的算法感兴趣？这篇文章让你使用由<a class="ae jd" href="https://roboflow.com/" rel="noopener ugc nofollow" target="_blank"> Roboflow </a>提供的<a class="ae jd" href="https://public.roboflow.com/object-detection/self-driving-car" rel="noopener ugc nofollow" target="_blank"> Udacity自动驾驶汽车数据集</a>进行更深入的研究。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/6b297e13d18c95f090968267a155bdf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*v5FcfuAUS0QwK3r2"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">Photo by <a class="ae jd" href="https://unsplash.com/@rpnickson?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Roberto Nickson</a> on <a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="90af" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">YOLOv5</h1><div class="jf jg jh ji fd ab cb"><figure class="ks jj kt ku kv kw kx paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><img src="../Images/0a335451b94fc64d697deab736f66ea3.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*OhZ2b9GttQyixpqXyPBHsw.jpeg"/></div></figure><figure class="ks jj ky ku kv kw kx paragraph-image"><img src="../Images/1b572e56763c4052935f62c2acfb1b6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/0*kM_6bu1pla7UqfxK.gif"/><figcaption class="jq jr et er es js jt bd b be z dx kz di la lb"><em class="lc">YOLOv5 inferencing live on video with COCO weights</em></figcaption></figure></div><p id="965c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">YOLO</strong>—<strong class="ih hj">Y</strong>ou<strong class="ih hj">O</strong>only<strong class="ih hj">L</strong>ook<strong class="ih hj">O</strong>nce是在COCO数据集上预先训练的一系列对象检测架构和模型。YOLOv5🚀代表<a class="ae jd" href="https://ultralytics.com/" rel="noopener ugc nofollow" target="_blank"> Ultralytics </a>对未来视觉AI方法的开源研究。</p><p id="fafd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">YOLOv5快如闪电。根据<a class="ae jd" href="https://blog.roboflow.com/yolov5-v6-0-is-here/#:~:text=Performance%20and%20speed%20benchmarks%20for,size%2032%20%2D%20Tesla%20v100)." rel="noopener ugc nofollow" target="_blank">报告</a>，它在COCO上提供了最新速度基准1666 FPS的最先进的对象检测。YOLOv5也是惊人的准确。所有这些，加上YOLOv5的尺寸小得多，使得YOLOv5成为自动驾驶汽车的最佳架构之一，如果不是最好的话。</p><div class="jf jg jh ji fd ab cb"><figure class="ks jj ld ku kv kw kx paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><img src="../Images/a157e517792fd488a0d41aae70fa87f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/0*bT6WgMq30QLBtFIG.png"/></div></figure><figure class="ks jj le ku kv kw kx paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><img src="../Images/bb0ef6d18abb862e14cbb43650c7f985.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/0*bM4bPLSebutmbxxG.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx lf di lg lb">Image via <a class="ae jd" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank">https://github.com/ultralytics/yolov5</a></figcaption></figure></div><p id="a243" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">YOLO把一幅图像分成一个网格系统，每个网格检测自己内部的物体。这使得它们能够在有限的计算资源下非常快速地执行。</p><p id="16c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了理解Yolov5如何改进性能及其架构，让我们来看一下下面的高级对象检测架构:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lh"><img src="../Images/e40a154a0b89b6f15e28d6b02c2b78f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tYTg-fA3n41Yuj72.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es li"><img src="../Images/b81015a2cbc5d6443b3118c65ca0cd12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*f9o2SGOE7T_QX8uG.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">Yolov5s model</figcaption></figure><h1 id="2599" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">步伐</h1><p id="f752" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">我们将通过在<a class="ae jd" href="https://public.roboflow.com/object-detection/self-driving-car" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Udacity自动驾驶汽车数据集</strong> </a> <strong class="ih hj">上训练YOLOv5所需的步骤。</strong></p><blockquote class="lo lp lq"><p id="efd3" class="if ig lr ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">你可以参考这款<a class="ae jd" href="https://colab.research.google.com/drive/1I3vLiAPh_08BdEo0JoNyzVIqVKmxn3fJ?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Google Colab笔记本</a>跟着做。</p></blockquote><p id="b7b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了训练我们的检测器，我们采取以下步骤:</p><ul class=""><li id="bae9" class="lv lw hi ih b ii ij im in iq lx iu ly iy lz jc ma mb mc md bi translated">准备数据集</li><li id="16a0" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated">安装YOLOv5依赖项</li><li id="8ed0" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated">从Roboflow下载自动驾驶汽车物体检测数据集</li><li id="6097" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated">为培训建立YAML档案</li><li id="400b" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated">训练模型</li><li id="6041" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated">评估绩效</li><li id="aabb" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated">可视化训练数据</li><li id="0097" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated">在测试图像上运行推理</li></ul><h1 id="987c" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">准备数据集</h1><p id="ab87" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">我们将使用<a class="ae jd" href="https://public.roboflow.com/object-detection/self-driving-car" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Udacity自动驾驶汽车数据集</strong> </a>，，该数据集在<a class="ae jd" href="https://public.roboflow.com/object-detection" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Roboflow公共物体检测数据集</strong> </a>中可用。</p><p id="408b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该数据集包含11个类别的97，942个标签和15，000幅图像。有1720个空示例(道路上没有物体的图像)。这11个类别包括汽车、卡车、行人、信号和骑自行车的人。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mj"><img src="../Images/26b5e8c5cd6a94a75416695c8c40ae5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8BpQAH7ILTrza2F-WHE-yQ.png"/></div></div></figure><p id="2739" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您还可以使用Roboflow的便捷<a class="ae jd" href="https://docs.roboflow.com/annotate" rel="noopener ugc nofollow" target="_blank">注释工具</a>在图像上添加注释。Roboflow还允许您简化数据预处理和增强步骤，并根据您的选择执行训练测试分割！</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mk"><img src="../Images/f79b2f5eacb54446c26da60c77d5b628.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*jdsELhGzzZdPkNBgreWuGQ.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx">These are the settings I have applied to my dataset.</figcaption></figure><h1 id="b0f2" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak">安装YOLOv5依赖项</strong></h1><p id="0b31" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">我们首先克隆YOLOv5存储库并安装依赖项。这将设置我们的编程环境，为运行对象检测训练和推理命令做好准备。</p><p id="3e8b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Google Colab附带了一个预装的GPU加速器，允许我们加速我们的训练。请确保在开始和导入所需的依赖项之前调整这些设置。</p><h1 id="4222" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">从Roboflow下载数据集</h1><p id="6ea8" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">使用Roboflow，您可以下载数据集，创建免费帐户，并将数据集作为项目上传到您的工作空间中。注释之后，应用所需的预处理和扩充步骤，下载YOLOv5 PyTorch格式的代码片段。我已经将所有图像的大小调整为416 x 416像素，并增加了5%的噪声，以便模型学习得更好。</p><p id="12cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">我应用的噪声使它看起来像是在下雨，使我的模型能够在这种情况下进行物体检测。</strong></p><div class="jf jg jh ji fd ab cb"><figure class="ks jj ml ku kv kw kx paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><img src="../Images/b140344813625e007fbcacf4d2d23f7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*TjqAmo29UfMMd-kn6wff1Q.png"/></div></figure><figure class="ks jj mm ku kv kw kx paragraph-image"><img src="../Images/c31aa1967a12e467e77e47060e0b9af4.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*M9m2SBaexn1KuzU1YVidJg.png"/></figure></div><h1 id="6531" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">为培训建立YAML档案</h1><p id="ae80" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">为了训练一个YOLOv5模型，我们需要两个YAML文件。</p><p id="b64e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一个YAML明确指出:</p><ul class=""><li id="d7cb" class="lv lw hi ih b ii ij im in iq lx iu ly iy lz jc ma mb mc md bi translated">对应于这些类的名称</li><li id="6b2e" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated">我们想要检测的类的数量</li><li id="4348" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated">我们的培训和验证数据在哪里</li></ul><p id="15f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的这个YAML看起来像这样:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mn"><img src="../Images/7541056b81a5832f67d42d6a79328ed2.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*OF2p7YpKFmoCHjMKGzL_eQ.png"/></div></figure><p id="51ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二个YAML是指定整个模型配置。其网络架构可以修改，正确的<em class="lr">数量_类别</em>也需要指定。</p><h1 id="572d" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">训练模型</h1><p id="0056" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">我们可以使用以下超参数来获得我们模型的最佳结果:</p><ul class=""><li id="27f9" class="lv lw hi ih b ii ij im in iq lx iu ly iy lz jc ma mb mc md bi translated"><strong class="ih hj"> img: </strong>定义输入图像尺寸</li><li id="d724" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated"><strong class="ih hj">批量:</strong>确定批量大小</li><li id="e0c4" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated"><strong class="ih hj">时期:</strong>定义训练时期的数量</li><li id="44d0" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated"><strong class="ih hj">数据:</strong>设置YAML文件的路径</li><li id="eb3f" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated"><strong class="ih hj"> cfg: </strong>指定型号配置</li><li id="55c8" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated"><strong class="ih hj">权重:</strong>指定权重的自定义路径</li><li id="4e22" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated"><strong class="ih hj">名称:</strong>结果名称</li><li id="7ce7" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated"><strong class="ih hj"> nosave: </strong>仅保存最后一个检查点</li><li id="f280" class="lv lw hi ih b ii me im mf iq mg iu mh iy mi jc ma mb mc md bi translated"><strong class="ih hj">缓存:</strong>缓存图像以加快训练速度</li></ul><h1 id="d76c" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">评估绩效</h1><p id="4460" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">完成培训后，我们现在准备评估我们模型的性能。我们可以用<a class="ae jd" href="https://www.tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">张量板</strong> </a> <strong class="ih hj">来形象化表现。</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mo"><img src="../Images/3aa8a1707e150fba925ff93048b2dd28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*T1iCg8Nrj1dJwEXsOJHx5w.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx">Training Metrics</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mp"><img src="../Images/845c0b3995115934df35ac5779044c2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jg9jFjIR-oK2fENhO-3V5A.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx">Training Losses</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mq"><img src="../Images/fb72a76aecaaa3c02a0642906d1f64f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A0nGlGq7PygZZyK1-8dchA.png"/></div></div></figure><h1 id="4fbb" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">可视化训练数据</h1><p id="d57f" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">在训练期间，YOLOv5训练管道创建了具有增强功能的批量训练数据。我们可以将训练数据真实情况以及扩充的训练数据可视化。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mr"><img src="../Images/6952464ed41e4b4c3882f10daa9604b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rMMmtHvatP3R_MkKr7p20Q.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx"><em class="lc">Our training data ground truth</em></figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mr"><img src="../Images/6957b33eac2f83152943dbf6fcfe7a97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ElkbrPZ48zKO3_p16cmDFg.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx"><em class="lc">Training data with augmentations</em></figcaption></figure><h1 id="2f99" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">在测试图像上运行推理</h1><p id="605e" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">我们现在采用经过训练的模型，并对测试图像进行推断。我们使用在训练模型进行推理时创建的权重。</p><p id="69f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们来看看我们的结果:</p><div class="jf jg jh ji fd ab cb"><figure class="ks jj ms ku kv kw kx paragraph-image"><img src="../Images/4c48c936d27841b74c34826c6c3148af.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*_Wvr8JjHk3o9PfiBKOC3cA.jpeg"/></figure><figure class="ks jj mt ku kv kw kx paragraph-image"><img src="../Images/7ebba0af5a83f6a1e1f03806f1b5f64a.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*u6yLnE3gTPaDKQP46uTIjw.jpeg"/></figure><figure class="ks jj mu ku kv kw kx paragraph-image"><img src="../Images/3736157c216daed7dff93860dd060ebe.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*KremYCTfTl4Yd8QjFoQ8Mw.jpeg"/><figcaption class="jq jr et er es js jt bd b be z dx mv di mw lb">Predictions on test images</figcaption></figure></div><h1 id="8b0f" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">结论</h1><p id="db8b" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">现在，一个充满自动驾驶汽车的世界似乎只是一个梦想。但是随着这一领域的进一步发展，我确信这将很快成为可能，而不仅仅是白日梦。</p><p id="3714" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章中的插图仅仅是物体检测的一个例子——一个基本的构建模块。真正的挑战来自对这些物体的三维感知，以及汽车如何对这些物体做出反应。周围的某些因素，如天气和低于标准的基础设施，也会影响这些汽车的性能。</p><p id="bca5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将这些课程作为课程的一部分将引起人们的兴趣，并有助于在该领域进行进一步的研究和开发。这无疑将加速这一进程，并使自动驾驶汽车很快成为现实。希望这篇文章能有助于激发你们所有人的兴趣！</p></div></div>    
</body>
</html>