<html>
<head>
<title>Web-scraping tables in Python using beautiful soup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用漂亮的汤在Python中抓取Web表</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/web-scraping-tables-in-python-using-beautiful-soup-8bbc31c5803e?source=collection_archive---------0-----------------------#2021-05-27">https://medium.com/geekculture/web-scraping-tables-in-python-using-beautiful-soup-8bbc31c5803e?source=collection_archive---------0-----------------------#2021-05-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/52f651fef90a696b824cfffbdb154744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*omTkxDMRMWuFbOBS"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Photo by <a class="ae iu" href="https://unsplash.com/@pmiazga?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Piotr Miazga</a> on <a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="b15b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们并不总是能够访问一个整洁的、有组织的数据集。<em class="jt"> csv </em>格式；有时，我们需要的数据可以在网上找到，我们必须能够收集这些数据。对我们来说幸运的是，Python有一个以包的形式出现的解决方案<em class="jt">美丽的汤。</em></p><p id="d5c8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们应该从在我们的环境中使用这个库开始。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="0703" class="kd ke hi jz b fi kf kg l kh ki">pip install beautifulsoup4</span></pre><p id="6643" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从<a class="ae iu" href="http://www.crummy.com/software/BeautifulSoup/" rel="noopener ugc nofollow" target="_blank">文件</a>中，我们了解到:</p><blockquote class="kj kk kl"><p id="1fe3" class="iv iw jt ix b iy iz ja jb jc jd je jf km jh ji jj kn jl jm jn ko jp jq jr js hb bi translated">Beautiful Soup是一个Python库，用于从HTML和XML文件中提取数据。</p></blockquote><p id="9f33" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">今天，我们将看看在HTML中被格式化为表格的数据集。在我们继续之前，我想简单提醒一下这些表的核心结构。</p><h1 id="bcd5" class="kp ke hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">HTML中的表格结构</h1><p id="c9ff" class="pw-post-body-paragraph iv iw hi ix b iy lm ja jb jc ln je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">我知道不是每个人都熟悉HTML如果没有别的，下面的图片是一个很好的提醒HTML表格的基本结构。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/04e709ea275b7c7d8503ff9c151afdfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*e8v0N9O30bERmEW6pbI3mA.png"/></div></figure><p id="f107" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">注意每个<em class="jt">表格行</em> (TR)有一个或多个<em class="jt">表格数据</em> (TD)。这意味着我们可以迭代每一行，然后提取每一列数据。</p><p id="170b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们看看我们将收集的数据。我选择了两个数据集来演示使用<em class="jt"> beautiful soup </em>库的不同方法。第一个是<a class="ae iu" href="https://pt.wikipedia.org/wiki/Lista_de_bairros_de_Manaus" rel="noopener ugc nofollow" target="_blank">玛瑙斯邻里列表</a>；第二个是<a class="ae iu" href="https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M" rel="noopener ugc nofollow" target="_blank">多伦多邻里列表</a>(其中的一部分)。</p><h1 id="76bc" class="kp ke hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">1.玛瑙斯邻居列表</h1><p id="b432" class="pw-post-body-paragraph iv iw hi ix b iy lm ja jb jc ln je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">给你一些背景，马瑙斯是巴西亚马逊州的一个城市。下图是它的一张明信片:<a class="ae iu" href="https://www.bbc.com/culture/article/20170316-the-beautiful-theatre-in-the-heart-of-the-amazon-rainforest" rel="noopener ugc nofollow" target="_blank">亚马逊剧院</a>。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/260e7003009aa77b2a3904a309328ce4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-fUxqagBthqdudRX"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Photo by <a class="ae iu" href="https://unsplash.com/@rivailjunior?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Rivail Júnior</a> on <a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="380b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面的截图显示了我们的第一个数据集的前几行。在这个<a class="ae iu" href="https://pt.wikipedia.org/wiki/Lista_de_bairros_de_Manaus" rel="noopener ugc nofollow" target="_blank">维基百科页面</a>中可以找到。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/cf5895e91f34a88e5f6fad8704c9c024.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BuZBxsJEVq_M4zfllBdhmA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">There is a total of 63 neighborhoods in Manaus.</figcaption></figure><p id="d004" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">列名使用葡萄牙语，这是巴西的母语。让我们理解每一列在英语中代表什么:</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/f9c106e058f0a38143ab8f4cf020203a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XdGYqc4b8xQOoIlAeXsKFg.png"/></div></div></figure><p id="c4f7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请注意，社区是按区域组织的(南、北、东、中南部等。).在总面积和人口密度上，有些国家比其他国家更大。</p><p id="6b76" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们开始收集数据吧！</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="36bb" class="kd ke hi jz b fi kf kg l kh ki"><em class="jt"># Importing the required libraries</em><br/><strong class="jz hj">import</strong> requests<br/><strong class="jz hj">import</strong> pandas <strong class="jz hj">as</strong> pd<br/><strong class="jz hj">from</strong> bs4 <strong class="jz hj">import</strong> BeautifulSoup</span></pre><p id="d195" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">导入必要的库之后，我们必须下载站点的实际HTML。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="9285" class="kd ke hi jz b fi kf kg l kh ki"><em class="jt"># Downloading contents of the web page</em><br/>url <strong class="jz hj">=</strong> "https://pt.wikipedia.org/wiki/Lista_de_bairros_de_Manaus"<br/>data <strong class="jz hj">=</strong> requests<strong class="jz hj">.</strong>get(url)<strong class="jz hj">.</strong>text</span></pre><p id="54ed" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后我们创建一个漂亮的组对象</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="8b31" class="kd ke hi jz b fi kf kg l kh ki"><em class="jt"># Creating BeautifulSoup object</em><br/>soup <strong class="jz hj">=</strong> BeautifulSoup(data, 'html.parser')</span></pre><p id="25a8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在有了页面的HTML，所以我们需要找到我们想要的表格。我们可以检索第一个可用的表格，但是页面可能包含多个表格，这在维基百科页面中很常见。为此，我们必须查看所有表格并找到正确的表格。但是，我们不能盲目前进。让我们看看HTML的结构。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/dbeec1679400a667617801ec3b0dfa93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K-2YVBMoF70prYaLMlrf5Q.png"/></div></div></figure><p id="3a5c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">的确，不止一张桌子。在上图中，突出显示的表是我们要收集的表。不幸的是，这些表没有标题，但是它们有class属性。我们可以使用这些信息来选择正确的表。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="fe7f" class="kd ke hi jz b fi kf kg l kh ki"><em class="jt"># Verifying tables and their classes</em><br/>print('Classes of each table:')<br/><strong class="jz hj">for</strong> table <strong class="jz hj">in</strong> soup<strong class="jz hj">.</strong>find_all('table'):<br/>    print(table<strong class="jz hj">.</strong>get('class'))</span><span id="cdcc" class="kd ke hi jz b fi lw kg l kh ki"><br/>OUTPUT:</span><span id="faac" class="kd ke hi jz b fi lw kg l kh ki">Classes of each table:<br/>['box-Desatualizado', 'plainlinks', 'metadata', 'ambox', 'ambox-content']<br/>['wikitable', 'sortable']<br/>['nowraplinks', 'collapsible', 'collapsed', 'navbox-inner']</span></pre><p id="94f6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们的代码告诉我们，我们想要第二个表(又名。class = 'wikitable '和' sortable ')。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="71b4" class="kd ke hi jz b fi kf kg l kh ki"><em class="jt"># Creating list with all tables</em><br/>tables <strong class="jz hj">=</strong> soup<strong class="jz hj">.</strong>find_all('table')<br/><br/><em class="jt">#  Looking for the table with the classes 'wikitable' and 'sortable'</em><br/>table <strong class="jz hj">=</strong> soup<strong class="jz hj">.</strong>find('table', class_<strong class="jz hj">=</strong>'wikitable sortable')</span></pre><p id="3510" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">注意，在将类作为参数传递时，我们不需要使用逗号。一旦我们有了正确的表，我们就可以提取它的数据来创建我们自己的数据框架。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="6e0c" class="kd ke hi jz b fi kf kg l kh ki"><em class="jt"># Defining of the dataframe</em><br/>df <strong class="jz hj">=</strong> pd<strong class="jz hj">.</strong>DataFrame(columns<strong class="jz hj">=</strong>['Neighborhood', 'Zone', 'Area', 'Population', 'Density', 'Homes_count'])<br/><br/><em class="jt"># Collecting Ddata</em><br/><strong class="jz hj">for</strong> row <strong class="jz hj">in</strong> table<strong class="jz hj">.</strong>tbody<strong class="jz hj">.</strong>find_all('tr'):    <br/>    <em class="jt"># Find all data for each column</em><br/>    columns <strong class="jz hj">=</strong> row<strong class="jz hj">.</strong>find_all('td')<br/>    <br/>    <strong class="jz hj">if</strong>(columns <strong class="jz hj">!=</strong> []):<br/>        neighborhood <strong class="jz hj">=</strong> columns[0]<strong class="jz hj">.</strong>text<strong class="jz hj">.</strong>strip()<br/>        zone <strong class="jz hj">=</strong> columns[1]<strong class="jz hj">.</strong>text<strong class="jz hj">.</strong>strip()<br/>        area <strong class="jz hj">=</strong> columns[2]<strong class="jz hj">.</strong>span<strong class="jz hj">.</strong>contents[0]<strong class="jz hj">.</strong>strip('&amp;0.')<br/>        population <strong class="jz hj">=</strong> columns[3]<strong class="jz hj">.</strong>span<strong class="jz hj">.</strong>contents[0]<strong class="jz hj">.</strong>strip('&amp;0.')<br/>        density <strong class="jz hj">=</strong> columns[4]<strong class="jz hj">.</strong>span<strong class="jz hj">.</strong>contents[0]<strong class="jz hj">.</strong>strip('&amp;0.')<br/>        homes_count <strong class="jz hj">=</strong> columns[5]<strong class="jz hj">.</strong>span<strong class="jz hj">.</strong>contents[0]<strong class="jz hj">.</strong>strip('&amp;0.')<br/><br/>        df <strong class="jz hj">=</strong> df<strong class="jz hj">.</strong>append({'Neighborhood': neighborhood,  'Zone': zone, 'Area': area, 'Population': population, 'Density': density, 'Homes_count': homes_count}, ignore_index<strong class="jz hj">=True</strong>)</span></pre><p id="a534" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请注意，我们首先创建了一个空的Dataframe，但是我们给了它列名。然后我们找到所有的<em class="jt">行</em>；对于每一行，我们需要所有的<em class="jt">数据。</em>一旦我们有了数据，我们就可以使用索引来引用每个可用的列。我们必须查看HTML结构，以便在提取过程中使用正确的引用。在这个例子中，一些列有HTML标签<em class="jt"> span </em>，需要额外的剥离来处理奇怪的字符。让我们看看我们的Dataframe返回了什么。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="488c" class="kd ke hi jz b fi kf kg l kh ki">df<strong class="jz hj">.</strong>head()</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/57b04524d32990f8b3bacd4ba6ef7e4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*rkuf8KEfixdwDTx2X9BfWQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">Output of the <em class="ly">head </em>call</figcaption></figure><p id="b518" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">难以置信！我们正在查看从维基百科页面提取的数据。这里有一个提示:熊猫有一个提取HTML页面的方法，不需要太多的努力。</p><h2 id="d629" class="kd ke hi bd kq lz ma mb ku mc md me ky jg mf mg lc jk mh mi lg jo mj mk lk ml bi translated">亲tip</h2><p id="d60c" class="pw-post-body-paragraph iv iw hi ix b iy lm ja jb jc ln je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">方法<em class="jt"> read_html </em>返回一个包含满足我们的属性规范的html元素的Dataframes的列表<strong class="ix hj">。在本例中，我们寻找一个包含类的表:wikitable和sortable。<em class="jt">千位</em>参数指定用于解析千位的分隔符。</strong></p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="7bf6" class="kd ke hi jz b fi kf kg l kh ki">df_pandas <strong class="jz hj">=</strong> pd<strong class="jz hj">.</strong>read_html(url, attrs <strong class="jz hj">=</strong> {'class': 'wikitable sortable'},  flavor<strong class="jz hj">=</strong>'bs4', thousands <strong class="jz hj">=</strong>'.')</span></pre><p id="43d6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们看一下数据图表。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="cac1" class="kd ke hi jz b fi kf kg l kh ki">df_pandas[0]<strong class="jz hj">.</strong>head()</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/0ab80faf6cda4e08a72fe2d4f73a8cfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ZxAUogClkr_5sSs-dHN4Q.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Pandas extracted this Dataframe for us</figcaption></figure><h1 id="0c96" class="kp ke hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">2.多伦多邻居列表</h1><p id="8884" class="pw-post-body-paragraph iv iw hi ix b iy lm ja jb jc ln je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">像以前一样，让我们先看看数据。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/6cc75795189b2babfafadca5695bbf0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*12ai4gkEtM_xOAwA5sbnLA.png"/></div></div></figure><p id="5d88" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">与第一个数据集不同，这个数据集不是按行和列组织的。相反，数据被分组在一个指示邮政编码的列下。让我们简单看一下页面的HTML结构。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/731fb75a81c57c767e2dfd0d6c9a12d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BjWafzSCjIsUPtDp-Ognrw.png"/></div></div></figure><p id="d9a9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">注意这里的两件事。首先，一些列为空，并显示消息“<em class="jt">未分配</em>”。第二，每一列都有一个段落(标签<em class="jt"> p </em>)和一个跨度(标签<em class="jt"> span </em>)。让我们开始收集过程。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="2eeb" class="kd ke hi jz b fi kf kg l kh ki"><strong class="jz hj"># Importing libraries<br/>import</strong> requests<br/><strong class="jz hj">import</strong> pandas <strong class="jz hj">as</strong> pd<br/><strong class="jz hj">from</strong> bs4 <strong class="jz hj">import</strong> BeautifulSoup</span></pre><p id="ce37" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">导入必要的库后，我们下载HTML数据。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="0dc4" class="kd ke hi jz b fi kf kg l kh ki"><em class="jt"># Downloading contents of the web page</em><br/>url <strong class="jz hj">=</strong> 'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'<br/>data <strong class="jz hj">=</strong> requests<strong class="jz hj">.</strong>get(url)<strong class="jz hj">.</strong>text</span></pre><p id="ff54" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们创建了<em class="jt"> BeautifulSoup </em>对象。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="7b40" class="kd ke hi jz b fi kf kg l kh ki"><em class="jt"># Create BeautifulSoup object</em><br/>soup <strong class="jz hj">=</strong> BeautifulSoup(data, 'html5lib')</span><span id="9775" class="kd ke hi jz b fi lw kg l kh ki"><em class="jt"># Get table</em><br/>table <strong class="jz hj">=</strong> soup<strong class="jz hj">.</strong>find('table')</span></pre><p id="9228" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">注意，在这种情况下，我们可以直接找到表格，因为页面上只有一个表格。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="cb76" class="kd ke hi jz b fi kf kg l kh ki">contents <strong class="jz hj">=</strong> []<br/><br/><em class="jt"># Getting all rows</em><br/><strong class="jz hj">for</strong> row <strong class="jz hj">in</strong> table<strong class="jz hj">.</strong>find_all('td'):<br/>    cell <strong class="jz hj">=</strong> {}<br/>    <strong class="jz hj">if</strong> row<strong class="jz hj">.</strong>span<strong class="jz hj">.</strong>text <strong class="jz hj">==</strong> 'Not assigned':<br/>        <strong class="jz hj">pass</strong><br/>    <strong class="jz hj">else</strong>:<br/>        cell['PostalCode'] <strong class="jz hj">=</strong> row<strong class="jz hj">.</strong>p<strong class="jz hj">.</strong>text[:3]<br/>        cell['Borough'] <strong class="jz hj">=</strong> (row<strong class="jz hj">.</strong>span<strong class="jz hj">.</strong>text)<strong class="jz hj">.</strong>split('(')[0]<br/>        cell['Neighborhood'] <strong class="jz hj">=</strong> (((((row<strong class="jz hj">.</strong>span<strong class="jz hj">.</strong>text)<strong class="jz hj">.</strong>split('(')[1])<strong class="jz hj">.</strong>strip(')'))<strong class="jz hj">.</strong>replace(' /',','))<strong class="jz hj">.</strong>replace(')',' '))<strong class="jz hj">.</strong>strip(' ')<br/>        contents<strong class="jz hj">.</strong>append(cell)</span></pre><p id="0d59" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这个数据集中，我们研究了每一列(标签<em class="jt"> td </em>)。我们拒绝空列，从段落和跨度中提取内容。最后，我们将<em class="jt">单元格</em>添加到<em class="jt">内容列表</em>中。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="1a0a" class="kd ke hi jz b fi kf kg l kh ki"><em class="jt"># Creating the dataframe</em><br/>df <strong class="jz hj">=</strong> pd<strong class="jz hj">.</strong>DataFrame(contents)<br/><br/><em class="jt"># Changing some values to more comprehensive names</em><br/>df['Borough']<strong class="jz hj">=</strong>df['Borough']<strong class="jz hj">.</strong>replace({'Downtown TorontoStn A PO Boxes25 The Esplanade':'Downtown Toronto Stn A',<br/>                                     'East TorontoBusiness reply mail Processing Centre969 Eastern':'East Toronto Business',<br/>                                     'EtobicokeNorthwest':'Etobicoke Northwest','East YorkEast Toronto':'East York/East Toronto',<br/>                                     'MississaugaCanada Post Gateway Processing Centre':'Mississauga'})<br/></span></pre><p id="c699" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们通过将内容列表传递给熊猫方法数据框架来创建数据集。此外，我们缩短了区列中一些行的名称。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="92b1" class="kd ke hi jz b fi kf kg l kh ki"><em class="jt"># Visualizing dataframe</em><br/>df<strong class="jz hj">.</strong>head()</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es mp"><img src="../Images/5f3747577ca478f5a021c203fa3b700c.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*a3kbr7oJpyTIDd7odMF1NQ.png"/></div></figure><p id="00d2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">成功！我们根据需要提取了数据集。</p><p id="d7dc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">感谢您的阅读！您可以在下面的资源库中找到这些项目的代码:【https://github.com/TSantosFigueira/Coursera_Capstone<a class="ae iu" href="https://github.com/TSantosFigueira/Coursera_Capstone" rel="noopener ugc nofollow" target="_blank"/></p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/50d527c0c62330f531e040c2087da7d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QE2mS7a-qzk9K-h1"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Photo by <a class="ae iu" href="https://unsplash.com/@marcobian?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Marco Bianchetti</a> on <a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div></div>    
</body>
</html>