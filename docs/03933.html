<html>
<head>
<title>Logistic Regression | The Linear Regression Intuition | Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑回归|线性回归直觉|第1部分</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/logistic-regression-the-linear-regression-intuition-part-1-47cfae8a8c2c?source=collection_archive---------43-----------------------#2021-06-17">https://medium.com/geekculture/logistic-regression-the-linear-regression-intuition-part-1-47cfae8a8c2c?source=collection_archive---------43-----------------------#2021-06-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/a6915667ae6a410d47dbc5eeb2eb0f7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JrPI5Mqkyp0V5bX9Bf7WhQ@2x.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Logistic Regression | Part 1</figcaption></figure><p id="dc7f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在线性回归博客中，我谈到了进入机器学习的世界。在了解了线性回归这一回归问题后，我们通常会进入逻辑回归。在这个博客中，我们将学习关于分类问题的线性回归直觉的一切。如果你还没有看过线性回归博客，这里有链接:</p><div class="js jt ez fb ju jv"><a href="https://kumawatrohan.medium.com/beginners-guide-to-machine-learning-linear-regression-ab4c30d3ece2" rel="noopener follow" target="_blank"><div class="jw ab dw"><div class="jx ab jy cl cj jz"><h2 class="bd hj fi z dy ka ea eb kb ed ef hh bi translated">机器学习初学者指南|线性回归</h2><div class="kc l"><h3 class="bd b fi z dy ka ea eb kb ed ef dx translated">当我们进入机器学习的世界时，我们大多数人都从它是什么开始，然后从线性回归开始…</h3></div><div class="kd l"><p class="bd b fp z dy ka ea eb kb ed ef dx translated">kumawatrohan.medium.com</p></div></div><div class="ke l"><div class="kf l kg kh ki ke kj io jv"/></div></div></a></div><h1 id="1b5a" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">介绍</h1><p id="6cbe" class="pw-post-body-paragraph iu iv hi iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr hb bi translated">分类的目的是确定一个观察值属于哪一类，这是通过理解因变量和自变量之间的关系来完成的。这里的因变量是分类的，而自变量可以是数字或分类的。</p><p id="de3a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">逻辑回归是一个分类问题。逻辑回归的思想是找到特征和特定结果的概率之间的关系。当我们的目标变量是分类变量时使用它。例如:在猫和狗之间分类，学生不及格或及格，一个人是否有糖尿病，等等。</p><p id="5a1d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">逻辑回归也有两种类型:</p><figure class="ln lo lp lq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/9b08537eac97d9148807f60e3e2cd776.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TgXMdFvn8UBkLAOzjbCgZA@2x.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Types of Logistic Regression</figcaption></figure><p id="94bc" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">大家心中应该产生的一个问题是，如果是分类算法，为什么是Logistic回归而不是Logistic分类？</p><h1 id="ede8" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">为什么是逻辑回归？</h1><p id="6dd2" class="pw-post-body-paragraph iu iv hi iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr hb bi translated">让我们借助一个例子来理解这一点:</p><figure class="ln lo lp lq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/be354c4e84911cdc98de8b7370a42c9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*feFy2uFE8pxOI2N8zMJ5VQ@2x.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Example 1</figcaption></figure><p id="30ac" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这张图表示，在X-Y轴上，我们在X轴上绘制了体重，Y轴表示一个人可能肥胖，也可能不肥胖。通俗地说，我们根据一个人的体重来划分这个人是肥胖还是不肥胖。如果某人体重超过80公斤，他/她就是肥胖，如果低于80公斤，他/她就不是肥胖。我们应该想出一些能直接给我们结果(肥胖/不肥胖)的东西。</p><p id="9ef7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">可以用线性回归解决这个问题吗？</p><p id="7bf4" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在线性回归中，我们将试图找到一条直线，使得直线和点之间的距离总和最小。我们可以设定一个条件，如果我们的“y”值超过或等于一个特定值，那么我们就认为这个人肥胖。我们可以利用线性回归来解决这个二元分类问题。</p><figure class="ln lo lp lq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/174a38fc02d826a866cb14e9168ce4d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b3kLe7W5Jz5_IeI-8eLzvg@2x.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Example 2 (Condition)</figcaption></figure><p id="b9f9" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果是，那么线性回归有什么问题？</p><p id="93a3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们考虑一下，我们得到了一个异常值，我们的最佳拟合线将随之改变。根据这条新的最佳匹配线，如果有人体重超过100公斤，那么这个人就超重了。这个结果不是我们想要的！</p><figure class="ln lo lp lq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/19980eb3a2f8947103f1c33757c0fde0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Pl4v-cfAvKKNjK1rIR6xA@2x.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Example 3 (Flaw)</figcaption></figure><p id="a766" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">使用线性回归，我们用距离来计算一切。它引入了高错误率。如果我们的值大于1或者小于0，对于这种情况我们应该考虑什么？</p><h1 id="4ee4" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">摘要</h1><p id="18cb" class="pw-post-body-paragraph iu iv hi iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr hb bi translated">我们不使用线性回归进行分类，因为它处理连续值，而分类问题要求离散值。线性模型不输出概率，但它将类视为数字(0和1)。它符合使点超平面之间的距离最小化的最佳超平面(对于单个特征，一条线)。它还会给出小于0和大于1的值。由于预测的结果不是概率，而是点之间的线性插值，因此没有有意义的阈值来区分一个类别和另一个类别。线性模型不能扩展到多类分类问题。你必须开始用2标记下一个类，然后是3，依此类推。这些类可能没有任何有意义的顺序，但是线性模型会在要素和类预测之间的关系上强加一种奇怪的结构。具有正权重的要素的值越高，它对预测具有较高数值的类的贡献就越大，即使碰巧相似的类并不比其他类更接近。</p><p id="b0de" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这篇博客是关于我们是否可以使用线性回归进行逻辑回归，我们发现从技术上来说我们可以执行这个算法，但是它有更高的错误率。因此，我们不使用线性回归来解决分类问题。在逻辑回归博客的第2部分，我们将理解逻辑回归背后的直觉，以及在构建我们的分类模型时，它为什么比线性回归更好。</p></div></div>    
</body>
</html>