<html>
<head>
<title>Feed-Forward Implemented: Deep Learning with PyTorch Part #4</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">前馈实现:PyTorch深度学习第4部分</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/feed-forward-implemented-deep-learning-with-pytorch-part-4-9761721698c?source=collection_archive---------16-----------------------#2021-05-19">https://medium.com/geekculture/feed-forward-implemented-deep-learning-with-pytorch-part-4-9761721698c?source=collection_archive---------16-----------------------#2021-05-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="ffe0" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用基本Python从头开始实现一个简单的神经网络</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/ce0a8867558a622ca52d59f0820c4ced.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*W15Xo7Ipf7Ld4eWC"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@florianolv?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Florian Olivo</a> on <a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="56af" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">欢迎来到PyTorch深度学习第4部分！如果你是新手，可以看看前面的部分。前面的部分都在<a class="ae jn" href="https://jinalshah2002.medium.com" rel="noopener">我的媒体页面</a>上。作为复习，在上一篇文章中，我介绍了前馈数学。前馈是神经网络的基本概念之一。前馈是一个过程，在这个过程中，你的神经网络接受你的输入，通过你的隐藏层“馈送”它们，并“吐出”一个输出。</p><p id="ed8b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在本文中，我将提供一个用Python实现前馈的完整实现。本文中的所有代码都可以在我的<a class="ae jn" href="https://github.com/JinalShah2002" rel="noopener ugc nofollow" target="_blank"> Github页面</a>的<a class="ae jn" href="https://github.com/JinalShah2002/Deep-Learning-with-PyTorch" rel="noopener ugc nofollow" target="_blank">这个资源库</a>中找到。我已经尽了最大努力对代码进行了彻底的注释，以便您理解每一步都发生了什么。我强烈建议您获取代码样本并进行实验。毕竟，对于编码，你是边做边学的。事不宜迟，我们开始工作吧！</p><h1 id="0847" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">基本设置</h1><p id="d542" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">在我们直接进入代码之前，确保我们的环境设置正确是非常非常重要的。你用的编辑器真的取决于你。我强烈建议你下载<a class="ae jn" href="https://www.anaconda.com" rel="noopener ugc nofollow" target="_blank"> Anaconda平台</a>。这是因为你会自动安装所有的基础数据科学工具如Jupyter Notebook，sklearn等。如果您选择不下载Anaconda，请确保您已经安装了<a class="ae jn" href="https://numpy.org" rel="noopener ugc nofollow" target="_blank"> NumPy </a>库。这可以通过键入以下命令来完成:</p><ul class=""><li id="4541" class="lh li hi jq b jr js ju jv jx lj kb lk kf ll kj lm ln lo lp bi translated">pip安装数量</li></ul><p id="7584" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">公平的警告，在本教程中，我假设你有基本的Python知识和关于面向对象编程(OOP)概念的知识。</p><h1 id="39c4" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">密码</h1><p id="07b1" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">我们将寻求建立的神经网络架构将是一个简单的3层神经网络。图1提供了对这种神经网络架构的直观理解。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lq"><img src="../Images/86a378051a007a6373d7b6b15d3a80fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Syh7JLuBOdY2gWJRcy1I-g.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Figure 1: This is the neural network architecture that we will be implementing. X1 represents are the 1, and the only, input. B1 &amp; B2 represent the biases for each layer, and w1,w2,w3, and w4 represent the weights. The image was created by the author.</figcaption></figure><p id="96e5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">此外，我将使用的激活函数将是sigmoid。通常，您可能会使用各种激活函数，比如ReLU或tanh，但是为了简单起见，我使用sigmoid。</p><p id="a6ef" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">您可能已经注意到，神经网络的架构相对简单。这样做的主要原因是，我想让你对前馈在神经网络中如何工作有一个简单而具体的理解。如果我们实现了一个有很多很多隐藏层的更复杂的架构，我保证你从零开始实现之后，你的脑子会完全炸了。此外，我们将要实现的神经网络很可能在数据集上表现不佳。这有两个原因:</p><ul class=""><li id="960e" class="lh li hi jq b jr js ju jv jx lj kb lk kf ll kj lm ln lo lp bi translated">神经网络还没有训练好。我将在以后的文章中介绍神经网络的训练方面。</li><li id="cc82" class="lh li hi jq b jr lr ju ls jx lt kb lu kf lv kj lm ln lo lp bi translated">这太简单了。使用这种神经网络架构来解决问题是非常罕见的。我知道没有什么是不可能的，但这种情况会非常非常接近。</li></ul><p id="205a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">以下是完整的代码:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lw lx l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Figure 2: the full code of the feed-forward implementation for a neural network</figcaption></figure><p id="1dc1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这段代码很多，我们来走一遍。如果您注意图2的底部，可以看到我已经实现了sigmoid函数。正如我上面提到的，这个函数将作为神经网络的激活函数。如果您不熟悉sigmoid激活函数，图3提供了它的数学表示。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ly"><img src="../Images/29c50cb65f948e63552090e816307b11.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*Gp5E23P5d2PY5D5kOo8ePw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Figure 3: The Mathematical Representation of the Sigmoid Function. <a class="ae jn" href="https://analyticsindiamag.com/beginners-guide-neural-network-math-python/" rel="noopener ugc nofollow" target="_blank">https://analyticsindiamag.com/beginners-guide-neural-network-math-python/</a></figcaption></figure><p id="4acf" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">此外，图4显示了对它的图形化理解。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lz"><img src="../Images/69e99b38b69abfc0191c051223cd318c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UnSW1b5LdpFlBx5hR54J0w.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Figure 4: A graphical representation of the sigmoid function. <a class="ae jn" href="https://analyticsindiamag.com/beginners-guide-neural-network-math-python/" rel="noopener ugc nofollow" target="_blank">https://analyticsindiamag.com/beginners-guide-neural-network-math-python/</a></figcaption></figure><p id="9c08" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如图4所示，sigmoid函数以压缩0 &amp; 1之间的值而自豪。如果你熟悉经典的机器学习，你可能会认为这是逻辑回归。</p><p id="d9e4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">关于sigmoid函数说得够多了，让我们把注意力转向forward函数，这是这段代码的核心。在forward函数中，你可以看到我是如何通过隐藏层和输出层输入X的。换句话说，我正在执行神经网络的前馈阶段。正如我们在以前的文章中讨论的，前馈本质上是许多矩阵乘法。这在代码中显而易见。如你所见，我首先将偏置和输入矩阵连接成一个矩阵。然后，我通过<a class="ae jn" href="https://www.khanacademy.org/math/precalculus/x9e81a4f98389efdf:matrices/x9e81a4f98389efdf:multiplying-matrices-by-matrices/a/multiplying-matrices" rel="noopener ugc nofollow" target="_blank">矩阵乘法</a>将这个矩阵乘以权重。我对隐藏层和输出层重复这些步骤。这两层之间唯一的区别是，我将sigmoid激活函数应用于隐藏层的输出。为了简单起见，我没有将sigmoid函数应用于输出层；但是，有时您可能希望对输出图层应用激活函数。例如，您可能想要获取概率作为输出，因此您可能想要在输出图层上应用<a class="ae jn" href="https://en.wikipedia.org/wiki/Softmax_function" rel="noopener ugc nofollow" target="_blank">soft max激活</a>函数。</p><p id="6b32" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我要指出的最后一点是构造函数(__init__ function)中的权重和偏差声明。如您所见，我将权重设置为随机数。这里要指出的重要一点是，无论何时你建立一个神经网络，你将总是从随机权重开始。这是因为，例如，如果我们将每个权重设置为0，那么反向传播可能在更新权重等方面存在问题。为了不陷入这种混乱，我们随机设置权重。此外，您可能还注意到，我将偏差设置为等于1。<strong class="jq hj">通常，神经网络中的偏差设置为1。</strong></p><h1 id="37d6" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">为什么要使用框架？</h1><p id="f3a6" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">我想通过讨论当我们可以从头开始实现神经网络时，我们为什么要使用深度学习框架来结束这篇文章。老实说，这个问题有一个非常简单的答案:从头开始实现一个非常深的神经网络(比如100+个隐藏层)对我们来说工作量太大了。此外，深层神经网络背后的数学可能会让你的大脑真的爆炸。像PyTorch和Tensorflow这样的框架为我们做了所有繁重的工作。它们使得建立神经网络变得非常简单和容易。我们所要做的就是定义我们的架构、损失函数等等。为什么我们要“重新发明轮子”？</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/af4e59624ebe19c044597eda30fac76e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*arwFSWTXBjDe2fr_"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@aaronburden?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Aaron Burden</a> on <a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="eced" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">关闭</h1><p id="52a1" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">如果你读到了这篇文章的结尾，我感谢你。作为读者，你的支持真的激励我去创造更多有意义的内容。我希望您从零开始学到了一两件关于实现前馈的事情。一如既往，如果你有任何问题，请在下面的评论中留下。如果你有任何反馈，也请在下面的评论中或者在这篇文章的私人评论中告诉我。如果你有兴趣接触，请随时通过<a class="ae jn" href="https://www.linkedin.com/in/jinalshah2002/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>与我联系。下次见！享受深度学习！</p></div></div>    
</body>
</html>