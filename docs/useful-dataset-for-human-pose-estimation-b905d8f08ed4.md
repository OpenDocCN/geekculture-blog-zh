# 用于人体姿态估计的有用数据集

> 原文：<https://medium.com/geekculture/useful-dataset-for-human-pose-estimation-b905d8f08ed4?source=collection_archive---------22----------------------->

![](img/1b57585bb192a557823a2f877dd48b83.png)

Photo by [Cade Prior](https://unsplash.com/@medicadetion?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

人工智能是每个行业中使用最多的技术，因为它便于出色地完成工作。其中，数据集在任何推荐系统中都起着至关重要的作用。因此，我提出了一个基于人体姿态的数据集的概要。人体姿态估计，每个计算机视觉研究员都想在这方面做出贡献。希望你喜欢我的文章！

# **MPII**

MPII 是**M**ax**P**lanck**I**nstitute**I**informatik 的缩写。Mykhaylo，Leonid，Peter 和 Bernt 代表 MPII 人体姿态数据集。这是一个国家的艺术基准评估连贯的人类姿态估计。它包括用于多人的 2D 姿势估计，其包含大约 25K 个图像，其中大约有 40K 个人在其上标注了身体关节。它包含了 410 项人类活动，这些活动都是以相应的标签定期执行的。所有的图片都是从 YouTube 视频中提取的，没有标注帧。在三维姿态测试集上取得了很好的效果，特别是在头部和躯干的定位上，在遮挡图像部分也取得了很好的效果。

# **田蜜**

COCO 是 **Co** ntext 中**C**ommon**O**objects 的缩写。这个 2D 姿态估计数据集是由来自谷歌大脑、MSR、加州理工学院、TTI 芝加哥分校、WaveOne、康乃尔理工学院、脸书人工智能研究所、佐治亚理工学院和 CMU 的研究员通过从 Flickr 收集数据合作准备的。它高度集中于对象检测、字幕和基于分段的数据特征。它有一些诱人的功能，如上下文识别，超像素的东西和对象分割。它由 300K 图像组成，其中超过 200K 是标记图像。它有 80 个物品类别和 91 个物品类别。更令人兴奋的功能是，每张图片都有 5 个标题，250，000 人的图片都有关键点注释。它在密集姿态、语义分割、全景分割、检测、关键点标注和图像字幕任务上显示了有效的结果。

# **HumanEva**

这个数据集是由马克斯·普朗克智能系统感知系统研究所准备的。它由两个数据集组成，分别是

# HumanEva-I

该数据集使用软件同步，一次保存七个摄像机。摄像机有两种类型:3 色和 4 灰度摄像机，其中 6 个摄像机是运动捕捉摄像机。它有训练、验证和测试数据集。

# **HumanEva-II**

通过一次保持四个摄像机，使用硬件来同步该数据集。有 4 台彩色摄像机，其中 8 台是动作捕捉摄像机。它只有测试数据集。

这是针对单人的 3D 姿态估计，其包括在两种类型的数据集中讨论的视频序列。基于标记的运动捕捉相机用于准备 3D 姿态地面真实图像。它由执行 6 种常见动作的 4 个受试者组成。2D 和 3D 姿态中误差度量是可用的。

# **人类 3.6 米**

根据数据集的名称，它有 360 万个 11 个被崇拜的专业演员的 3D 人体姿势图像，其中有 6 个男性和 5 个女性在 17 个不同的活动中。使用高度校准的和基于飞行时间的 4 个摄像机捕获频率为 50Hz 和高分辨率的视频帧。测量每个配置和像素级的 24 个身体部位标签。演员的 3D 激光扫描被利用。它有适当的背景减法和包围盒的人。

# **超现实**

超现实是**S**ynetic h**U**man for**R REAL**tasks 的缩写。它包含了照片般真实的渲染，在纹理、形状、视角和姿势上有巨大的变化。当提供 RGB 视频输入时，它对于生成身体部位、光流、2D 和 3D 姿态、表面法线和深度具有良好的功效。有 600 万帧人造人。使用 SMPL(带皮肤的多人线性模型)身体模型生成合成身体，该身体模型的参数与由原始 3D MoCap 标记数据提供的 MoSh 方法相关。

# **FLIC**

FLIC 是**F**rames**L**abelled**I**n**C**inema 的缩写。它由 5003 张取自好莱坞电影场景的图片组成。它是使用 canonical person detector 在 30 部电影的每个连续第十帧上收集的。总共有 20000 人被纳入置信图的考虑范围，这些置信图被发送到人口高度密集的亚马逊土耳其人那里，以获得地面真相标签。在 Turkers 图像的帮助下，进行上身关节注释，并考虑五个标记点的中值作为离群点注释。测试数据由 1016 个数据图像组成。不得将 FLIC 用于培训和测试。因此，如果我们使用它在不同的数据集上测试和训练机器，因为它是训练数据的超集，这可能会导致过拟合。它也有 FLIC-full 数据集，其中有大量来自 mass 电影的帧集，这些电影的手部关节注释是由 Mechanical Turk 制作的。

# **LSP**

LSP 是**L**EADS**S**ports**P**ose dataset 的缩写。它由 2000 张仅与八种不同体育活动相关的带注释的姿势图像组成。它们是从 Flickr 上收集的。所有图像都缩小到大约 150 像素长。所有的运动图像都能够检测 14 个关键点关节位置。训练和测试数据按 50%的比例划分。

最后，我试图总结几个数据集的细节。我希望它会有用。在评论区分享你的观点，这样在下一篇文章中我可以改进它。