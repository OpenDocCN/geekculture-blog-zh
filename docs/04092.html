<html>
<head>
<title>Speech recognition using Hidden Markov Models and Maximum Likelihood approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于隐马尔可夫模型和最大似然法的语音识别</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/speech-recognition-using-hidden-markov-models-and-maximum-likelihood-approach-aac2bc320e2a?source=collection_archive---------33-----------------------#2021-06-21">https://medium.com/geekculture/speech-recognition-using-hidden-markov-models-and-maximum-likelihood-approach-aac2bc320e2a?source=collection_archive---------33-----------------------#2021-06-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/d576968624f8a3a1772299e38d7a7c3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bjmkBAN-sH1R60nG"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Photo by <a class="ae iu" href="https://unsplash.com/@elodiso?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Leon Dewiwje</a> on <a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="ce97" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接收到的信号是数据和噪声的融合，因此分析语音信号的隐马尔可夫模型是基于维特比算法，从卷积码或网格图导出的，该卷积码或网格图是从卷积编码器转换的数据获得的。HMM和ML使用联合概率和独立事件概念来增强接收信号。当使用HMM解码该信号时，那么在解码之后，可以预测未来的结果。通过应用概率HMM方法获得的启发式特征可以帮助您决定是否存在什么情绪或者哪个单词将被进一步说出，从而可以接受关于当前状况的心态，并且可以实现富有成效的输出。这是文章的概述，希望你会觉得有用。</p><p id="3ec1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">简介</strong></p><p id="ca4e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用HMM- Viterbi算法进行语音信号增强和预测。概率方法因此被用于从接收的信号中预测启发式结果。卷积码编码器被送入维特比解码器，它主要利用联合概率和独立事件概念，预示着未来丰富的输出，它可以帮助你在先前输入的基础上决定下一个词是什么。深度学习太强大了，无法轻松解决现实问题。语音识别是可以预见的，未来的问题可以很容易地解决。</p><p id="052e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">最大似然估计</strong></p><p id="0f4e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最大似然法是一种用于通信的概率方法。在现实世界中，通信信道的计算过于复杂，因此为了计算这种复杂性，我们需要一个概率模型解码器，它可以帮助解码具有错误概率的信号。解码模型应该能够计算复杂的通信信道。基于所传输信号的经验数据，优先考虑用于解决复杂性的解码模型。这里，语音信号是要被接收的预兆，因此，最大似然方法在这里被预先选择。每个模型都有自己的一组参数来表征它们。最大似然法是基于联合概率和独立事件的概念，使用概率密度函数来绘制信号，强调连续数据。在分析数据的机器学习中，要考虑在实际测试中准备的数据集。为了训练具有连续数据的模型，回归方法是优选的。这里，语音信号将被训练，并且其未来的启发式预测将被做出，因此使用隐马尔可夫模型。</p><p id="8d10" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">格子图</strong></p><p id="15b1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">网格是一种图形，其节点被排序成垂直切片，每个节点每次都连接到至少一个较早的节点和至少一个较晚的节点。网格中的最早和最晚时间只有一个节点。</p><p id="8042" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">网格用于通信理论和加密的编码器和解码器。它们也是在Baum-Welch算法或Viterbi算法或隐马尔可夫模型中使用的中心数据类型。</p><p id="1325" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">维特比算法</strong></p><p id="4b29" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">维特比算法是借助于格子图或卷积码来解决隐藏状态的动态解码编程算法。它最常用于对约束长度k≤3的卷积码进行解码，但实际中使用k=15的值。</p><p id="9418" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">卷积码与分组码的不同之处在于编码方案中存在记忆。也就是说，卷积编码器通过向输入流符号添加冗余来实现低误码率传输。因此，它产生的输出位多于移入其存储器的输入位。卷积码是通过将待传输的信息序列通过线性有限状态移位寄存器来产生的。卷积编码器的码率定义为输入位数与输出位数之比。一般而言，码率定义为Rc = k/n，编码器以(K，K，n)格式表示，其中</p><p id="41db" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">n:由编码器产生的代码符号的数量</p><p id="96b8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">k:进入编码器的信息位数</p><p id="eb1a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">k:代码的约束长度</p><p id="0c1a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">编码器的约束长度是代码内存的度量。(K，K，n)卷积编码器的结构如下图所示</p><p id="53bf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">(K，K，n)卷积码可以(例如)通过使用一组n个向量来指定，n个模2加法器中的每一个都有一个向量。每个向量具有Kk个维度，并且包含编码器到模2加法器的连接。向量的第I个位置中的1表示移位寄存器中的相应级连接到模2加法器，0表示该级和模2加法器之间没有连接。具体来说，让我们考虑约束长度为K = 3、k = 1和n = 2的二进制卷积编码器，如下图所示。</p><p id="ffef" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">隐马尔可夫模型</strong></p><p id="6c85" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">HMM基于扩充马尔可夫链。马尔可夫链是一个模型马尔可夫链，它告诉我们一些关于随机变量序列的概率，状态，每一个都可以取某个集合中的值。这些集合可以是单词、标签或代表任何事物的符号，比如天气。马尔可夫链做了一个很强的假设，如果我们想预测序列中的未来，唯一重要的是当前状态。当前状态之前的状态对未来没有影响，除非通过当前状态。</p><p id="af31" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">更正式地，考虑一系列状态变量q1，q2，…，qi。马尔可夫模型体现了关于这个序列概率的马尔可夫假设:在预测未来时，过去并不重要，只有现在才重要。马尔可夫假设:</p><p id="98be" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">P(qi = a | Q1…qi 1)= P(qi = a | qi 1)</p><p id="bafa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">状态在图中被表示为节点，而带有概率的转换被表示为边。</p><p id="3923" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当我们需要计算一系列可观察事件的概率时，马尔可夫链是很有用的。然而，在许多情况下，我们感兴趣的事件是隐藏的:我们不会直接观察它们。例如，我们通常不会观察到文本中隐藏的词性标签。相反，我们看到单词，必须从单词序列中推断出标签。我们称标签为隐藏的，因为它们没有被观察到。隐马尔可夫模型(HMM)允许我们谈论观察到的事件隐马尔可夫模型(如我们在输入中看到的单词)和我们认为是概率模型中的因果因素的隐藏事件(如词性标记)。HMM由以下组件指定:</p><p id="acd7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Q = q1q2…qN一组N个状态</p><p id="933e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">A = a11… aij … aNN一个转移概率矩阵a，每个aij代表从状态I转移到状态j的概率，s.t.PN j=1aij = 1 ∀i</p><p id="1179" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">O = o1，o2… oT一系列的T个观察值，每一个都来自词汇V = v1，v2，…，vV</p><p id="ad66" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">B = bi (ot)一系列观察似然性，也称为发射概率，每一个都表示从一个状态i π =π1，π2，…，πN产生一个观察ot的概率。πi是马氏链从状态I开始的概率，有些状态j可能有πj = 0，意味着它们不能是初始状态。此外，Pn i=1，πi = 1</p><p id="54ec" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一阶隐马尔可夫模型实例化了两个简化的假设。首先，与一阶马尔可夫链一样，特定状态的概率仅取决于前一状态:马尔可夫假设:</p><p id="a5c8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">P(qi | Q1…qi 1)= P(qi | qi 1)</p><p id="1ca7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">第二，输出观察oi的概率仅取决于产生观察qi的状态，而不取决于任何其他状态或任何其他观察:</p><p id="375a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出独立性:</p><p id="af0b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">P (oi|q1…qi，…，qT，o1，…，oi，…，oT) = P(oi|qi)</p><p id="8d01" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">隐马尔可夫模型最大似然法</strong></p><p id="7241" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">隐马尔可夫模型假设一个随机变量序列是条件独立的，给定一个形成马尔可夫链的状态变量序列。这些模型的最大似然估计可以使用EM算法来执行。本文证明了极大似然估计序列的相合性。隐马尔可夫模型形成了一大类有用的随机过程模型，其中一系列计数、比例或多变量观察值同样容易描述。这些模型基于描述系统状态演变的马尔可夫链{Xi}。给定状态变量{xi}的实现序列，观察变量{Yi}是条件独立的，每个Yi的分布取决于相应的状态xi。在估计问题中，假设Y的分布属于一个参数族，并且假设状态空间是有限的。隐马尔可夫模型的特殊情况，其中观察变量只有有限多个值，被称为马尔可夫链的概率函数；这个模型是由鲍姆和佩特里(1966)提出的。隐马尔可夫模型和状态空间模型之间有明显的相似性，例如线性状态空间模型:</p><p id="8305" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">xi = Fxi-1+ x，</p><p id="025c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">yi = HXi + Wi，</p><p id="6e2a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由未观测的状态变量{Xi}、观测值{Y}和噪声变量{ V；}和Wi}。在状态空间模型的许多应用中，目标是基于观察集Y1，.。。Y，即，如果i = n则滤波，如果i &lt; n, or prediction if i &gt; n则平滑。在具有正态误差的经典模型中，使用卡尔曼滤波器来执行重建。</p><p id="e9fe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">条件1:随机矩阵[ajk</p><p id="2ede" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">(φ0)]是不可约的。</p><p id="1c80" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">条件2:{ f(y，θ))的至多m个元素的混合族是可识别的。</p><p id="7d79" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">条件3:对于每个y，f (y，.)是连续的，在无穷远处消失。</p><p id="5e70" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">条件4:对于每个j，k，ajk(。)和θj(。)都是连续的。</p><p id="3707" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">条件5:Eφ0[| log f(y1，θj(φ0)I]</p><p id="511b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Condition 6: For every EΦ0[sup ||θ’ -θ||&lt; δ (logf (y1, θ’))] 0，(||。||)是欧氏距离，x+ = max{x，0))。</p><p id="a1c0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> HMM和语音识别</strong></p><p id="7068" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">语音识别是将语音信号转换成单词序列的过程。各种方法已经用于语音识别，包括动态编程和神经网络。<strong class="ix hj"> </strong> HMM具有非常丰富的数学结构，因此可以形成广泛应用的理论基础。HMM模型，当应用得当时，在实践中可以很好地用于几个重要的应用。</p><p id="892e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">语音识别包括两个主要模块，特征提取和特征匹配。特征提取模块的目的是将语音波形转换成某种类型的表示，以便进一步分析和处理，这种提取的信息称为特征向量。信号处理前端模块完成语音信号到特征向量的转换过程。如上面的框图所示，前端的输入是无噪声的语音样本，其输出是特征向量。在特征匹配中，将从未知语音样本中提取的特征向量与声学模型进行评分，得分最高的模型获胜，其输出被视为已识别单词。以下是实现前端(提取特征因子)的几种方法</p><p id="9b35" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">MFCC(梅尔频率倒谱系数)LPC(线性预测编码)</p><p id="caa1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦获得特征向量，我们就建立声学模型。声学模型用于对未知语音样本进行评分。如框图所示，前端的输出作为声学模型的输入。不同类型的声学模型有</p><p id="83a0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">VQ法典</p><p id="6a7a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">GMM-高斯混合模型</p><p id="59e5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">声学模型表示:在语音识别中，声音的基本单位是音素。音位是用来区分词义的最小单位。对于“CAT”音素序列，K是A和t。在英语中，大约有46个音素。我们可以使用这个音素的适当连接从英语词典中构造任何单词。为了识别一个给定的单词，我们需要从语音样本中提取音素。由于语音信号的慢时变特性，短时频谱分析是表征语音信号最常用的方法。当在足够短的时间内(10到25毫秒之间)检查时，它的特性相当稳定。然而，随着时间的推移，信号特征会发生变化，以反映所发出的不同语音。利用这种观察，我们发现在10到25毫秒内提取的特征向量对应于单个音素。对于HMM中的语音识别，我们为每个基本单元(音素)分配一个唯一的HMM。研究表明，每个音素HMM可以用三种状态来表示，即开始、中间和结束状态。</p><p id="8bd1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了理解这一点，以孤立词识别器为例，词汇表中的每个词都有不同的HMM。当未知单词出现时，它相对于所有HMM模型被评分，并且具有最高评分的HMM被认为是被识别的单词。如框图所示，声学模型的输出是音素序列。通过反向查找字典(音素—单词),我们可以找到相应的单词。但是通常有许多单词具有相同音素序列，例如car key和Khakee具有相同的音素序列。在这种情况下，语言结构就进入了画面。语言结构使用上下文信息来缩小已识别单词的范围，以类似于给定的语法结构。这种类型的模型被称为单音或上下文无关模型，以下是不同类型的HMM</p><p id="5dba" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">1.上下文无关音素HMM</p><p id="31e7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">状态数:每个音素的d状态HMM通常等于3)</p><p id="a235" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">准确性:在连续语音识别中不准确</p><p id="2869" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">紧凑:d状态HMM导致需要计算的参数更少</p><p id="3d1e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">概述:是的，我们可以使用现有的音素HMM为新单词构建HMM</p><p id="b638" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.上下文相关三音素HMM</p><p id="c707" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">状态数:每个音素的d状态HMM</p><p id="0830" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">准确性:准确，因为它具有左右音素关系11</p><p id="7574" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">紧凑:每个音素具有直接的左右关系，需要计算更多的参数</p><p id="0a20" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">概述:是</p><p id="a147" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.全词HMM</p><p id="b64e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">状态数:无音素生成</p><p id="d671" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">分配状态数以模拟整个单词</p><p id="89b1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">准确:是的，需要大量的训练数据和少量的词汇</p><p id="cad2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">紧凑:不，随着词汇量的增加，需要太多的状态</p><p id="7f29" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">常规:否，无法使用此表示法构建新单词</p><p id="6110" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在实践中，三音素模型被广泛应用于使用隐马尔可夫模型的语音识别中。现在我们不讨论如何从语音信号中提取特征向量。我们假设使用MFCC或线性预测编码我们得到所需的特征向量。在MFCC的情况下，它是39维向量。问题是如何将特征向量映射到HMM状态。为此，我们使用称为向量量化的技术。</p><p id="b6b5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">创建特征向量的训练集</p><p id="d517" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">将他们分成几个小组</p><p id="840e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">用符号表示每个类别</p><p id="8eeb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于每个类别Vk，计算其由给定HMM状态生成的概率。</p><p id="3139" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在矢量量化中，我们定义了包含每个符号条目的码本，该码本也称为原型矢量或码字。例如，如果我们有256个类别(即8比特VQ)，我们在码本中有256个条目。如图8所示，将输入向量与每个原型向量进行比较，选择具有最小距离的向量，并将其索引值给予输入向量。</p><p id="bb65" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如何生成码书(K-means聚类)？</p><p id="e1ff" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从L个训练向量中选择M个向量——其中M = 2B作为初始码字(选择它们之间距离最大的M)</p><p id="b422" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于每个训练向量，找到最近的码字(最小距离)。将该训练向量分配给该单元</p><p id="5188" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于每个单元，计算该单元的质心。新的码字是质心</p><p id="a687" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">重复最后两步，直到平均距离低于阈值</p><p id="6376" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如我们看到的评价问题即给定观测序列O = O1，O2，O3，，OT如何计算P(O|λ)。在那里我们应用链式法则计算P(O|λ)如图10:链式法则—难解算法P(O|λ) = X整体状态πQ1 bq1(O1)aq1q 2 bq2(O2)aqT 1 Qt bqT(OT)这是O(NT)的一个阶。如图10所示，P(o1，o2，O3)在所有状态序列上的概率为P(O1，o2，o3|q0，q0) + P(o1，o2，o3|q0，q0，q1) + P(o1，o2，o3|q0，q1，q0) + P(o1，O2，o3|q0，q1，Q0)…。为了提高效率，我们使用前向变量，该变量使用动态规划技术将阶数降低到N2T。在第2.5.2节中，我们定义了前向变量，使得αt(i) = P(O1，O2，，Oi，qt = Si |λ),并通过对所有I的所有先前值αt 1(I)求和来计算αt(j)。图11显示了音素序列为W AH和n的单词“ONE”的计算。在前向计算中，我们考虑对所有传入节点求和，以找到P(O|λ)。因为我们音素模型是二元模型，所以只有它的前身状态输入被考虑来计算概率和。为了更好地理解，参考图11，在时间t=3时，状态N的输入仅来自状态AH和N，而不是来自w。这样，给定观察序列和模型λ，我们可以找到P(O|λ)。</p><p id="f317" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这样，语音信号的解码和增强可以借助于HMM维特比算法来完成。</p><p id="f0bc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">参考文献</strong></p><p id="3314" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">[1]，，董，，郭伟斌，“无线信号识别中的深度学习技术综述”，载《无线通信与移动计算》2019年第一期</p><p id="c3e2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">[2] Brian G. Leroux，“隐马尔可夫模型的最大似然估计”，随机过程及其应用40(1992)127–143，1990</p><p id="5bc5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">[3]丹尼尔·茹拉夫斯基(Daniel Jurafsky)和詹姆斯·马丁(James H. Martin)，《隐马尔可夫模型》，语音和语言处理，2019年</p><p id="4148" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">[4] Iead Rezek，Peter Sykacek，Stephen J. Roberts，“耦合隐马尔可夫模型的贝叶斯和最大似然学习的比较”，研究之门，2000年</p><p id="20d6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">[5]李冰，巴保明，“多用户CPM系统简化最大似然接收机的设计”，科学世界杂志，2014年第一卷，2014</p><p id="a3ae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">[6] M. J. F. Gales，“基于HMM的语音识别的最大似然线性变换”，计算机语音和语言，1998年</p><p id="dfd6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">[7] Johanna Tuominen和Juha Plosila，“行动系统中的异步维特比解码器”，研究之门，2005年</p></div></div>    
</body>
</html>