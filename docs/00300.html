<html>
<head>
<title>Word Embedding on Stock Market News</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">股票新闻中的词汇嵌入</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/word-embeddings-on-stock-market-news-7c3d17e5e7ef?source=collection_archive---------3-----------------------#2021-01-08">https://medium.com/geekculture/word-embeddings-on-stock-market-news-7c3d17e5e7ef?source=collection_archive---------3-----------------------#2021-01-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/3db9a25d4a77e18406046e72009c633e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uVM6sVFrYfnmVu0gbD6svw.jpeg"/></div></div></figure><p id="75f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">单词嵌入是自然语言处理(NLP)中最流行的语言建模之一，其中来自词汇表的单词或短语被映射到多维向量空间。它能够捕捉单词的上下文、语义和句法相似性、与其他单词的关系等。</p><p id="dedb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">描述单词嵌入以及如何加减单词的最著名的例子是<em class="jo">‘Queen’</em>word。这个单词是通过将与单词<em class="jo">国王</em>和<em class="jo">女人</em>相关联的向量相加而得到的，同时减去<em class="jo">男人</em>等于与皇后相关联的向量。</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="632c" class="jy jz hi ju b fi ka kb l kc kd">King - Man + Women = Queen</span></pre></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><p id="2cb8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本文中，我们将尝试在股市新闻上进行单词嵌入。我们有一个关于<em class="jo"> Covid疫苗新闻</em>的虚拟数据集，它被分成几个段落。</p><figure class="jp jq jr js fd ij"><div class="bz dy l di"><div class="kl km l"/></div><figcaption class="kn ko et er es kp kq bd b be z dx">The dataset</figcaption></figure><p id="5d2f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">应该首先对数据集中的每个段落进行预处理。我们的预处理功能包括:</p><ul class=""><li id="4469" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn kw kx ky kz bi translated"><strong class="is hj">清洗</strong>:仅用于获取字母</li><li id="d742" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated"><strong class="is hj">分词</strong>:将句子分解成音节</li><li id="1a35" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated"><strong class="is hj">删除停用词</strong>:删除常用词(如:我、有、他们等。)被认为是不重要的单词</li></ul><p id="ba52" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">实际上，我们可以使用词汇化和词干化方法进行预处理。此外，我们可以在预处理中添加更多的停用词。</p><figure class="jp jq jr js fd ij"><div class="bz dy l di"><div class="kl km l"/></div><figcaption class="kn ko et er es kp kq bd b be z dx">The pre-processing functions</figcaption></figure><p id="6dc0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在数据集已经被预处理之后，我们继续将数据集训练成单词嵌入模型。我们使用来自<a class="ae lf" href="https://radimrehurek.com/gensim/models/word2vec.html" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj"> gensim python库</strong> </a> <strong class="is hj"> </strong>的<strong class="is hj"> Word2Vec </strong>工具来训练它。Word2Vec通常用于生成检测同义词或为部分句子建议单词的模型。它有两种模型架构，分别是<strong class="is hj">跳过程序</strong>和<strong class="is hj"> Cbow </strong>。不同的是CBOW使用周围的上下文单词来预测目标/当前单词，而Skip-gram使用当前单词来预测几个上下文单词。</p><figure class="jp jq jr js fd ij"><div class="bz dy l di"><div class="kl km l"/></div><figcaption class="kn ko et er es kp kq bd b be z dx">The training model function</figcaption></figure><p id="8c6d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从我们拥有的数据集，我们将其训练成一个单词嵌入模型<em class="jo">(包含单词和向量)</em>，该模型用于获取相似单词。例如，我们试图找出哪些词与疫苗有关，结果如下:</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="f2aa" class="jy jz hi ju b fi ka kb l kc kd"># words related to vaccine<br/>[('takes', 0.15888293087482452), ('vaccinate', 0.14267049729824066), ('access', 0.14085279405117035), ('end', 0.13962803781032562), ('eu', 0.12622541189193726), ('normal', 0.12466207891702652), ('making', 0.11808254569768906), ('provide', 0.10831684619188309), ('supplies', 0.10447120666503906), ('approved', 0.1038375273346901)]</span></pre><p id="581d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在自然语言处理领域，单词嵌入是许多领域的著名方法，这可能是自然语言处理问题的关键，包括股票领域问题。</p><p id="bbe3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">参考:</p><ul class=""><li id="b95a" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn kw kx ky kz bi translated"><a class="ae lf" href="https://machinelearningmastery.com/what-are-word-embeddings/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/what-are-word-embedding/</a></li><li id="0ea4" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated"><a class="ae lf" href="https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa" rel="noopener" target="_blank">https://towards data science . com/introduction-to-word-embedding-and-word 2 vec-652 d0c 2060 fa</a></li></ul></div></div>    
</body>
</html>