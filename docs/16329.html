<html>
<head>
<title>SetFit- Few shot learning for Youtube Comments</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">set fit-Youtube评论的少量镜头学习</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/setfit-few-shot-learning-for-youtube-comments-2aa1edfbdba2?source=collection_archive---------9-----------------------#2022-12-22">https://medium.com/geekculture/setfit-few-shot-learning-for-youtube-comments-2aa1edfbdba2?source=collection_archive---------9-----------------------#2022-12-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="dbbb" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">问题陈述:</strong></h1><p id="9d98" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">通常今天完成的ML依赖于标记的数据。在现实世界中，很难找到贴有标签的数据，等待一些数据科学家捡起来并开始构建模型。</p><p id="c777" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">根据<a class="ae kg" href="https://www.grandviewresearch.com/industry-analysis/data-collection-labeling-market" rel="noopener ugc nofollow" target="_blank">的一份报告</a>“2021年，全球数据收集和标签市场规模价值16.7亿美元，预计从2022年到2030年将以25.1%的复合年增长率(CAGR)扩张”。</p><p id="3e3f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">甚至在数据科学家中也有这样一种观念，即要有好性能，他们需要大量的数据。这就是像<strong class="jf hj">少投学习</strong>这样的技术可以派上用场的地方。</p><h1 id="391e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">什么是少投学习？</h1><p id="fc14" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">它是监督ML的一部分，在监督ML中，模型被给定一些带标签的例子，然后使用它来训练，以对看不见的例子进行推断(预测)。</p><p id="0a75" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">目标是减少在给定任务上实现类似性能所需的训练数据量。</p><h1 id="c80d" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">什么是SetFit？</h1><p id="b723" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">set fit(<strong class="jf hj">Se</strong>tence<strong class="jf hj">T</strong>transformer<strong class="jf hj">Fi</strong>ne-<strong class="jf hj">T</strong>uning):一个高效的句子变形器微调框架。</p><p id="e239" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">培训分为两个阶段:</p><ol class=""><li id="b537" class="kh ki hi jf b jg kb jk kc jo kj js kk jw kl ka km kn ko kp bi translated">句子转换器微调:这以连体方式发生在句子对上，目标是最大化语义不同的句子之间的距离，最小化语义相似的句子之间的距离。</li><li id="7f67" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">分类头训练:将富文本嵌入并与类别标签形成分类训练集。分类模型采用Logistic回归模型。(在未来，我认为这可以是任何分类模型。)</li></ol><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es kv"><img src="../Images/c41a09d7289e66eee8b90a29041b7230.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xoqnZwCfE4oPo0XXDazQWw.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx">Two stage training process</figcaption></figure><p id="969b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">有关这一切如何工作和基准测试结果的更多详细信息，请参考<a class="ae kg" href="https://huggingface.co/blog/setfit" rel="noopener ugc nofollow" target="_blank">博客</a>和SetFit论文。</p><p id="96ab" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">仅仅通过用多语言转换器替换基本句子转换器，它就给出了很好的结果。</p><h2 id="6e9f" class="ll ig hi bd ih lm ln lo il lp lq lr ip jo ls lt it js lu lv ix jw lw lx jb ly bi translated">根据推断:</h2><ol class=""><li id="fc23" class="kh ki hi jf b jg jh jk jl jo lz js ma jw mb ka km kn ko kp bi translated">将看不见的样本传递给句子转换器(使用少量训练样本进行微调)以生成密集嵌入。</li><li id="faca" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">分类头使用这种富文本嵌入来返回一个类标签。</li></ol><h1 id="2347" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">数据集源:</h1><p id="1af2" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">数据集是使用Youtube API收集的。它包含了数据科学相关频道的YouTube评论集。<a class="ae kg" href="https://www.kaggle.com/datasets/tushifire/youtube-data-science-channels-comments" rel="noopener ugc nofollow" target="_blank"> Kaggle数据集</a></p><p id="fefc" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">注意:</strong>如果在kaggle上运行，首先卸载tensorflow，因为预装版本的tf有问题。</p><pre class="kw kx ky kz fd mc md me bn mf mg bi"><span id="2354" class="mh ig hi md b be mi mj l mk ml">%pip uninstall tensorflow -y</span></pre><p id="d670" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">如果您直接希望看到实际结果，请跳到模型的<strong class="jf hj">推理部分。</strong></p><h1 id="d711" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">安装套件</h1><pre class="kw kx ky kz fd mc md me bn mf mg bi"><span id="6574" class="mh ig hi md b be mi mj l mk ml">%pip install setfit</span></pre><p id="361a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">让我们进入代码示例。</p><h2 id="0016" class="ll ig hi bd ih lm ln lo il lp lq lr ip jo ls lt it js lu lv ix jw lw lx jb ly bi translated">问题陈述:</h2><p id="2f21" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">想象你自己是一名在YouTube上教学的教育工作者，你想看到来自学生的问题。但是评论区有点乱。建立一个系统，从杂乱的评论中过滤出问题。</p><p id="7ee8" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><em class="mm">形式上，给定一条评论预测文本是否是问句。</em></p><p id="0e8a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">将数据集加载到pandas数据框中，并过滤掉注释字段。</p><pre class="kw kx ky kz fd mc md me bn mf mg bi"><span id="07eb" class="mh ig hi md b be mi mj l mk ml">comments_df = pd.read_csv('/kaggle/input/youtube-data-science-channels-comments/Coreyms_comments.csv',engine='python')<br/>comments_text_df = pd.DataFrame(comments_df['snippet_topLevelComment_snippet_textOriginal'])</span></pre><p id="d620" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">看看评论样本。运行下面的单元格，为每个类(问题和非问题)生成一些样本。</p><pre class="kw kx ky kz fd mc md me bn mf mg bi"><span id="9f58" class="mh ig hi md b be mi mj l mk ml">comments_text_df.sample(5)</span></pre><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mn"><img src="../Images/6160c62253f5f5b219041f95f6307368.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LOgPf-X6Gak1Gub_yuahLw.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx">sample comments</figcaption></figure><h1 id="9657" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">数据监管</h1><p id="b721" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我为两个班收集了16篇课文的样本。请记住，我们这里没有标记的培训数据。</p><pre class="kw kx ky kz fd mc md me bn mf mg bi"><span id="3f73" class="mh ig hi md b be mi mj l mk ml"># questions is a list of text comments which are questions.<br/># not_questions is a list of text comments which are  not questions.<br/>df = pd.DataFrame()<br/>df['text'] = questions<br/>df['label'] = True<br/><br/>df1 = pd.DataFrame()<br/>df1['text'] = not_questions<br/>df1['label'] = False<br/><br/>combined_comments_df = pd.concat([df,df1])<br/>combined_comments_df = combined_comments_df.reset_index(drop =True)</span></pre><p id="2db7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">将熊猫数据帧转换为拥抱人脸数据集</p><pre class="kw kx ky kz fd mc md me bn mf mg bi"><span id="8715" class="mh ig hi md b be mi mj l mk ml">from datasets import Dataset<br/>dataset = Dataset.from_pandas(combined_comments_df)<br/>dataset</span></pre><pre class="mo mc md me bn mf mg bi"><span id="86e0" class="mh ig hi md b be mi mj l mk ml">from setfit import SetFitModel<br/>model_id = 'sentence-transformers/all-MiniLM-L6-v2'<br/>model = SetFitModel.from_pretrained(model_id)<br/></span></pre><p id="73fd" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这个模型id可以被修改成任何预先训练好的模型形式<a class="ae kg" href="https://www.sbert.net/docs/pretrained_models.html" rel="noopener ugc nofollow" target="_blank">句子-变形金刚</a>。</p><h1 id="849c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">训练装备</h1><p id="3f0f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">让我们定义我们的SetFitTrainer。</p><pre class="kw kx ky kz fd mc md me bn mf mg bi"><span id="4a6a" class="mh ig hi md b be mi mj l mk ml">from sentence_transformers.losses import CosineSimilarityLoss<br/><br/>from setfit import SetFitTrainer<br/><br/>trainer = SetFitTrainer(<br/>    model=model,<br/>    train_dataset=dataset,<br/>    eval_dataset=dataset,<br/>    loss_class=CosineSimilarityLoss,<br/>    num_iterations=20,<br/>    num_epochs=10,<br/>    column_mapping={"text": "text", "label": "label"},<br/>)<br/>trainer.train()</span></pre><p id="8215" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我也使用了与eval_dataset相同的数据集。我们也可以定义不带eval_dataset的培训师。</p><p id="00cd" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">注意:</strong>最好有一个单独的eval_dataset。为此必须再次标记几个数据点。</p><p id="09e6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">就这样，我们训练了一个分类器，每个只有16个例子。</p><p id="fc59" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">如果你愿意，你可以把你的模型推到中心，并与他人分享。</p><h1 id="cd07" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">推理模型</h1><p id="0734" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">服务SetFit模型与服务任何HuggingFace模型没有太大区别。</p><p id="584b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">下面显示了每个类的2个例子。</p><pre class="kw kx ky kz fd mc md me bn mf mg bi"><span id="c376" class="mh ig hi md b be mi mj l mk ml">from setfit import SetFitModel<br/><br/>model = SetFitModel.from_pretrained("tushifire/setfit_youtube_comments_is_a_question")<br/><br/># Run inference<br/>preds = model(["i loved the spiderman movie!", "pineapple on pizza is the worst 🤮"])<br/>preds<br/># array([False, False])<br/><br/>preds = model(["""what video do I watch that takes the html_output and insert it into the actual html page?""",<br/>               "Why does for loop end without a break statement"])<br/>preds<br/># array([ True,  True])</span></pre><p id="759e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">效果挺好的。</p><p id="e89c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们可以通过以下方式提高分类器的性能:</p><ol class=""><li id="613a" class="kh ki hi jf b jg kb jk kc jo kj js kk jw kl ka km kn ko kp bi translated">使用更大的预训练模型</li><li id="dab4" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">进行超参数搜索</li><li id="00fe" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">找出与社交媒体评论、教育领域等领域相同的预训练模型。</li></ol><p id="62de" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在<a class="ae kg" href="https://www.kaggle.com/code/tushifire/setfit-few-shots-youtube-comments" rel="noopener ugc nofollow" target="_blank"> kaggle笔记本</a>看完整代码。</p><h1 id="025a" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">参考</h1><ol class=""><li id="17e1" class="kh ki hi jf b jg jh jk jl jo lz js ma jw mb ka km kn ko kp bi translated">数据市场:<a class="ae kg" href="https://www.grandviewresearch.com/industry-analysis/data-collection-labeling-market" rel="noopener ugc nofollow" target="_blank">https://www . grandview research . com/industry-analysis/data-collection-labeling-Market</a></li><li id="a917" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">拥抱脸博客:<a class="ae kg" href="https://huggingface.co/blog/setfit" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/blog/setfit</a></li><li id="43ac" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">预训车型:<a class="ae kg" href="https://www.sbert.net/docs/pretrained_models.html" rel="noopener ugc nofollow" target="_blank">https://www.sbert.net/docs/pretrained_models.html</a></li><li id="37f6" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">Github回购:<a class="ae kg" href="https://github.com/huggingface/setfit" rel="noopener ugc nofollow" target="_blank">https://github.com/huggingface/setfit</a></li><li id="e890" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">高效的无提示少投学习<a class="ae kg" href="https://arxiv.org/abs/2209.11055" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2209.11055</a></li></ol></div></div>    
</body>
</html>