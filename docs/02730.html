<html>
<head>
<title>ML algorithms 1.09: Gradient Boosting Machines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最大似然算法1.09:梯度推进机器</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/ml-algorithms-1-09-1-gradient-boosted-machines-9abd09c4bdfe?source=collection_archive---------45-----------------------#2021-05-24">https://medium.com/geekculture/ml-algorithms-1-09-1-gradient-boosted-machines-9abd09c4bdfe?source=collection_archive---------45-----------------------#2021-05-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/43261f9c61e96eab088f717130126449.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U_ixWe72FnWTgNRBnWM4jA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Souce: <a class="ae iu" href="https://unsplash.com/photos/90siM5kmRbM?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditShareLink" rel="noopener ugc nofollow" target="_blank">Shapelined</a></figcaption></figure><h2 id="e929" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">介绍</h2><p id="9a02" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">梯度推进机器是一种推进集成技术。增强算法性能更好，因为方差和偏差都可以通过仔细的超参数调整来控制。与AdaBoost中的树桩相比，GBM使用浅层决策树。它们的预测/估计性能介于AdaBoost和XGBoost之间。GBM的优点是性能比AdaBoost好，但机制比XGBoost简单。</p><h2 id="2a2a" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">模型</h2><p id="0efc" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">设<strong class="jv hj"> X </strong>为具有<em class="ko"> m </em>个样本和<em class="ko"> n </em>个特征的特征集。设<strong class="jv hj"> y </strong>为连续响应。</p><p id="c59e" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">模型的参数表示为:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ku"><img src="../Images/9a3f6f125db3527e29c5a3dcb9349f1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3kZg9Q6x1nt3iFCW.png"/></div></div></figure><p id="abf5" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">对于回归:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es kz"><img src="../Images/935f8758a59b924200c950c5fdddbf1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/0*k44nr7SaYGTGb12w.png"/></div></figure><p id="d1ef" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">对于分类:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es kz"><img src="../Images/3a47fce0c4feee06fc7c239ca1ff824a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/0*VtmMYpoGSqj_b_tH.png"/></div></figure><p id="073e" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">这里，通过softmax函数预测的类别k的概率由下式给出:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es la"><img src="../Images/1c19c9ab95d2e5d7e90d5bebc7b44bdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/0*7kH5FAsg_jFQP96C.png"/></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es lb"><img src="../Images/eb7e080a7eb5d5dedea90bb7cf47c03a.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/0*yix8jdzgrYdj8fQJ.png"/></div></figure><p id="56e0" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">在GBM分类中，我们为K个类建立K棵平行树。</p><p id="dcf6" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">当我们创建第一棵树时，它只有根节点，这是回归问题所有响应的平均值。对于分类问题，根节点的softmax值是最初数据中所有类别中的类别k的分数。对于我们随后构建的每棵树<em class="ko"> t </em>,我们尝试使树适合残差。在分类中，残差的计算方式与回归树中相同，因为实际上，我们正在为每个k类构建回归树，以匹配k类的概率。残差的计算方式如下:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es lc"><img src="../Images/92fe6afbb46ee5f7018b5dd2f22713b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/0*zn__ZfoCzCwTyLWM.png"/></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es ld"><img src="../Images/538e8f0fc01fd39204442bc2d719934b.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/0*hxmTCKXJE2SOyMD8.png"/></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es le"><img src="../Images/111a614fd81282a4053811bfcc9c1720.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/0*lyrxT5NA8YISdzWy.png"/></div></figure><p id="6d51" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">我们使用MSE或其他分裂标准<strong class="jv hj">将树<em class="ko"> t </em>拟合到残差，用于回归和分类</strong>。与先前的树相比，发生了不同的分裂，因为该树正被拟合到残差，该残差正接近实际的<strong class="jv hj"> <em class="ko"> y </em> </strong> <em class="ko"> </em>并且每个树都被构造。此后，我们必须优化损失函数L，如下所示:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/331cbdf827bbae6a5faeb4fcb88b1837.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/0*AfzCggH-0HdbXAcY.png"/></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lg"><img src="../Images/4bfe79eb702c34b1c7237cc9b77156b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cUDBC6qcGcQiEZHx.png"/></div></div></figure><p id="126e" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">被提升的树很浅。对于每个残差，根据其特征(n个特征)，它到达树t中的特定叶子。总共<strong class="jv hj"> m </strong>个观察值(引导后)将到达叶子。所以，<em class="ko">一般来说</em>不止一个观测到达每片叶子。我们需要以连续的方式找到每片树叶的最佳值。</p><p id="10ff" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">对于回归，我们需要找到损失函数l的梯度。回归的损失函数由MSE给出:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/5b380bcd0128186a86e10ea70ea6a5b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/0*NSee9Ul5dsqANHPe.png"/></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es li"><img src="../Images/78187405db930d441184fbc2e7164575.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/0*8mXlXbl6wlcVvbpA.png"/></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/abb64a06e6974eadddaafa769e5fdbea.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/0*EaBtApSA-XpcT2bh.png"/></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/266d46d4b8e9c4aaafb82f344f8856d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/0*ZhwDBX3JLomBw_hg.png"/></div></figure><p id="1437" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">对于分类，我们需要找到类别k的损失函数L的梯度。GBM分类问题的损失函数由多项式偏差给出:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/4d99a4f4eb8f6b38ad4f1b40c3a43274.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*us6eto-a14wQ-_7p.png"/></div></div></figure><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/0a4fe13df9c85f7607516ea3c9019056.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/0*-8WxaVk8kEX6QVQl.png"/></div></figure><p id="1308" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">粗略地说，在树t中，对于类k，在每片叶子中，γ是该类是k的概率。通过求解上面的方程，我们得到每片叶子的最佳γ。随着每棵树的构建，我们在损失函数的负梯度方向上移动<strong class="jv hj"> L </strong>接近实际的<strong class="jv hj"> y. </strong></p><p id="4f2b" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">在树t建立之后，树t输出估计值如下:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/275e28d31c3a2bed4eb4336ca9275a10.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*RfZaT0e8ry7_VjrTUaBjRQ.png"/></div></figure><p id="8922" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">对于分类，具有最高概率的类作为输出给出。</p><p id="b825" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">下一棵树t的残差计算如下:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="ab fe cl lo"><img src="../Images/53e013e4213d962147164220cc4b0e81.png" data-original-src="https://miro.medium.com/v2/format:webp/1*uEzlnEtg__rik2OpFs4gHQ.png"/></div></figure><p id="53ae" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">以这种方式构建树，直到树的最大数量被构建或者残差低于某个阈值ε。</p><h2 id="b804" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">预言；预测；预告</h2><p id="8446" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">增强机器的最终预测是所有树的预测的总和，这些树由学习率加权。</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/66f19baf6f0b82867f78b682748ce27c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mb_OvyD5ukZwMZ62oR_mvA.png"/></div></div></figure><p id="bc62" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">参考资料:</p><p id="c76c" class="pw-post-body-paragraph jt ju hi jv b jw kp jy jz ka kq kc kd jg kr kf kg jk ks ki kj jo kt kl km kn hb bi translated">我参考了Josh Starmer在他的渐变增强视频中展示的一些材料。其余内容来自学校教授的课程材料。</p></div></div>    
</body>
</html>