<html>
<head>
<title>Dynamic Self Organizing Maps (GSOM)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">动态自组织地图(GSOM)</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/dynamic-self-organizing-maps-gsom-60a785fbe39d?source=collection_archive---------13-----------------------#2021-03-09">https://medium.com/geekculture/dynamic-self-organizing-maps-gsom-60a785fbe39d?source=collection_archive---------13-----------------------#2021-03-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="0052" class="hg hh hi bd b fp hj hk hl hm hn ho dx hp translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="7947" class="pw-subtitle-paragraph io hr hi bd b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf dx translated">不断增长的自组织地图——简介</h2></div><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es jg"><img src="../Images/ef468e6f551e86a4d2fb5ffb7053e60a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aTOBGoXwF_ak-wbp.jpeg"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx">Fig.1. GSOM Map: Photo by Author generated for an Experiment</figcaption></figure><p id="8914" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">作为计算机科学与工程专业的最后一年本科生，我目前正在参与一个与视频监控相关的项目，我经常遇到SOM和GSOM，因为我们正在与“无监督”学习密切合作。使用GSOM很有意思，因为它在保持拓扑结构的同时支持降维。下面的文章更多的是对GSOM论文的总结。</p></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="7147" class="kz la hi bd lb lc ld le lf lg lh li lj ix lk iy ll ja lm jb ln jd lo je lp lq bi translated">SOM及其局限性</h1><p id="76bc" class="pw-post-body-paragraph jw jx hi jy b jz lr is kb kc ls iv ke kf lt kh ki kj lu kl km kn lv kp kq kr hb bi translated">我们用来研究和利用的数据由复杂的模式组成，并且通常是高维的。一般来说，主要的问题不是找出模式，而是从许多现有的模式中找出<strong class="jy hs"> <em class="lw">有用的模式</em> </strong>。对于这种由复杂的未知结构组成的数据集，聚类变得至关重要。无监督的降维和聚类/模式识别方法更有益，因为无监督是一种非定向技术，并且能够很好地处理不同的数据类型。</p><p id="9e65" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">自组织映射(SOM)已被用作将高维数据映射成二维(或三维)特征图的工具[1]。由于SOM可以保持数据的拓扑结构，因此特征图可以用来观察和解释数据的结构。SOM还可以用于从高维输入空间到简单的二维或三维输出空间的降维。</p><h1 id="aa43" class="kz la hi bd lb lc lx le lf lg ly li lj ix lz iy ll ja ma jb ln jd mb je lp lq bi translated">SOM设计的目标行为是相似的输入应该激发较近的神经元，而不同的(变化的)输入应该激发较远的神经元[1]。</h1><p id="c777" class="pw-post-body-paragraph jw jx hi jy b jz lr is kb kc ls iv ke kf lt kh ki kj lu kl km kn lv kp kq kr hb bi translated">SOM主要由<strong class="jy hs">三层</strong>组成；输入层、竞争层和输出层。</p><ol class=""><li id="c340" class="mc md hi jy b jz ka kc kd kf me kj mf kn mg kr mh mi mj mk bi translated"><strong class="jy hs">输入层— </strong>接受多维输入向量。</li><li id="5450" class="mc md hi jy b jz ml kc mm kf mn kj mo kn mp kr mh mi mj mk bi translated"><strong class="jy hs">竞争层— </strong>来自输入层的多个加权输入由竞争层中的每个神经元获得。竞争层中的每个神经元也与其他神经元相关联，形成其“邻居”。竞争层通常实现为一维或二维。在接收到给定的输入时，一些神经元将被激发，导致对邻近神经元的减速(惩罚)或加速(促进)效应。</li></ol><p id="cdab" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">3.<strong class="jy hs">输出层— </strong>我们希望解释竞争层中节点之间的互连的方式。</p><p id="12cd" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">SOM算法可以分解为:</p><blockquote class="mq mr ms"><p id="cb12" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">启动(随机)</p><p id="4638" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">竞争(横向抑制连接和选择获胜者节点)</p><p id="7b8f" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">合作(确定一个社区)</p><p id="a0ff" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">自适应(累积权重并更新获胜者及其邻居节点)</p><p id="1a90" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">平滑(随着迭代的增加，减小<strong class="jy hs">邻域半径</strong>或引入可选的平滑阶段)</p></blockquote><p id="5366" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">但是<strong class="jy hs"> <em class="lw"> SOM不是动态的</em> </strong>并且本质上要求具有预定的网络结构。这是一个限制，可以通过动态地允许SOM网络增长和构造自己来解决。此外，预先确定SOM的结构的必要性可能导致过早形成簇而不是被组织成适当的簇的情况。解决这些问题需要动态增长的自组织地图(GSOM)。</p></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="174c" class="kz la hi bd lb lc ld le lf lg lh li lj ix lk iy ll ja lm jb ln jd lo je lp lq bi translated">成长自组织地图</h1><p id="a4cb" class="pw-post-body-paragraph jw jx hi jy b jz lr is kb kc ls iv ke kf lt kh ki kj lu kl km kn lv kp kq kr hb bi translated">GSOM是自组织映射的扩展，可以动态增长。GSOM算法可以在<strong class="jy hs"> <em class="lw">三个</em> </strong>阶段研究，决定GSOM的重要参数很少。</p><h1 id="ee36" class="kz la hi bd lb lc lx le lf lg ly li lj ix lz iy ll ja ma jb ln jd mb je lp lq bi translated">重要参数</h1><p id="6237" class="pw-post-body-paragraph jw jx hi jy b jz lr is kb kc ls iv ke kf lt kh ki kj lu kl km kn lv kp kq kr hb bi translated"><strong class="jy hs">展开因子</strong>:用于控制GSOM节点/节点图的展开。它取0到1之间的值。扩展因子不依赖于数据的维度。</p><p id="84f7" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated"><strong class="jy hs">增长阈值:</strong>启动节点生成的阈值。当误差(<strong class="jy hs">输入向量和权重向量之间的差</strong>)大于增长阈值时，强制生成新的节点。如果GT较高，将导致GSOM分布较少，而当GT较低时，将导致GSOM分布较好。</p></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="b853" class="kz la hi bd lb lc ld le lf lg lh li lj ix lk iy ll ja lm jb ln jd lo je lp lq bi translated">GSOM算法</h1><h1 id="39b2" class="kz la hi bd lb lc lx le lf lg ly li lj ix lz iy ll ja ma jb ln jd mb je lp lq bi translated">1.初始阶段</h1><p id="a0a9" class="pw-post-body-paragraph jw jx hi jy b jz lr is kb kc ls iv ke kf lt kh ki kj lu kl km kn lv kp kq kr hb bi translated">在这个特定阶段，算法用随机数初始化起始节点的权重向量。一般来说，GSOM算法从4个节点开始，这4个节点提供了在它们想要的方向上生长的自主权，因为它们都是边界节点。</p><p id="1481" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">数值变量<strong class="jy hs"> H_err </strong>在初始化时被初始化为“0”。<strong class="jy hs"> <em class="lw">展开因子</em> </strong> (SF)必须在此阶段指定。并且该算法还倾向于根据指定的要求计算给定数据集的<strong class="jy hs"> <em class="lw">增长阈值</em> </strong> (GT)。GT将作为启动节点生成的阈值。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es mw"><img src="../Images/58c335257bb09f768cc613a3f45435de.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/0*h5anuDKoL4Oqj1k9.jpeg"/></div><figcaption class="js jt et er es ju jv bd b be z dx">Fig.2. Initial GSOM(A)</figcaption></figure><blockquote class="mq mr ms"><p id="aeb7" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated"><strong class="jy hs">初始化阶段总结:</strong></p><p id="02ab" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">-用0和1之间的随机数初始化起始节点(通常为4个)的权重向量。</p><p id="4575" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">-确定扩散系数(SF)</p><p id="2066" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">-使用公式<strong class="jy hs"> GT = -D x ln(SF) </strong>计算具有<strong class="jy hs"> (D) </strong>维度和已定义的扩展因子<strong class="jy hs"> (SF) </strong>的数据集的增长阈值<strong class="jy hs"> (GT) </strong></p></blockquote><h1 id="933d" class="kz la hi bd lb lc lx le lf lg ly li lj ix lz iy ll ja ma jb ln jd mb je lp lq bi translated">2.生长阶段</h1><p id="5ee0" class="pw-post-body-paragraph jw jx hi jy b jz lr is kb kc ls iv ke kf lt kh ki kj lu kl km kn lv kp kq kr hb bi translated">我们现在在这一阶段向网络提供输入。最初，类似于SOM ( <strong class="jy hs"> <em class="lw">)竞争阶段</em> </strong>)算法，GSOM也基于欧几里德距离将最接近输入向量的权重向量确定为获胜者(或<strong class="jy hs">【BMU】</strong>-最佳匹配单元)。GSOM可以被认为是输入空间的2D表示，其中输入空间被权重向量(W_i)划分为Voronoi区域(V_i ),并且每个Voronoi区域由一个神经元(I)表示。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es mx"><img src="../Images/6132c3df53bb374ee57d352d81d342c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/0*3XAIDdoqJZxPjNlF.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx">Fig.3. Voronoi Diagram — Photo by Charles Francis in Quora</figcaption></figure><blockquote class="mq mr ms"><p id="7f99" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">Voronoi图是将一个平面划分成靠近一组给定对象中的每一个的区域。在最简单的情况下，这些物体只是平面上有限多的点。对于每一粒种子，都有一个相应的区域，由平面上离该种子比离其他任何一粒种子都近的所有点组成。”[3].</p></blockquote><p id="25ba" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated"><strong class="jy hs"><em class="lw">SOM的合作和适应</em> </strong>阶段之后，权重更新仅发生在BMU和获胜者的邻域。在GSOM，与SOM相比，起始邻域被选择得更小。</p><p id="bb18" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">当该节点的总误差(特定节点的权重向量和输入权重向量之间的<strong class="jy hs">差)</strong>小于增长阈值(GT)时；即，如果，<strong class="jy hs"> H_err &lt; GT </strong>，则该算法不允许增长新的节点。但当节点的总误差<strong class="jy hs"> <em class="lw">大于增长阈值</em></strong>(GT)时；即<strong class="jy hs"> H_err &gt; GT </strong></p><ul class=""><li id="afec" class="mc md hi jy b jz ka kc kd kf me kj mf kn mg kr my mi mj mk bi translated"><strong class="jy hs"> <em class="lw">在边界节点</em> </strong>中生成新节点。并且在所有空闲的相邻位置上生成新节点，因为计算出新节点的最佳精确位置的计算成本更高。</li></ul><blockquote class="mq mr ms"><p id="5824" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">“一个<strong class="jy hs">边界节点</strong>至少有一个紧邻位置没有节点”[1]。在定义每个节点最多可以有4个直接邻居的GSOM中，边界节点是指可以增加3个邻居或者可以在剩余的三个方向上移动的节点。</p></blockquote><ul class=""><li id="e62f" class="mc md hi jy b jz ka kc kd kf me kj mf kn mg kr my mi mj mk bi translated">在生成新节点后，更新权重是必要的。有<strong class="jy hs">四种</strong>可能的方式(见图4。)</li></ul><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es mz"><img src="../Images/0cf961459776b4d53c8eda2b719a17e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/0*LgCU3_m_TYHHAneX.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx">Fig.4. Weight updating in GSOM new nodes by Damminda et al.</figcaption></figure><ol class=""><li id="1a45" class="mc md hi jy b jz ka kc kd kf me kj mf kn mg kr mh mi mj mk bi translated">当在其一侧时，新节点以连续的方式具有两个旧节点(图4(a))</li></ol><p id="7797" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">= &gt; if W2 &gt; W1 = &gt;<strong class="jy hs">W _ new</strong>= W1-(W2—W1)</p><p id="6365" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">= &gt;如果W1 &gt; W2 = &gt;<strong class="jy hs">W _ new</strong>= W1+(W1-W2)</p><p id="8547" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">2.当新节点被放置在两个旧节点之间时(图4(b))</p><p id="d3ad" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">=&gt; <strong class="jy hs"> W_new = (W1+W2)/2 </strong></p><p id="b50a" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">3.当新节点只有一个作为旧节点的<em class="lw">直接</em>邻居时(图4(c))</p><p id="df29" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">= &gt; if W2 &gt; W1 = &gt;<strong class="jy hs">W _ new</strong>= W1-(W2-W1)</p><p id="a052" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">= &gt;如果W1 &gt; W2 = &gt;<strong class="jy hs">W _ new</strong>= W1+(W1-W2)</p><p id="98b4" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">4.当节点因老化后被移除而被隔离时，生成的新节点只有一个相邻的旧节点</p><p id="5f11" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">= &gt;<strong class="jy hs">W _ new =</strong>(R1+R2)/2；r_1，r_2唯一一个相邻节点的权向量的范围的下限值和上限值。</p><blockquote class="mq mr ms"><p id="5bdc" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated"><strong class="jy hs">成长阶段总结:</strong></p><p id="2674" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">-基于输入向量与神经元的最接近度来选择优胜节点/神经元。</p><p id="f88b" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">特定输入的获胜者向量和输入向量之间的差被累积为该神经元的误差值(I)。</p><p id="6597" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">-如果由特定权重向量贡献的误差对累积误差贡献很大，则将决定生成新的神经元，因为较高的误差贡献指的是胜出的神经元不是输入向量的最佳代表。</p><p id="0fa8" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">-将创建新节点，从边界节点开始增长。对于新节点，权重增加。</p></blockquote><h1 id="2807" class="kz la hi bd lb lc lx le lf lg ly li lj ix lz iy ll ja ma jb ln jd mb je lp lq bi translated">3.平滑阶段</h1><p id="d730" class="pw-post-body-paragraph jw jx hi jy b jz lr is kb kc ls iv ke kf lt kh ki kj lu kl km kn lv kp kq kr hb bi translated">当创建的新节点越来越少时，增长阶段停止，平滑阶段开始。在这个平滑阶段，该算法降低了学习率并固定了一个小的起始邻域。</p><blockquote class="mq mr ms"><p id="5dda" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">D <strong class="jy hs">平滑阶段和生长阶段的差异</strong></p><p id="9100" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">-仅考虑直接连接的节点的权重自适应</p><p id="a352" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated">-不添加新节点。</p></blockquote></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="a447" class="kz la hi bd lb lc ld le lf lg lh li lj ix lk iy ll ja lm jb ln jd lo je lp lq bi translated">为什么GSOM这么有优势？</h1><ul class=""><li id="7bd9" class="mc md hi jy b jz lr kc ls kf na kj nb kn nc kr my mi mj mk bi translated">GSOM是一种无监督的方法，可用于对一组先验未知的数据进行聚类。</li><li id="f7a3" class="mc md hi jy b jz ml kc mm kf mn kj mo kn mp kr my mi mj mk bi translated">GSOM是一种可视化技术，可为数据分析师提供更多洞察，从而从2D地图的更复杂数据中发现模式。</li><li id="a5fe" class="mc md hi jy b jz ml kc mm kf mn kj mo kn mp kr my mi mj mk bi translated">GSOM也擅长降维。它能够将高维数据映射到二维数据。</li><li id="c907" class="mc md hi jy b jz ml kc mm kf mn kj mo kn mp kr my mi mj mk bi translated">允许动态增长。因为不需要预先确定网络的结构，所以还可以防止过早形成簇，而不是组织成适当的簇。</li></ul></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><h1 id="975f" class="kz la hi bd lb lc ld le lf lg lh li lj ix lk iy ll ja lm jb ln jd lo je lp lq bi translated">参考</h1><p id="1178" class="pw-post-body-paragraph jw jx hi jy b jz lr is kb kc ls iv ke kf lt kh ki kj lu kl km kn lv kp kq kr hb bi translated">[1] T. Kohonen，自组织地图。德国柏林:SpringerVerlag，1995。</p><p id="e32e" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">[2]“用于知识发现的控制增长的动态自组织图”，Damminda Alahakoon，Saman K. Halgamuge，IEEE成员，和Bala Srinivasan，2000年5月。</p><p id="8a9a" class="pw-post-body-paragraph jw jx hi jy b jz ka is kb kc kd iv ke kf kg kh ki kj kk kl km kn ko kp kq kr hb bi translated">[3] A. Okabe，B. Boots和K. Sugihara，Voronoi图的空间镶嵌、概念和应用。纽约:威利出版社，1992年</p></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><blockquote class="mq mr ms"><p id="3302" class="jw jx lw jy b jz ka is kb kc kd iv ke mt kg kh ki mu kk kl km mv ko kp kq kr hb bi translated"><em class="hi">注意:感谢您读到这里，如果您在理解上遇到任何挑战或我的解释中有错误，我们可以一起讨论。我之前的博客关于</em> <a class="ae nd" rel="noopener" href="/datadriveninvestor/how-does-self-organizing-algorithm-works-f0664af9bf04"> <em class="hi"> SOM </em> </a> <em class="hi">讨论了更多的数学(或者更确切地说是面向考试)方法，但这里更多的是对GSOM的解释。</em></p></blockquote></div></div>    
</body>
</html>