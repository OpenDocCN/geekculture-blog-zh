<html>
<head>
<title>Introduction to Bayesian methods</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯方法介绍</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/introduction-to-bayesian-methods-9e31eaab5978?source=collection_archive---------15-----------------------#2021-11-25">https://medium.com/geekculture/introduction-to-bayesian-methods-9e31eaab5978?source=collection_archive---------15-----------------------#2021-11-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="99ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章是用最简单的话向机器学习从业者介绍贝叶斯方法。先来一张图，一个问题。</p><h2 id="dab5" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">贝叶斯思维的原则</h2><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es jy"><img src="../Images/3f5433e066446746733982da0cf6fa5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HTggtVDhYh35ufTYVnInkQ.jpeg"/></div></div><figcaption class="kk kl et er es km kn bd b be z dx">Photo by <a class="ae ko" href="https://unsplash.com/@nathanael240606?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Nathanaël Desmeules</a> on <a class="ae ko" href="https://unsplash.com/t/athletics?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="1d62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个男人为什么骑自行车？有几种可能的答案:</p><ul class=""><li id="6a1e" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated">他正在参加一场体育比赛。</li><li id="c604" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">他在去上班的路上。</li><li id="1d58" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">他被一条龙追赶。</li></ul><p id="75cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从他的职业运动服来看，我会选择第一个答案。当然，第二个和第三个答案可能是真的(例如在电影场景中)，但我们只根据图片中的信息做出预测。贝叶斯思维的几个原则是:</p><ol class=""><li id="5bc2" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ld kv kw kx bi translated">利用先前的知识。(除了在比赛中，人们通常不穿专业的自行车装备)</li><li id="ec10" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ld kv kw kx bi translated">选择最能解释观察结果的。(图中没有工作的迹象，也没有龙)</li><li id="d5c0" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ld kv kw kx bi translated">避免做额外的假设。(如果没有龙，我们就不假设这张图的框架外有龙存在)</li></ol><h2 id="8f3a" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">贝叶斯定理</h2><p id="1c3f" class="pw-post-body-paragraph if ig hi ih b ii le ik il im lf io ip iq lg is it iu lh iw ix iy li ja jb jc hb bi translated">在著名的核心函数之前，我们需要知道两个规则:链式规则和求和规则。链式法则表明，联合概率分布可以分解成一系列条件分布。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es lj"><img src="../Images/0bf25109234c3cb8580a157db3591229.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*XfTZ5L_7_jtR49xvWQLfdw.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx"><a class="ae ko" href="https://www.coursera.org/learn/bayesian-methods-in-machine-learning/lecture/rPZgT/think-bayesian-statistics-review" rel="noopener ugc nofollow" target="_blank">https://www.coursera.org/learn/bayesian-methods-in-machine-learning/lecture/rPZgT/think-bayesian-statistics-review</a></figcaption></figure><p id="7ced" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">求和规则说，给定一个联合概率分布，我们可以得到一个随机变量的分布，如果我们对另一个进行积分，如下所示。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es lk"><img src="../Images/a0baa003289cac2985f52da5b5f93686.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*7OEW8tZs5HxKZn-pPFBytQ.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx"><a class="ae ko" href="https://www.coursera.org/learn/bayesian-methods-in-machine-learning/lecture/rPZgT/think-bayesian-statistics-review" rel="noopener ugc nofollow" target="_blank">https://www.coursera.org/learn/bayesian-methods-in-machine-learning/lecture/rPZgT/think-bayesian-statistics-review</a></figcaption></figure><p id="b395" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们有下面显示的最重要和非常简单的贝叶斯定理公式，其中θ表示模型中的一组参数，X表示观察数据。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es ll"><img src="../Images/6aafa6c18edd40747ed82a9c0433def3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eh--QbG11aE-dzTHcmXSsg.jpeg"/></div></div></figure><p id="be65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个公式是如此重要，以至于我们对公式中的每个部分都有正式的名称，即后验、先验、似然和证据。</p><ul class=""><li id="ec64" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated">先验:我们对参数的假设。请注意，在最简单的情况下，我们只有一个标量参数，假设该值受标准正态分布控制。</li><li id="ae42" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">证据:观察数据的分布。同样，它是高度抽象的，证据可以用多种方式表达:图片的像素值数组，句子的一键编码序列，等等。</li><li id="dbce" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">可能性:我们的参数如何解释观察到的数据。</li><li id="0df3" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">后验:给定观测数据，这组参数在现实世界中发生的概率有多大？</li></ul><p id="133a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如上图所标注的，证据概率分布也可以通过求和规则来计算。但是只要想想我们现在的深度学习模型有多复杂(一个简单的任务就有几百万个参数)。大多数时候都很棘手。</p><h2 id="93be" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">作为正则项的先验假设</h2><p id="392a" class="pw-post-body-paragraph if ig hi ih b ii le ik il im lf io ip iq lg is it iu lh iw ix iy li ja jb jc hb bi translated">下图是我对单变量/多变量正态分布及其概率密度分布的注释。此外，我还展示了具有选定先验的贝叶斯网络(不是贝叶斯神经网络)如何与具有L2正则化的最小二乘问题完全相同。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es lm"><img src="../Images/834c6914b04ec59ce0d4febee4a1c5e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yvyvbX5XkvviUBAJXsd1Dg.jpeg"/></div></div></figure><p id="13bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最小二乘问题就像机器学习的Hello World，在这里，您希望用一条线来拟合2D平面上的一组数据点。我不应该浪费你的时间，因为这里有一个完美的视觉效果。最小二乘问题是带有平方损失的第一次回归。</p><p id="a0af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从我的笔记中，你可以看到贝叶斯网络是一个有向图。我们用此图建立了最小二乘问题的模型:权重和数据都会影响目标值(因此有指向箭头)。我们假设先验服从正态分布。</p><p id="24be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你不想看方程，我希望你有这样的收获:正态分布假设意味着权重是围绕平均值形成的，并由标准差控制，这在直觉上与L2正则化相同。</p><h2 id="2399" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">分析推理</h2><p id="dfb4" class="pw-post-body-paragraph if ig hi ih b ii le ik il im lf io ip iq lg is it iu lh iw ix iy li ja jb jc hb bi translated">让我们重温一下贝叶斯定理来评估计算证据概率分布的困难性。</p><p id="28f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，我们正在对奈良美智的画做一些工作。主要目标可以是任何东西，比如那些孩子的性别？(如果我们有图片的标签，就可以进行监督学习)在我们最大化参数的后验概率之前(假设在深度神经网络中)，我们要计算P(X)，这本身就是一个非常难的问题。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div class="er es ln"><img src="../Images/821fee3d0295938904fef248a6877948.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*M1o5gidh_fDnOCQObpf9QA.png"/></div><figcaption class="kk kl et er es km kn bd b be z dx">Yoshitomo Nara is famous for drawing kids</figcaption></figure><p id="c63c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是深度学习模型解决的普遍生成任务，如<a class="ae ko" href="https://en.wikipedia.org/wiki/Variational_autoencoder" rel="noopener ugc nofollow" target="_blank"/>或<a class="ae ko" href="https://en.wikipedia.org/wiki/Generative_adversarial_network" rel="noopener ugc nofollow" target="_blank">甘</a>。为了学习一个P(X ),我们正在重建一个机器画家，他画的和奈良美智一模一样。为什么我们要为了完成简单的任务而去实现困难的目标呢？</p><p id="3c9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们求助于最大后验概率(MAP)估计来避免计算证据。我们想计算贝叶斯公式中后验概率的arg max/Theta。如果你想清楚了，P(X)在这个任务中是无关紧要的，我们可以忽略它。你想对P(X|Theta)P(Theta)求导，让它为零。然后你会得到θ的点估计。</p><figure class="jz ka kb kc fd kd er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es ll"><img src="../Images/6aafa6c18edd40747ed82a9c0433def3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eh--QbG11aE-dzTHcmXSsg.jpeg"/></div></div></figure><p id="25ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我在这里跳到地图的反面。</p><ul class=""><li id="020f" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated">对于重新参数化不是不变的。(将sigmoid函数放到标准正态分布上，你会发现最大值发生了变化)</li><li id="6687" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">不能作为先验，因为这是点估计。</li><li id="5f06" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">这很可能是一个不典型的点。(容易出现异常值)</li></ul><h2 id="eabf" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">共轭先验</h2><p id="41ec" class="pw-post-body-paragraph if ig hi ih b ii le ik il im lf io ip iq lg is it iu lh iw ix iy li ja jb jc hb bi translated">我们还可以通过选择共轭先验来避免计算证据概率分布。维基百科的定义如下，</p><blockquote class="lo lp lq"><p id="4be2" class="if ig lr ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">在<a class="ae ko" href="https://en.wikipedia.org/wiki/Bayesian_probability" rel="noopener ugc nofollow" target="_blank">贝叶斯概率</a>理论中，如果<a class="ae ko" href="https://en.wikipedia.org/wiki/Posterior_probability" rel="noopener ugc nofollow" target="_blank">后验分布</a><em class="hi">p</em>(<em class="hi">θ</em>|<em class="hi">x</em>)与<a class="ae ko" href="https://en.wikipedia.org/wiki/Prior_probability_distribution" rel="noopener ugc nofollow" target="_blank">先验概率分布</a> <em class="hi"> p </em> (θ)在同一个<a class="ae ko" href="https://en.wikipedia.org/wiki/List_of_probability_distributions" rel="noopener ugc nofollow" target="_blank">概率分布族</a>中，则先验和后验称为<strong class="ih hj">共轭分布，</strong>和先验称为<strong class="ih hj">共轭先验</strong></p><p id="060a" class="if ig lr ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">——<a class="ae ko" href="https://en.wikipedia.org/wiki/Conjugate_prior" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Conjugate_prior</a></p></blockquote><p id="853d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用一句话来说，如果它看起来(字面上)像一个先验，你检查后验。共轭关系是先验和似然之间的关系。如果我们有共轭先验，我们就能有精确的后验，这真是太棒了。唯一的缺陷是，我们只有几对共轭关系，大多数时候，它们不足以解决我们的问题。</p><p id="3088" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里列出了一些常见的分布:伽玛/贝塔/伯努利/正态/等等。</p><h2 id="a0d1" class="jd je hi bd jf jg jh ji jj jk jl jm jn iq jo jp jq iu jr js jt iy ju jv jw jx bi translated">参考</h2><div class="lv lw ez fb lx ly"><a href="https://www.coursera.org/learn/bayesian-methods-in-machine-learning" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab dw"><div class="ma ab mb cl cj mc"><h2 class="bd hj fi z dy md ea eb me ed ef hh bi translated">机器学习的贝叶斯方法</h2><div class="mf l"><h3 class="bd b fi z dy md ea eb me ed ef dx translated">人们在许多领域应用贝叶斯方法:从游戏开发到药物发现。他们给了很多人超能力…</h3></div><div class="mg l"><p class="bd b fp z dy md ea eb me ed ef dx translated">www.coursera.org</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ki ly"/></div></div></a></div></div></div>    
</body>
</html>