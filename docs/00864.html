<html>
<head>
<title>Different Activation Functions for Deep Neural Networks You Should Know</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度神经网络的不同激活函数你应该知道</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/different-activation-functions-for-deep-neural-networks-you-should-know-ea5e86f51e84?source=collection_archive---------2-----------------------#2021-03-16">https://medium.com/geekculture/different-activation-functions-for-deep-neural-networks-you-should-know-ea5e86f51e84?source=collection_archive---------2-----------------------#2021-03-16</a></blockquote><div><div class="ds hc hd he hf hg"/><div class="hh hi hj hk hl"><div class=""/><div class=""><h2 id="5be8" class="pw-subtitle-paragraph il hn ho bd b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc dx translated">深度神经网络中使用的新的和流行的激活函数的快速快照</h2></div><p id="03b1" class="pw-post-body-paragraph jd je ho jf b jg jh ip ji jj jk is jl jm jn jo jp jq jr js jt ju jv jw jx jy hh bi translated"><strong class="jf hp"> <em class="jz">了解深度神经网络常用的激活函数:Sigmoid、Softmax、tanh、ReLU、Softplus、PReLU、ReLU6、eLU、SELU、Swish、Mish</em>T3】</strong></p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es ka"><img src="../Images/50cda2766e623b82a2f6a2e651a857d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*LIIoilXGJLdLpu_oTf_PSw.png"/></div></figure><h2 id="3d98" class="ki kj ho bd kk kl km kn ko kp kq kr ks jm kt ku kv jq kw kx ky ju kz la lb lc bi translated">深…的工作</h2></div></div>    
</body>
</html>