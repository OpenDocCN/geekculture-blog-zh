<html>
<head>
<title>Journey putting YOLO v7 model into TensorFlow Lite (Object Detection API) model running on Android</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将YOLO v7模型放入运行在Android上的TensorFlow Lite(对象检测API)模型的旅程</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/journey-putting-yolo-v7-model-into-tensorflow-lite-object-detection-api-model-running-on-android-e3f746a02fc4?source=collection_archive---------1-----------------------#2022-09-01">https://medium.com/geekculture/journey-putting-yolo-v7-model-into-tensorflow-lite-object-detection-api-model-running-on-android-e3f746a02fc4?source=collection_archive---------1-----------------------#2022-09-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="7143" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">前言</h1><p id="be0f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这篇文章不是关于如何将PyTorch模型转换为Tensorflow Lite模型的教程，而是我尝试在边缘设备(例如，Android)上使用YOLO v7(微型)PyTorch模型的旅程的总结。</p><p id="d22c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这篇文章可能没有使用最佳选项，因为它主要局限于我自己的技能和我的目标。</p><h2 id="cc7a" class="kg ig hi bd ih kh ki kj il kk kl km ip jo kn ko it js kp kq ix jw kr ks jb kt bi translated">我的技能</h2><p id="6f6c" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我认为自己足够了解PyTorch，在使用Tensorflow.js和Keras方面经验很少，但绝对没有使用TensorFlow v1和TensorFlow Lite的经验。</p><p id="81df" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">此外，我主要用React Native开发移动应用程序，因此学习如何开发Android应用程序是另一个挑战。</p><h2 id="7e8e" class="kg ig hi bd ih kh ki kj il kk kl km ip jo kn ko it js kp kq ix jw kr ks jb kt bi translated">那为什么不TensorFlow.js + React Native呢？</h2><p id="92e6" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我看到人们使用TensorFlow.js和React Native在移动设备上放置模型。但我的目标是将它放在边缘设备上，如Raspberry Pi或甚至ESP32/Arduino设备(不太可能有YOLOv7这样的巨型模型)，所以我坚持使用TensorFlow Lite(甚至TensorFlow Lite micro，这可能更具挑战性)</p><h2 id="19d7" class="kg ig hi bd ih kh ki kj il kk kl km ip jo kn ko it js kp kq ix jw kr ks jb kt bi translated">前言结束</h2><p id="be94" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我希望这篇文章能为那些想做同样或类似练习的人提供一些有用的信息。</p><h1 id="8847" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">我的皈依之旅</h1><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/953c587368f3ef61e4ab1bccab08f29c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wwSaaTbPJg0_0KmQdwND4w.png"/></div></div></figure><p id="525d" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这是我努力实现目标的道路。网上有很多关于如何将PyTorch模型转换为其他格式的文章(有些文章确实有相同的目标— TensorFlow Lite)，那么我的旅程有什么特别之处呢？</p><h2 id="846f" class="kg ig hi bd ih kh ki kj il kk kl km ip jo kn ko it js kp kq ix jw kr ks jb kt bi translated">我使用的图书馆</h2><ol class=""><li id="3b68" class="lg lh hi jf b jg jh jk jl jo li js lj jw lk ka ll lm ln lo bi translated"><strong class="jf hj"> PyTorch to ONNX </strong> — YOLO v7源代码提供了代码，它不仅覆盖了图形，而且令人惊讶的是，非最大值抑制操作也包含在图形中</li><li id="c640" class="lg lh hi jf b jg lp jk lq jo lr js ls jw lt ka ll lm ln lo bi translated"><strong class="jf hj"> ONNX to TensorFlow </strong> —一个叫onnx-tensorflow ( <a class="ae lu" href="https://github.com/onnx/onnx-tensorflow/" rel="noopener ugc nofollow" target="_blank"> Github链接</a>)的库，我相信这是ONNX github组织下最官方的库了</li><li id="19c5" class="lg lh hi jf b jg lp jk lq jo lr js ls jw lt ka ll lm ln lo bi translated"><strong class="jf hj"> TensorFlow到TensorFlow Lite </strong> —官方TensorFlow Python库中的TensorFlow Lite转换器(tf.lite.TFLiteConverter)</li></ol><h1 id="f841" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">打嗝/障碍</h1><h2 id="f418" class="kg ig hi bd ih kh ki kj il kk kl km ip jo kn ko it js kp kq ix jw kr ks jb kt bi translated">PyTorch YOLO v7模型与TensorFlow Lite对象检测API要求之间的输入/输出差异</h2><p id="e72a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jf hj"> <em class="lv">首先，为什么坚持使用TensorFlow Lite对象检测API？</em>T11】</strong></p><p id="1e7f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这是因为我不想从头开始开发Android上的客户端应用程序，所以我重用(更新)了TensorFlow Lite中的示例应用程序，它使用了对象检测API。</p><p id="89ab" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">另一种方法是使用较低级别的TensorFlow Lite解释器API，它可以在解释器会话运行之前和之后做任何事情，但需要对Android应用程序进行大量修改。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lw"><img src="../Images/36c5066019add9f6f654856e20bef9df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-8sQSgaKtNZcxyS6sg0Hhw.png"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx"><a class="ae lu" href="https://www.tensorflow.org/lite/examples/object_detection/overview" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/lite/examples/object_detection/overview</a></figcaption></figure><p id="fe47" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="lv">问题/症状</em> </strong></p><p id="d50d" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">因此，在经历了从PyTorch到TensorFlow Lite模型的转换代码后，将模型加载到应用程序中，应用程序抱怨它无法模仿模型。</p><p id="3ead" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在“adb logcat”的帮助下[这是为了提醒自己是如何实现的]，我看到错误是关于期望的输入维度的。</p><p id="94ea" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">根据<a class="ae lu" href="https://www.tensorflow.org/lite/inference_with_metadata/task_library/object_detector#model_compatibility_requirements" rel="noopener ugc nofollow" target="_blank">型号兼容性要求</a>:</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es mb"><img src="../Images/f051bf08f54ac94dbdb6f1aa0ce7128b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lhYFqBGEMJthUJ0HJwlh2g.png"/></div></div></figure><p id="b983" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="lv">输入差值</em> </strong></p><p id="9946" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">PyTorch图像处理使用布局NCWH(批量大小、通道、宽度、高度)，而TensorFlow Lite要求NWHC(批量大小、宽度、高度、通道)，这需要张量轴的置换。</p><p id="6913" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="lv">输出差值</em> </strong></p><p id="fc52" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这是关于YOLOv7模型预测输出，该模型会将每个检测结果的边界框、置信度得分和类别连接成大小为6的1个张量，如下所示:[x0，y0，x1，y1，score，class]</p><p id="e1e7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="lv">我尝试过/考虑过的</em> </strong></p><p id="e111" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> 1。[失败Android应用程序/ TensorFlow Lite库级别</strong></p><p id="c87d" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我探索的第一件事是在Android应用程序级别，我发现对象检测API似乎不是用Java编写的，TensroFlow Lite Java库通过jni与之交互，人们可以在<a class="ae lu" href="https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/java/src/native/task/vision/detector/object_detector_jni.cc" rel="noopener ugc nofollow" target="_blank"> tflite-support github查看源代码以获得对象检测的jni实现</a>(用C编写)，所以看起来像是使用对象检测API。</p><p id="95c0" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> 2。【使用】模型(在链中)级别</strong></p><p id="eb24" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">另一个想法是用转换步骤包装模型，以使预期的输入和输出一致。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ca"><img src="../Images/5e1fb69a5ec01cfcbc6a3900dff4f3ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FlMfUi7JuP3PWI1gqV43yw.png"/></div></div></figure><p id="d7f7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这条道路上有许多模式:</p><p id="c602" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj">tensor flow Lite model</strong>——这是以flatbuffer格式存储的，看起来不会被篡改</p><p id="712b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> TensorFlow SavedModel </strong> —以我对TensorFlow有限的了解，这个保存的模型应该被认为是静态图，虽然人们可能能够将其转换为Keras模型(或者ONNX导出到Keras模型，而不是这个静态图模型)并执行修改，但我选择通过。</p><p id="b153" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> ONNX graph </strong> —这是我最初的候选，我相信有一种方法可以执行这样的操作，因为它实际上是一个图形(模型中的每一层都被视为图形节点，计算是边)。</p><p id="ac75" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这种方法在Nvidia的TensorRT onnx-graphsurgeon库中是可行的，他们有如何修改图形的<a class="ae lu" href="https://github.com/NVIDIA/TensorRT/tree/main/tools/onnx-graphsurgeon/examples" rel="noopener ugc nofollow" target="_blank">示例</a>，所以我想在原始输入之前添加一个置换(NWHC到NCWH)节点，并在最后删除concat节点。</p><p id="72a6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我最终放弃了这个想法，因为我当时对图形结构不是太确定。</p><p id="e771" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> PyTorch模型</strong> —我没有考虑在PyTorch模型中执行“外科手术”作为首选，因为这涉及到模型向前传递后的“非最大抑制”操作，所以即使我可以用前面的置换操作包装PyTorch模型(nn.module)，我仍然需要弄清楚非最大抑制如何进入ONNX导出的模型(作为图形操作而不是某种循环程序代码，我承认当我看到它时感到非常惊讶)。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es mc"><img src="../Images/b5f15936f33e96fb3669367f3bef62d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r4GXGGfoyBthmy0s1sslUQ.png"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">the NonMaxSupression operation inside the ONNX exported graph, visualized with Netron (<a class="ae lu" href="https://netron.app/" rel="noopener ugc nofollow" target="_blank">https://netron.app/</a>)</figcaption></figure><p id="82c8" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">所以我所做的是打开源代码并跟踪YOLOv7 <a class="ae lu" href="https://github.com/WongKinYiu/yolov7/blob/main/export.py" rel="noopener ugc nofollow" target="_blank"> export.py </a>代码，我看到试图为ONNX注册NMS插件的行，所以我猜测，非最大值抑制是在ONNX中预实现的，所以这就是神奇发生的地方。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es md"><img src="../Images/813777b4838a779dddd2c22d58062092.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jX8yUsRUbh928ShEi08OGQ.png"/></div></div></figure><p id="d350" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="lv">我的【方案】</em> </strong></p><p id="0876" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">找到了神奇的地方，我决定将github项目民间化并更新源代码。</p><p id="e3ce" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">对于输入NWHC =&gt; NCWH，我更新了experiemental.py中的End2End模块</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es me"><img src="../Images/58c503aeefa9b3706c41da195e23a9a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*00D-lQ_kwHonw-fMU6VKCQ.png"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">Original</figcaption></figure><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es mf"><img src="../Images/b49841eed0bc186696f3c0e9140ca43c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zasyYdm3b5Gr35Voi9ev1Q.png"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">Updated with an permute action (conditioned)</figcaption></figure><p id="053d" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">为了“分割”输出，我在experimental.py文件的ONNX_ORT模块中设置了条件</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es mg"><img src="../Images/51ec654090ee68e83e7462cfa5200191.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bp0EjypEgwlpjrx52ELOQA.png"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">Original</figcaption></figure><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es mh"><img src="../Images/0e9c39940723b8347a62a0b09056cd3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3TN6cgj8y1SQfbuQLs_OuQ.png"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">Updated to return 4 elements instead of concatenated result</figcaption></figure><pre class="kv kw kx ky fd mi mj mk ml aw mm bi"><span id="41ef" class="kg ig hi mj b fi mn mo l mp mq">return selected_scores.reshape(1,-1), (selected_boxes/640).unsqueeze(-1).permute(2,0,1), selected_categories.reshape(1,-1), selected_indices.shape[0].unsqueeze(-1).float()</span></pre><p id="ceb6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">共有4个部分:</p><ol class=""><li id="098b" class="lg lh hi jf b jg kb jk kc jo mr js ms jw mt ka ll lm ln lo bi translated"><strong class="jf hj">输出序列</strong>—tensor flow Lite模型的预期序列应该是<strong class="jf hj"> <em class="lv">(包围盒，置信度得分，类别，检测结果数)</em> </strong>但是这里我返回了<strong class="jf hj"> <em class="lv">(得分，包围盒，类别，检测结果数)</em> </strong>，这纯粹是经验主义的，不确定在操作的转换链中哪里弄乱了序列，Android应用程序会抱怨dimension(这花了我不少时间才弄明白)</li><li id="cab6" class="lg lh hi jf b jg lp jk lq jo lr js ls jw lt ka ll lm ln lo bi translated"><strong class="jf hj">边界框除以640</strong>—yolov 7 tiny模型运行在固定的640 x 640输入上，边界框输出范围是(0，640)，但是对象检测API期望比率，所以简单的做法是用640除它(这里是固定的，所以现在是硬编码的)</li><li id="3c27" class="lg lh hi jf b jg lp jk lq jo lr js ls jw lt ka ll lm ln lo bi translated"><strong class="jf hj">检测到的项目数</strong> —我第一次使用len(selected_boxes)时，出现了一个错误(我忘了是因为Android应用崩溃还是因为导出)，但原因很简单，ONNX导出期望跟踪张量的图形数据流，而len(selected_boxes)切断了跟踪路径，因此对于检测到的结果数，输出将会丢失，经过一些尝试和错误，这个<strong class="jf hj"><em class="lv">selected _ indexes . shape[0]。unsqueze(-1)。(</em> </strong> <em class="lv"> </em>浮空招数</li><li id="a3c4" class="lg lh hi jf b jg lp jk lq jo lr js ls jw lt ka ll lm ln lo bi translated">为什么？float()？—这是因为PyTorch Tensor.shape输出是整数，这使得它不同于其他3个元素(它们都是浮点的)，TensorFlow Lite不喜欢它</li></ol><h1 id="2801" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">中断</h1><p id="aadd" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">还有一些关于Android应用程序的部分，但我想我会暂停在这里，提供更多的更新。</p><p id="f058" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">无论如何，通过这个旅程导出的TensorFlow Lite模型确实可以在Android应用程序中工作，但它太慢了(CPU 2线程推理花费了大约1500毫秒，相比之下，高效Det v2量化仅为大约400毫秒，而MobileNetv1量化为大约80毫秒)</p><p id="2548" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">YOLO v7的量子化……是我一直在做的一项任务，但至今没有任何成果……</p><p id="ce2e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">(待续……)</p></div></div>    
</body>
</html>