# 梯度推进分类器

> 原文：<https://medium.com/geekculture/gradient-boosting-classifier-f7a6834979d8?source=collection_archive---------1----------------------->

什么是梯度增强分类器？它做什么，如何执行分类？我们能在它的帮助下建立一个好的模型并做出有价值的预测吗？

![](img/501b9ca82c58ecdbcf380eb4858b91c5.png)

# 什么是梯度增强分类器？

**梯度推进分类器**是一套机器学习算法，包括几个较弱的模型，将它们组合成一个强大的大模型，具有高度预测输出。一类模型因其能够有效地对数据集进行分类而广受欢迎。

梯度推进分类器通常在建模中使用决策树。但是这些值是如何获得、处理和分类的呢？

**分类**是一个过程，机器学习算法被给定一些数据，并将其放入离散的类中。这些类对于每个数据都是唯一的，并相应地进行分类。例如，在我们的电子邮箱中，我们有“**收件箱**”和“**垃圾邮件**”这样的类别，收到的邮件根据信件的上下文特征进行分类。

**回归**也是一种机器学习算法，基于 ML 模型得到的结果工作。换句话说，我们获得的是一个实值，也是一个连续值(体重，身高)。回归旨在根据连续值(体重、身高、脉搏等)预测值(一个人的年龄)。)

梯度推进是由 Jerome Friedman 提出的，他认为通过小的步骤可以更好地预测正在测试的数据集。

为了进行预测和构建决策树，我们需要执行几个步骤。

# **第一步——收集和分析我们的数据**

![](img/c247b5d37c93c86a1a112f3b0d46d55f.png)

在上表中，我们使用的是从六名患者那里收集的**训练数据**。这些数据显示了患者的胸痛、脉搏(每分钟心跳次数)、体重(体重不足、正常和超重)以及心脏病史。我们在这里的目的是理解**梯度增强**如何将模型拟合到这种训练数据。

# 第二步——赔率和概率计算

![](img/14748cc45cc3b89145c9df205928ff7a.png)

使用**梯度提升进行分类**，我们在**日志(赔率)**中发现每个患者的初始预测。

为了计算总的 **log (odds)** ，让我们区分一下对心脏病回答“**是**”的患者和回答“**否**”的患者。这里，我们在**训练数据集**中有 4 名患者作出肯定回答，还有 2 名患者作出否定回答。那么，病人有心脏病的**对数(赔率)**是

![](img/8da8c6e1028de6d0d73010f42c185348.png)

这个数字将作为**初始预测**出现在我们树的**初始叶子**中。

但是我们如何将初始预测用于**分类**？最简单和最聪明的方法是将**对数(赔率)**转换为**概率**。这里的诀窍是使用**逻辑功能**。

而我们的**概率**会是这样的:

![](img/fba0e0ac01f67372f9317d7d9982451d.png)

借助我们初步获得的**对数(赔率)**，我们得到的心脏病概率是

![](img/db2b1e70e95e7d91f8df93759e5d46f1.png)

数字 **0.5** 被认为是基于它做出分类决策树的**概率阈值**，所以它上面的每一个数字都让一个病人自动容易得心脏病。更多信息 [*点击链接*](https://www.youtube.com/watch?v=4jRBRDbJemM) 观看 ROC 和 AUC 机器学习曲线。

# **第三步——残差计算**

我们执行**残差计算**以获得观察值和预测值之间的差异。我们不能将**训练数据集**中的每个患者都归类为肯定患有心脏病的患者，因为其中两个患者没有确认任何心脏偏差。因此，最好借助于得到的**伪残差**数来测量初始预测误差。让我们把每一个“**是**的答案记为 **1** ，每一个“**否**的答案记为 **0** 。从下图中了解我们这样做的原因:

![](img/06f380bbf760a2dba942dee59c41765b.png)

这里，**残差** =(二元心脏病—概率)或残差=(是/否答案— 0.67)。我们将获得的结果放入表格的新列中。

![](img/b40a12baae62879620b8ccf904aaabdc.png)

在计算了每个患者的**残差**之后，我们将获得新的值，以在**初始预测**的决策树叶子内工作。

![](img/b5b35f40388ee6abb335f83bb972be87.png)

# **第四步——构建决策树**

为了构建决策树，我们需要使用**胸痛**、**脉搏**和**体重**数据来预测树叶和残差。因此，有必要调查哪一列将最好地描述所获得的结果。为此，我们将把训练数据分成三个子表，并构建三棵更小的树，三个较弱的模型稍后将合并成一个强模型。

## **1。胸痛(二进制数据集)**

如果胸痛的答案是“**是**”，那么我们就需要求**残差平方和(RSS)** 以及这个正答案的平均值。

![](img/00c33f3f902036498c3f4f566b4a7249.png)

要计算“**是**答案的平均值，我们应该取所有回答为肯定的患者，将这些数字相加，并乘以答案的数量，即 **3** 。举个例子，

![](img/7a54e1a40025d06e616bbbeca8239c2f.png)

**残差平方和**或 **RSS** 是残差平方和，表示从数据集实际值预测的误差。小 RSS 表明模型完美地拟合了数据。这里， **average1** 和 **RSS1** 是得到的结果，对应我们训练模型的条件，而 **average2** 和 **RSS2** 是没有得到的结果。

![](img/e6e8db65999f52f2044c2fb2afce7c1d.png)

上面的公式将***уI****显示为残差列中的一个元素。和*为平均数。**

**![](img/fab83e7772e472e51da3f45217fc95dd.png)**

**由于也有一个“**否**”的答案，我们应该将其考虑在内，并对回答为否定的患者执行相同的计算:将数字相加并乘以 **3** 。**

**![](img/795654f093c28ee8e6e1a44fb71b54e2.png)****![](img/aadd6e50789267b53b2b5461d32fac54.png)**

**基于平均值和 **RSS** 计算，我们将获得以下树叶:**

**![](img/2252291c40592ab8386d698195a7d655.png)**

**这里，我们有两个带残差的叶子，但是如果我们想计算数据误差，我们需要添加 **RSS1** 和 **RSS2** ，结果如下:**

**![](img/0da64656841725c01833c77b6bb93cc9.png)**

## ****2。权重(分类数据集)****

**为了找出分类数据中的错误，有必要将体重划分(或归类)成这样的子段，如**体重不足**(低于正常)**正常**和**超重**(高于正常)。**

**![](img/387c80c7e005ab7c0eb1933072ad18aa.png)**

**为了找到这里的残差和 RSS，我们按照之前执行的相同步骤。**

**![](img/e6961f5c9ad378390f1529a9599c558b.png)****![](img/4c205d61b903645d674a00c4998b8106.png)****![](img/f3d0f44679c07fbace459af82f267ac9.png)****![](img/c565541e1d9ff7ab9e9d786d396f7758.png)**

## ****3。脉冲(数值数据集)****

**为了了解脉象的差异和数据误差，我们需要获取患者的几个脉象指标。比如每分钟 **68** 、 **70** 、 **75** 、 **88** 、 **95** 、 **115** 拍。脉冲是一个数值，其中条件是可变的。所以，我们取我们的脉搏值，按照生长的顺序进行分类。然后，我们将需要一个图形来可视化变量和获得的残差。**

**![](img/b1c2bb80f3158607489003a05b7bbab0.png)**

**我们取脉搏的前两个值并计算它们的平均结果。例如 **(68+70)/2=69** 。然后我们在图上用红线显示这个结果。**

**![](img/f7f6aeaafb84195fe49e47c4e4d0a6b7.png)**

**之后，我们的目标是尝试找到图中左侧和右侧的**残差平均值**。由于左侧只有一个元素，我们的平均值如下:**

**![](img/789c72cc4ff583c442d642abd31f95af.png)**

**由于平均结果是 **0.33** ，我们需要在图表中显示出来。例如**

**![](img/72f90a1d8a62aaa4a8abf2217a29eb0b.png)**

**此外，我们的计算转移到图表右侧的平均值。它将是:**

**![](img/377c50fbe357d092d3282a9e9eb5a1f3.png)**

**我们也在图表上展示了这个结果。**

**![](img/5b69a71f5477766e923e4f3fa924cd61.png)**

**所以，最后一步是计算残差。这可以借助以下公式来完成。**

**![](img/454e32e376a014d200b77a68e3552f33.png)****![](img/3c0d40157e7945d1be2952c5f5db7b69.png)**

**我们需要对脉冲的所有相邻值执行相同的计算。这样做，我们获得了以下结果:**

**![](img/f87007ab32f7ca9aef5054711af9decb.png)**

**让我们也像上面的例子一样计算相同的**平均 1/平均 2** 、 **RSS1/RSS2** ，以及总的 **RSS** 值。**

**![](img/29f5fe470026ab34666ef4279495a66b.png)****![](img/d66f610f3c768a91e274ffb1596e63dd.png)****![](img/238e58ac47f1b56ea0dfbe6f8b688e4a.png)****![](img/eb92ac7d1c8e7f117e19ded23394dd37.png)****![](img/58bcde7925baae854c98dd467a4c131c.png)****![](img/f5a0311cb963a63cdea551ee7679d97a.png)****![](img/a5c03121efef393b14b6ef10b0594da1.png)**

**在我们获得所有邻近结果后，有必要选择**最佳最小选项**。该结果是在 **70** 和 **75** 之间的脉冲范围内实现的。基于这个最小数量，我们可以构建以下树:**

**![](img/ddb4042877fd370256e5d32fe0449724.png)**

**在用残差构建树时，**最小的 RSS** 是当我们获得**权重=低于正常**值时。所以，我们把这个值作为树的根。**

**![](img/c565541e1d9ff7ab9e9d786d396f7758.png)**

**然后，直观地显示，我们在左叶上只有一个值，在右叶上有五个值。所以，我们需要对右边的叶子进行同样的计算，得到一棵新的树。**

**![](img/2f0a214efa515d7a96f32a06cca46955.png)**

**计算完成后，我们将获得的数据输入到前一棵树的右叶，得到以下结果:**

**![](img/de5ffe3eb5ab283937f875d2906ad3ba.png)**

**当我们将数据分成最小的组(一片叶子上不超过 3 个元素)时，我们可以进入下一步。**

# ****步骤 5——计算输出值****

**为了计算**输出值**，我们需要使用以下公式:**

**![](img/1fd6f1d70d2d13cf87d71c992aa7fa39.png)**

**这个公式是常用的转换方法，它允许计算每片叶子的输出值。**

**![](img/e122fc10b15860ffe494423d892e0087.png)**

**将已经获得的值输入到公式中，我们将得到具有输出值的新树。**

**![](img/8ce91ab58fabb96d6534fec35a3f9732.png)**

# ****第六步——基于新值的概率计算****

**这一步需要用新数据更新**预测**部分。所以，我们把最初的叶子和新的树结合起来。这个新的树是按学习率缩放的，学习率是 **0.8** ，这仅仅是为了说明的目的。**

**![](img/1011718408da81a3f6277036c1671940.png)**

**这个计算和我们之前在文章开头做的是一样的。然而，我们得到的输出是全新的。还是那句话，在求出**新概率**后，让我们求出**新余数**。**

**![](img/cb717df2c7b247d818f8bd6ce64a389c.png)****![](img/ced6a05f9605bf27411c0eebf65648bf.png)**

**有了新的残差数据，就有可能构建新的树。**

**![](img/7d6988df4f0d40f54d5d21761a3e0e84.png)**

**重复树构建过程，直到指定了最大数量的树或者残差变得尽可能小。**

**为了使例子简单，一个**分级提升**已经被配置为仅仅**树的两个版本**。在这里，有必要将一个新人归类为患有心脏病或没有这种疾病的人。所以，我们在做同样的预测，计算潜在的概率。**

**让我们在公式中输入我们的学习率，等于 **0.8** ，和 **log(odds)** ，等于 **0.69** 。这样，我们将获得以下内容:**

**![](img/0b48b5cb99de6472e9badb83c7678471.png)**

**但是为了更详细地向你展示，想象我们有一个新病人，并想计算这个病人患心脏病的概率。**

**![](img/d4fcc5c0fda985ed70996ebd2934f017.png)**

**让我们用下面的公式来计算我们预测的**对数(赔率)**:**

**![](img/6122fcb9057b2ebebf8de0d4cd83c677.png)**

**结果将是:**

**![](img/e0b925621c21a546b9a0b9784310fcf8.png)**

**使用我们在**步骤 2** 中提到的概率公式，我们可以得到下一个结果。**

**![](img/e293d2c66a8b2d56f0300bddd5bddfff.png)**

**所以，基于已经取得的结果，我们的**新患者**有 **0.95** 的概率会得心脏病。**

# **总结**

****梯度增强分类器**的当前概览显示在**训练数据集**上，但这与它可以用于真实数据集的方式相同。例如，如果确实需要预测患者目前或将来是否有患心脏病的可能性。因此，现在您对什么是梯度推进分类器以及它如何在**分类**和**树构建**中工作以获得准确的预测和结果有了一个概念。**

****作者:**首席运营官纳扎尔克瓦尔塔尼[伊诺克斯福特](https://inoxoft.com/)**

****特约作者:**奥列西亚·斯拉维卡尼克， [Inoxoft](https://inoxoft.com/) 的软件工程师**

**【inoxoft.com】原载于 2021 年 2 月 2 日[](https://inoxoft.com/blog/gradient-boosting-classifier-inoxoft/)**。****