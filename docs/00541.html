<html>
<head>
<title>Neural Networks From Scratch: A Simple Fully Connected Feed Forward Network in C++</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始的神经网络:一个简单的C++全连接前馈网络</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/neural-networks-from-scratch-a-simple-fully-connected-feed-forward-network-in-c-29e9542bcdef?source=collection_archive---------2-----------------------#2021-02-28">https://medium.com/geekculture/neural-networks-from-scratch-a-simple-fully-connected-feed-forward-network-in-c-29e9542bcdef?source=collection_archive---------2-----------------------#2021-02-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/17b890fec0e9369591d57eaa04a94949.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9KopNr5vCfDO3raOjc1JZA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Source: Cognitive Science Program — Indiana University Bloomington</figcaption></figure><h1 id="feac" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">介绍</h1><p id="f2bd" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">神经网络是现代机器学习的基石。但是很容易放弃对神经网络的实际理解，因为有大量的工具可以让你用几行代码创建和训练一个模型。因此，在这个系列中，我希望通过从头开始创建不同种类的神经网络来提供一个基础的、实用的理解。我们将从最简单的一种开始:完全连接的前馈神经网络。理解这些是如何工作的，并且能够从零开始创造，对于发展到更复杂的网络(例如卷积、循环、对抗)是至关重要的。要完成这个过程，您只需要具备C++的基础知识，并对神经网络的工作原理有所了解。最后，你将拥有一个可以随意摆弄的前馈神经网络。</p><h1 id="294c" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">结构</h1><p id="05e5" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">我们的网络将有两部分:一个线性层和一个sigmoid激活函数。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es kq"><img src="../Images/26bf7bfd45f1aa2f04b0c6380b45b14e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*8UgZu3_xQmaNJy9Av7FJUQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">Linear Layer</figcaption></figure><p id="3372" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">上图描绘了一个非常简单的线性图层，它接受两个输入并产生一个输出。sigmoid层要简单得多，因为它只对每个输出应用sigmoid函数。我将在各自的章节中详细阐述这两个组件。一旦我们完成了这两个部分，我们就可以将它们结合起来创建不同的神经网络架构。</p><h1 id="a582" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">线性层</h1><p id="3f8e" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">典型的神经网络由多个线性层组成。每一层执行输入向量的线性变换。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es la"><img src="../Images/8affaac0482ed0723ae696a278e1ba41.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*RY2fg-r8u7L7uslhjjHOBw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">Linear Layer Math</figcaption></figure><p id="e624" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">我们可以将线性层所做的工作分解为两部分:前馈和反向传播。前馈时，我们将权重矩阵乘以一个输入向量来产生一个输出(如上图所示)。反向传播是我们的网络如何“学习”输出什么。更具体地说，反向传播改变了网络中的权重，以最小化网络输出和预期输出之间的差异。我将在这里简要解释反向传播背后的数学原理，但是为了更深入地探索这个主题，我建议您使用我在最后链接的资源。</p><p id="61d1" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated"><strong class="ju hj">设置</strong></p><p id="42a0" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">最后，经过深思熟虑，我们可以开始编码我们的线性层。加载您选择的编辑器，让我们开始吧。</p><p id="d374" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">创建一个新文件，命名为“LinearLayer.h”。我们将在这里创建我们的线性图层类。首先在文件中写入以下内容:</p><figure class="kr ks kt ku fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="b30f" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">我们的层将需要另一个指定输入和输出大小的构造函数。在这个构造函数中，我们还将设置一个学习率并初始化我们的权重。</p><figure class="kr ks kt ku fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="0017" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">现在设置已经完成，我们可以写线性层的前馈部分了。</p><h2 id="1ce3" class="ld iv hi bd iw le lf lg ja lh li lj je kd lk ll ji kh lm ln jm kl lo lp jq lq bi translated"><strong class="ak">前馈</strong></h2><p id="bac7" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">我们的前馈方法将需要做三件事:接受一个输入向量，将输入向量与我们的权重矩阵相乘，并输出乘积向量。我们还需要存储输入和输出向量，因为我们稍后在反向传播期间需要它们。</p><figure class="kr ks kt ku fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><h2 id="7795" class="ld iv hi bd iw le lf lg ja lh li lj je kd lk ll ji kh lm ln jm kl lo lp jq lq bi translated"><strong class="ak">反向传播</strong></h2><p id="c2a7" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">在我们进入代码之前，这被证明是非常简单的，我将简单地回顾一下反向传播背后的数学。考虑前面描述的简单线性层。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es kq"><img src="../Images/26bf7bfd45f1aa2f04b0c6380b45b14e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*8UgZu3_xQmaNJy9Av7FJUQ.png"/></div></figure><p id="14e0" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">该网络的输出计算如下:</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/6d9f7c72f785c5b4c2e5f921a4ec54ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:348/format:webp/1*9-TgeS1rD4NzW4sSl0LlUQ.png"/></div></figure><p id="1987" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">现在假设对于任何给定的两个输入，我们的预期输出由以下函数决定:</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/e1d1371c9bdf788a6bf86ca4d249373b.png" data-original-src="https://miro.medium.com/v2/resize:fit:140/format:webp/1*MbWCfYuIivuVNmC0pJSc_g.png"/></div></figure><p id="1643" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">我们的网络输出和预期输出之间的误差可以计算为</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/fcd411edd5252ee9ab2e2302e4c7aed7.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/1*CcfNU4Lz04x7D5CA9sslvw.png"/></div></div></figure><p id="030d" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">这是我们的误差函数。现在，我们面临一个最优化问题。我们希望设置权重，使误差函数E最小。为此，我们将使用一种称为梯度下降的常用方法。从广义上讲，梯度下降包括在给定当前权重的情况下，确定误差函数的最陡下降方向。然后我们改变我们的权重，使我们在给定的方向上移动，从而减少误差。为了确定最陡下降的方向，我们需要计算误差函数的梯度。如下所示:</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/e60071d8e5ebc2f85cdcea460583fc7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:234/format:webp/1*EZw348pktIwEh9MMrsOT9g.png"/></div></figure><p id="b2cc" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">为我们的样本线性图层计算这个值，我们得到</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/8edd675176646aced806775eae0490a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*aQWE0VhS74xU09YKxADKrw.png"/></div></figure><p id="71fd" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">梯度会给我们最陡上升的方向，所以我们只需要取向量的负值就可以得到最陡下降的方向。然后我们会相应地改变我们的权重。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/7a22a6cb11699bcffeeaa3f52d0f5bb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/1*_S_hDYKUoOFEYWvIFsyTeg.png"/></div></figure><p id="1858" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">注意，我们将梯度乘以eta，这就是我们的学习速率。</p><p id="4115" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">我们刚刚讨论的是梯度下降的一个具体而简单的应用。通常情况下，我们的线性层会堆叠在许多其他线性层的后面，因此它的输出不会是整个网络的输出。但是不管网络的结构如何，以下用于改变给定权重的等式将成立:</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/5057aa240c4e95ea3bf97ce7e1d00443.png" data-original-src="https://miro.medium.com/v2/resize:fit:366/format:webp/1*V2HDi3bzz_SO1bg6OYxGRQ.png"/></div></figure><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/a845d8ce4a915111882fb7a6c2877471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*uc5hSrTdoHIkzbJ-OQMMow.png"/></div></div></figure><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lz"><img src="../Images/cf017973056ac746ff12e02e6c86385e.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*xQPSaCm81sfZrbym95CrPw.png"/></div></figure><p id="ee60" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">因此，为了执行反向传播，我们将期望我们的线性层接收关于每个层的输出的误差的偏导数。反过来，我们还将计算误差相对于每一层输入的偏导数，然后将其发送给前一层。你现在可能开始明白为什么这叫做反向传播了。</p><p id="d840" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">如果大部分内容超出了你的理解范围，请不要担心。我在这里没有深入探讨，为了更好地理解，我建议使用我在最后链接的资源。</p><p id="d3af" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">现在让我们来看看代码。</p><figure class="kr ks kt ku fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="080b" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">幸运的是，尽管梯度下降背后的数学看起来很复杂，但代码非常简单。这样，我们就完成了我们的线性层。现在我们继续讨论乙状结肠激活函数。</p><h1 id="7e4a" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">Sigmoid激活函数</h1><p id="93ad" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">sigmoid激活函数是一个有用的工具，它允许我们将输出压缩到0到1之间。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/79029d07d8ec9f1ecf88a4b829120d13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HXCBO-Wx5XhuY_OwMl0Phw.png"/></div></div></figure><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/24bd464e59f23ba51a9db3a23256beb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:258/format:webp/1*rsfbeIMgwxDbdNCVAo2SIQ.png"/></div></figure><p id="190c" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">上面显示的是sigmoid函数。回想一下之前描述的简单线性层。它的输出是</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/6d9f7c72f785c5b4c2e5f921a4ec54ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:348/format:webp/1*9-TgeS1rD4NzW4sSl0LlUQ.png"/></div></figure><p id="eb04" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">注意S(0) = 0.5，y &gt; 0时S(y) &gt; 0.5，S(y) &lt; 0.5 when y &lt; 0. From this, we can say that if our input lies on the line y = 0, then our output will be 0.5, and otherwise, it will be greater than or less than 0.5 depending on whether our output is above or below the line.</p><p id="6e28" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">Again we will start with some basic setup. Begin by creating a “Sigmoid.h” file.</p><figure class="kr ks kt ku fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><h2 id="ba30" class="ld iv hi bd iw le lf lg ja lh li lj je kd lk ll ji kh lm ln jm kl lo lp jq lq bi translated"><strong class="ak">前馈</strong></h2><p id="0b1a" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">用我们的乙状结肠向前输送非常简单。我们只需要将我们的函数应用于给定输入向量中的每个值。</p><figure class="kr ks kt ku fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><h2 id="b095" class="ld iv hi bd iw le lf lg ja lh li lj je kd lk ll ji kh lm ln jm kl lo lp jq lq bi translated"><strong class="ak">反向传播</strong></h2><p id="a8bb" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">反向传播又有点令人毛骨悚然。但是因为没有权重需要改变，我们需要做的就是确定关于输入的偏导数。请注意，sigmoid函数的导数为</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/3304ceb134653dbeb3a1081f143b21cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*9xZPJEZXU5Od3p22egwdKA.png"/></div></figure><p id="9d15" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">利用这一点，我们可以编写反向传播方法。</p><figure class="kr ks kt ku fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><h1 id="ab8b" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">组合成分:模型</h1><p id="806c" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">我们拥有网络所需的所有部件。但是在你开始混合线性层和sigmoid层之前，我们需要考虑一些细节。为了涵盖这些细节，我将创建一个非常简单的模型，其中包括一个具有两个输入值和一个输出值的线性图层，以及一个位于末端的sigmoid图层。</p><p id="b797" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">创建一个. cpp文件，并随意命名。在这个文件中，我们将创建一个模型类，它创建了我们的模型，并详细说明了它的组件如何协同工作。代码如下:</p><figure class="kr ks kt ku fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="8e1c" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">注意，在我们的反向传播方法中，我们计算误差函数相对于网络输出的导数。然后传递到我们的乙状结肠层。其他一切都很简单。我们的构造函数创建了两层，前馈方法规定了这些层对输入进行操作的顺序</p><h1 id="30d2" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">线性分离任务</h1><p id="1d3e" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">现在，我们可以使用上一节中的模型来执行线性分离任务。下面的代码演示了如何使用5x + 7y = 0这一行来训练模型以分离数据点。</p><figure class="kr ks kt ku fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="7c57" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">最佳做法是使用未用于训练的数据集子集来测试模型。但是对于这个相对琐碎的例子，我刚刚使用了相同的数据。</p><h1 id="9b8b" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">结束了</h1><p id="35c1" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">这就是了。你可以使用我上两节的代码来掌握如何使用线性层和sigmoid层。有了这两个组件，你可以做出一些非常酷的东西。你可能会感兴趣的一个项目是使用MNIST数据集训练一个模型来识别手写数字。以后我会详细介绍如何用我们在本文中创建的组件制作这个项目。但在那之前，继续玩不同的模型，找点乐子。</p><p id="b458" class="pw-post-body-paragraph js jt hi ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp hb bi translated">关于神经网络的更多信息:【http://neuralnetworksanddeeplearning.com/chap1.html】T4。</p></div></div>    
</body>
</html>