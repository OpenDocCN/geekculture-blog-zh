<html>
<head>
<title>Robot Operating System: How to Model Point Cloud Data in ROS2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器人操作系统:如何在ROS2中建模点云数据</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/robot-operating-system-how-to-model-point-cloud-data-in-ros2-d36674619078?source=collection_archive---------9-----------------------#2022-01-17">https://medium.com/geekculture/robot-operating-system-how-to-model-point-cloud-data-in-ros2-d36674619078?source=collection_archive---------9-----------------------#2022-01-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/a1245a3ec4b3f3643f763283e8226af9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UKhem4WuBErCT39CGtzbWA.png"/></div></div></figure><p id="278d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">RADU在RViz和Gazebo的模拟进展顺利。在上一篇文章中，我们学习了如何启动机器人并使用teleop节点操作它。在本文中，我们将添加两个视觉传感器。首先，当机器人四处移动时，一个图像摄像头可以看到机器人的实时反馈。第二，深度相机传感器，它输出点云，这是机器人周围的距离测量，其中的颜色代表物体有多远。这两个传感器有助于2D导航和3D物体识别。</p><p id="4710" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">注:技术环境为Ubuntu 20.04，ROS2福克西，Gazebo11，RViz2。</em></p><p id="afc2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">本文原载于我的博客</em><a class="ae jp" href="https://admantium.com/blog/ros10_model_point_cloud_data/" rel="noopener ugc nofollow" target="_blank"><em class="jo">admantium.com</em></a><em class="jo">。</em></p><h1 id="e1a9" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">凉亭中的视觉传感器</h1><p id="40f6" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">在上一篇文章中，我们看到了如何添加一个插件来控制凉亭模拟中的机器人。添加视觉传感器遵循相同的方法:从<a class="ae jp" href="https://github.com/ros-simulation/gazebo_ros_pkgs/wiki" rel="noopener ugc nofollow" target="_blank"> Gazebo插件文档</a>中识别插件，检查并应用配置，然后将其添加到您的机器人的URDF模型中。</p><p id="7e64" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">URDF模型需要扩展如下:</p><ul class=""><li id="8401" class="kt ku hi is b it iu ix iy jb kv jf kw jj kx jn ky kz la lb bi translated">定义URDF的环节和关节</li><li id="2e41" class="kt ku hi is b it lc ix ld jb le jf lf jj lg jn ky kz la lb bi translated">可选:定义一个<code class="du lh li lj lk b">frame</code>连杆和关节</li><li id="8ef5" class="kt ku hi is b it lc ix ld jb le jf lf jj lg jn ky kz la lb bi translated">在<code class="du lh li lj lk b">&lt;gazebo&gt;</code>标签中定义一个<code class="du lh li lj lk b">sensor</code>和<code class="du lh li lj lk b">plugin</code>标签</li></ul><p id="d7a2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最佳实践是在单独的XACRO文件中定义机器人的任何附加传感器。这使您能够为特定的模拟目标提供不同的机器人配置。</p><h1 id="e0bf" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">添加摄像机</h1><p id="131b" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">先说相机插件。正如<a class="ae jp" href="https://github.com/ros-simulation/gazebo_ros_pkgs/wiki/ROS-2-Migration:-Camera" rel="noopener ugc nofollow" target="_blank">所记录的</a>，有不同类型的摄像机可供选择。我们将选择插件<code class="du lh li lj lk b">libgazebo_ros_camera.so</code>来模拟传统相机。</p><h1 id="e71b" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">URDF模型</h1><p id="262e" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">第一步是添加适当的链接和关节。相机传感器在这方面很特殊:您需要为相机定义一个链接和一个关节，并为充当相机参考点的相机帧定义另一个链接和关节。这是必需的URDF部分。</p><pre class="ll lm ln lo fd lp lk lq lr aw ls bi"><span id="8725" class="lt jr hi lk b fi lu lv l lw lx">&lt;?xml version="1.0"?&gt;<br/>&lt;robot xmlns:xacro="http://www.ros.org/wiki/xacro" name="radu"&gt;<br/>  &lt;link name='rgb_cam_camera_link'&gt;<br/>    &lt;visual&gt;<br/>      &lt;origin xyz="0 0 0" rpy="0 0 0" /&gt;<br/>      &lt;geometry&gt;<br/>        &lt;box size="0.02 0.04 0.01" /&gt;<br/>      &lt;/geometry&gt;<br/>    &lt;/visual&gt;<br/>  &lt;/link&gt;</span><span id="c593" class="lt jr hi lk b fi ly lv l lw lx">  &lt;joint name="rgb_cam_camera_link_joint" type="fixed"&gt;<br/>    &lt;origin rpy="0 0 0" xyz="0.30 0.0 0.065" /&gt;<br/>    &lt;parent link="base_link" /&gt;<br/>    &lt;child link="rgb_cam_camera_link" /&gt;<br/>    &lt;axis xyz="0 0 0" /&gt;<br/>  &lt;/joint&gt;</span><span id="f805" class="lt jr hi lk b fi ly lv l lw lx">  &lt;link name="rgb_cam_camera_link_frame"&gt;&lt;/link&gt;<br/>  &lt;joint name="rgb_cam_camera_frame_joint" type="fixed"&gt;<br/>    &lt;origin xyz="0.01 0 0" rpy="0 0 0" /&gt;<br/>    &lt;parent link="rgb_cam_camera_link" /&gt;<br/>    &lt;child link="rgb_cam_camera_link_frame" /&gt;<br/>    &lt;axis xyz="0 0 0" /&gt;<br/>  &lt;/joint&gt;<br/>&lt;/robot&gt;</span></pre><p id="b460" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，我们需要在我们的机器人URDF中添加<code class="du lh li lj lk b">&lt;sensor&gt;</code>和<code class="du lh li lj lk b">&lt;plugin&gt;</code>标签。</p><pre class="ll lm ln lo fd lp lk lq lr aw ls bi"><span id="d017" class="lt jr hi lk b fi lu lv l lw lx">&lt;?xml version="1.0"?&gt;<br/>&lt;robot xmlns:xacro="http://www.ros.org/wiki/xacro" name="radu"&gt;<br/>  &lt;gazebo reference="rgb_cam_camera_link_frame"&gt;<br/>    &lt;sensor type="camera" name="rgb_camera"&gt;<br/>      &lt;update_rate&gt;10.0&lt;/update_rate&gt;<br/>      &lt;camera name="rgb_camera"&gt;</span><span id="d31f" class="lt jr hi lk b fi ly lv l lw lx">        &lt;pose&gt;0 0 0 0 0 0&lt;/pose&gt;</span><span id="06ee" class="lt jr hi lk b fi ly lv l lw lx">        &lt;horizontal_fov&gt;1.3962634&lt;/horizontal_fov&gt;<br/>        &lt;image&gt;<br/>          &lt;width&gt;640&lt;/width&gt;<br/>          &lt;height&gt;480&lt;/height&gt;<br/>          &lt;format&gt;YUYV&lt;/format&gt;<br/>        &lt;/image&gt;<br/>        &lt;clip&gt;<br/>          &lt;near&gt;0.005&lt;/near&gt;<br/>          &lt;far&gt;10.0&lt;/far&gt;<br/>        &lt;/clip&gt;<br/>      &lt;/camera&gt;</span><span id="f0f3" class="lt jr hi lk b fi ly lv l lw lx">      &lt;plugin name="camera_controller" filename="libgazebo_ros_camera.so"&gt;<br/>        &lt;alwaysOn&gt;true&lt;/alwaysOn&gt;<br/>        &lt;updateRate&gt;0.0&lt;/updateRate&gt;<br/>        &lt;cameraName&gt;rgb_camera&lt;/cameraName&gt;<br/>        &lt;imageTopicName&gt;image_raw&lt;/imageTopicName&gt;<br/>        &lt;cameraInfoTopicName&gt;camera_info&lt;/cameraInfoTopicName&gt;<br/>        &lt;frameName&gt;rgb_cam_camera_link_frame&lt;/frameName&gt;<br/>        &lt;hackBaseline&gt;0.07&lt;/hackBaseline&gt;<br/>        &lt;distortionK1&gt;0.0&lt;/distortionK1&gt;<br/>        &lt;distortionK2&gt;0.0&lt;/distortionK2&gt;<br/>        &lt;distortionK3&gt;0.0&lt;/distortionK3&gt;<br/>        &lt;distortionT1&gt;0.0&lt;/distortionT1&gt;<br/>        &lt;distortionT2&gt;0.0&lt;/distortionT2&gt;<br/>      &lt;/plugin&gt;<br/>    &lt;/sensor&gt;<br/>  &lt;/gazebo&gt;<br/>&lt;/robot&gt;</span></pre><p id="df79" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个声明使用了一个有用的技巧:URDF文件可以包含多个<code class="du lh li lj lk b">&lt;gazebo reference="NAME"&gt;</code>标签，Gazebo将解析这些标签，就好像您将所有声明都写在一个全局<code class="du lh li lj lk b">&lt;gazebo&gt;</code>标签中一样。</p><p id="4adb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">配置摄像机的主要属性如下:</p><ul class=""><li id="6030" class="kt ku hi is b it iu ix iy jb kv jf kw jj kx jn ky kz la lb bi translated"><code class="du lh li lj lk b">&lt;image&gt;</code>图像的宽度、高度和格式</li><li id="5cfb" class="kt ku hi is b it lc ix ld jb le jf lf jj lg jn ky kz la lb bi translated"><code class="du lh li lj lk b">&lt;clip&gt;</code>近距和远距属性控制图像记录的裁剪方式</li></ul><p id="1cf9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于插件，我们需要定义更新率(<code class="du lh li lj lk b">0.0</code>意味着一个恒定的流)，图像和相机信息的主题名称，以及几个失真因子。</p><h1 id="bde9" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">RViz模拟</h1><p id="3a20" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">传感器配置好后，我们就可以启动机器人和RViz了。在RViz内部，我们需要添加摄像头显示，然后将其配置为订阅主题<code class="du lh li lj lk b">/rgb_camera/image_raw</code>。如果操作正确，您可以看到图像实时视图。</p><p id="4dd5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在下面的截图中，您可以在右侧看到凉亭模拟，在左侧看到带有摄像机视图的RViz。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/415334258c7c7d09adbda13882b20ae6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1NYdcjFoK0sXwWv4.png"/></div></div></figure><h1 id="e4fc" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">深度相机</h1><p id="50e5" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">成功安装默认图像相机后，我们可以继续添加深度相机。</p><p id="1105" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最初，我计划将Gazebo插件用于我将在机器人中使用的深度传感器:英特尔实感D435。在我对这个插件的研究中，我发现这个官方的、特定的插件只适用于ROS1。一些用户试图让这个传感器运行，正如这个<a class="ae jp" href="https://answers.ros.org/question/348331/realsense-d435-gazebo-plugin/" rel="noopener ugc nofollow" target="_blank"> ROS answers线程</a>中记录的那样——他们成功地在Gazebo中启动了控制器，但无法获得任何传感器数据。因此，我决定使用一个类似的工作插件来模拟3D点云:ROS2射线传感器。</p><h1 id="9f65" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">URDF模型</h1><p id="1b20" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">和以前一样，我们首先需要在机器人模型中创建正确的链接。对于深度传感器，我们只需要一个连杆和一个关节。这里是相关的URDF。</p><pre class="ll lm ln lo fd lp lk lq lr aw ls bi"><span id="04e2" class="lt jr hi lk b fi lu lv l lw lx">&lt;?xml version="1.0"?&gt;<br/>&lt;robot xmlns:xacro="http://www.ros.org/wiki/xacro" name="radu"&gt;<br/>  &lt;link name='laser_link'&gt;<br/>    &lt;visual&gt;<br/>      &lt;origin xyz="0 0 0" rpy="0 0 0" /&gt;<br/>      &lt;geometry&gt;<br/>        &lt;box size="0.02 0.04 0.01" /&gt;<br/>      &lt;/geometry&gt;<br/>    &lt;/visual&gt;<br/>  &lt;/link&gt;</span><span id="5eaf" class="lt jr hi lk b fi ly lv l lw lx">  &lt;joint name="laser_link_joint" type="fixed"&gt;<br/>    &lt;origin rpy="0 0 0" xyz="0.10 0.1 0.085" /&gt;<br/>    &lt;parent link="base_link" /&gt;<br/>    &lt;child link="laser_link" /&gt;<br/>    &lt;axis xyz="0 0 0" /&gt;<br/>  &lt;/joint&gt;<br/>&lt;/robot&gt;</span></pre><p id="3719" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其次，我们添加一个额外的<code class="du lh li lj lk b">&lt;gazebo reference=""&gt;</code>标签，其中包括<code class="du lh li lj lk b">&lt;sensor&gt;</code>和<code class="du lh li lj lk b">&lt;plugin&gt;</code>标签。</p><pre class="ll lm ln lo fd lp lk lq lr aw ls bi"><span id="4968" class="lt jr hi lk b fi lu lv l lw lx">&lt;?xml version="1.0"?&gt;<br/>&lt;robot xmlns:xacro="http://www.ros.org/wiki/xacro" name="radu"&gt;<br/>  &lt;gazebo reference="laser_link"&gt;<br/>    &lt;sensor type="ray" name="head_laser_scanner"&gt;<br/>      &lt;pose&gt;0.0 0 0 0 0 0&lt;/pose&gt;<br/>      &lt;ray&gt;<br/>        &lt;scan&gt;<br/>          &lt;horizontal&gt;<br/>            &lt;samples&gt;181&lt;/samples&gt;<br/>            &lt;resolution&gt;1&lt;/resolution&gt;<br/>            &lt;min_angle&gt;-1.57080&lt;/min_angle&gt;<br/>            &lt;max_angle&gt;1.57080&lt;/max_angle&gt;<br/>          &lt;/horizontal&gt;<br/>        &lt;/scan&gt;<br/>        &lt;range&gt;<br/>          &lt;min&gt;0.08&lt;/min&gt;<br/>          &lt;max&gt;10&lt;/max&gt;<br/>          &lt;resolution&gt;0.05&lt;/resolution&gt;<br/>        &lt;/range&gt;<br/>        &lt;noise&gt;<br/>          &lt;type&gt;gaussian&lt;/type&gt;<br/>          &lt;mean&gt;0.0&lt;/mean&gt;<br/>          &lt;stddev&gt;0.01&lt;/stddev&gt;<br/>        &lt;/noise&gt;<br/>      &lt;/ray&gt;</span><span id="e79c" class="lt jr hi lk b fi ly lv l lw lx">      &lt;always_on&gt;1&lt;/always_on&gt;<br/>      &lt;update_rate&gt;30&lt;/update_rate&gt;<br/>      &lt;visualize&gt;true&lt;/visualize&gt;</span><span id="5593" class="lt jr hi lk b fi ly lv l lw lx">      &lt;plugin name="laser_scanner" filename="libgazebo_ros_ray_sensor.so"&gt;<br/>        &lt;ros&gt;<br/>          &lt;namespace&gt;/&lt;/namespace&gt;<br/>          &lt;argument&gt;~/out:=laser&lt;/argument&gt;<br/>        &lt;/ros&gt;<br/>        &lt;output_type&gt;sensor_msgs/PointCloud2&lt;/output_type&gt;<br/>        &lt;frame_name&gt;laser_link&lt;/frame_name&gt;<br/>      &lt;/plugin&gt;<br/>    &lt;/sensor&gt;<br/>  &lt;/gazebo&gt;<br/>&lt;/robot&gt;</span></pre><p id="8198" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">传感器类型为<code class="du lh li lj lk b">ray</code>，包括以下配置选项:</p><ul class=""><li id="bba5" class="kt ku hi is b it iu ix iy jb kv jf kw jj kx jn ky kz la lb bi translated"><code class="du lh li lj lk b">&lt;scan&gt;</code>标签可以包括<code class="du lh li lj lk b">&lt;horizontal&gt;</code>和<code class="du lh li lj lk b">&lt;vertical&gt;</code>标签，用于沿着这些定义进行扫描。每个都定义了最小和最大角度、样本数(检测到的点数)和分辨率</li><li id="5913" class="kt ku hi is b it lc ix ld jb le jf lf jj lg jn ky kz la lb bi translated">使用<code class="du lh li lj lk b">&lt;range&gt;</code>您可以定义传感器探测环境的绝对距离</li><li id="fef6" class="kt ku hi is b it lc ix ld jb le jf lf jj lg jn ky kz la lb bi translated">可选的<code class="du lh li lj lk b">&lt;noise&gt;</code>标签定义了如何在仿真中清除接收到的测量值。</li></ul><p id="79b3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">根据传感器定义，<code class="du lh li lj lk b">&lt;plugin&gt;</code>为该传感器配置名称空间、主题、数据格式和参考链接。</p><h1 id="1b8a" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">凉亭和RViz模拟</h1><p id="4e32" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">不需要修改启动文件——以主题<code class="du lh li lj lk b">/robot_description</code>发布的新URDF文件包含了新的传感器和插件。但是我们会看到什么呢？</p><p id="9e1a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在Gazebo中，我们看到了传感器的视觉表现:发射的光线。我注意到，在我的模拟中，只有房间的墙壁，而不是物体，阻挡了传感器的光线——显然，它们有不同的物理特性，但这对于模拟来说是可以的。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/b04ab679371f9a4cf4ed64d7c4b49d22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pL_NVmbivwF_kP1r.png"/></div></div></figure><p id="c69a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在RViz中，我们可以看到传感器数据的实时模拟，并在移动时准确地看到房间的轮廓。一旦开始，我们通过<code class="du lh li lj lk b">Add</code>按钮添加一个新的显示，选择<code class="du lh li lj lk b">PointCloud2</code>，然后配置主题为<code class="du lh li lj lk b">/laser</code>，显示点的大小为0.03米。这将如下所示。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/9b00bd13ed2249917547e540d2d555c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8KL6pjSDBTejnWGH.png"/></div></div></figure><h1 id="b0c1" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结论</h1><p id="1b73" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb kq jd je jf kr jh ji jj ks jl jm jn hb bi translated">用传感器插件增强机器人模拟提供了对机器人模型的重要见解。在ROS2中，官方Gazebo插件包括驱动器、IMU、GPS、相机等。本文展示了添加传感器的基本步骤。首先，定义传感器的链接和关节。其次，添加一个带有传感器和插件配置的<code class="du lh li lj lk b">&lt;gazebo&gt;</code>标签。传感器在仿真工具Gazebo和RViz中的显示方式不同。在Gazebo中，插件公开了可以控制和/或可视化的直接接口。在RViz中，您需要添加额外的显示类型来监听插件提供的主题，例如显示实时摄像机或点云。正确配置后，您的机器人模型会显示其环境，并在模拟中为您提供更好的控制。</p></div></div>    
</body>
</html>