<html>
<head>
<title>Privacy Debate: Apple Scans iCloud Photos On-Device for Child Pornography</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">隐私辩论:苹果扫描iCloud设备上的儿童色情照片</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/privacy-debate-apple-scans-icloud-photos-on-device-for-child-pornography-d544c87a559f?source=collection_archive---------47-----------------------#2021-08-23">https://medium.com/geekculture/privacy-debate-apple-scans-icloud-photos-on-device-for-child-pornography-d544c87a559f?source=collection_archive---------47-----------------------#2021-08-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class="if ig ez fb ih ii"><a href="https://techcatcher.io" rel="noopener  ugc nofollow" target="_blank"><div class="ij ab dw"><div class="ik ab il cl cj im"><h2 class="bd hj fi z dy in ea eb io ed ef hh bi translated">科技捕手</h2><div class="ip l"><h3 class="bd b fi z dy in ea eb io ed ef dx translated">关于技术、隐私、人工智能伦理及其政策含义的简短片段和内容监管</h3></div><div class="iq l"><p class="bd b fp z dy in ea eb io ed ef dx translated">techcatcher.io</p></div></div></div></a></div><p id="54e9" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">2021年8月，<a class="ae jp" href="https://www.apple.com/child-safety/" rel="noopener ugc nofollow" target="_blank">苹果宣布</a>从iOS 15开始扫描用户iCloud照片中的儿童性虐待素材(CSAM)。与谷歌和微软不同，<a class="ae jp" href="https://www.microsoft.com/en-us/photodna" rel="noopener ugc nofollow" target="_blank">从他们的云服务器为CSAM </a>扫描用户照片，苹果的扫描将发生在用户的设备上，就在照片被同步到iCloud之前。苹果声称他们的方式增强了隐私，因为<a class="ae jp" href="https://www.theverge.com/2021/8/10/22613225/apple-csam-scanning-messages-child-safety-features-privacy-controversy-explained" rel="noopener ugc nofollow" target="_blank">它不会暴露任何关于其他用户照片的信息</a>，如果它扫描它的服务器，这可能不是真的。然而，批评者警告说，这可能会给执法部门获取设备上的用户数据带来危险。</p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es jq"><img src="../Images/87e84d6b93dd8fcea0d16b6ede34a041.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*76MGoo_gKdnz2oYMFw91WQ.jpeg"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx"><a class="ae jp" href="https://www.apple.com/child-safety/" rel="noopener ugc nofollow" target="_blank">Source</a>: Apple Child Safety</figcaption></figure><p id="cd8b" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如下图所示，<a class="ae jp" href="https://www.apple.com/child-safety/pdf/CSAM_Detection_Technical_Summary.pdf" rel="noopener ugc nofollow" target="_blank">如果两个条件都满足，苹果的算法只会解密用户的照片以供人工检查</a>。首先，照片必须与国家失踪和被剥削儿童中心策划的已知CSAM内容相匹配。其次，用户必须在iCloud上存储足够多的超过给定阈值的匹配照片。</p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es kg"><img src="../Images/bace244911253637d264e981c18aba80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*384QHaGfAra2Xu64agywqw.png"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx"><a class="ae jp" href="https://www.apple.com/child-safety/pdf/CSAM_Detection_Technical_Summary.pdf" rel="noopener ugc nofollow" target="_blank">Source</a>: Apple CSAM Detection — Technical Summary</figcaption></figure><p id="9964" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">计算机科学家之间的意见有分歧:<a class="ae jp" href="https://9to5mac.com/2021/08/05/apple-announces-new-protections-for-child-safety-imessage-safety-icloud-photo-scanning-more/" rel="noopener ugc nofollow" target="_blank">一些人称赞它是对抗CSAM和保护用户隐私的一种方式</a>，利用加密技术来最大限度地减少对私人数据的入侵。然而其他人警告说，苹果现在可能<a class="ae jp" href="https://www.theverge.com/2021/8/10/22613225/apple-csam-scanning-messages-child-safety-features-privacy-controversy-explained" rel="noopener ugc nofollow" target="_blank">拥有绕过端到端加密的技术能力</a>，它将无法无视执法部门对用户数据的要求，就像它在2016年圣贝纳迪诺枪击案争议中所做的那样<a class="ae jp" href="https://www.theverge.com/2016/2/17/11036306/apple-fbi-iphone-encryption-backdoor-tim-cook" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es kh"><img src="../Images/0fc4cda7e72ca4ab8641843a37e190ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jo92zb_6MtS6q-BjuK79OA.jpeg"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx"><a class="ae jp" href="https://www.apple.com/child-safety/pdf/Expanded_Protections_for_Children_Technology_Summary.pdf" rel="noopener ugc nofollow" target="_blank">Source</a>: Apple Expanded Protections for Children</figcaption></figure></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="ac32" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">相关报道-&gt;法院支持谷歌:利用哈希值检测儿童色情</h1><p id="0bf2" class="pw-post-body-paragraph ir is hi it b iu ln iw ix iy lo ja jb jc lp je jf jg lq ji jj jk lr jm jn jo hb bi translated">2015年7月，威廉·米勒在他的Gmail中附上了两份儿童色情文件。谷歌的散列值算法发现并向当局报告了它们。<a class="ae jp" href="https://www.courtlistener.com/opinion/4835528/united-states-v-william-miller/?q=algorithm&amp;type=o&amp;order_by=score%20desc&amp;stat_Precedential=on&amp;filed_after=12%2F01%2F2020" rel="noopener ugc nofollow" target="_blank">米勒辩称</a>当执法部门查看他在谷歌上分享的文件时，他受到了<a class="ae jp" href="https://www.dbllaw.com/artificial-intelligence-and-the-impact-it-has-in-criminal-investigations-today/" rel="noopener ugc nofollow" target="_blank">不合理的搜查</a>。<a class="ae jp" href="https://www.courtlistener.com/opinion/4835528/united-states-v-william-miller/?q=algorithm&amp;type=o&amp;order_by=score%20desc&amp;stat_Precedential=on&amp;filed_after=12%2F01%2F2020" rel="noopener ugc nofollow" target="_blank">但是第六巡回法庭认为</a>政府在这个案件中没有进行第四修正案搜索:谷歌的散列值搜索创造了一个“虚拟的确定性”,即米勒的图像是非法的，使得政府的搜索只披露了谷歌已经披露的内容。那么哈希值是如何虚拟确定地检测色情内容的呢？</p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es ls"><img src="../Images/8584e16ef729b5a9f5d0db63f2a75d80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jjHhf6gSabF1JwgwE_D8xw.jpeg"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx"><a class="ae jp" href="https://news.microsoft.com/on-the-issues/2018/09/12/how-photodna-for-video-is-being-used-to-fight-online-child-exploitation/" rel="noopener ugc nofollow" target="_blank">(Microsoft uses hash value based techniques to detect child pornography in video)</a></figcaption></figure><p id="b393" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在这种情况下，哈希是图像文件的唯一数字指纹，可以抵抗像调整大小这样的更改。对于上传到Gmail的每个文件，谷歌都会计算其哈希值，并将其与国家失踪和受剥削儿童中心管理的经确认的色情内容进行比较。如果两个哈希值匹配，谷歌将向适当的监管机构报告照片，而不查看电子邮件的内容。<a class="ae jp" href="https://www.blog.google/around-the-globe/google-europe/using-ai-help-organizations-detect-and-report-child-sexual-abuse-material-online/" rel="noopener ugc nofollow" target="_blank">谷歌后来宣布，它正在使用深度神经网络来检测以前没有记录的新的儿童性虐待材料。</a></p><div class="if ig ez fb ih ii"><a href="https://techcatcher.io" rel="noopener  ugc nofollow" target="_blank"><div class="ij ab dw"><div class="ik ab il cl cj im"><h2 class="bd hj fi z dy in ea eb io ed ef hh bi translated">科技捕手</h2><div class="ip l"><h3 class="bd b fi z dy in ea eb io ed ef dx translated">关于技术、隐私、人工智能伦理及其政策含义的简短片段和内容监管</h3></div><div class="iq l"><p class="bd b fp z dy in ea eb io ed ef dx translated">techcatcher.io</p></div></div></div></a></div></div></div>    
</body>
</html>