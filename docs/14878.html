<html>
<head>
<title>What is Data cleaning? How data cleaning can be done?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是数据清洗？如何进行数据清理？</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/what-is-data-cleaning-how-data-cleaning-can-be-done-20722af9dc67?source=collection_archive---------8-----------------------#2022-09-30">https://medium.com/geekculture/what-is-data-cleaning-how-data-cleaning-can-be-done-20722af9dc67?source=collection_archive---------8-----------------------#2022-09-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/d1d7c8dbb7815ed4b94a748563e22c8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hQSC_6f4HDmuPPjFIoG-eQ.jpeg"/></div></div></figure><p id="6234" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当我们从一个来源收集数据时，它被称为原始数据或原始数据。每一个原始数据都有可能变成信息。可以看我的<a class="ae jo" rel="noopener" href="/geekculture/data-information-and-knowledge-4e8b9fdeaa04">文章</a>了解更多的信息和知识。</p><p id="be53" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当我们从data exhaust收集数据时，我们会得到大量的原始数据。数据枯竭是指互联网或计算机用户在网上活动和交易过程中留下的非常规数据或数据痕迹。这包括地理空间、网络、时间序列、网站访问、点击链接，甚至鼠标悬停，这些都是以cookies、临时文件、日志文件、可存储选项等形式出现的。处理后的一些数据可用于预测分析、改进用户界面和布局设计等。</p><p id="4b60" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这些原始数据可能有很多干扰、重复、未格式化或有多种格式，通常没有模式，并且缺乏一致性和完整性。为了从这些数据中提取信息或见解以做出业务决策，我们必须确保数据是干净的，并执行数据质量检查。如果没有清理数据和执行质量检查，那么它可能会导致不正确或错误的见解，并最终导致不正确的业务决策。数据只有在经过清理和质量检查后才有价值。</p><h1 id="9452" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">数据清理</h1><p id="d9e6" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">数据清理也称为数据清理或数据擦洗，是将脏的或杂乱的数据转换为干净数据的过程，这些数据可以提供给机器学习模型或用于数据分析。所有数据集可能不需要所有的数据清理过程。基本的数据清理过程是:</p><h2 id="dfc6" class="ks jq hi bd jr kt ku kv jv kw kx ky jz jb kz la kd jf lb lc kh jj ld le kl lf bi translated">删除重复项:</h2><p id="3707" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">当数据被废弃或通过不同方式收集时，或者当客户提交冗余表单或来自不同数据源的混合数据时，或者当数据在系统之间传输时，就会出现重复数据。这些重复的记录增加了存储成本。但是，当将数据标记为重复时，它应该是一个完整的副本，因为部分重复可能具有商业价值。例如，如果是根据每月的交易次数来检查客户，则客户详细信息将是相同的，只有交易、交易金额和其他与交易相关的详细信息将是不同的。因此，应该根据业务目标来分析部分重复数据。</p><p id="6930" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了用python解释这一点，我用youtube的废弃数据制作数据科学视频，数据集可以从<a class="ae jo" href="https://github.com/SandKrish/Data-Cleaning/blob/main/DataScience_Youtube_Videos.csv" rel="noopener ugc nofollow" target="_blank">这里</a>访问。在python中，使用duplicate()函数返回一系列真值和假值，用于描述数据框中的哪些行被复制。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lg"><img src="../Images/b03584ccfa5664f7e857975c4de7321f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oviPWRx01GVGjx-eN4n_wA.png"/></div></div></figure><p id="5e0a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，duplicate()函数为173行中的两个不同的行返回了True，这表明这两行中的每一行都有一个副本。</p><p id="12ec" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">部分重复可以通过使用带有duplicate()函数的子集来识别。如果我们必须找到channel_name的部分副本，我们可以使用df[df . duplicated(subset = " Channel _ Name ")]来找到它们。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/cd7596bf2c605428407f3c83ce86ce75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z1s2_fgA3EzWU-erC50Y4Q.png"/></div></div></figure><p id="dbf2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这个数据集中，我们有67个Channel_Name的部分副本。</p><p id="1988" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要删除重复项，我们可以将drop_duplicates()与keep as first、last或False一起使用，这将保留第一个重复项并删除rest，保留最后一个重复项并删除rest，或者同时删除所有重复项。“保持值”的默认值为“第一”。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lm"><img src="../Images/f0b3788c12d7132dbe5a12ad87b8dc24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OQueWuf-WP7O9UDo2wQCeA.png"/></div></div></figure><p id="4ccf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里result_df只有171，这意味着删除了两个重复的记录。代码片段解释了相同的内容。</p><h2 id="3c52" class="ks jq hi bd jr kt ku kv jv kw kx ky jz jb kz la kd jf lb lc kh jj ld le kl lf bi translated">删除不相关的观察/数据:</h2><p id="997c" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">如果业务目标是在一个时间范围内分析数据，不属于这个类别的数据可以被删除。同样，如果我们的数据有许多列，如全名、名字、姓氏、中间名和用户id，除了全名之外，我们可以删除其余的3列，因为这对目标没有任何意义。通过移除不相关的观察和/或数据，得到的数据将更有效，并且对业务目标的干扰最小。</p><h2 id="26ad" class="ks jq hi bd jr kt ku kv jv kw kx ky jz jb kz la kd jf lb lc kh jj ld le kl lf bi translated">修复结构错误:</h2><p id="110d" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">有不同形式的结构错误，如废弃的数据可能有' \n '，或者包含要输入的城市的类型表单可能有城市缩写或完整形式或城市的旧名称，则不适用可以写成NA、N/A或No。因此这些类型的结构错误应在数据清理流程中解决。</p><p id="0842" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在数据集中，我们可以看到“\n”代表Video_Title。我们使用replace()来清理Video_Title。我们还可以检查任何其他列是否有' \n '，如果有，也可以清理该列。</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/3bd4de664416a744b8b2c85cd2e39680.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dVbyJDqRWMlvxtrnZdhYrg.png"/></div></div></figure><p id="6d10" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在清理完“\n”之后使用strip()总是一个更好的做法，这样可以修剪掉多余的空格。这里我们可以看到只有Video_Title有' \n's。</p><p id="60df" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">完整的Python代码可以从<a class="ae jo" href="https://github.com/SandKrish/Data-Cleaning/blob/main/DataCleaning.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>访问。</p><h2 id="9d9d" class="ks jq hi bd jr kt ku kv jv kw kx ky jz jb kz la kd jf lb lc kh jj ld le kl lf bi translated"><strong class="ak">格式:</strong></h2><p id="85b8" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">如果数据是从不同的来源收集的，如2021年9月12日、2021年12月9日、2021年12月9日、2021年9月12日或21年9月12日，则日期可以有不同的格式。因此，在分析数据或将其提供给ML模型之前，将数据格式化为单一格式是必须遵循的步骤。</p><h2 id="b36b" class="ks jq hi bd jr kt ku kv jv kw kx ky jz jb kz la kd jf lb lc kh jj ld le kl lf bi translated"><strong class="ak">过滤不想要的离群值:</strong></h2><p id="e0ae" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">当一个观察值的平均值是标准偏差的正负2倍时，它被认为是异常值。但是，如果我们有一个离群值，我们不应该在没有适当分析的情况下丢弃它。如果一些文件的文件大小是异常值，那么这些文件很可能包含重复值或不相关的观察值，而这些值或观察值没有被处理。因此，第一步是检查和分析文件内容，而不是在没有任何适当验证的情况下就丢弃它。有时离群值是有效的，它们可以证明我们的业务目标。</p><h2 id="9de0" class="ks jq hi bd jr kt ku kv jv kw kx ky jz jb kz la kd jf lb lc kh jj ld le kl lf bi translated">处理缺失值</h2><p id="e82a" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">在处理缺失值之前，应执行其余所有数据清理过程，尤其是删除重复项和处理不相关观察值或数据和异常值。否则，在使用平均值/中值进行数据插补时，您将采用整个数据的平均值或中值，这将给出错误的结果。处理缺失值的几种方法如下:</p><p id="6f29" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果一列有85%的值丢失，那么我们没有足够的数据来填充这些丢失的值。所以我们可以放弃这个专栏。</p><p id="3317" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当一个列缺少分类值时，我们可以用默认值或“未知”来替换它。但是当数值缺失时，我们可以用均值或中值或KNN插补来估算。或者根据业务目标，我们可以使用预测算法来预测缺失值，这将提供更好的准确性，除非缺失值预计具有非常高的方差。</p><p id="fa06" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据清理完成后，在获取数据进行分析或将其提供给ML模型之前，应该进行数据质量检查。在我的下一篇文章中，我将介绍数据质量检查以及如何进行检查。</p></div><div class="ab cl lo lp gp lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="hb hc hd he hf"><p id="f434" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你觉得这篇文章有用，请鼓掌:)</p></div></div>    
</body>
</html>