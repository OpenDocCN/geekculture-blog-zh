<html>
<head>
<title>Web Audio API and computer audio learnings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">网络音频API和计算机音频学习</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/web-audio-api-and-computer-audio-learnings-f5390acdb3ec?source=collection_archive---------6-----------------------#2022-07-24">https://medium.com/geekculture/web-audio-api-and-computer-audio-learnings-f5390acdb3ec?source=collection_archive---------6-----------------------#2022-07-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="28ba" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">文章的意图</h1><p id="5a4b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这将作为我未来学习电脑音频和网络音频API的笔记。如果我有新的收获，我会试着更新这篇文章。</p><p id="5500" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我会试着把它变成一个问答，这样我问自己的相关问题就会在这里得到回答。</p><h2 id="8dbf" class="kg ig hi bd ih kh ki kj il kk kl km ip jo kn ko it js kp kq ix jw kr ks jb kt bi translated"><strong class="ak">一般问题</strong></h2><p id="0864" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jf hj"><em class="ku">web音频api如何工作</em> </strong></p><p id="6169" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">web audio api使用一些操作功能(音频节点)构建源(声音输入，如麦克风、web视频/音频标签或音频流)和最终到达目的地(如扬声器)之间的节点图</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es kv"><img src="../Images/15c275939a881737d11720106e2a264b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DELNpIJAiZPrgZCL.jpg"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx">Image from <a class="ae ll" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API" rel="noopener ugc nofollow" target="_blank">https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API</a></figcaption></figure><h2 id="93bf" class="kg ig hi bd ih kh ki kj il kk kl km ip jo kn ko it js kp kq ix jw kr ks jb kt bi translated">问题提交给分析器</h2><p id="7486" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><strong class="jf hj"> <em class="ku">它是如何工作的？</em>T9】</strong></p><p id="763b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">示例中的函数调用非常简单，上游节点会将声音信号传递到分析器节点，我们可以获得时域或频域数据。</p><p id="77cf" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="ku">那么fftsize是什么呢？</em>T13】</strong></p><p id="9cfc" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">FFT是快速傅立叶变换的简称，其大小将控制输出点的数量。文档含糊地解释了如下的效果/结果:</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es lm"><img src="../Images/f271167c82ebf606e25e52fef6f6a62a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*9yg_DsFynhkwN4XsyWkwVA.png"/></div><figcaption class="lh li et er es lj lk bd b be z dx">from <a class="ae ll" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API" rel="noopener ugc nofollow" target="_blank">https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API</a></figcaption></figure><p id="86b9" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">从我的理解来说，fftsize就是目标bin的大小(或者应该是正弦波频率的多少？)快速傅立叶变换(FFT)将应用于信号。</p><p id="7abb" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">根据chromium实现的源代码，实际的核心代码在<a class="ae ll" href="https://github.com/chromium/chromium/blob/main/third_party/blink/renderer/modules/webaudio/realtime_analyser.cc" rel="noopener ugc nofollow" target="_blank"> realtime_analyser.cc </a>，getFloatFrequencyData或getByteFrequencyData API引用C文件中的同名函数。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es ln"><img src="../Images/98e11d5bee4b9a7dd32834b5caf995df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*iyD3OzoSWC32JXMF-nabcQ.png"/></div></figure><p id="5238" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">主调用是DoFFTAnalysis()，逻辑是“大致”:</p><pre class="kw kx ky kz fd lo lp lq lr aw ls bi"><span id="de47" class="kg ig hi lp b fi lt lu l lv lw">1. copy data from input buffer to temp buffer for FFT<br/>2. call ApplyWindow(buffer, fft_size) # this is to transform the data with a Blackman window to facilitate FFT<br/>3. call DoFFT(...) on the buffer<br/>4. Take the return from FFT, combine the real and complex number into magnitude and scale it</span></pre><p id="b9dc" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="ku">那么为什么最终的bin大小是fftsize的一半呢？</em>T19】</strong></p><p id="4e8a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我相信这是由于奈奎斯特极限，任何超过1/2采样频率只是重复(？)和冗余(这也可能与FFT将输入样本信号视为无限重复波有关)。</p><p id="2a2a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="ku">为什么代码看不到实际的FFT实现？</em> </strong></p><p id="e2cf" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我认为，尝试执行实际FFT操作的代码行是特定于平台的，并且依赖于其他库</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es lx"><img src="../Images/e3f51ddd8d28fd4512e6ddc9b2da2faf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*eSXRtCoQIdG-79ZAfuZkRg.png"/></div><figcaption class="lh li et er es lj lk bd b be z dx">This line is the line calling the DoFFT function</figcaption></figure><p id="f214" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">当我们检查文件夹时</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es ly"><img src="../Images/2c71a88d53e983262073d6022a546595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*UdtQ04A_fz4pR2GnLhTeOQ.png"/></div></figure><p id="de7f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这些不同的文件夹对于analysis_frame有它们自己的实现细节(我“相信”核心实现是pffft，但我不是100%确定)</p><p id="42b4" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">下面是pffft实现，我们看到这里实现了len = fft_size / 2:</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es lz"><img src="../Images/069693bb58d394fe81de05a899b81dd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*t8VnoeN2nN5ITisGOiV4iw.png"/></div></figure><p id="e964" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="ku">什么是布莱克曼窗？</em> </strong></p><p id="73af" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我相信这两个视频(<a class="ae ll" href="https://www.youtube.com/watch?v=Q8N8pZ8P3f4" rel="noopener ugc nofollow" target="_blank">视频1 </a>，<a class="ae ll" href="https://www.youtube.com/watch?v=pD7f6X9-_Kg" rel="noopener ugc nofollow" target="_blank">视频2) </a>会比我给出更好的解释。我有限的理解是，这有助于FFT减少泄漏(并产生更好的结果来更精确地捕捉频率)</p><p id="0a4f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">请注意，Blackman windows只是不同类型的windows中的一种。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ma"><img src="../Images/beccb52a0b4f0e00fadda5e702d7c90d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6_t7wU80oAQkkPQ81i4XiA.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx">screen capture from video: <a class="ae ll" href="https://www.youtube.com/watch?v=Q8N8pZ8P3f4" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=Q8N8pZ8P3f4</a></figcaption></figure><p id="f788" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">【getByteFrequencyData()和getFloatFrequencyData()有什么区别？ </p><p id="dc05" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">get byte函数执行与get float函数相同的操作，只是在返回之前增加了一个标度(到0–255)。</p><p id="b4f6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这里我有一个问题:当我检查浮点返回的值时，这些值都是-ve分贝范围从-20到-190，字节转换是如何工作的(因为min _分贝_是默认值= -100，max分贝是默认值-30 &lt;= these are written in realtime_analyser.h)</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es mb"><img src="../Images/91f172e10a81b1b3cbf0a13e613d3992.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*pNPvZq0A5a7YlKqFGF4Bcw.png"/></div></figure><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es mc"><img src="../Images/12c2790479526cca12599e018c0cc8d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*DvI2OqFtt4dxxsA1cYvRCg.png"/></div><figcaption class="lh li et er es lj lk bd b be z dx">Compare to above, it just add the lines after the call to audio_utilities::LinearToDecibels(…);</figcaption></figure><p id="5af8" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="ku">分析器返回的bin的大小/单位是多少？</em>T11】</strong></p><p id="092a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">如上所述，仓的大小与fftsize有关，因此如果我们将2048作为fftsize，我们将得到1024 (2048 / 2)个数字(以分贝或字节为单位)，每个数字对应于特定频率范围的信号幅度，该范围与我们的采样速率有关。</p><p id="6d92" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">如果我们以44100 Hz对音频进行采样，那么每个bin /数据代表“采样率/频率”下的信号幅度。</p><p id="8de4" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在我们的示例中，该值为44100 / 2048，约为21.5 Hz，因此返回数组中的第一个数据应构成对应于0–21.5Hz的振幅，第二个值为21.5–43Hz…</p><p id="b19b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="ku">我们测量/采样信号需要多长时间？</em>T15】</strong></p><p id="c03a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">对于这一点，我不是100%确定，但据我了解，它与帧大小和采样率有关。这个框架就是代码中的" analysis_frame"。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es lx"><img src="../Images/e3f51ddd8d28fd4512e6ddc9b2da2faf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*eSXRtCoQIdG-79ZAfuZkRg.png"/></div></figure><p id="155c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">帧大小由提供的fftsize定义。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es mc"><img src="../Images/b26e2b3a07cdcf9318333428184c48f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*CXu1fTe_9U4YYnAYt_yssg.png"/></div></figure><p id="d882" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">因此，我们可以得出这样的结论:我们正在获取一帧样本大小= 2048(在我们的示例中)，采样率= 44100 Hz(每秒样本数)，因此我们正在分析1 / 44100 * 2048 = 0.046(秒)的声音</p><p id="e0e4" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我还参考了<a class="ae ll" href="http://musicandcomputersbook.com/chapter3/03_05.php" rel="noopener ugc nofollow" target="_blank">这本书的在线章节“频率和时间分辨率的权衡”</a>(以及以下章节)。</p><p id="59ef" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">(更多内容请点击此处……)</p><p id="57e6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">(下一项是MDN示例的可视化)</p><h2 id="ec69" class="kg ig hi bd ih kh ki kj il kk kl km ip jo kn ko it js kp kq ix jw kr ks jb kt bi translated">参考</h2><p id="f461" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">以下是我阅读的参考资料:</p><p id="89eb" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="ku">关于编码和实现</em> </strong></p><p id="abf3" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">官方网络音频API文档 —在一定程度上有帮助，你会得到基本的基础，有他们引用的示例代码(在github中)，你已经可以做一些东西了，但是当我想知道为什么和如何实现它时，我们需要找到其他来源</p><p id="3ae7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae ll" href="https://github.com/chromium/chromium/blob/9841ee86b710dc649cf41772f560600324cadf45/third_party/blink/renderer/modules/webaudio/realtime_analyser.cc" rel="noopener ugc nofollow" target="_blank">Chromium音频处理的源代码</a>(或【blink webaudio的原始回购 )—每个浏览器在支持下实现web audio API的方式不同，这个是针对Chromium的(Chrome的基础)，从这里我了解到一些API是如何实现的，并回答了我的一些“为什么”问题</p><p id="17f5" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae ll" href="https://www.youtube.com/watch?v=uasGsHf7UYA" rel="noopener ugc nofollow" target="_blank">Neil McCallion的视频【我玩JavaScript:制作网络音频合成器(Neil McCallion)】</a>—观看涵盖编码和一些音乐理论的视频很有趣，一步一步的解释有助于完成MDN文档中的未知内容。</p><p id="55d1" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae ll" href="https://www.youtube.com/watch?v=VXWvfrmpapI" rel="noopener ugc nofollow" target="_blank">关于构建nice analytic的视频【面向初学者的JavaScript音频速成班】</a> —适合初学者水平，web音频API上的编码并没有超出MDN文档太多，但很高兴看到可视化如何与azalyser节点输出联系起来。</p><p id="74c0" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae ll" href="https://www.youtube.com/watch?v=JNtuLw2fybo" rel="noopener ugc nofollow" target="_blank">制作交互式旋律播放器的视频【使用普通JavaScript、HTML Canvas和web audio API的Melody Maker应用】</a> —这太有趣了，是使用Web Audio API的另一个很好的例子。</p><p id="eab5" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae ll" href="https://towardsdatascience.com/audio-deep-learning-made-simple-part-1-state-of-the-art-techniques-da1d3dff2504" rel="noopener" target="_blank">音频深度学习制作了简单系列</a> —即使它更专注于深度学习，第一篇和第二篇文章解释了音频数据是如何被处理和理解的，澄清了许多基础问题</p><p id="d5c9" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="ku">论</em> </strong></p><p id="b75d" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">很好的音频编程概念和数学的报道，如果你喜欢视频的话，有一个youtube频道</p><p id="d12b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">音乐和电脑书——这本书很好地涵盖了电脑音乐，有声音示例和微型网络程序来帮助说明这个想法(仍在阅读)</p><p id="57d6" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">马克·纽曼的傅立叶变换课程——他的解释比我那时的大学教授好得多，至少值得看看免费视频</p><p id="b36f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><a class="ae ll" href="https://pages.mtu.edu/~suits/Physicsofmusic.html" rel="noopener ugc nofollow" target="_blank">MTU</a>的音乐物理学笔记——他们班上的课程笔记，可能会有用(还没读完)</p></div></div>    
</body>
</html>