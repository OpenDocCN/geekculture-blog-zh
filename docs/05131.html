<html>
<head>
<title>Finding the important features of a feature set: A classification task with sklearn’s algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">寻找特征集的重要特征:使用sklearn算法的分类任务</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/finding-the-important-features-of-a-feature-set-a-classification-task-with-sklearns-algorithms-3003f740faf9?source=collection_archive---------7-----------------------#2021-07-11">https://medium.com/geekculture/finding-the-important-features-of-a-feature-set-a-classification-task-with-sklearns-algorithms-3003f740faf9?source=collection_archive---------7-----------------------#2021-07-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/a2a2e4f13fef56c44e37e6400d34695d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wnfngm0k7LDmX_-0A1sjwg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Photo by <a class="ae iu" href="https://unsplash.com/@tanuj_dargan?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Tanuj Dargan</a> from Unsplash</figcaption></figure><h1 id="0d90" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">介绍</h1><p id="ea18" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">在大多数机器学习任务中，分析师需要了解特征集中的重要特征，这些特征对目标变量有较大的影响。在为任务准备好初步模型之后，这些关于重要特征的知识肯定有助于通过丢弃一些“不相关”的特征来使模型变得更好——尽管这也取决于使用哪个分类器来建模。</p><p id="2dbc" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">在本文中，我们将查看一个分类任务，其中我们将使用一些<a class="ae iu" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> sklearn </a>的分类器对我们的目标变量进行分类，并尝试为我们的数据集准备一个分类模型。然后对于“最佳”模型，我们将找到特征重要性度量。</p><h1 id="9041" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">数据集</h1><p id="6a70" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">我们将使用的数据集基于银行贷款，其中目标变量是取值为0或1的分类变量“bad_loan”。我们还有10个连续变量的特征。我们有大约5400次观察。<em class="kw">如果我们的任何读者想要数据集，请通过</em> <a class="ae iu" href="https://www.linkedin.com/in/pritam-kumar-patro-1098b9163/" rel="noopener ugc nofollow" target="_blank"> <em class="kw"> LinkedIn </em> </a>告诉我。我们数据集的头尾看起来像这样:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/6f7c6cc70fe1145fd0172c030fe9ea1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y8w6pg_sU8WLW8zZS3ozhw.png"/></div></div></figure><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lc"><img src="../Images/414d7fbb76234e2af6e5235fde22a720.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zy_W4hBeQZceFLbxxT0zSg.png"/></div></div></figure><h1 id="fd4f" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">用sklearn的算法用Python编程</h1><p id="fed9" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">在本文中，我们将分析数据，并使用sklearn的一些算法将分类模型拟合到我们的数据中。我们开始吧！！！</p><pre class="ky kz la lb fd ld le lf lg aw lh bi"><span id="81a2" class="li iw hi le b fi lj lk l ll lm">import numpy as np<br/>import pandas as pd<br/>from sklearn.model_selection import train_test_split</span><span id="2e7b" class="li iw hi le b fi ln lk l ll lm">file=pd.read_csv("D:/TDS1_Data.csv")<br/>df=pd.DataFrame(file)</span></pre><p id="23c8" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">有了这个代码块，我们已经将数据集加载到机器中进行分析。然后让我们看看数据集中的变量。</p><pre class="ky kz la lb fd ld le lf lg aw lh bi"><span id="38b2" class="li iw hi le b fi lj lk l ll lm">for columns in df.columns:<br/>    print(columns)</span></pre><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/b088843a8fb416f7bc2bcc8a9b5d7756.png" data-original-src="https://miro.medium.com/v2/resize:fit:302/format:webp/1*2Hsaq4JNKSE0B8GjbnD7kg.png"/></div></figure><p id="f222" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">对于下一组代码行，我们将把数据集分成训练集(70%)和测试集(30%)。</p><pre class="ky kz la lb fd ld le lf lg aw lh bi"><span id="fc77" class="li iw hi le b fi lj lk l ll lm">X = df.drop(‘bad_loan’, axis=1)<br/>y = df[‘bad_loan’].copy()</span><span id="adda" class="li iw hi le b fi ln lk l ll lm">features=[]<br/>for columns in X.columns:<br/>    features.append(columns)</span><span id="f83e" class="li iw hi le b fi ln lk l ll lm">rand_seed = 42</span><span id="7a7a" class="li iw hi le b fi ln lk l ll lm">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=rand_seed)</span></pre><p id="f533" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">在我们将数据集分成训练集和测试集之后，让我们使用来自sklearn的一些分类器来建模和拟合我们的训练集。我们将使用<a class="ae iu" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html" rel="noopener ugc nofollow" target="_blank">装袋分类器</a>、<a class="ae iu" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">随机森林分类器</a>和<a class="ae iu" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html" rel="noopener ugc nofollow" target="_blank">梯度推进</a>分类器来完成任务。但是首先，我们将使用一个<a class="ae iu" href="https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html" rel="noopener ugc nofollow" target="_blank">虚拟</a>分类器来确定我们的训练集的准确性。</p><pre class="ky kz la lb fd ld le lf lg aw lh bi"><span id="1645" class="li iw hi le b fi lj lk l ll lm">from sklearn.dummy import DummyClassifier</span><span id="1da8" class="li iw hi le b fi ln lk l ll lm">dummy_clf = DummyClassifier(strategy=”most_frequent”)<br/>dummy_clf.fit(X_train, y_train)</span><span id="0c1f" class="li iw hi le b fi ln lk l ll lm">dummy_clf.predict(X_train)</span><span id="c84e" class="li iw hi le b fi ln lk l ll lm">print(“Baseline Accuracy of X_train is:”,””, dummy_clf.score(X_train, y_train).round(3))</span></pre><p id="10b5" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我们发现精确度为:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/7c72adc2c627035c909df18bba44fe79.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*6lmppj6adpp5CdPXbyp96g.png"/></div></figure><p id="3b3f" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">在下一组代码行中，我们将使用一些分类器来建模我们的训练数据集。我们从装袋分类器开始。我们还将举例说明如何制作分类模型的分类报告:)</p><pre class="ky kz la lb fd ld le lf lg aw lh bi"><span id="cd9b" class="li iw hi le b fi lj lk l ll lm">from sklearn.ensemble import BaggingClassifier<br/>from sklearn.metrics import accuracy_score</span><span id="1abe" class="li iw hi le b fi ln lk l ll lm">bagg_clf = BaggingClassifier(random_state=rand_seed)<br/>bagg_model = bagg_clf.fit(X_train, y_train)<br/>bagg_model_fit = bagg_model.predict(X_test)</span><span id="32e7" class="li iw hi le b fi ln lk l ll lm">print(“Accuracy of the Bagging model is:”,””, accuracy_score(y_test, bagg_model_fit).round(3))</span><span id="6360" class="li iw hi le b fi ln lk l ll lm">from sklearn.metrics import (<br/> classification_report,<br/> recall_score,<br/> precision_score,<br/> accuracy_score<br/>)<br/>print(‘Classification Report for the Bagging model is:\n’)<br/>print(classification_report(y_test, bagg_model))</span></pre><p id="631a" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">上述代码行的输出是:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/3d6c45fa191ad0c14020e05ac12af5a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*lviRq6kqoUwb7C3B8jYvfQ.png"/></div></figure><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/3c9f0e8ae951e8862a8a636c662e5506.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*wajSgYho5QnWt_7XTz89Nw.png"/></div></figure><p id="525c" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我们看到集合方法对提高模型的准确性帮助很大。与训练模型相比，bagging模型的准确率提高了10%左右。现在我们转向随机森林分类器。</p><pre class="ky kz la lb fd ld le lf lg aw lh bi"><span id="a744" class="li iw hi le b fi lj lk l ll lm">from sklearn.ensemble import RandomForestClassifier</span><span id="6b42" class="li iw hi le b fi ln lk l ll lm">ranfor_clf = RandomForestClassifier(n_estimators=10, max_features=7, random_state=rand_seed)<br/>ranfor_model = ranfor_clf.fit(X_train,y_train)<br/>ranfor_model_fit = ranfor_model.predict(X_test)</span><span id="8f33" class="li iw hi le b fi ln lk l ll lm">print(“Accuracy of the Random Forest model is:”,””, accuracy_score(y_test, ranfor_model_fit).round(3))</span></pre><p id="bdb2" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我们发现精确度为:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/c97aa629b7f7747f46768b9a70cabd3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*yY59Qc3nPLaIMu6klP3-fA.png"/></div></figure><p id="f211" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我们可以看到，随机森林分类器的准确性仍然有所提高，但可以忽略不计。在大多数情况下，这是一个很好的指标，表明在当前的设置下，我们不会获得任何合理的更好的精度。让我们看看梯度提升分类器是否能帮助我们获得更好的准确性。</p><pre class="ky kz la lb fd ld le lf lg aw lh bi"><span id="2106" class="li iw hi le b fi lj lk l ll lm">from sklearn.ensemble import GradientBoostingClassifier</span><span id="295d" class="li iw hi le b fi ln lk l ll lm">gradboost_clf = GradientBoostingClassifier()<br/>gradboost_model = gradboost_clf.fit(X_train,y_train)<br/>gradboost_model_fit = gradboost_model.predict(X_test)</span><span id="3076" class="li iw hi le b fi ln lk l ll lm">print(“Accuracy of the Gradient Boosting model is:”,””, accuracy_score(y_test, gradboost_model_fit).round(3))</span></pre><p id="8fbc" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我们发现精确度为:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/d623fd71dc33beb975cc38b7b0edc4ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*KdoJcUzA44SwBDMGTlLV1Q.png"/></div></figure><p id="bc91" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">现在我们可以得出结论，使用集合方法，90%是我们可以挽救的最好精度:)<em class="kw">请不要这样，这不是提高模型精度的终点。</em></p><p id="6f01" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">随着梯度增强分类器在三个分类器中实现最高的准确性，现在让我们根据特征的重要性来寻找特征的各个权重。</p><pre class="ky kz la lb fd ld le lf lg aw lh bi"><span id="3ab7" class="li iw hi le b fi lj lk l ll lm">imp_features = gradboost_model.feature_importances_</span><span id="fb37" class="li iw hi le b fi ln lk l ll lm">for i in imp_features:<br/>    print(i.round(3))</span><span id="1899" class="li iw hi le b fi ln lk l ll lm">df_imp_features = pd.DataFrame({"features":features}).join(pd.DataFrame({"weights":imp_features}))</span><span id="beac" class="li iw hi le b fi ln lk l ll lm">df_imp_features.sort_values(by=['weights'], ascending=False)</span></pre><p id="c2cb" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我们得到一个输出:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/f7785cf230dd4f8a95f9e75d95dd5574.png" data-original-src="https://miro.medium.com/v2/resize:fit:406/format:webp/1*AURAR19erq3nBQa4h2ch8w.png"/></div></figure><h1 id="d0c6" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">结论</h1><p id="d659" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">我们看到“债务与公司比率”和“债务数量”是梯度推进模型中两个最重要的特征。我们还看到sklearn没有直接找到重要特性名称的方法，因此我们必须手动找到它们。</p></div></div>    
</body>
</html>