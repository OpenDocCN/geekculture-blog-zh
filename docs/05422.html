<html>
<head>
<title>LOGISTIC REGRESSION</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑回归</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/logistic-regression-2111fa695cdd?source=collection_archive---------32-----------------------#2021-07-20">https://medium.com/geekculture/logistic-regression-2111fa695cdd?source=collection_archive---------32-----------------------#2021-07-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/7e92f3b01e210648cbdcddf3e03c2a50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iY8hGadXo4wZ1ExH"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Photo by <a class="ae hv" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Markus Spiske</a> on <a class="ae hv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><p id="f828" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">逻辑回归是用于二元分类问题的监督机器学习算法，即目标只有两个可能的值。<br/>例如，它可用于预测患者的癌症，其中target = 0表示无癌症，反之亦然，或者将邮件检测为垃圾邮件或无垃圾邮件等。</p><h2 id="6a44" class="jt ju hy bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">LR的假设</h2><ul class=""><li id="695f" class="ko kp hy ix b iy kq jc kr jg ks jk kt jo ku js kv kw kx ky bi translated">逻辑回归假设数据几乎或线性可分。</li><li id="91ec" class="ko kp hy ix b iy kz jc la jg lb jk lc jo ld js kv kw kx ky bi translated">它要求自变量之间很少或没有多重共线性。这意味着独立变量之间的相关性不应该太高。</li><li id="0bff" class="ko kp hy ix b iy kz jc la jg lb jk lc jo ld js kv kw kx ky bi translated">它通常需要较大的样本量。</li></ul><h2 id="2a4d" class="jt ju hy bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">逻辑回归工作</h2><figure class="lf lg lh li fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es le"><img src="../Images/b00264532a18bb5c032495b815e31805.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EuNlx3d0EVoq-mKLC2Mg8w.jpeg"/></div></div></figure><p id="e980" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">假设你有两个可线性分离的类(用左边的点和十字表示)，你可以很容易地画一条线/超平面来分离这些类。<br/>让我们把这个超平面表示为π : (w，b)。<br/>平面的方程是<br/>π= w’x+b，其中x是一个数据点，它是一个矢量。</p><p id="a5e0" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们在这里的任务是找到w和b，以便我们得到超平面的方程，使得它最好地分离这两类。<br/>假设我们的目标(y)在这里是+1代表+ve点(圆点)，-1代表-ve点(十字)。<br/> <em class="lj">一个点到平面的距离(di) = w'xi，为方便起见我们假设w为单位向量。<br/> </em>现在，让我们看看如何使用下面的4个案例进行分类——</p><ul class=""><li id="d8cf" class="ko kp hy ix b iy iz jc jd jg lk jk ll jo lm js kv kw kx ky bi translated"><strong class="ix hz">案例1 </strong> : y = +ve，w'xi = +ve <br/>这意味着我们的模型说xi属于正类，我们看到<br/> y = +ve。因此我们可以说<br/>(一* w'xi) &gt; 0 <br/> <strong class="ix hz">正确归类</strong></li><li id="11ee" class="ko kp hy ix b iy kz jc la jg lb jk lc jo ld js kv kw kx ky bi translated"><strong class="ix hz">案例二:</strong> y = -ve，w'xi = -ve <br/>这意味着xi属于否定类，我们看到<br/> y = -ve。由此我们可以说<br/>(一* w'xi) &gt; 0 <br/> <strong class="ix hz">正确归类</strong></li><li id="4078" class="ko kp hy ix b iy kz jc la jg lb jk lc jo ld js kv kw kx ky bi translated"><strong class="ix hz">案例三</strong> : y = +ve，w'xi = -ve <br/>这意味着xi属于否定类，但是我们看到<br/> y = +ve。因此我们可以说<br/>(一* w'xi) &lt; 0 <br/> <strong class="ix hz">误分类</strong></li><li id="7ec4" class="ko kp hy ix b iy kz jc la jg lb jk lc jo ld js kv kw kx ky bi translated"><strong class="ix hz">案例四</strong> : y =-ve，w'xi = +ve <br/>这意味着xi属于正类，但是我们看到<br/> y = -ve。因此我们可以说<br/>(一* w'xi) &lt; 0 <br/> <strong class="ix hz">误分类</strong></li></ul><p id="57c1" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="lj">为了使我们的分类器良好，正确分类的点的总数应该增加。因此我们的动机是得到</em><strong class="ix hz"><em class="lj">max(</em>σ<em class="lj">(易* w'xi)) </em> </strong> <em class="lj">。</em></p><h2 id="e5a5" class="jt ju hy bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">使用SIGMOID消除异常值的影响</h2><p id="7b32" class="pw-post-body-paragraph iv iw hy ix b iy kq ja jb jc kr je jf jg ln ji jj jk lo jm jn jo lp jq jr js hb bi translated">因为带符号的距离会受到异常值的严重影响并产生误差。因此，为了防止这种情况，如果它超过某个阈值，我们将sigmoid应用于带符号的距离。<br/>所以我们的平面方程变成了—</p><blockquote class="lq"><p id="106d" class="lr ls hy bd lt lu lv lw lx ly lz js dx translated">w * = argmaxσsigmoid(yi * w ' Xi)，其中σ从i =1到n，n =总数据点，arg max代表w</p></blockquote><p id="3936" class="pw-post-body-paragraph iv iw hy ix b iy ma ja jb jc mb je jf jg mc ji jj jk md jm jn jo me jq jr js hb bi translated">考虑到y = (-1，+1)的逻辑回归的最终优化问题变成了:</p><blockquote class="lq"><p id="0e8f" class="lr ls hy bd lt lu lv lw lx ly lz js dx translated"><strong class="ak">w * = argminσlog(1+exp(-yi * w ' Xi))</strong>，其中σ从i =1到n，n =总数据点，arg min代表w</p></blockquote><p id="883d" class="pw-post-body-paragraph iv iw hy ix b iy ma ja jb jc mb je jf jg mc ji jj jk md jm jn jo me jq jr js hb bi translated">如果数据中的要素具有不同比例的值，则必须执行列标准化，因为它也会影响带符号的距离。</p><h2 id="2136" class="jt ju hy bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">L1和L2正规化</h2><p id="d572" class="pw-post-body-paragraph iv iw hy ix b iy kq ja jb jc kr je jf jg ln ji jj jk lo jm jn jo lp jq jr js hb bi translated">我们上面推导的优化方程会导致过拟合的问题，因为为了最小化方程的值，w可以趋向于+无穷大或-无穷大。<br/>这反过来将导致训练数据的完美拟合，因为最小值将是完美的0，因此过度拟合。为了摆脱上述问题，我们使用正则化。</p><ul class=""><li id="f26a" class="ko kp hy ix b iy iz jc jd jg lk jk ll jo lm js kv kw kx ky bi translated">我们在方程中加入一个正则项，以防止w趋于无穷大。</li><li id="2d80" class="ko kp hy ix b iy kz jc la jg lb jk lc jo ld js kv kw kx ky bi translated">使用的正则项如果等于λ(w'w ),则它是L2正则化，如果它是λ(||w||)，则它被称为L1正则化。</li></ul><p id="3586" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">λ这里是超参数，可以通过交叉验证找到。</p><blockquote class="mf mg mh"><p id="1683" class="iv iw lj ix b iy iz ja jb jc jd je jf mi jh ji jj mj jl jm jn mk jp jq jr js hb bi translated"><strong class="ix hz"> L1正则化</strong><br/><strong class="ix hz">w * = argminσlog(1+exp(-yi * w ' Xi))+λ(| | w | |)，</strong>其中σ从i =1到n，n =总数据点数，arg min代表w</p></blockquote><p id="3709" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用L1正则化的优点是它使所有不太重要的特征为0，即该特征的对应w将为0。所以L1区。如果我们有高维数据的话会非常有用。但是如果我们使用L2正则化，那么对应于该特征的w将是一个非常小的值。</p><blockquote class="mf mg mh"><p id="99b8" class="iv iw lj ix b iy iz ja jb jc jd je jf mi jh ji jj mj jl jm jn mk jp jq jr js hb bi translated"><strong class="ix hz"> L2正则化</strong><br/><strong class="ix hz">w * = argminσlog(1+exp(-yi * w ' Xi))+λ(w ' w)，</strong>其中σ从i =1到n，n =总数据点，arg min代表w</p></blockquote><p id="1a12" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hz">过拟合和欠拟合</strong></p><ul class=""><li id="fabd" class="ko kp hy ix b iy iz jc jd jg lk jk ll jo lm js kv kw kx ky bi translated">如果λ = 0，则意味着我们在考虑原始方程，因此会导致过拟合。</li><li id="e690" class="ko kp hy ix b iy kz jc la jg lb jk lc jo ld js kv kw kx ky bi translated">如果λ -&gt;无穷大，那么这意味着我们根本没有考虑原始方程，所以预测会非常不准确，从而导致拟合不足。</li></ul><h2 id="cf65" class="jt ju hy bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">确定LR的特征重要性和可解释性</h2><p id="9482" class="pw-post-body-paragraph iv iw hy ix b iy kq ja jb jc kr je jf jg ln ji jj jk lo jm jn jo lp jq jr js hb bi translated">如果我们假设所有的特征都是独立的，那么我们可以通过查看它们相应的权重来确定特征的重要性。<br/>如果特定特征的权重较高，那么我们可以说，该特定特征在确定类别中具有更大的作用。<br/>通过这种方式，我们也可以很容易地解释模型，因为我们知道哪些特征或哪些因素负责该预测。</p><h2 id="0b08" class="jt ju hy bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated">训练和运行时间复杂性和空间复杂性</h2><ul class=""><li id="8fe3" class="ko kp hy ix b iy kq jc kr jg ks jk kt jo ku js kv kw kx ky bi translated">训练时间= O(n*d ),其中n =数据点数，d =维数</li><li id="cc55" class="ko kp hy ix b iy kz jc la jg lb jk lc jo ld js kv kw kx ky bi translated">运行时间= O(d)</li><li id="8673" class="ko kp hy ix b iy kz jc la jg lb jk lc jo ld js kv kw kx ky bi translated">空间复杂度= O(d)</li></ul><h2 id="2a62" class="jt ju hy bd jv jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn bi translated"><strong class="ak">实施逻辑回归</strong></h2><p id="0b6c" class="pw-post-body-paragraph iv iw hy ix b iy kq ja jb jc kr je jf jg ln ji jj jk lo jm jn jo lp jq jr js hb bi translated">我们将使用来自Kaggle的一个非常著名的数据集，任务是创建一个模型来预测哪些乘客在泰坦尼克号沉船中幸存。数据集可以从<a class="ae hv" href="https://www.kaggle.com/c/titanic/overview" rel="noopener ugc nofollow" target="_blank">这里</a>下载。<em class="lj"> <br/>这也是一个二进制分类问题，其中目标“幸存”对于没有在灾难中幸存的人是0，对于幸存的人是1。</em></p><p id="4b80" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将数据预处理成x_train和y_train，并从sklearn导入逻辑回归。</p><figure class="lf lg lh li fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ml"><img src="../Images/1cdbe02395b6b5bdbff26e8a100efc50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WM4ZBO3v298Hrl3pwhvp0Q.png"/></div></div></figure><ul class=""><li id="2ee3" class="ko kp hy ix b iy iz jc jd jg lk jk ll jo lm js kv kw kx ky bi translated">在上面的代码片段中，我们看到penalty = 'l1 '。LR的sklearn实现中的这个属性决定了我们想要的正则化类型。</li><li id="d906" class="ko kp hy ix b iy kz jc la jg lb jk lc jo ld js kv kw kx ky bi translated">C参数是λ的倒数。较小的C值决定了强正则化。</li></ul><p id="50d1" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">可以参考LR在Titanic数据集<a class="ae hv" href="https://github.com/guptaa98/Kaggle-Notebooks/blob/master/Titanic%20kaggle.ipynb" rel="noopener ugc nofollow" target="_blank">上的详细实现这里</a>。</p></div></div>    
</body>
</html>