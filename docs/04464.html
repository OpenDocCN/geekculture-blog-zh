<html>
<head>
<title>Feature Engineering for Categorical Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分类数据的特征工程</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/feature-engineering-for-categorical-data-a77a04b3308?source=collection_archive---------4-----------------------#2021-06-28">https://medium.com/geekculture/feature-engineering-for-categorical-data-a77a04b3308?source=collection_archive---------4-----------------------#2021-06-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="32ed" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">除了一键编码之外，还有几个有用的技巧</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/978d3c844bfa9cc1760764897dc909e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ntoLSDrOdTEkVNNb"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@alexmotoc?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Alex Motoc</a> on <a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="a469" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在机器学习中，特征是指机器学习模型的输入或原始数据的数字表示。表格数据中有两种主要的特征:数值特征和类别特征。特征工程是从原始数据中提取特征并将其转换为适合机器学习模型的格式的过程。对于数字特征，最常用的特征工程是对数变换、标准化和规范化。对于分类特征，我们有很多方法可以将它们转换成数字，但是何时以及如何使用这些方法呢？这篇文章是关于为分类特性实现特性工程的。</p><p id="ea2b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在我们深入研究技术之前，让我先介绍一下我们用于说明的数据集:<a class="ae jn" href="https://archive.ics.uci.edu/ml/datasets/in-vehicle+coupon+recommendation" rel="noopener ugc nofollow" target="_blank">车载优惠券推荐</a>。该数据集是通过王等人(2017)对亚马逊机械土耳其人的调查收集的。调查描述了不同的驾驶场景，包括目的地、当前时间、天气、乘客等。，然后询问该人如果他或她是司机，他或她是否愿意接受优惠券。车载优惠券推荐数据集中的几乎所有特征都是分类的，这些特征可以分为三种类型:用户属性、上下文属性和优惠券属性。为简单起见，我将跳过关于这些功能的详细介绍，有关原始数据集的更多信息，可以查看上面的数据集链接，或检查我的<a class="ae jn" href="https://www.kaggle.com/iyet1killer/classification-on-categorical-data-part-1-sklearn/notebook" rel="noopener ugc nofollow" target="_blank"> Kaggle笔记本</a>。</p><h2 id="5b98" class="kk kl hi bd km kn ko kp kq kr ks kt ku jx kv kw kx kb ky kz la kf lb lc ld le bi translated">顺序编码</h2><p id="d977" class="pw-post-body-paragraph jo jp hi jq b jr lf ij jt ju lg im jw jx lh jz ka kb li kd ke kf lj kh ki kj hb bi translated">顾名思义，这种方法只适用于序数数据。有序数据是一种具有内在顺序的分类数据。例如等级、年龄范围和收入范围。在我们的数据集中，我们有那些顺序列:<strong class="jq hj">餐馆20到50 </strong>，<strong class="jq hj">餐馆20 </strong>，<strong class="jq hj">外卖</strong>，<strong class="jq hj">咖啡馆</strong>，<strong class="jq hj">酒吧</strong>，<strong class="jq hj">年龄</strong>，以及<strong class="jq hj">收入</strong>。下面是我对这些列的顺序编码的实现:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><h2 id="fa7a" class="kk kl hi bd km kn ko kp kq kr ks kt ku jx kv kw kx kb ky kz la kf lb lc ld le bi translated">一键编码</h2><p id="cbf7" class="pw-post-body-paragraph jo jp hi jq b jr lf ij jt ju lg im jw jx lh jz ka kb li kd ke kf lj kh ki kj hb bi translated">名义数据是另一种分类数据，对于名义变量，最简单的编码方法是一热编码。如果一个变量有三个类别，那么一键编码将把它转换成三个新的类别。例如，名为color的变量有三个类别:红色、绿色和蓝色。在一次性编码之后，新变量应该是这样的:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="417f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">一键编码的主要缺点是增加了维数。如果您有一个包含许多类别的变量，那么在一次性编码之后，数据集将比以前更加稀疏。通过<code class="du lm ln lo lp b">sklearn.preprocessing.OneHotEncoder</code>可以实现一键编码。这里有一个用<code class="du lm ln lo lp b">sklearn.Pipeline</code>和<code class="du lm ln lo lp b">ColumnTransformer</code>实现混合数据类型的特征工程的例子。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><h2 id="c0f8" class="kk kl hi bd km kn ko kp kq kr ks kt ku jx kv kw kx kb ky kz la kf lb lc ld le bi translated">频率编码</h2><p id="6252" class="pw-post-body-paragraph jo jp hi jq b jr lf ij jt ju lg im jw jx lh jz ka kb li kd ke kf lj kh ki kj hb bi translated">频率编码是另一种用于名义数据的技术，它对类别的频率进行编码，因此不会增加数据集中的维数。这里有一个简单的例子:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Original Dataset</figcaption></figure><p id="8320" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">频率编码后，原始数据集将是:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">After Frequency Encoding</figcaption></figure><p id="9388" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">类别被该类别在该变量中出现的频率所取代。请注意，当一些类别有相同的频率时，就像这个例子一样，我们确实丢失了原始数据的信息。下面是参考<a class="ae jn" href="https://www.kaggle.com/bhavikapanara/frequency-encoding" rel="noopener ugc nofollow" target="_blank"> Bhavika的代码</a>的频率编码的实现。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><h2 id="1f84" class="kk kl hi bd km kn ko kp kq kr ks kt ku jx kv kw kx kb ky kz la kf lb lc ld le bi translated">k折叠目标编码</h2><p id="e789" class="pw-post-body-paragraph jo jp hi jq b jr lf ij jt ju lg im jw jx lh jz ka kb li kd ke kf lj kh ki kj hb bi translated">目标编码是分类数据特征工程中的神奇方法之一，其基本思想是利用类别相对于目标的统计量对原始类别进行编码。下面是一个简单的目标编码的例子。假设我们有一个二元目标变量和三个类别:红色、绿色和蓝色:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="6ade" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果我们用均值目标编码，用目标变量的期望值对三种颜色进行编码，我们会得到<code class="du lm ln lo lp b">red_target = 0.5</code>、<code class="du lm ln lo lp b">green_target = 0.25</code>、<code class="du lm ln lo lp b">blue_target = 0.4</code>。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">After target encoding</figcaption></figure><p id="0fb5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">至于目标编码的缺点，第一个缺点就像序数频率编码一样——不健壮。在这个转换过程中，信息可能会丢失，特别是当目标的期望值对于许多类别来说非常接近时。另一个缺点是，由于在计算中涉及目标变量，存在数据泄露的风险。为了缓解这个问题，可以使用k折叠技术来交叉计算目标变量的期望值。<a class="ae jn" rel="noopener" href="/@pouryaayria/k-fold-target-encoding-dfe9a594874b">这里有一篇Pourya </a>的文章，清晰地解释了k fold目标编码的机制，并提供了实现它的代码。基于他的工作，我添加了一些文档字符串和注释，使代码更具可读性:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="2a2b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">下面是我为训练和测试数据实现它们的代码:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><h2 id="9df8" class="kk kl hi bd km kn ko kp kq kr ks kt ku jx kv kw kx kb ky kz la kf lb lc ld le bi translated">基于K原型聚类的特征扩展</h2><p id="6b82" class="pw-post-body-paragraph jo jp hi jq b jr lf ij jt ju lg im jw jx lh jz ka kb li kd ke kf lj kh ki kj hb bi translated">除了编码方法，还有其他特征工程技术，如降维和特征扩展。在本文中，我们将介绍一种有效的混合数据类型特征扩展方法——基于k原型聚类的特征扩展。</p><p id="d1c0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对于数值数据，k-means算法是最常用的特征扩展聚类方法。与层次凝聚聚类相比，k-means更有效，因为它是线性复杂度，而层次聚类是二次复杂度，这使得它对于大数据集是昂贵的。</p><p id="61bc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">要用k-means聚类实现特征扩展，我们只需简单地添加聚类标签作为新特征。如果目标信息是可用的，我们也可以包括它来改进聚类过程。通过这样做，目标信息将被泄露到聚类成员中，但是在大多数情况下，我们不需要关注它，因为聚类算法的有损压缩将已经提取出一些目标信息。当数据集较小时，k重交叉验证可用于减少因包含目标特征而引入的偏差。</p><p id="0bf9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">但是，k-means算法对分类数据没有意义。为了扩展k-means算法的使用，<a class="ae jn" href="https://link.springer.com/article/10.1023/A:1009769707641" rel="noopener ugc nofollow" target="_blank">黄</a>发明了k-modes和k-prototypes算法。引用他的论文:“k-modes算法使用简单的匹配相异度来处理分类对象，用模式代替聚类的均值，并在聚类过程中使用基于频率的方法来更新模式，以最小化聚类成本函数。通过这些扩展，k-modes算法能够以类似于k-means的方式对分类数据进行聚类。k-prototypes算法通过定义一个组合的相异度，进一步整合了k-means和k-modes算法，以允许对由混合数字和分类属性描述的对象进行聚类。因此，在大多数情况下，k-prototypes对于混合数据的聚类是一个不错的解决方案。</p><p id="6007" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">k-modes和k-prototypes算法的Python实现可以在<a class="ae jn" href="https://github.com/nicodv/kmodes#id2" rel="noopener ugc nofollow" target="_blank"> kmodes </a>包中找到。要实现k-prototypes算法，我们需要做的第一件事是找到一个合适的k。剪影图可以用于它。下面是使用我们的数据集找到合适的k的代码，绘制剪影图的代码是从<a class="ae jn" href="https://github.com/ageron/handson-ml2/blob/master/09_unsupervised_learning.ipynb" rel="noopener ugc nofollow" target="_blank">用Scikit-Learn、Keras和TensorFlow进行动手机器学习，第二版由Aurelien Geron </a>编写。</p><p id="8b9f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">为了使用k原型，我们需要指出分类特征的列索引。使用sklearn的预处理器后，列名和索引发生了变化:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="328b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然后我们包括目标特征，并绘制k从2到9的轮廓图:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lq"><img src="../Images/04b9635707d85a42daa1e864809f750b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pbBjql5XzAgDQQnBLZJbUw.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lr"><img src="../Images/56d978ca7a0107a4e24005de54eed55a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JFnwyBOQPE0283pLnzf9QA.png"/></div></div></figure><p id="ecdd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">剪影系数的范围从-1到+1，剪影分数是聚类中所有实例的平均剪影系数。接近+1的系数意味着该实例在自己的分类内，远离其他分类，而接近0的系数意味着它接近分类边界，最后接近-1的系数意味着该实例可能被分配到错误的分类。</p><p id="1672" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">根据数据计划a的轮廓图，当𝑘=2,3,4,5作为红色虚线指示平均轮廓分数时，轮廓分数看起来良好。我们选择𝑘=4as作为我们k原型聚类的聚类数。</p><p id="5843" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在挑选了k的数量之后，现在我们可以实现k-prototypes算法来进行特性扩展。下面的特征器是基于Alice Zheng和Amanda Casari 在<a class="ae jn" href="https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/" rel="noopener ugc nofollow" target="_blank">机器学习的特征工程中的k-means特征器，我修改了代码使其适合k-原型。</a></p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="1ea2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">以下是我们使用车载优惠券数据集的方式:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lk ll l"/></div></figure><h2 id="20e6" class="kk kl hi bd km kn ko kp kq kr ks kt ku jx kv kw kx kb ky kz la kf lb lc ld le bi translated">方法比较</h2><p id="548a" class="pw-post-body-paragraph jo jp hi jq b jr lf ij jt ju lg im jw jx lh jz ka kb li kd ke kf lj kh ki kj hb bi translated">我们将计划A中的数据应用于频率和目标编码，而将计划B中的数据应用于一次性编码。功能扩展版本基于计划a。以下是通过五个不同的基本模型测试分类的准确性。频率和目标编码版本在k最近邻分类器上获得了最高的准确率，而特征扩展版本在决策树归纳模型上获得了最高的准确率。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="ls ll l"/></div></figure><h2 id="d863" class="kk kl hi bd km kn ko kp kq kr ks kt ku jx kv kw kx kb ky kz la kf lb lc ld le bi translated">摘要</h2><p id="5dd1" class="pw-post-body-paragraph jo jp hi jq b jr lf ij jt ju lg im jw jx lh jz ka kb li kd ke kf lj kh ki kj hb bi translated">本文介绍了分类数据的一些特征工程技术。有关车载优惠券数据集的分类任务以及这些特征工程方法和机器学习模型之间的交互的更多信息，请查看<a class="ae jn" href="https://www.kaggle.com/iyet1killer/classification-on-categorical-data-part-1-sklearn#Model-Training" rel="noopener ugc nofollow" target="_blank">我的kaggle笔记本。</a></p><p id="5c09" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">欢迎评论，分享你的观点！</p></div></div>    
</body>
</html>