<html>
<head>
<title>Cross Validation in Python using StatsModels and Sklearn with Logistic Regression Example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Python中使用StatsModels和Sklearn进行交叉验证，并使用逻辑回归示例</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/cross-validation-f05b885f2d70?source=collection_archive---------15-----------------------#2021-07-04">https://medium.com/geekculture/cross-validation-f05b885f2d70?source=collection_archive---------15-----------------------#2021-07-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="2f31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本教程中，我们将学习什么是机器学习中的交叉验证，以及如何使用<code class="du jd je jf jg b">StatsModels</code>和<code class="du jd je jf jg b">Sklearn</code>包在python中实现。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es jh"><img src="../Images/55626d47413f108a3418717ee06b607b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5fnn2iyhBOOealAsDSk1JQ.jpeg"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx">Cross validation in Machine Learning</figcaption></figure><h2 id="eff8" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">什么是交叉验证，为什么我们需要它？</h2><p id="8fb0" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">交叉验证是机器学习中的一种重采样方法。为了理解交叉验证，我们需要首先回顾训练错误率和测试错误率之间的区别。</p><p id="c29e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">训练错误率</strong>是由相同数据产生的平均错误(分类问题中的错误分类),模型就是根据这些数据进行训练的。</p><p id="e33a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">相比之下，<strong class="ih hj">测试错误率</strong>是在看不见的测试数据集(也称为验证数据集)上使用训练好的模型所产生的平均错误。</p><p id="e933" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在没有测试数据的情况下，我们无法判断我们的模型在看不见的数据上是否同样有效，这是任何机器学习问题的最终目标。当拟合/训练的模型用于看不见的数据时，使用测试数据来估计平均误差的过程被称为交叉验证。简而言之，我们在看不见的数据上交叉验证我们的预测，因此命名为“交叉验证”。</p><h2 id="b164" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">交叉验证的类型</h2><ul class=""><li id="e975" class="kx ky hi ih b ii ks im kt iq kz iu la iy lb jc lc ld le lf bi translated">验证集方法</li></ul><p id="5c6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种方法是最简单的。只需将数据分为两部分，即训练数据集和测试数据集。在训练数据集上训练您的模型，并在测试数据集上运行验证。这种方法可能会有问题，因为我们假设我们的测试数据代表整个数据，这在实践中可能会被违反。因此，我们的测试误差估计可能非常不稳定。此外，由于机器学习方法往往在较少的观察值上训练时表现更差，因此它可能会设置验证错误率以高估测试错误率。</p><ul class=""><li id="2bf8" class="kx ky hi ih b ii ij im in iq lg iu lh iy li jc lc ld le lf bi translated">留一交叉验证:</li></ul><p id="e445" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">顾名思义，我们在训练模型时会从训练数据中留下一个观察值。从技术上讲，这种方法和上面的一样，但是在我们的测试数据集中，我们只有一行。不同的是，我们通过运行for循环来重复这个实验，并在每次迭代中取1行作为测试数据，得到尽可能多的行的测试误差，最后取误差的平均值。理想情况下，我们应该运行for循环n次(其中n =样本大小)。此时，我们已经可以识别这里的问题了。当您的数据很大时，这种方法可能非常低效。</p><ul class=""><li id="206d" class="kx ky hi ih b ii ij im in iq lg iu lh iy li jc lc ld le lf bi translated">k倍交叉验证:</li></ul><p id="2219" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是上述两种类型的混合体。我们将数据分成k个折叠，并运行k次for循环，在每次迭代中将其中一个折叠作为测试数据集。</p><p id="6318" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将在本教程中使用验证集方法和k-Fold。</p><h1 id="baf5" class="lj jy hi bd jz lk ll lm kd ln lo lp kh lq lr ls kk lt lu lv kn lw lx ly kq lz bi translated">应用</h1><p id="06c6" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">让我们动手做一些编码吧。你兴奋吗？</p><p id="cf2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我也是！</p><h2 id="4c74" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">问题设置</h2><p id="1e22" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我们将使用心脏数据集，使用数据集中的所有预测因子来预测心脏病发作的概率。在这样做的时候，我们还想使用交叉验证来估计该部分中描述的逻辑回归模型的测试误差。</p><h2 id="a8f2" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">数据集信息:</h2><p id="298f" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我从机器学习和智能系统中心获取了这个数据集</p><p id="eeaf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">https://archive.ics.uci.edu/ml/datasets/Heart+Disease<a class="ae ma" href="https://archive.ics.uci.edu/ml/datasets/Heart+Disease" rel="noopener ugc nofollow" target="_blank"/></p><p id="dba0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">。该数据库包含76个属性，但所有发表的实验都提到使用其中14个属性的子集。特别是，克利夫兰数据库是迄今为止唯一被ML研究人员使用的数据库。“目标”字段是指患者是否存在心脏病。它是从0(不存在)到4的整数值。“目标”字段是指患者是否存在心脏病。如果整数值为0 =表示没有/较少心脏病发作的机会，如果整数值为1 =则表示更多心脏病发作的机会。</p><p id="261b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">患者的姓名和社会安全号码最近也被从数据库中删除，并被替换为虚拟值。</p><p id="8480" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所有四个未处理的文件也存在于该目录中。一个被“处理”的文件是包含克利夫兰数据库的文件。</p><p id="5d36" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要查看测试费用(由Peter Turney捐赠)，请查看“费用”文件夹。</p><p id="b9fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用的属性:</p><ol class=""><li id="efe7" class="kx ky hi ih b ii ij im in iq lg iu lh iy li jc mb ld le lf bi translated">第三名(年龄)</li><li id="5a32" class="kx ky hi ih b ii mc im md iq me iu mf iy mg jc mb ld le lf bi translated">#4(性)</li><li id="909b" class="kx ky hi ih b ii mc im md iq me iu mf iy mg jc mb ld le lf bi translated">#9 (cp)</li><li id="bdf1" class="kx ky hi ih b ii mc im md iq me iu mf iy mg jc mb ld le lf bi translated">第十名(trestbps)</li><li id="f67a" class="kx ky hi ih b ii mc im md iq me iu mf iy mg jc mb ld le lf bi translated">#12 (chol)</li><li id="54aa" class="kx ky hi ih b ii mc im md iq me iu mf iy mg jc mb ld le lf bi translated">第16位</li><li id="ed8a" class="kx ky hi ih b ii mc im md iq me iu mf iy mg jc mb ld le lf bi translated">第19名(休息心电图)</li><li id="f49a" class="kx ky hi ih b ii mc im md iq me iu mf iy mg jc mb ld le lf bi translated">第32位(塔拉奇)</li><li id="6542" class="kx ky hi ih b ii mc im md iq me iu mf iy mg jc mb ld le lf bi translated">第38名(exang)</li><li id="4da9" class="kx ky hi ih b ii mc im md iq me iu mf iy mg jc mb ld le lf bi translated">第40名(旧峰)</li><li id="a7be" class="kx ky hi ih b ii mc im md iq me iu mf iy mg jc mb ld le lf bi translated">#41(坡度)</li><li id="3d0d" class="kx ky hi ih b ii mc im md iq me iu mf iy mg jc mb ld le lf bi translated">第44名(加拿大)</li><li id="63de" class="kx ky hi ih b ii mc im md iq me iu mf iy mg jc mb ld le lf bi translated">第51名</li><li id="b36d" class="kx ky hi ih b ii mc im md iq me iu mf iy mg jc mb ld le lf bi translated">#58(目标)(预测属性)</li></ol><p id="ae69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，该数据集有一些缺失数据。为了简单起见，我们将尝试完整的案例分析。</p><pre class="ji jj jk jl fd mh jg mi mj aw mk bi"><span id="4ea8" class="jx jy hi jg b fi ml mm l mn mo">import pandas as pd<br/>import numpy as np</span><span id="1ddf" class="jx jy hi jg b fi mp mm l mn mo">df = pd.read_csv('heart.csv')</span><span id="2164" class="jx jy hi jg b fi mp mm l mn mo">df.head()</span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="ab fe cl mq"><img src="../Images/168a71313f290003bfcd1ca335a821ca.png" data-original-src="https://miro.medium.com/v2/format:webp/1*jwVGXnOBm1eewTkuc9Uj3w.png"/></div></figure><h2 id="91cd" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">使用统计模型的物流回归模型</h2><p id="fb62" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">查看初始模型拟合的最简单和更优雅的方式(与<code class="du jd je jf jg b">sklearn</code>相比)是使用<code class="du jd je jf jg b">statsmodels</code>。我很欣赏它只用一行代码就生成的总结报告。</p><pre class="ji jj jk jl fd mh jg mi mj aw mk bi"><span id="152f" class="jx jy hi jg b fi ml mm l mn mo">from statsmodels.formula.api import logit<br/>fit_logit = logit("target ~ age + sex + cp + trestbps +	chol + 	fbs + 	restecg +	thalach +	exang	 + oldpeak	+ slope + 	ca +	thal", df).fit()<br/>print(fit_logit.summary())</span><span id="29f5" class="jx jy hi jg b fi mp mm l mn mo">Optimization terminated successfully.<br/>         Current function value: 0.348904<br/>         Iterations 7<br/>                           Logit Regression Results                           <br/>==============================================================================<br/>Dep. Variable:                 target   No. Observations:                  303<br/>Model:                          Logit   Df Residuals:                      289<br/>Method:                           MLE   Df Model:                           13<br/>Date:                Sat, 03 Jul 2021   Pseudo R-squ.:                  0.4937<br/>Time:                        14:47:19   Log-Likelihood:                -105.72<br/>converged:                       True   LL-Null:                       -208.82<br/>Covariance Type:            nonrobust   LLR p-value:                 7.262e-37<br/>==============================================================================<br/>                 coef    std err          z      P&gt;|z|      [0.025      0.975]<br/>------------------------------------------------------------------------------<br/>Intercept      3.4505      2.571      1.342      0.180      -1.590       8.490<br/>age           -0.0049      0.023     -0.212      0.832      -0.050       0.041<br/>sex           -1.7582      0.469     -3.751      0.000      -2.677      -0.839<br/>cp             0.8599      0.185      4.638      0.000       0.496       1.223<br/>trestbps      -0.0195      0.010     -1.884      0.060      -0.040       0.001<br/>chol          -0.0046      0.004     -1.224      0.221      -0.012       0.003<br/>fbs            0.0349      0.529      0.066      0.947      -1.003       1.073<br/>restecg        0.4663      0.348      1.339      0.181      -0.216       1.149<br/>thalach        0.0232      0.010      2.219      0.026       0.003       0.044<br/>exang         -0.9800      0.410     -2.391      0.017      -1.783      -0.177<br/>oldpeak       -0.5403      0.214     -2.526      0.012      -0.959      -0.121<br/>slope          0.5793      0.350      1.656      0.098      -0.106       1.265<br/>ca            -0.7733      0.191     -4.051      0.000      -1.147      -0.399<br/>thal          -0.9004      0.290     -3.104      0.002      -1.469      -0.332<br/>==============================================================================</span></pre><h2 id="0d4f" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">简要模型解释</h2><p id="f48a" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我们发现性别、cp、thalach、exang、oldpeak、ca和thal变量与心脏病发作显著相关(我们并没有推断出这个问题中的因果关系)。</p><h2 id="e989" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">使用验证数据集方法的交叉验证</h2><p id="7197" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">让我们将数据分成两组，即训练和测试</p><pre class="ji jj jk jl fd mh jg mi mj aw mk bi"><span id="5822" class="jx jy hi jg b fi ml mm l mn mo">from sklearn.model_selection import train_test_split<br/>train, test = train_test_split(df, test_size = 0.3, random_state = 1)</span></pre><p id="0cd9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们在训练数据上拟合模型，并查看测试错误率以进行比较。</p><pre class="ji jj jk jl fd mh jg mi mj aw mk bi"><span id="58f2" class="jx jy hi jg b fi ml mm l mn mo">fit_logit_train = logit("target ~ age + sex + cp + trestbps +	chol + 	fbs + 	restecg +	thalach +	exang	 + oldpeak	+ slope + 	ca +	thal", train).fit()<br/>train_pred = fit_logit_train.predict(test)<br/><br/># converting probability to labels<br/>def convert_prob_to_label(prob, cutoff = 0.5):<br/>    label = None<br/>    if prob &gt; cutoff:<br/>        label = 1<br/>    else:<br/>        label = 0<br/>    return label<br/><br/>pred_labels = list(map(convert_prob_to_label, train_pred))<br/>pred_labels = np.asarray(pred_labels)</span><span id="8b0d" class="jx jy hi jg b fi mp mm l mn mo">Optimization terminated successfully.<br/>         Current function value: 0.317208<br/>         Iterations 8</span><span id="5b3b" class="jx jy hi jg b fi mp mm l mn mo">from sklearn.metrics import confusion_matrix<br/>conf_matrix = confusion_matrix(test.target, pred_labels)</span></pre><p id="3f75" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的混淆矩阵，我们可以计算错误分类率为</p><pre class="ji jj jk jl fd mh jg mi mj aw mk bi"><span id="5808" class="jx jy hi jg b fi ml mm l mn mo">mis_rate = (conf_matrix[[1],[0]].flat[0] + conf_matrix[[0],[1]].flat[0])/len(test)</span><span id="c157" class="jx jy hi jg b fi mp mm l mn mo">print(f"Misclassification rate = {mis_rate :.3f}")</span><span id="f10d" class="jx jy hi jg b fi mp mm l mn mo">Misclassification rate = 0.220</span></pre><p id="a13c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经有了很好的模型。请注意，我们还没有进行任何型号选择。然而，这种错误分类率可能是由于偶然，并可能取决于测试数据。因此，我们可能高估了测试错误率。为了获得更稳定的测试误差/错误分类率的估计，我们可以使用k-fold交叉验证。</p><h2 id="f300" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated"><strong class="ak">使用Sklearn进行k倍交叉验证</strong></h2><pre class="ji jj jk jl fd mh jg mi mj aw mk bi"><span id="120f" class="jx jy hi jg b fi ml mm l mn mo">from sklearn.model_selection import RepeatedKFold<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.model_selection import cross_val_score<br/>X = df.loc[ : , ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']]<br/>y = df[['target']]<br/><br/>cv = RepeatedKFold(n_splits=10, n_repeats= 10, random_state=1)<br/>model = LogisticRegression()<br/>scores = 1 - cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)</span><span id="489f" class="jx jy hi jg b fi mp mm l mn mo">import seaborn as sns<br/>ax = sns.histplot(x=scores, kde=True)</span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="ab fe cl mq"><img src="../Images/4ad893f68120b539f9dc1121ac0362fa.png" data-original-src="https://miro.medium.com/v2/format:webp/1*9qkxFd_x3-CDyz33CzcsCA.png"/></div></figure><p id="a198" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的直方图清楚地向我们展示了测试误差的可变性。提供测试误差的平均值和标准误差，而不是提供测试误差的单个数字估计值，对于决策来说总是更好。</p><h2 id="fa86" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">结论</h2><pre class="ji jj jk jl fd mh jg mi mj aw mk bi"><span id="3e09" class="jx jy hi jg b fi ml mm l mn mo">print(f"Mean of misclassification error rate in test date is, {np.mean(scores) : .3f} with standard deviation = {np.std(scores) : .4f} ")</span><span id="c02b" class="jx jy hi jg b fi mp mm l mn mo">Mean of misclassification error rate in test date is,  0.165 with standard deviation =  0.0693</span></pre><p id="7789" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们看到交叉验证有助于我们获得稳定的、更稳健的测试误差估计。在下一篇博客中，我们将使用bootstrap方法做同样的事情。</p></div></div>    
</body>
</html>