<html>
<head>
<title>An Introduction to Regression Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归分析导论</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/regression-analysis-57841ec34d1b?source=collection_archive---------11-----------------------#2021-10-22">https://medium.com/geekculture/regression-analysis-57841ec34d1b?source=collection_archive---------11-----------------------#2021-10-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="6c14" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">线性回归</h1><p id="e9c0" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">回归分析是广泛使用的预测方法之一。线性回归可能是最基本的机器学习方法，也是每个有抱负的数据科学家的高级分析学习路径的起点。</p><p id="b782" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">线性回归是两个或多个变量之间因果关系的线性近似。</p><p id="6871" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">回归模型非常有价值，因为它们是进行推断和预测的最常用方法之一。除此之外，回归分析也被用来以有意义的方式确定和评估影响某一结果的因素。</p><p id="b66d" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">与许多其他统计技术一样，回归模型帮助我们根据样本数据对总体进行预测。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/1875a1e28e6eba1e23b9522d770f80d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*INIr1Dn7E7CrF4MNgLxYDw.png"/></div></div></figure><h2 id="9389" class="ks ig hi bd ih kt ku kv il kw kx ky ip jo kz la it js lb lc ix jw ld le jb lf bi translated">线性回归模型</h2><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lg"><img src="../Images/90d3224317beb3571de8a4a3f46db8ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*Haz1qDzo6TP1zVAu_aWAKg.png"/></div></figure><p id="544f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">注意:当我们提到人口模型时，我们使用希腊字母。</p><h2 id="83bf" class="ks ig hi bd ih kt ku kv il kw kx ky ip jo kz la it js lb lc ix jw ld le jb lf bi translated">线性回归方程</h2><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es li"><img src="../Images/f19f1c2062d2cea3c4e716281fa644b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*nJxgnGwlv_QDSpRNSJyCqA.png"/></div></figure><h2 id="a7d7" class="ks ig hi bd ih kt ku kv il kw kx ky ip jo kz la it js lb lc ix jw ld le jb lf bi translated">线性回归的几何表示</h2><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lj"><img src="../Images/a0d42653b95a505697c4645f6b3ad02b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nOdmbrKmuvflJVvbc204Cg.jpeg"/></div></div></figure><p id="2509" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">注:平均而言，误差的期望值(平均值)为0，这就是为什么它没有包含在回归方程中。</p><h1 id="352e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">相关和回归</h1><h2 id="04bb" class="ks ig hi bd ih kt ku kv il kw kx ky ip jo kz la it js lb lc ix jw ld le jb lf bi translated">相互关系</h2><ul class=""><li id="b210" class="lk ll hi jf b jg jh jk jl jo lm js ln jw lo ka lp lq lr ls bi translated">表示两个变量之间的关系。</li><li id="372c" class="lk ll hi jf b jg lt jk lu jo lv js lw jw lx ka lp lq lr ls bi translated">显示两个变量一起移动(无论哪个方向)。</li><li id="ef55" class="lk ll hi jf b jg lt jk lu jo lv js lw jw lx ka lp lq lr ls bi translated">对称w.r.t .这两个变量:<em class="lh"> p(x，y) = p(y，x)。</em></li><li id="a5c9" class="lk ll hi jf b jg lt jk lu jo lv js lw jw lx ka lp lq lr ls bi translated">一个点(一个数)。</li></ul><h2 id="b1c3" class="ks ig hi bd ih kt ku kv il kw kx ky ip jo kz la it js lb lc ix jw ld le jb lf bi translated">回归</h2><ul class=""><li id="6698" class="lk ll hi jf b jg jh jk jl jo lm js ln jw lo ka lp lq lr ls bi translated">表示两个或多个变量之间的关系。</li><li id="19a9" class="lk ll hi jf b jg lt jk lu jo lv js lw jw lx ka lp lq lr ls bi translated">显示原因和结果(一个变量受另一个变量影响)。</li><li id="2cc5" class="lk ll hi jf b jg lt jk lu jo lv js lw jw lx ka lp lq lr ls bi translated">一种方法——总是只有一个随机因变量。</li><li id="20bc" class="lk ll hi jf b jg lt jk lu jo lv js lw jw lx ka lp lq lr ls bi translated">一条线(在2D空间中)。</li></ul><h1 id="acb9" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">线性回归汇总表</h1><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es ly"><img src="../Images/069187f88e6cde507c498d6ec86e8e9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c3UNGm8uhZe4svQF00sNKA.jpeg"/></div></div></figure><h1 id="c2cf" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">OLS假设</h1><p id="618f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">OLS(普通最小二乘法)是估计线性回归方程最常用的方法之一。然而，它的简单性意味着它不能总是被使用。因此，在我们可以依赖这种估计方法之前，所有的OLS回归假设都应该满足。</p><ul class=""><li id="1da4" class="lk ll hi jf b jg kb jk kc jo lz js ma jw mb ka lp lq lr ls bi translated">线性-指定的模型必须代表线性关系</li><li id="9b5c" class="lk ll hi jf b jg lt jk lu jo lv js lw jw lx ka lp lq lr ls bi translated">无内生性-自变量不应与误差项相关</li><li id="53b1" class="lk ll hi jf b jg lt jk lu jo lv js lw jw lx ka lp lq lr ls bi translated">正态性和同方差性-误差的方差应该在观测值之间保持一致</li><li id="206c" class="lk ll hi jf b jg lt jk lu jo lv js lw jw lx ka lp lq lr ls bi translated">无自相关-误差项的值之间不应存在可识别的关系</li><li id="d2b6" class="lk ll hi jf b jg lt jk lu jo lv js lw jw lx ka lp lq lr ls bi translated">无多重共线性-任何预测变量都不应被其他预测变量完美解释。</li></ul><h1 id="ccc8" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">回归线备选方案</h1><p id="a4d2" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">OLS只是一个开始。OLS是最简单的，虽然往往足以估计回归线的方法。事实上，有更复杂的方法更适合某些数据集和问题。</p><ul class=""><li id="3421" class="lk ll hi jf b jg kb jk kc jo lz js ma jw mb ka lp lq lr ls bi translated">广义最小二乘(GLS)</li><li id="aed9" class="lk ll hi jf b jg lt jk lu jo lv js lw jw lx ka lp lq lr ls bi translated">最大似然估计</li><li id="b9ce" class="lk ll hi jf b jg lt jk lu jo lv js lw jw lx ka lp lq lr ls bi translated">贝叶斯回归</li><li id="c504" class="lk ll hi jf b jg lt jk lu jo lv js lw jw lx ka lp lq lr ls bi translated">核回归</li><li id="8cea" class="lk ll hi jf b jg lt jk lu jo lv js lw jw lx ka lp lq lr ls bi translated">高斯进度回归</li></ul><p id="01b4" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这个帖子到此为止。感谢您的阅读。</p><p id="a71e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><em class="lh">更多内容尽在</em><a class="ae mc" href="http://plainenglish.io/" rel="noopener ugc nofollow" target="_blank"><em class="lh">plain English . io</em></a></p></div></div>    
</body>
</html>