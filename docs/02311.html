<html>
<head>
<title>Building Text Classification Model in the Least Time and Coding Effort</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用最少的时间和编码工作量建立文本分类模型</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/building-text-classification-model-in-3-minutes-and-20-lines-of-code-deaca6aced37?source=collection_archive---------15-----------------------#2021-05-10">https://medium.com/geekculture/building-text-classification-model-in-3-minutes-and-20-lines-of-code-deaca6aced37?source=collection_archive---------15-----------------------#2021-05-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="5bce" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">如果我们能在做出掏钱(时间和精力)的决定之前获得产品的免费试用(模型预测)该有多好？</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/3098d44b08dc9a0f7b56cbb0a8f91e2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vo4g-rTaI-JMzec02vbk4w.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@nate_dumlao" rel="noopener ugc nofollow" target="_blank">Nathan Dumlao</a> on <a class="ae jn" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="95fb" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">介绍</h2><p id="0051" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">本文利用自然语言处理(NLP)库，如<strong class="ko hj"> Texthero </strong>和<strong class="ko hj"> FastText </strong>，它们在不牺牲性能的情况下缩短了文本分类器的开发。一个典型的文本分类器需要几个小时或几天来开发，从探索性数据分析、文本预处理、特征工程和特征选择开始，训练模型并最终评估性能。</p><p id="e1e3" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">因此，数据科学家只能看到投资后的回报。在通过遍历整个管道获得训练好的模型之前，无法回答不确定性。例如，我们不确定从Kaggle数据集训练的垃圾邮件分类器能否正确预测英式英语或新加坡英语的邮件？如果我们能在决定掏钱(时间和精力)之前获得产品的免费试用(模型预测)会有多好？</p><p id="9fd6" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">考虑到这一点，本文着重于用20行代码和3分钟的训练时间来训练模型。不会有关于架构的理论解释。有文章写了TextHero预处理文本有多方便，或者用FastText训练模型有多快，但是没有一篇文章同时使用这两者来压缩开发时间。</p><p id="b18c" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">让我们开始吧。</p><h1 id="0664" class="lk jp hi bd jq ll lm ln ju lo lp lq jy io lr ip kc ir ls is kg iu lt iv kk lu bi translated"><strong class="ak">导入库</strong></h1><p id="343a" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">这项任务将使用四个库</p><ol class=""><li id="8cd5" class="lv lw hi ko b kp lf ks lg jz lx kd ly kh lz le ma mb mc md bi translated"><strong class="ko hj">熊猫</strong>用于读取csv文件和操作数据</li><li id="84c6" class="lv lw hi ko b kp me ks mf jz mg kd mh kh mi le ma mb mc md bi translated"><strong class="ko hj"> Texthero </strong>用于文本预处理</li><li id="a455" class="lv lw hi ko b kp me ks mf jz mg kd mh kh mi le ma mb mc md bi translated"><strong class="ko hj">快速文本</strong>用于建立分类模型</li><li id="0117" class="lv lw hi ko b kp me ks mf jz mg kd mh kh mi le ma mb mc md bi translated"><strong class="ko hj">sci kit-学习</strong>进行评估</li></ol><pre class="iy iz ja jb fd mj mk ml mm aw mn bi"><span id="0af2" class="jo jp hi mk b fi mo mp l mq mr"># Import the libraries<br/>import texthero as hero<br/>import pandas as pd<br/>import fasttext<br/>from sklearn.metrics import confusion_matrix<br/>from sklearn.metrics import classification_report</span></pre></div><div class="ab cl ms mt gp mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="hb hc hd he hf"><h1 id="bc51" class="lk jp hi bd jq ll mz ln ju lo na lq jy io nb ip kc ir nc is kg iu nd iv kk lu bi translated">资料组</h1><p id="f7e9" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">本文中的数据集取自Kaggle竞赛“<strong class="ko hj">有毒评论分类挑战</strong>”。在这次挑战中，来自维基百科对话页面编辑的评论被人工标记为毒性类型(有毒、淫秽、威胁等)。为了简单起见，我们只考虑将注释二进制分类为“<em class="ne">有毒</em>类。</p><p id="3e7f" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">数据集可以在这里<a class="ae jn" href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge" rel="noopener ugc nofollow" target="_blank">下载。</a></p><blockquote class="nf ng nh"><p id="b352" class="km kn ne ko b kp lf ij kr ks lg im ku ni lh kw kx nj li kz la nk lj lc ld le hb bi translated"><em class="hi">免责声明:本次比赛的数据集包含可能被视为亵渎、粗俗或冒犯的文本。</em></p></blockquote><p id="f46f" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">第一步是使用Pandas读取数据集。毒性评论分类挑战数据集由1个带标签的训练数据集和2个将评论和标签分开的测试数据集组成。</p><pre class="iy iz ja jb fd mj mk ml mm aw mn bi"><span id="2a59" class="jo jp hi mk b fi mo mp l mq mr">train_df = pd.read_csv('train.csv')<br/>test_df = pd.read_csv('test.csv')<br/>test_label_df = pd.read_csv('test_labels.csv')</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nl"><img src="../Images/1890d0150ad38ffdd5010d6b0b475a87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YUFa5t-_Pj_2MO05TBZe3Q.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Random 10 samples from training data</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nm"><img src="../Images/86cd35752f9a4c1eaa7f6d344b9a9acd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DnkM-cYd0xURLgmxoiiLCg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Random 10 samples from testing data</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nn"><img src="../Images/b7a1819c9128bb8327cf43b14ccc6f80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sRIW35SfCgBYmt217Iz8wQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Random 10 samples from testing data label</figcaption></figure><p id="454d" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">根据Kaggle网页，值-1表示记录未用于评分。然而，我决定删除测试数据中带有'-1 '有毒标签的行，因为'-1 '不属于'有毒'或'无毒'类别。</p><p id="fe4f" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">我们对测试数据集及其标签执行了合并，并仅选择了有毒列中带有“0”或“1”的标签。</p><pre class="iy iz ja jb fd mj mk ml mm aw mn bi"><span id="fd44" class="jo jp hi mk b fi mo mp l mq mr">test_df = test_df.merge(test_label_df, left_on='id', right_on='id')<br/>test_df = test_df[(test_df['toxic'] == 0) | (test_df['toxic']==1)]</span></pre><h1 id="f038" class="lk jp hi bd jq ll lm ln ju lo lp lq jy io lr ip kc ir ls is kg iu lt iv kk lu bi translated">文本清理</h1><blockquote class="nf ng nh"><p id="7ef2" class="km kn ne ko b kp lf ij kr ks lg im ku ni lh kw kx nj li kz la nk lj lc ld le hb bi translated">Texthero是一个python包，可以有效地处理文本数据。它为NLP开发人员提供了一个工具来快速理解任何基于文本的数据集，并提供了一个可靠的管道来清理和表示文本数据，从零到英雄。</p></blockquote><p id="794b" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">文本清理在任何NLP任务中都是必不可少的，因为模型努力学习底层模式来解决我们的问题。文本清理管道是特定于任务的。</p><p id="66c6" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">例如，许多文本清理删除停用词，因为它在分类中的作用微不足道。然而，在某些情况下，如作者归属(确定文档作者的分类任务)，停用词被保留并用作分类中的特征。</p><p id="89a3" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">Texthero通过简单地调用<em class="ne">text hero . preprocessing . clean .</em>来支持对Pandas数据帧的文本清理操作。默认流水线进程执行诸如填充Nan值、小写、停用词移除、数字和标点符号移除等步骤。</p><p id="da7d" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">默认<em class="ne">的预处理方法</em>可以在<a class="ae jn" href="https://texthero.org/docs/api/texthero.preprocessing.clean" rel="noopener ugc nofollow" target="_blank">这里</a>找到，附加的预处理方法可以在<a class="ae jn" href="https://texthero.org/docs/api-preprocessing" rel="noopener ugc nofollow" target="_blank">这里</a>找到。您还可以为文本预处理定义一个自定义管道，如下图<a class="ae jn" href="https://towardsdatascience.com/try-texthero-the-absolute-simplest-way-to-clean-and-analyze-text-in-pandas-6db86ed14272" rel="noopener" target="_blank">所示</a>。</p><p id="453c" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">在这里，我们演示了可以使用单个命令'<em class="ne">text hero . preprocessing . clean '，</em>来清理文本数据，以减少时间和复杂性。</p><pre class="iy iz ja jb fd mj mk ml mm aw mn bi"><span id="4bf2" class="jo jp hi mk b fi mo mp l mq mr">train_df['comment_text_cleaned'] = train_df['comment_text'].pipe(hero.clean)<br/>test_df['comment_text_cleaned'] = test_df['comment_text'].pipe(hero.clean)</span></pre><h1 id="95db" class="lk jp hi bd jq ll lm ln ju lo lp lq jy io lr ip kc ir ls is kg iu lt iv kk lu bi translated">系统模型化</h1><p id="8db9" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">FastText是一个由脸书人工智能研究实验室创建的用于学习单词嵌入和文本分类的库。在网站上，它将Fasttext描述为:</p><blockquote class="nf ng nh"><p id="a9c4" class="km kn ne ko b kp lf ij kr ks lg im ku ni lh kw kx nj li kz la nk lj lc ld le hb bi translated">FastText是一个开源、免费、轻量级的库，允许用户学习文本表示和文本分类器。它在标准的通用硬件上工作。模型可以缩小尺寸，甚至适合移动设备。</p></blockquote><p id="fee7" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">API文件可以在<a class="ae jn" href="https://fasttext.cc/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="4967" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">因为FastText是作为一个高效的NLP工具而设计的。只使用CPU就可以非常快速地训练模型，最重要的是，它不需要GPU。但需要C++编译器、Python(2.7版或≥ 3.4版)，以及支持的Python库，如NumPy &amp; SciPy、pybind11等。</p><p id="6668" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">第一步是格式化要训练的数据集。FastText要求将数据保存在txt文件中，格式为_ _ label _ _(<category>)<space><cleaned text="">，如下所示:</cleaned></space></category></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es no"><img src="../Images/5b49e20f50a275a27f20e4963fbe34b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*bNp8xA8Nl0SnGGsFo9Be_w.png"/></div></figure><blockquote class="nf ng nh"><p id="379c" class="km kn ne ko b kp lf ij kr ks lg im ku ni lh kw kx nj li kz la nk lj lc ld le hb bi translated">P <!-- -->用“__label__”重新固定类别列的每一行</p></blockquote><pre class="iy iz ja jb fd mj mk ml mm aw mn bi"><span id="860a" class="jo jp hi mk b fi mo mp l mq mr">train_df.iloc[:, 0] = train_df.iloc[:, 0].apply(lambda x: '__label__' + str(x))<br/>test_df.iloc[:, 0] = test_df.iloc[:, 0].apply(lambda x: '__label__' + str(x))</span></pre><blockquote class="nf ng nh"><p id="6b02" class="km kn ne ko b kp lf ij kr ks lg im ku ni lh kw kx nj li kz la nk lj lc ld le hb bi translated">在本地保存txt文件</p></blockquote><pre class="iy iz ja jb fd mj mk ml mm aw mn bi"><span id="a923" class="jo jp hi mk b fi mo mp l mq mr">train_df[['toxic', 'comment_text_cleaned']].to_csv('toxic_train.txt', <br/>                                          index = False, <br/>                                          sep = ' ',<br/>                                          header = None)</span><span id="999f" class="jo jp hi mk b fi np mp l mq mr">test_df[['toxic', 'comment_text_cleaned']].to_csv('toxic_test.txt', <br/>                                     index = False, <br/>                                     sep = ' ',<br/>                                     header = None )</span></pre><blockquote class="nf ng nh"><p id="c381" class="km kn ne ko b kp lf ij kr ks lg im ku ni lh kw kx nj li kz la nk lj lc ld le hb bi translated">训练模型</p></blockquote><pre class="iy iz ja jb fd mj mk ml mm aw mn bi"><span id="e238" class="jo jp hi mk b fi mo mp l mq mr">model = fasttext.train_supervised('toxic_train.txt', wordNgrams=2, epoch = 300, lr = 0.8)</span></pre><p id="b438" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">尽管有一个大的数据集(大约160，000标签数据)，分类模型在我的英特尔处理器i7–9750h上在1.5分钟(100个历元)或4.5分钟(300个历元)内训练得非常快。</p><h1 id="96c4" class="lk jp hi bd jq ll lm ln ju lo lp lq jy io lr ip kc ir ls is kg iu lt iv kk lu bi translated">估价</h1><pre class="iy iz ja jb fd mj mk ml mm aw mn bi"><span id="5aa9" class="jo jp hi mk b fi mo mp l mq mr">y_pred = test_df.iloc[:, 1].apply(lambda x: model.predict(x)[0][0])<br/>y_true = test_df.iloc[:, 0]</span><span id="9bfd" class="jo jp hi mk b fi np mp l mq mr">print(classification_report(y_true, y_pred))<br/>confusion_matrix(y_true, y_pred)</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nq"><img src="../Images/a67a0c9fba5d1212c7d0632bba5bc3c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b1cJjwyX4dinw6JWmqSCJg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Classification report and confusion matrix of 300 epochs</figcaption></figure><h1 id="1712" class="lk jp hi bd jq ll lm ln ju lo lp lq jy io lr ip kc ir ls is kg iu lt iv kk lu bi translated">做出预测</h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nr"><img src="../Images/92c20c30cc21ae80ac2b783985c42b0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PPVvpFna-MLEOl4XBjL_lw.png"/></div></div></figure><p id="f2bb" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">该模型通过正确地将句子<em class="ne">’</em><strong class="ko hj"><em class="ne">该死的</em></strong><em class="ne">’</em>识别为100%确信它是有毒的和将<strong class="ko hj"> <em class="ne">该死的，我喜欢它</em></strong>’识别为70%确信它是无毒的<strong class="ko hj"/>来展示其分类能力。</p><h1 id="3992" class="lk jp hi bd jq ll lm ln ju lo lp lq jy io lr ip kc ir ls is kg iu lt iv kk lu bi translated">开发周期短的好处</h1><p id="08ac" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">fast实施的目的是快速了解数据和活动场所，以便在实际实施之前进行规划。</p><h2 id="95d4" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">基线模型</h2><p id="4df2" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">我们可以粗略地估计分类器模型，并且可以使用经过训练的模型作为基线模型。</p><p id="2224" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">下表显示了出色的性能。<a class="ae jn" href="https://arxiv.org/pdf/1607.01759.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ns"><img src="../Images/1881e0181ad0635acda3a9b2b0153920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*Wo2rhXsF6EGpg7aqp3zVJQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Competitive performance despite short training time</figcaption></figure><h2 id="5bc3" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">用最少的代码快速训练</h2><p id="bbbf" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">模型的训练时间通常少于3分钟(约160条记录)，我们可以通过试验不同的预处理和建模设置来研究模型性能。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nt"><img src="../Images/dc4a07728b353758a0834cf649a60c71.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*XUGnHLel-nP2b9Z5c48n0w.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">The training and testing time comparison (<a class="ae jn" href="https://arxiv.org/pdf/1607.01759.pdf" rel="noopener ugc nofollow" target="_blank">link</a>)</figcaption></figure><h2 id="dc2b" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">操场</h2><p id="8f5a" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">例如，估计要使用的合适单词Ngrams，或者用不同的预处理技术进行测试(Remove_diacritics？将数字转换成文本？保留停用词？).</p><h2 id="5d4f" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">选择合适的数据集弄脏你的手</h2><p id="cf2e" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">较短的开发周期有助于选择训练数据。数据科学家经常不得不在没有给出足够的测试数据的情况下训练NLP模型，并且不得不依赖于来自互联网的开放数据集来训练模型。然后，我们可以从未知的训练中获得一个经过训练的模型，看看训练数据是否符合我们的测试数据。</p><h1 id="9700" class="lk jp hi bd jq ll lm ln ju lo lp lq jy io lr ip kc ir ls is kg iu lt iv kk lu bi translated">完整代码</h1><p id="4a14" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">完整的代码可以在github <a class="ae jn" href="https://github.com/yuanxy33/text-classifier-texthero-fasttext" rel="noopener ugc nofollow" target="_blank">这里</a>获得</p><pre class="iy iz ja jb fd mj mk ml mm aw mn bi"><span id="ed86" class="jo jp hi mk b fi mo mp l mq mr"># Library<br/>import texthero as hero<br/>import pandas as pd<br/>import fasttext<br/>from sklearn.metrics import classification_report<br/>from sklearn.metrics import confusion_matrix</span><span id="07de" class="jo jp hi mk b fi np mp l mq mr"># Reading the files<br/>train_df = pd.read_csv('toxic_text_classification/train.csv/train.csv')<br/>test_df = pd.read_csv('toxic_text_classification/test.csv/test.csv')<br/>test_label_df = pd.read_csv('toxic_text_classification/test_labels.csv/test_labels.csv')<br/>test_df = test_df.merge(test_label_df, left_on='id', right_on='id')<br/>test_df = test_df[(test_df['toxic'] == 0) | (test_df['toxic']==1)]</span><span id="d1f9" class="jo jp hi mk b fi np mp l mq mr"># Text-cleaning<br/>train_df['comment_text_cleaned'] = train_df['comment_text'].pipe(hero.clean)<br/>test_df['comment_text_cleaned'] = test_df['comment_text'].pipe(hero.clean)</span><span id="7ae3" class="jo jp hi mk b fi np mp l mq mr">train_df= train_df[['toxic','comment_text_cleaned']]<br/>test_df= test_df[['toxic','comment_text_cleaned']]<br/></span><span id="1796" class="jo jp hi mk b fi np mp l mq mr"># Formatting file for modelling<br/>train_df.iloc[:, 0] = train_df.iloc[:, 0].apply(lambda x: '__label__' + str(x))<br/>test_df.iloc[:, 0] = test_df.iloc[:, 0].apply(lambda x: '__label__' + str(x))</span><span id="1f7d" class="jo jp hi mk b fi np mp l mq mr">train_df[['toxic', 'comment_text_cleaned']].to_csv('toxic_train.txt', <br/>                                          index = False, <br/>                                          sep = ' ',<br/>                                          header = None)</span><span id="a6d6" class="jo jp hi mk b fi np mp l mq mr">test_df[['toxic', 'comment_text_cleaned']].to_csv('toxic_test.txt', <br/>                                     index = False, <br/>                                     sep = ' ',<br/>                                     header = None )</span><span id="5bdd" class="jo jp hi mk b fi np mp l mq mr"># Model training<br/>model = fasttext.train_supervised('toxic_train.txt', wordNgrams=3, epoch = 150, lr = 0.8)</span><span id="0dc7" class="jo jp hi mk b fi np mp l mq mr"># Evaluation<br/>y_pred = test_df.iloc[:, 1].apply(lambda x: model.predict(x)[0][0])<br/>y_true = test_df.iloc[:, 0]</span><span id="7bbf" class="jo jp hi mk b fi np mp l mq mr">print(classification_report(y_true, y_pred))<br/>print(confusion_matrix(y_true, y_pred))</span><span id="08a0" class="jo jp hi mk b fi np mp l mq mr"># Prediction<br/>testing_text = 'Damn'<br/>clean_text = hero.clean(pd.Series(testing_text))[0]<br/>model.predict(clean_text)</span></pre></div></div>    
</body>
</html>