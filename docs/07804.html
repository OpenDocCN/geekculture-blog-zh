<html>
<head>
<title>NLP Tutorial: Topic Modeling in Python with BerTopic</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP教程:使用BerTopic在Python中进行主题建模</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/nlp-tutorial-topic-modeling-in-python-with-bertopic-da760e1d03aa?source=collection_archive---------0-----------------------#2021-10-02">https://medium.com/geekculture/nlp-tutorial-topic-modeling-in-python-with-bertopic-da760e1d03aa?source=collection_archive---------0-----------------------#2021-10-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/c70e46d032af5e4aa1e50a948ee8ce16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ac1aZX0LTeFZ8vQGIlgD8Q.jpeg"/></div></div></figure><p id="0517" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">主题建模</strong>是一种无监督的机器学习技术，可以自动识别文档(文本数据)中存在的不同主题。数据已经成为运营全球许多企业的关键资产/工具。使用主题建模，您可以收集非结构化数据集，分析文档，并获得相关的和所需的信息，这些信息可以帮助您做出更好的决策。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jo"><img src="../Images/fda82c2cb1739aed16444e82f73321c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Nn0kNiPBc4u6UbPP"/></div></div></figure><p id="589c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有不同的技术来执行主题建模(例如LDA ),但是，在这篇NLP教程中，你将学习如何使用由<a class="ae jt" href="https://github.com/MaartenGr?ref=hackernoon.com" rel="noopener ugc nofollow" target="_blank">马腾·格罗腾·奥斯特</a>开发的BerTopic技术。</p><h1 id="f89d" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">目录:</h1><ol class=""><li id="6521" class="ks kt hi is b it ku ix kv jb kw jf kx jj ky jn kz la lb lc bi translated">什么是BerTopic</li><li id="2f81" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">如何安装BerTopic</li><li id="6f10" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">加载东京奥运会推文数据</li><li id="f34b" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">创建BerTopic模型</li><li id="60ae" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">选择热门话题</li><li id="5355" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">选择一个主题</li><li id="00ac" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">主题建模可视化</li><li id="d0d9" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">话题缩减</li><li id="caf7" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">作出预测</li><li id="84a5" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn kz la lb lc bi translated">保存并加载模型</li></ol><h1 id="a562" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">什么是BerTopic？</h1><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/0c92a5ee43a194d2831925ec02902fdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/0*JamRuKyYk29xj1IT"/></div></div></figure><p id="aa8f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">BerTopic是一种主题建模技术，它使用转换器(BERT嵌入)和基于类的TF-IDF来创建密集的集群。它还允许您轻松地解释和可视化所生成的主题。</p><p id="794f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">BerTopic算法包含3个阶段:</p><p id="ff4d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 1。嵌入文本数据(文档)<br/> </strong>在该步骤中，该算法用BERT提取文档嵌入，或者它可以使用任何其他嵌入技术。</p><p id="a5c9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">默认情况下，它使用以下语句transformers</p><ul class=""><li id="1e23" class="ks kt hi is b it iu ix iy jb lj jf lk jj ll jn lm la lb lc bi translated"><strong class="is hj">“释义-MiniLM-L6-v2”</strong>-这是一个基于英语BERT的模型，专门为语义相似性任务训练。</li><li id="8754" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn lm la lb lc bi translated"><strong class="is hj">“paraphrase-multilingual-MiniLM-L12-v2</strong>”——这与第一个类似，一个主要区别是xlm模型适用于50多种语言。</li></ul><p id="1ecb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 2。聚类文档<br/> </strong>它使用UMAP来减少嵌入的维数，并使用HDBSCAN技术来聚类减少的嵌入并创建语义相似文档的聚类。</p><p id="0359" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 3。创建一个主题表示<br/> </strong>最后一步是用<a class="ae jt" href="https://towardsdatascience.com/creating-a-class-based-tf-idf-with-scikit-learn-caea7b15b858?ref=hackernoon.com" rel="noopener" target="_blank">基于类别的TF-IDF </a>提取并约简主题，然后用最大边际相关性提高单词的连贯性。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/dc3189ca35343426e912a84d8195fd49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CMkR9LeJvOVJ0XGG"/></div></div></figure><h1 id="145e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">如何安装BerTopic</h1><p id="fe8c" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">您可以通过pip安装该软件包:</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="3e5f" class="lw jv hi ls b fi lx ly l lz ma">pip install bertopic</span></pre><p id="e07d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您对可视化选项感兴趣，您需要按如下方式安装它们。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="2977" class="lw jv hi ls b fi lx ly l lz ma">pip install bertopic[visualization]</span></pre><p id="7ab7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">BerTopic支持不同的转换器和语言后端，您可以使用它们来创建模型。您可以根据下面的选项安装一个。</p><ul class=""><li id="ea41" class="ks kt hi is b it iu ix iy jb lj jf lk jj ll jn lm la lb lc bi translated">pip安装bertopic[flair]</li><li id="cf06" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn lm la lb lc bi translated">pip安装bertopic[gensim]</li><li id="59f7" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn lm la lb lc bi translated">pip安装bertopic[空间]</li><li id="7ce1" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn lm la lb lc bi translated">pip安装bertopic[使用]</li></ul><h1 id="eb5e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">图书馆</h1><p id="6b63" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">我们将使用下面的库来帮助我们从BerTopic加载数据和创建模型。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="f267" class="lw jv hi ls b fi lx ly l lz ma">#import packages</span><span id="fdac" class="lw jv hi ls b fi mb ly l lz ma">import pandas as pd <br/>import numpy as np<br/>from bertopic import BERTopic</span></pre><h1 id="d583" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">第一步。加载数据</h1><p id="4e33" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">在这篇NLP教程中，我们将使用【2020年东京奥运会推文，目标是创建一个可以根据主题自动对推文进行分类的模型。</p><p id="2d44" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你可以在这里下载数据集<a class="ae jt" href="https://www.kaggle.com/gpreda/tokyo-olympics-2020-tweets?ref=hackernoon.com" rel="noopener ugc nofollow" target="_blank"/>。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="f7f1" class="lw jv hi ls b fi lx ly l lz ma">#load data <br/>import pandas as pd <br/> <br/>df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/data/tokyo_2020_tweets.csv", engine='python')<br/> <br/># select only 6000 tweets <br/>df = df[0:6000]</span></pre><p id="ff4f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">注意:</strong>出于计算原因，我们只选择了6000条推文。</p><h1 id="6891" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">第二步。创建模型</h1><p id="4b15" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">要使用BERTopic创建一个模型，需要将tweets作为一个列表加载，然后将其传递给fit_transform方法。该方法将执行以下操作:</p><ul class=""><li id="fa20" class="ks kt hi is b it iu ix iy jb lj jf lk jj ll jn lm la lb lc bi translated">将模型拟合到推文集合上。</li><li id="d78d" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn lm la lb lc bi translated">生成话题。</li><li id="5f8e" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn lm la lb lc bi translated">返回带有主题的推文。</li></ul><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="8108" class="lw jv hi ls b fi lx ly l lz ma"># create model <br/> <br/>model = BERTopic(verbose=True)<br/> <br/>#convert to list <br/>docs = df.text.to_list()<br/> <br/>topics, probabilities = model.fit_transform(docs)</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/4446ca4a487f1deae852973d0825ba70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BR_owq_AWP7r-2sJ"/></div></div></figure><h1 id="9dc4" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">第三步。选择热门话题</h1><p id="1b1b" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">定型模型后，您可以按降序访问主题的大小。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="f48a" class="lw jv hi ls b fi lx ly l lz ma">model.get_topic_freq().head(11)</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es md"><img src="../Images/c800f31c973d9c1cb8df804f10633280.png" data-original-src="https://miro.medium.com/v2/resize:fit:494/0*YhsLRI5OWTc00D1L"/></div></figure><p id="99a4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">注意:</strong> Topic -1是最大的，它指的是不分配给任何生成的主题的离群tweets。在这种情况下，我们将忽略主题1。</p><h1 id="10e7" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">第四步。选择一个主题</h1><p id="eced" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">您可以选择一个特定的主题，并获得该主题的前n个单词及其c-TF-IDF分数。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="de44" class="lw jv hi ls b fi lx ly l lz ma">model.get_topic(6)</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/e2663c7708e4b651649e6edd06b4d671.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/0*os6m6PFFKDLwK7wj"/></div></div></figure><p id="55ef" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于这个选定的主题，常见的词是瑞典，目标，罗尔福，瑞典人，目标，足球。很明显，这个话题的焦点是“瑞典队的<strong class="is hj">足球</strong>”。</p><h1 id="c9c5" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">步骤5:主题建模可视化</h1><p id="0d96" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">BerTopic允许您以非常类似于LDAvis的方式可视化生成的主题。这将让你对主题的质量有更多的了解。在本文中，我们将研究三种可视化主题的方法。</p><h1 id="25bc" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">可视化主题</h1><p id="7f5a" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">visualize_topics方法可以帮助您可视化主题及其大小和相应的单词。可视化的灵感来自LDavis。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="a8e6" class="lw jv hi ls b fi lx ly l lz ma">model.visualize_topics()</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es mf"><img src="../Images/04acdca2cdb8d68d934c17ed15ffe7a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/0*qw_3TEBpaVu_caUz"/></div></figure><h1 id="1fb4" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">可视化术语</h1><p id="126a" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">visualize_barchart方法将通过创建c-TF-IDF得分的条形图来显示一些主题的选定术语。然后，您可以相互比较主题表示，并从生成的主题中获得更多见解。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="538f" class="lw jv hi ls b fi lx ly l lz ma">model.visualize_barchart()</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/bdf46706917d9055c9cf7e2268a9998b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7yY0nAQlKQQgWKBu"/></div></div></figure><p id="c499" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上图中，你可以看到话题4中的热门词汇是自豪、感谢、加油、欢呼和祝贺。</p><h1 id="c724" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">可视化主题相似性</h1><p id="942b" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">您还可以想象某些主题彼此之间有多相似。要可视化热图，只需调用。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="e3a7" class="lw jv hi ls b fi lx ly l lz ma">model.visualize_heatmap()</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/8e13b17f5c395b1802bcda6f71519f52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*h2gW45tJk1tWxtHR"/></div></div></figure><p id="51c4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上图中，您可以看到主题<strong class="is hj"> 93 </strong>与主题<strong class="is hj"> 102 </strong>相似，相似度得分为<strong class="is hj"> 0.933。</strong></p><h1 id="69ef" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">话题缩减</h1><p id="9b0c" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">有时你可能会产生太多或太少的主题，BerTopic为你提供了一个以不同方式控制这种行为的选项。</p><p id="cd58" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">(a)您可以通过将参数“<strong class="is hj"> nr_topics </strong>”设置为您想要的主题数量。BerTopic会找到相似的主题并将其合并。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="1726" class="lw jv hi ls b fi lx ly l lz ma">model = BERTopic(nr_topics=20)</span></pre><p id="1b00" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的代码中，将生成的主题数量是20。</p><p id="68a3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">(b)另一种选择是自动减少主题数量。要使用此选项，您需要在训练模型之前将“<strong class="is hj"> nr_topics </strong>”设置为“<strong class="is hj"> auto </strong>”。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="a5de" class="lw jv hi ls b fi lx ly l lz ma">model = BERTopic(nr_topics="auto")</span></pre><p id="7a17" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后一个选项是在训练模型之后减少主题的数量。如果重新训练模型需要很多时间，这是一个很好的选择。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="80f5" class="lw jv hi ls b fi lx ly l lz ma">new_topics, new_probs = model.reduce_topics(docs, topics, probabilities, nr_topics=15)</span></pre><p id="2c24" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的示例中，您在定型模型后将主题数量减少到15个。</p><h1 id="efcb" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">第六步:做预测</h1><p id="768b" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">为了预测新文档的主题，您需要在transform方法上添加一个新的实例。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="be5b" class="lw jv hi ls b fi lx ly l lz ma">topics, probs = model.transform(new_docs)</span></pre><h1 id="032e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">步骤7:保存模型</h1><p id="dcf2" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">您可以使用save方法来储存已定型的模型。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="7ecf" class="lw jv hi ls b fi lx ly l lz ma">model.save("my_topics_model")</span></pre><h1 id="8172" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">步骤8:加载模型</h1><p id="b6c2" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">您可以使用load方法加载模型。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="7b80" class="lw jv hi ls b fi lx ly l lz ma">BerTopic_model = BERTopic.load("my_topics_model")</span></pre><h1 id="9422" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">关于用BerTopic在Python中进行主题建模的最后思考</h1><p id="b1ab" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">在本NLP教程中，您已经学习了</p><ul class=""><li id="bae4" class="ks kt hi is b it iu ix iy jb lj jf lk jj ll jn lm la lb lc bi translated">如何创建BerTopic模型？</li><li id="603a" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn lm la lb lc bi translated">选择生成的主题。</li><li id="1935" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn lm la lb lc bi translated">可视化主题和每个主题的单词，以获得更多的见解。</li><li id="35dc" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn lm la lb lc bi translated">减少生成主题数量的不同技术。</li><li id="8e1f" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn lm la lb lc bi translated">如何进行预测？</li><li id="1848" class="ks kt hi is b it ld ix le jb lf jf lg jj lh jn lm la lb lc bi translated">如何保存和加载BerTopic模型？</li></ul><p id="85aa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">BerTopic在创建模型时提供了许多特性。例如，如果您有一个特定语言的数据集(默认情况下，它支持英语模型)，您可以通过在配置模型时设置语言参数来选择语言。</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="69cb" class="lw jv hi ls b fi lx ly l lz ma">model = BERTopic(language="German")</span></pre><p id="591a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">注意:</strong>选择其嵌入模型存在的语言。</p><p id="7ac6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果文档中混合了多种语言，可以设置</p><pre class="jp jq jr js fd lr ls lt lu aw lv bi"><span id="e63d" class="lw jv hi ls b fi lx ly l lz ma">language="multilingual"</span></pre><p id="8c18" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">支持超过50种语言。</p><p id="6f5e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你学到了新的东西或者喜欢阅读这篇文章，请分享给其他人看。在那之前，下期帖子再见！</p><p id="9837" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">也可以在Twitter <a class="ae jt" href="https://twitter.com/Davis_McDavid?ref=hackernoon.com" rel="noopener ugc nofollow" target="_blank"> @Davis_McDavid </a>上找我。</p><p id="03eb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="mh">最后一件事:在以下链接中阅读更多类似的文章。</em></p><div class="mi mj ez fb mk ml"><a href="https://medium.datadriveninvestor.com/nlp-datasets-from-huggingface-how-to-access-and-train-them-8852c2aca74" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab dw"><div class="mn ab mo cl cj mp"><h2 class="bd hj fi z dy mq ea eb mr ed ef hh bi translated">来自HuggingFace的NLP数据集:如何访问和训练它们</h2><div class="ms l"><h3 class="bd b fi z dy mq ea eb mr ed ef dx translated">拥抱脸的数据集库提供了一个非常有效的方法来加载和处理原始文件或…</h3></div><div class="mt l"><p class="bd b fp z dy mq ea eb mr ed ef dx translated">medium.datadriveninvestor.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz io ml"/></div></div></a></div><div class="mi mj ez fb mk ml"><a rel="noopener follow" target="_blank" href="/geekculture/how-to-perform-data-augmentation-with-augly-library-e32279916b14"><div class="mm ab dw"><div class="mn ab mo cl cj mp"><h2 class="bd hj fi z dy mq ea eb mr ed ef hh bi translated">如何使用Augly库进行数据扩充</h2><div class="ms l"><h3 class="bd b fi z dy mq ea eb mr ed ef dx translated">来自脸书的一个新的开源python库</h3></div><div class="mt l"><p class="bd b fp z dy mq ea eb mr ed ef dx translated">medium.com</p></div></div><div class="mu l"><div class="na l mw mx my mu mz io ml"/></div></div></a></div><div class="mi mj ez fb mk ml"><a href="https://medium.datadriveninvestor.com/23-common-data-science-interview-questions-for-beginners-59c2265a947e" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab dw"><div class="mn ab mo cl cj mp"><h2 class="bd hj fi z dy mq ea eb mr ed ef hh bi translated">初学者常见的23个数据科学面试问题</h2><div class="ms l"><h3 class="bd b fi z dy mq ea eb mr ed ef dx translated">回答常见面试问题的指南和资源。</h3></div><div class="mt l"><p class="bd b fp z dy mq ea eb mr ed ef dx translated">medium.datadriveninvestor.com</p></div></div><div class="mu l"><div class="nb l mw mx my mu mz io ml"/></div></div></a></div><p id="29c3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="mh">本文首发</em> <a class="ae jt" href="https://hackernoon.com/nlp-tutorial-topic-modeling-in-python-with-bertopic-372w35l9" rel="noopener ugc nofollow" target="_blank"> <em class="mh">此处</em> </a> <em class="mh">。</em></p></div></div>    
</body>
</html>