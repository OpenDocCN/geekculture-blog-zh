<html>
<head>
<title>Build Your Own Big Data Ecosystem — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建您自己的大数据生态系统—第1部分</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/build-your-own-big-data-ecosystem-part-1-a19e4c778632?source=collection_archive---------2-----------------------#2021-02-21">https://medium.com/geekculture/build-your-own-big-data-ecosystem-part-1-a19e4c778632?source=collection_archive---------2-----------------------#2021-02-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="c2f2" class="hg hh hi bd b fp hj hk hl hm hn ho dx hp translated" aria-label="kicker paragraph">详细的演练</h2><div class=""/><div class=""><h2 id="554a" class="pw-subtitle-paragraph io hr hi bd b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf dx translated">在Kubernetes上运行火花</h2></div><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es jg"><img src="../Images/79320f17b2d3220d0b94288473b398b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0pR6q8yLHoLhpcGeeoDCrw.jpeg"/></div></div></figure><p id="b186" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">数据是我们如今所做的一切不可或缺的一部分。几乎我们周围的一切都以某种形式产生数据。只有当我们能够从中提取有意义的见解时，这些数据才对我们有用。这就是数据分析的用武之地。我们有很多产品可以满足我们的大数据需求，但它们通常需要高昂的许可成本。</p><p id="b7af" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在这个多部分系列中，我们将尝试使用所有开源工具创建我们自己的云不可知大数据生态系统。</p><p id="8a50" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">典型的大数据生态系统由以下部分组成</p><ul class=""><li id="2a99" class="ko kp hi ju b jv jw jy jz kb kq kf kr kj ks kn kt ku kv kw bi translated">运行大数据查询的核心数据分析引擎</li><li id="3b3b" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated">交互式创建查询的笔记本/UI界面</li><li id="5d02" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated">具有底层数据湖的通信信道</li><li id="8aa8" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated">管理ML模型生命周期的框架</li><li id="657e" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated">创建图表的可视化工具</li></ul></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><p id="ca8d" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">Spark以其高查询性能而闻名，并作为底层数据分析引擎广泛应用于许多成功的产品中，如AWS EMR、Databricks、Cloudera等。我们也将使用<strong class="ju hs"> Spark作为我们的数据分析引擎</strong></p><p id="5d80" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">为了使生态系统与底层基础设施分离，我们将在<strong class="ju hs"> Kubernetes </strong>上运行它，这样我们就可以在任何我们想要的地方运行它，并随时扩展它。从2.3版本开始，Spark可以在Kubernetes上运行。</p><h2 id="81d1" class="lj lk hi bd ll lm ln lo lp lq lr ls lt kb lu lv lw kf lx ly lz kj ma mb mc ho bi translated">简而言之，这篇博文</h2><p id="213f" class="pw-post-body-paragraph js jt hi ju b jv md is jx jy me iv ka kb mf kd ke kf mg kh ki kj mh kl km kn hb bi translated">我们将从官方的Spark发行版创建一个Spark Docker映像。然后，我们将在Azure中创建一个Kubernetes集群，并使用上面创建的Docker映像在集群中运行spark driver和executor pods。我们将在集群模式下运行一个样例Spark作业来计算这个Kubernetes集群中的Pi值。</p><h1 id="aafb" class="mi lk hi bd ll mj mk ml lp mm mn mo lt ix mp iy lw ja mq jb lz jd mr je mc ms bi translated">先决条件</h1><p id="4480" class="pw-post-body-paragraph js jt hi ju b jv md is jx jy me iv ka kb mf kd ke kf mg kh ki kj mh kl km kn hb bi translated">虽然我们可以使用windows机器来设置一切，但我强烈建议使用基于Ubuntu的机器，以获得更大的支持和易用性。</p><p id="4d8e" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">以下内容需要存在于您的开发机器中(如果没有使用云外壳)</p><ul class=""><li id="343b" class="ko kp hi ju b jv jw jy jz kb kq kf kr kj ks kn kt ku kv kw bi translated"><a class="ae mt" href="https://docs.docker.com/engine/install/ubuntu/" rel="noopener ugc nofollow" target="_blank">码头工人</a></li><li id="609e" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae mt" href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" rel="noopener ugc nofollow" target="_blank">库贝克特尔</a></li><li id="0878" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae mt" href="https://minikube.sigs.k8s.io/docs/start/" rel="noopener ugc nofollow" target="_blank"> minikube </a>(仅当您计划在本地系统上运行Kubernetes时)</li><li id="0e83" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae mt" href="https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-18-04" rel="noopener ugc nofollow" target="_blank"> Java-11 </a></li><li id="4806" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae mt" href="https://azure.microsoft.com/en-in/services/container-registry/" rel="noopener ugc nofollow" target="_blank"> Docker容器注册表</a> (ACR / ECR / Docker Hub等。)</li></ul><blockquote class="mu mv mw"><p id="fe93" class="js jt mx ju b jv jw is jx jy jz iv ka my kc kd ke mz kg kh ki na kk kl km kn hb bi translated">我使用过Azure的云外壳来运行我的大部分命令。这减少了设置所需的二进制文件的工作量，如Java、az cli、kubectl、python等，因为它们已经预先安装好了。</p></blockquote></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="f89e" class="mi lk hi bd ll mj nb ml lp mm nc mo lt ix nd iy lw ja ne jb lz jd nf je mc ms bi translated">Spark + Kubernetes —一些基本要素</h1><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es ng"><img src="../Images/b188efc3d43804e4b497acfc8e2057b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BDM4qaKA6Okue6jxT0_k3A.jpeg"/></div></div><figcaption class="nh ni et er es nj nk bd b be z dx">The execution model of Spark on Kubernetes</figcaption></figure><p id="0bea" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">Spark架构有3个主要部分。</p><ul class=""><li id="692e" class="ko kp hi ju b jv jw jy jz kb kq kf kr kj ks kn kt ku kv kw bi translated"><strong class="ju hs">驱动程序</strong> — <em class="mx">负责将一个传入的spark任务分解成更小的垃圾，并管理这些垃圾的执行</em></li><li id="b81c" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated"><strong class="ju hs">执行者</strong> — <em class="mx">负责运行整个任务中的一个单独部分，并将结果报告给驱动程序。</em></li><li id="48b5" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated"><strong class="ju hs">集群管理器</strong> — <em class="mx">负责管理Spark驱动程序和执行器运行的底层基础设施</em></li></ul><p id="0308" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">传统上，Spark使用Yarn、Mesos和独立的集群管理器，但从Spark 2.3开始，Spark包含了对Kubernetes的支持，并充当其集群管理器。</p><p id="3063" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在我们的用例中，Kubernetes调度程序负责在可用的节点中创建适当的驱动程序和执行器pod。</p><p id="0f26" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">我们可以在两种Spark模式、集群模式和客户端模式下执行作业。在这篇博客文章中，我们将介绍<strong class="ju hs">集群模式</strong>，在这种模式下，我们使用<strong class="ju hs"> spark-submit向Kubernetes </strong>集群提交一个作业，该集群在运行中创建spark上下文、驱动程序和执行器pod。</p><p id="63ee" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在本系列的第2部分中，我们将更深入地研究客户机模式。</p><h1 id="fc63" class="mi lk hi bd ll mj mk ml lp mm mn mo lt ix mp iy lw ja mq jb lz jd mr je mc ms bi translated"><strong class="ak">步骤1——创建Spark Docker图像</strong></h1><p id="cf81" class="pw-post-body-paragraph js jt hi ju b jv md is jx jy me iv ka kb mf kd ke kf mg kh ki kj mh kl km kn hb bi translated">在这一步，我们将创建支持pyspark的Spark Docker映像。我们将在Kubernetes pods上使用这张图片。</p><h2 id="671f" class="lj lk hi bd ll lm ln lo lp lq lr ls lt kb lu lv lw kf lx ly lz kj ma mb mc ho bi translated">下载并提取Spark</h2><p id="c6c0" class="pw-post-body-paragraph js jt hi ju b jv md is jx jy me iv ka kb mf kd ke kf mg kh ki kj mh kl km kn hb bi translated">运行下面的curl命令下载编译后的火花分布。或者，您也可以在web浏览器中访问URL并开始下载。</p><pre class="jh ji jj jk fd nl nm nn no aw np bi"><span id="7d01" class="lj lk hi nm b fi nq nr l ns nt">curl <a class="ae mt" href="https://mirrors.estointernet.in/apache/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz" rel="noopener ugc nofollow" target="_blank">https://mirrors.estointernet.in/apache/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz</a> --output spark-3.0.1-bin-hadoop3.2.tgz</span></pre><p id="2bee" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在撰写本文时，Spark版本的最新可用版本是3.0.1，Hadoop版本是3.2</p><p id="d80e" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">下载后，解压下载的zip文件</p><pre class="jh ji jj jk fd nl nm nn no aw np bi"><span id="ad61" class="lj lk hi nm b fi nq nr l ns nt">tar -xvzf spark-3.0.1-bin-hadoop3.2.tgz</span></pre><h2 id="4584" class="lj lk hi bd ll lm ln lo lp lq lr ls lt kb lu lv lw kf lx ly lz kj ma mb mc ho bi translated">构建Spark Docker映像</h2><p id="acb0" class="pw-post-body-paragraph js jt hi ju b jv md is jx jy me iv ka kb mf kd ke kf mg kh ki kj mh kl km kn hb bi translated">Spark附带了一个内置脚本“docker-image-tool.sh ”,它为我们创建了docker映像。在提取的文件夹的根级别中，运行以下命令。</p><pre class="jh ji jj jk fd nl nm nn no aw np bi"><span id="461f" class="lj lk hi nm b fi nq nr l ns nt">./bin/docker-image-tool.sh -r &lt;&lt;docker registry url&gt;&gt; -t v3.0.1-j11 -p kubernetes/dockerfiles/spark/bindings/python/Dockerfile -b java_image_tag=11-jre-slim build</span></pre><blockquote class="mu mv mw"><p id="210e" class="js jt mx ju b jv jw is jx jy jz iv ka my kc kd ke mz kg kh ki na kk kl km kn hb bi translated">注意—需要在运行脚本的机器上安装Docker。</p></blockquote><p id="e1f2" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在上面的命令中，我们使用如下参数执行docker-image-tool.sh</p><ul class=""><li id="119e" class="ko kp hi ju b jv jw jy jz kb kq kf kr kj ks kn kt ku kv kw bi translated"><strong class="ju hs"> -r </strong>用于docker注册表</li><li id="fe82" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated"><strong class="ju hs"> -t </strong>是输出docker图像的标签</li><li id="225f" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated"><strong class="ju hs"> -p </strong>是实际Docker文件的路径。我们使用上面的python Dockerfile，它应该出现在给定的路径中。这增加了对pyspark的支持。</li><li id="b498" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated"><strong class="ju hs"> -b </strong>是我们想要发送到Dockerfile的构建参数。在我们的例子中，我们提到了要用作11-jre-slim的java基础映像</li></ul><p id="2ea8" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在成功执行docker-image-tool.sh之后，您应该会在本地注册表中看到2个docker图像。一个名为&lt;<docker registry="" url=""> &gt;/spark，另一个名为&lt;<docker registry="" url=""> &gt;/spark-py</docker></docker></p><p id="a878" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">由于我们计划在接下来的部分中运行python查询，我们将在后续步骤中使用图像spark-py</p><h2 id="6c88" class="lj lk hi bd ll lm ln lo lp lq lr ls lt kb lu lv lw kf lx ly lz kj ma mb mc ho bi translated">将映像推送到容器注册表中</h2><p id="c1de" class="pw-post-body-paragraph js jt hi ju b jv md is jx jy me iv ka kb mf kd ke kf mg kh ki kj mh kl km kn hb bi translated">下一步是将docker映像推送到Docker存储库。在这篇文章的后半部分，我们将在运行spark-submit命令时引用图像的这个位置。</p><pre class="jh ji jj jk fd nl nm nn no aw np bi"><span id="aaea" class="lj lk hi nm b fi nq nr l ns nt">docker push &lt;&lt;docker registry url&gt;&gt;/spark-py:v3.0.1-j14</span></pre><h1 id="f6ad" class="mi lk hi bd ll mj mk ml lp mm mn mo lt ix mp iy lw ja mq jb lz jd mr je mc ms bi translated">步骤2 —创建Kubernetes集群</h1><p id="6939" class="pw-post-body-paragraph js jt hi ju b jv md is jx jy me iv ka kb mf kd ke kf mg kh ki kj mh kl km kn hb bi translated">既然我们的Spark docker映像已经准备好了，是时候启动Kubernetes集群来运行Spark了。</p><p id="01ae" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">我使用Azure Kubernetes服务在Azure上创建一个集群。但是由于这种方法并不真正关心您的集群在哪里，您可以将它部署到您选择的位置。</p><p id="6fab" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">创建一个AKS集群，遵循这个来自微软的<a class="ae mt" href="https://docs.microsoft.com/en-us/azure/aks/kubernetes-walkthrough-portal" rel="noopener ugc nofollow" target="_blank">官方文档</a>。</p><h2 id="d005" class="lj lk hi bd ll lm ln lo lp lq lr ls lt kb lu lv lw kf lx ly lz kj ma mb mc ho bi translated">设置kubectl</h2><p id="af0e" class="pw-post-body-paragraph js jt hi ju b jv md is jx jy me iv ka kb mf kd ke kf mg kh ki kj mh kl km kn hb bi translated">我们的第一个任务是配置kubectl来连接到我们的集群。kubectl处理通常位于$HOME/的kubeconfig文件。kube文件夹。各种各样的Kubernetes服务提供了不同的方式来配置kubectl，以便与集群一起工作。</p><p id="d5a1" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">对于AKS集群，运行下面的az-cli命令使kubectl指向它。</p><pre class="jh ji jj jk fd nl nm nn no aw np bi"><span id="632e" class="lj lk hi nm b fi nq nr l ns nt">az aks get-credentials --resource-group myResourceGroup --name myAKSCluster</span></pre><blockquote class="mu mv mw"><p id="f7b6" class="js jt mx ju b jv jw is jx jy jz iv ka my kc kd ke mz kg kh ki na kk kl km kn hb bi translated"><strong class="ju hs">注意</strong>——如果您从本地系统运行上述命令，您需要在运行之前运行“<strong class="ju hs"> az登录</strong></p></blockquote><p id="1f5a" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">您可以直接在Azure cloud shell上运行这个命令，并在那里开始使用kubectl。</p><h2 id="e2ea" class="lj lk hi bd ll lm ln lo lp lq lr ls lt kb lu lv lw kf lx ly lz kj ma mb mc ho bi translated">创建一个Kubernetes名称空间</h2><p id="c23a" class="pw-post-body-paragraph js jt hi ju b jv md is jx jy me iv ka kb mf kd ke kf mg kh ki kj mh kl km kn hb bi translated">接下来，我们在集群中创建一个名称空间。虽然我们可以使用默认的名称空间，但是当我们将许多其他工具作为同一个集群的一部分进行部署时，它被证明是一种更好、更具可伸缩性的方法。</p><p id="14e7" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">要创建命名空间，请运行以下命令</p><pre class="jh ji jj jk fd nl nm nn no aw np bi"><span id="dfd8" class="lj lk hi nm b fi nq nr l ns nt">kubectl create namespace spark</span></pre><h2 id="b1c6" class="lj lk hi bd ll lm ln lo lp lq lr ls lt kb lu lv lw kf lx ly lz kj ma mb mc ho bi translated">创建一个服务帐户并为其绑定一个角色</h2><p id="f1f6" class="pw-post-body-paragraph js jt hi ju b jv md is jx jy me iv ka kb mf kd ke kf mg kh ki kj mh kl km kn hb bi translated">作为Spark执行周期的一部分，驱动程序单元需要通过在需要时创建和删除单元来改变集群的状态。因此，我们需要Kubernetes中的一个服务帐户，它将对集群拥有编辑权限。我们将使用这个帐户运行我们的spark-submit命令。</p><pre class="jh ji jj jk fd nl nm nn no aw np bi"><span id="7a90" class="lj lk hi nm b fi nq nr l ns nt">kubectl create serviceaccount spark --namespace=spark</span><span id="12c4" class="lj lk hi nm b fi nu nr l ns nt">kubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=spark:spark --namespace=spark</span></pre><p id="f940" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">我们在spark名称空间中创建一个名为“spark”的服务帐户，集群角色为edit。</p><h2 id="1f38" class="lj lk hi bd ll lm ln lo lp lq lr ls lt kb lu lv lw kf lx ly lz kj ma mb mc ho bi translated">在Docker注册表上分配图像提取权限</h2><p id="dffb" class="pw-post-body-paragraph js jt hi ju b jv md is jx jy me iv ka kb mf kd ke kf mg kh ki kj mh kl km kn hb bi translated">为了在pods中创建容器，Kubernetes需要访问您的docker注册中心来提取docker图像。为此，我们在集群中使用凭据创建一个密码，然后将该密码与我们在上一步中创建的服务帐户相关联。</p><blockquote class="mu mv mw"><p id="8229" class="js jt mx ju b jv jw is jx jy jz iv ka my kc kd ke mz kg kh ki na kk kl km kn hb bi translated"><strong class="ju hs">注意</strong> —在创建AKS集群时，我们可以通过创建向导将Azure容器注册中心与它关联起来。如果您已经这样做了，您可以跳过这一步</p></blockquote><p id="0a03" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">运行下面的命令来创建密码</p><pre class="jh ji jj jk fd nl nm nn no aw np bi"><span id="a850" class="lj lk hi nm b fi nq nr l ns nt">kubectl create secret docker-registry docker-repo-access --namespace=spark --docker-server=&lt;&lt;docker registry url&gt;&gt; --docker-username=&lt;&lt;username&gt;&gt; --docker-password=&lt;&lt;password&gt;&gt;</span></pre><blockquote class="mu mv mw"><p id="a9cf" class="js jt mx ju b jv jw is jx jy jz iv ka my kc kd ke mz kg kh ki na kk kl km kn hb bi translated"><strong class="ju hs">注意</strong> —如果您在Azure之外的集群中使用ACR，您可以在AAD中创建一个服务主体，在ACR上为其提供ACR拉角色，并使用服务主体的客户端id &amp;客户端机密来代替用户名&amp;密码</p></blockquote><p id="9792" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">将密码分配给我们的服务帐户</p><pre class="jh ji jj jk fd nl nm nn no aw np bi"><span id="6d6a" class="lj lk hi nm b fi nq nr l ns nt">kubectl patch serviceaccount spark -p '{"imagePullSecrets": [{"name": "docker-repo-access"}]}' -n spark</span></pre><h1 id="f5d7" class="mi lk hi bd ll mj mk ml lp mm mn mo lt ix mp iy lw ja mq jb lz jd mr je mc ms bi translated">步骤3 —在集群上运行Spark作业</h1><p id="e678" class="pw-post-body-paragraph js jt hi ju b jv md is jx jy me iv ka kb mf kd ke kf mg kh ki kj mh kl km kn hb bi translated">通过我们在步骤2中执行的所有操作，我们的集群现在已经准备好运行一个spark作业。</p><p id="58b6" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">最后，是时候在这个集群上运行我们的第一个Spark作业了。</p><p id="5170" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">如果您从Azure cloud shell运行，请在新选项卡中打开另一个shell，并运行下面的命令来打开与IP地址为127.0.0.1:8001的集群的代理连接</p><pre class="jh ji jj jk fd nl nm nn no aw np bi"><span id="93c8" class="lj lk hi nm b fi nq nr l ns nt">kubectl proxy</span></pre><p id="1ff8" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">然后使用命令spark-submit来运行我们的作业。</p><pre class="jh ji jj jk fd nl nm nn no aw np bi"><span id="f37d" class="lj lk hi nm b fi nq nr l ns nt">./bin/spark-submit --master k8s://http://127.0.0.1:8001 --deploy-mode cluster --name spark-pi --class org.apache.spark.examples.SparkPi --conf spark.executor.instances=3 --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark --conf spark.kubernetes.container.image=ascendonk8s.azurecr.io/spark-py:v3.0.1-j14 local:///opt/spark/examples/jars/spark-examples_2.12-3.0.1.jar 1000</span></pre><ul class=""><li id="fd70" class="ko kp hi ju b jv jw jy jz kb kq kf kr kj ks kn kt ku kv kw bi translated">这是我们集群的API服务器的URL。k8s://是Spark用来将URL标识为Kubernetes集群端点的约定。</li><li id="7610" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated"><code class="du nv nw nx nm b">--name</code>这是我们为我们的Spark工作想要的名称</li><li id="11bc" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated"><code class="du nv nw nx nm b">--class</code>这是入口点Java类，我们的执行将从这里开始</li><li id="1890" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated"><code class="du nv nw nx nm b">--conf</code>使用它，我们可以提供我们需要的executor pods的数量、我们希望与pod关联的服务帐户以及用于启动pod的容器映像方面的详细信息。</li><li id="701c" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated"><code class="du nv nw nx nm b">local://</code>这是一个约定，告诉spark我们工作的代码包存在于容器本身中。使用它，我们指定需要运行名为spark-examples _ 2.12–3 . 0 . 1 . jar的jar文件，该文件位于映像中相应的路径。</li></ul><p id="76bd" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">提交命令后，您可以使用下面的命令在集群单元上放置一个观察器</p><pre class="jh ji jj jk fd nl nm nn no aw np bi"><span id="4e48" class="lj lk hi nm b fi nq nr l ns nt">watch kubectl get pods -n spark</span></pre><p id="9fe4" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">豆荚的生命周期如下</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es ny"><img src="../Images/f27525e0e003aa0072ba02daa173bee6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*NlMyvQ89XEX5xgxpv4FUHA.jpeg"/></div><figcaption class="nh ni et er es nj nk bd b be z dx">Pod life-cycle</figcaption></figure><p id="efca" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">如果你能在上面的“观察”命令中看到豆荚按照这个生命周期来来去去，那就意味着一切顺利。</p><p id="68fb" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">对于我们最后的验证，我们使用下面的命令检查驱动程序的日志</p><pre class="jh ji jj jk fd nl nm nn no aw np bi"><span id="d5d7" class="lj lk hi nm b fi nq nr l ns nt">kubectl logs &lt;&lt;driver_pods_name&gt;&gt;</span></pre><p id="6cd3" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">您应该会在输出中看到如下一行</p><pre class="jh ji jj jk fd nl nm nn no aw np bi"><span id="c2fa" class="lj lk hi nm b fi nq nr l ns nt">Pi is roughly 3.152155760778804</span></pre><p id="2c10" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">至此，我们结束了第一部分。我们现在已经为我们的生态系统打下了基础。</p><p id="0560" class="pw-post-body-paragraph js jt hi ju b jv jw is jx jy jz iv ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">在下一部分中，我们将探索在集群中使用Jupyter笔记本在客户机模式下运行交互式Spark查询。</p><h1 id="0d75" class="mi lk hi bd ll mj mk ml lp mm mn mo lt ix mp iy lw ja mq jb lz jd mr je mc ms bi translated">参考</h1><ul class=""><li id="db6b" class="ko kp hi ju b jv md jy me kb nz kf oa kj ob kn kt ku kv kw bi translated"><a class="ae mt" href="https://spark.apache.org/docs/latest/running-on-kubernetes.html#:~:text=Spark%20can%20run%20on%20clusters,configuration%2C%20container%20images%20and%20entrypoints." rel="noopener ugc nofollow" target="_blank">在Kubernetes官方Spark文档上运行Spark</a></li><li id="3308" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated">在AKS上运行Apache Spark作业。微软官方文档</li><li id="5057" class="ko kp hi ju b jv kx jy ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae mt" href="https://tech.olx.com/running-spark-on-kubernetes-a-fully-functional-example-and-why-it-makes-sense-for-olx-d56b6a61fcbe" rel="noopener ugc nofollow" target="_blank">Ola使用类似方法进行数据分析的使用案例</a></li></ul></div></div>    
</body>
</html>