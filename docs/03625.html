<html>
<head>
<title>Text Feature Extraction (1/3): Bag of Words Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本特征提取(1/3):单词袋模型</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/text-feature-extraction-1-3-bag-of-words-model-649dbeeade79?source=collection_archive---------7-----------------------#2021-06-12">https://medium.com/geekculture/text-feature-extraction-1-3-bag-of-words-model-649dbeeade79?source=collection_archive---------7-----------------------#2021-06-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/61cab80d457efab17cda09216647c416.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WzCFZFmO3yo1-Ecf3Xzgtw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx"><a class="ae iu" href="https://unsplash.com/s/photos/cafe-study" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="862f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi jt translated"><span class="l ju jv jw bm jx jy jz ka kb di">在</span>任何机器学习模型中，特征都起着主要作用。只有当特征是数字时，训练模型才是可能的。因此，我们有各种技术将分类编码成数字，如标签编码、一键编码、散列等。同样，在NLP中，基于文本的模型也需要使用各种特征提取技术(如单词袋(BOW)、TF-IDF或单词嵌入)来获得数字特征。</p><p id="3d76" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个博客系列将解释如何使用BOW、TFIDF和单词嵌入获得基于文本的数字特征。我们将在这个博客中讨论弓模型。BOW技术是最基本的特征提取和最早的方法。最容易理解和实现。那么，我们开始吧。</p><h2 id="b5cd" class="kc kd hi bd ke kf kg kh ki kj kk kl km jg kn ko kp jk kq kr ks jo kt ku kv kw bi translated">直觉</h2><p id="c767" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">在自然语言处理中，文档的集合称为语料库，而标记(词)的集合称为文档。这意味着具有相似单词的文档应该是相似的。</p><h2 id="7cfc" class="kc kd hi bd ke kf kg kh ki kj kk kl km jg kn ko kp jk kq kr ks jo kt ku kv kw bi translated">理论与概念</h2><ul class=""><li id="56c7" class="lc ld hi ix b iy kx jc ky jg le jk lf jo lg js lh li lj lk bi translated">单词包是一种将<strong class="ix hj">文本数据转换成数字向量</strong>作为特征的特征提取方法</li><li id="3ae6" class="lc ld hi ix b iy ll jc lm jg ln jk lo jo lp js lh li lj lk bi translated">这些数字是文档中每个单词(标记)的计数</li><li id="09aa" class="lc ld hi ix b iy ll jc lm jg ln jk lo jo lp js lh li lj lk bi translated">生成类型为<em class="lq"> scipy.sparse.csr.matrix </em>的<strong class="ix hj">稀疏矩阵</strong>(大部分为0)</li><li id="035f" class="lc ld hi ix b iy ll jc lm jg ln jk lo jo lp js lh li lj lk bi translated"><a class="ae iu" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank">下面的CountVectorizer() </a>提供了某些参数，这些参数能够执行数据预处理，如停止字、令牌模式、lower等。它在令牌大小上是灵活的，因为默认的ngram_range表示1个单词，但它可以根据使用情况进行更改。</li></ul><blockquote class="lr ls lt"><p id="8f20" class="iv iw lq ix b iy iz ja jb jc jd je jf lu jh ji jj lv jl jm jn lw jp jq jr js hb bi translated"><em class="hi"> class </em> <code class="du lx ly lz ma b">sklearn.feature_extraction.text.<strong class="ix hj">CountVectorizer</strong></code> ( <em class="hi"> * </em>，<em class="hi"> input='content' </em>，<em class="hi"> encoding='utf-8' </em>，<em class="hi"> decode_error='strict' </em>，<em class="hi"> strip_accents=None </em>，<em class="hi"> lowercase=True </em>，<em class="hi">预处理程序=None </em>，<em class="hi"> tokenizer=None </em>，<em class="hi"> stop_wordsu)\b\w\w+\b' </em>，<em class="hi"> ngram_range=(1 </em>，<em class="hi"> 1) </em>，<em class="hi"> analyzer='word' </em>，<em class="hi"> max_df=1.0 </em>，<em class="hi"> min_df=1 </em>，<em class="hi"> max_features=None </em>，<em class="hi"> vocabulary=None </em>，<em class="hi"> binary=False </em>，<em class="hi"/></p></blockquote><h2 id="275c" class="kc kd hi bd ke kf kg kh ki kj kk kl km jg kn ko kp jk kq kr ks jo kt ku kv kw bi translated">过程</h2><p id="13d4" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">让我们切入正题，研究一下建立单词袋模型的步骤。<br/> <strong class="ix hj"> <em class="lq">正文:</em> </strong>我是沙池，我是学习者</p><ol class=""><li id="32e2" class="lc ld hi ix b iy iz jc jd jg mb jk mc jo md js me li lj lk bi translated">文本被<strong class="ix hj">标记化</strong> <br/>“我”、“我”、“我”、“沙池”、“和”、“我”、“我”、“我”、“leaner”</li><li id="0da4" class="lc ld hi ix b iy ll jc lm jg ln jk lo jo lp js me li lj lk bi translated">找出独特的单词，构建一个<strong class="ix hj">词汇</strong> <br/>【我】【am】【沙池】【和】【学习者】</li><li id="116c" class="lc ld hi ix b iy ll jc lm jg ln jk lo jo lp js me li lj lk bi translated">通过一键编码将记号转换成数字向量，并<strong class="ix hj">计数每个词汇单词<br/></strong>{“I”:2，“am”:2，“沙池”:1，“and”:1，“学习者”:1}</li></ol><h2 id="44db" class="kc kd hi bd ke kf kg kh ki kj kk kl km jg kn ko kp jk kq kr ks jo kt ku kv kw bi translated">履行</h2><p id="017d" class="pw-post-body-paragraph iv iw hi ix b iy kx ja jb jc ky je jf jg kz ji jj jk la jm jn jo lb jq jr js hb bi translated">为了理解BOW模型，让我们先来看看如何手动实现，然后will for Sklearn实现。</p><ol class=""><li id="83d3" class="lc ld hi ix b iy iz jc jd jg mb jk mc jo md js me li lj lk bi translated"><strong class="ix hj">手动</strong></li></ol><ul class=""><li id="39a5" class="lc ld hi ix b iy iz jc jd jg mb jk mc jo md js lh li lj lk bi translated">让我们创建我们的句子语料库，并将它们转换成小写，以便不区分“this”和“This”。</li></ul><pre class="mf mg mh mi fd mj ma mk ml aw mm bi"><span id="2bec" class="kc kd hi ma b fi mn mo l mp mq">doc = ["This is a good city",<br/>      "You are good human",<br/>      "This is worth fight for your own worth"]<br/>#Convert into lowercase<br/>doc = list(map(str.lower, doc))</span></pre><ul class=""><li id="0536" class="lc ld hi ix b iy iz jc jd jg mb jk mc jo md js lh li lj lk bi translated">标记并创建一个识别独特单词的词汇表。<br/>为词汇设置索引</li></ul><pre class="mf mg mh mi fd mj ma mk ml aw mm bi"><span id="24ed" class="kc kd hi ma b fi mn mo l mp mq">unique_words = set((doc[0] + ' '+ doc[1] +' '+ doc[2]).split())<br/>index_dict = {}<br/>for ind, i in enumerate(sorted(unique_words)):<br/>    index_dict[i] = ind<br/>"""<br/>{'a': 0,<br/> 'are': 1,<br/> 'city': 2,<br/> 'fight': 3,<br/> 'for': 4,<br/> 'good': 5,<br/> 'human': 6,<br/> 'is': 7,<br/> 'own': 8,<br/> 'this': 9,<br/> 'worth': 10,<br/> 'you': 11,<br/> 'your': 12}<br/>"""</span></pre><ul class=""><li id="c6f4" class="lc ld hi ix b iy iz jc jd jg mb jk mc jo md js lh li lj lk bi translated">创建一个稀疏矩阵<br/>——遍历语料库中的每个文档(句子)。获取它的字数。<br/> -创建一个稀疏矩阵，为行、列和值创建变量。<br/> —获取与语料库相关的“行”数据<br/> —获取“列”数据作为与index_dict相关的索引<br/> —获取“值”数据作为与count_dict相关的计数</li></ul><pre class="mf mg mh mi fd mj ma mk ml aw mm bi"><span id="e214" class="kc kd hi ma b fi mn mo l mp mq">from scipy.sparse import csr_matrix</span><span id="e4de" class="kc kd hi ma b fi mr mo l mp mq">row,col,val = [],[],[]<br/>for idx, text in enumerate(doc):<br/>    count_dict = {}<br/>    tokens = text.split()<br/>    # Get count of each word in sentence<br/>    for word in tokens:        <br/>        count_dict[word] = tokens.count(word)   <br/>    <br/>    for word, count in count_dict.items():<br/>        ind = index_dict[word]        <br/>        row.append(idx)<br/>        col.append(ind)<br/>        val.append(count)<br/>print((csr_matrix((val, (row, col)),shape = (len(doc),len(index_dict)))).toarray())</span><span id="3be0" class="kc kd hi ma b fi mr mo l mp mq">"""<br/>[[1 0 1 0 0 1 0 1 0 1 0 0 0]<br/> [0 1 0 0 0 1 1 0 0 0 0 1 0]<br/> [0 0 0 1 1 0 0 1 1 1 2 0 1]]<br/>"""</span></pre><p id="b8d7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 2。上面的步骤只用两行代码就可以完成。Scikit-learn提供了一个名为Count Vectorizer的库，需要在语料库上进行拟合和转换。</strong></p><pre class="mf mg mh mi fd mj ma mk ml aw mm bi"><span id="645a" class="kc kd hi ma b fi mn mo l mp mq">cv = CountVectorizer(token_pattern=r"(?u)\b\w+\b")<br/>count_occurrences = cv.fit_transform(doc)<br/>count_occurrences.toarray()<br/>"""<br/>array([[1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0],<br/>       [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0],<br/>       [0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 2, 0, 1]], dtype=int64)<br/>"""</span></pre><h2 id="fafc" class="kc kd hi bd ke kf kg kh ki kj kk kl km jg kn ko kp jk kq kr ks jo kt ku kv kw bi translated">缺点</h2><ul class=""><li id="d788" class="lc ld hi ix b iy kx jc ky jg le jk lf jo lg js lh li lj lk bi translated"><strong class="ix hj">语义</strong>:因为只考虑字数，所以有语义、结构或语法意义</li><li id="beb2" class="lc ld hi ix b iy ll jc lm jg ln jk lo jo lp js lh li lj lk bi translated"><strong class="ix hj">稀疏矩阵</strong> : BOW产生一个稀疏矩阵(大部分是0)。任何稀疏模型都很难建模，因为它需要大量的内存和计算资源。</li></ul><p id="ecfb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了克服上述缺点，引入了TF-IDF特征提取方法，这是文本特征提取系列的下一部分。</p><p id="2682" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">看看我的</strong><a class="ae iu" href="https://github.com/shachi01/NLP/blob/main/BagOfWords_Scratch_Sklearn.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj">GitHub repo</strong></a><strong class="ix hj">总结了这里演示的所有代码。</strong></p><p id="cbef" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">此外，您还可以通过本</strong> <a class="ae iu" href="https://github.com/shachi01/NLP/blob/main/BagOfWords_MovieReviews.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> GitHub资源库</strong> </a> <strong class="ix hj">了解更多关于如何开发一个词袋模型来预测电影评论情绪的信息。</strong></p></div><div class="ab cl ms mt gp mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="hb hc hd he hf"><p id="0e8a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你喜欢这位作者的博客，请随意关注，因为这位作者向你保证会带来更多有趣的人工智能相关的东西。<br/> 谢谢，<br/>学习愉快！😄</p><p id="78fc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="lq">可以通过</em></strong><a class="ae iu" href="https://www.linkedin.com/in/kaul-shachi" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj"><em class="lq">LinkedIn</em></strong></a><strong class="ix hj"><em class="lq">取得联系。</em> </strong></p></div></div>    
</body>
</html>