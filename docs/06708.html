<html>
<head>
<title>Linear Regression in PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch中的线性回归</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/linear-regression-in-pytorch-262a4b7ed610?source=collection_archive---------25-----------------------#2021-08-26">https://medium.com/geekculture/linear-regression-in-pytorch-262a4b7ed610?source=collection_archive---------25-----------------------#2021-08-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/0eed74c31c796f52f01d4a562d74a187.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lgqVwWH8b-knCWyjsbJ-1w.jpeg"/></div></div></figure><h1 id="4195" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">免责声明</strong></h1><p id="9ba0" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">如果你正在寻找对机器学习基础或线性回归如何工作的深入解释，那么恐怕这篇文章不适合你。本文将深入探讨线性回归的实现，以及我们的模型在真实数据集上的表现。如果你确实想自己学习这些概念，在文章的底部，我们附上了几个来自可靠资源的链接以供参考。</p></div><div class="ab cl km kn gp ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="hb hc hd he hf"><h1 id="4451" class="iq ir hi bd is it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn bi translated">前提</h1><p id="ad92" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">机器学习不再是为最聪明的计算机科学家保留的精英领域。我们生活在一个任何背景的人都可以轻松实现机器学习模型的时代。然而，虽然这种进步对社区来说是巨大的，但对我和许多其他人来说，有一种可定制性的深刻渴望，这是sci-kit learn等机器学习库无法满足的。他们给出的分类器虽然是顶级的，但并没有授予我们许多人在训练模型时渴望的深度个性化，也不允许在GPU上训练模型。正因为如此，我们决定远离Sci-Kit Learn，转而选择一个能给我们带来渴望已久的<br/>开放性的图书馆。PyTorch是这个库，它为我们预先构建了许多复杂的工作，同时在实现M.L .算法时给我们留下了我们想要的自由。第一种算法是线性回归。</p><h1 id="2829" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">线性回归模型</h1><p id="8523" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">Pytorch是一个深度学习框架，因此具有易于使用和健壮的模型制作系统。我们利用这个系统的易用性，简单地改变它，使我们的线性回归模型，而不是神经网络。</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lc ld l"/></div><figcaption class="le lf et er es lg lh bd b be z dx">The Linear Model</figcaption></figure><p id="54ea" class="pw-post-body-paragraph jo jp hi jq b jr li jt ju jv lj jx jy jz lk kb kc kd ll kf kg kh lm kj kk kl hb bi translated">在初始化中，我们不使用任何类型的层，而是使用常规张量作为权重参数，在向前传递中，我们只使用参数和输入要素进行矩阵乘法。</p><h1 id="d189" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">数据集</h1><p id="603e" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">线性回归模型准备就绪后，就该在数据集上试验该模型了。我们选择的数据集是卡德霍数据集，具体来说是它的第三个版本。这些数据从一开始就没有准备好使用，因此需要一些数据清理和扩充。</p><p id="4459" class="pw-post-body-paragraph jo jp hi jq b jr li jt ju jv lj jx jy jz lk kb kc kd ll kf kg kh lm kj kk kl hb bi translated">列“里程”、“发动机”、“最大功率”都包含需要转换成浮点值的字符串值。为了实现这一点，删除了单位字符串，必要时将数据转换为标准单位，所有空值行也随着扭矩列一起删除。</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lc ld l"/></div></figure><p id="cb0c" class="pw-post-body-paragraph jo jp hi jq b jr li jt ju jv lj jx jy jz lk kb kc kd ll kf kg kh lm kj kk kl hb bi translated">接下来，其值为字符串的列被转换为分类列，这使得转换为数字数据更加容易。</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lc ld l"/></div></figure><p id="b717" class="pw-post-body-paragraph jo jp hi jq b jr li jt ju jv lj jx jy jz lk kb kc kd ll kf kg kh lm kj kk kl hb bi translated">从那里，基于数据的特征矩阵进行分析。从中我们可以看出，姓名和座位这两列与其他数据几乎没有关联。因此这些列被删除。数据看起来是这样的。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/b078da9c21835c4791792c9413f55e50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/0*3lxL83ig8KukaRfC"/></div></figure><p id="67f0" class="pw-post-body-paragraph jo jp hi jq b jr li jt ju jv lj jx jy jz lk kb kc kd ll kf kg kh lm kj kk kl hb bi translated">进一步分析数据后，很明显，许多色谱柱在不同的尺寸和规模下运行。为了解决爆炸梯度的问题，对相应的柱进行了归一化。为了标准化数据，我们使用了对数标度，因为我们的数据非常密集。结果数据看起来如此。</p><figure class="ky kz la lb fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/2ee6be769681b3fe8d06554046f62722.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/0*XmSaRTOMr0DTxpQ2"/></div></figure><h1 id="138c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">训练模型</h1><p id="60eb" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">为了训练模型，我们遵循基本PyTorch结构。</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lc ld l"/></div></figure><p id="3f4a" class="pw-post-body-paragraph jo jp hi jq b jr li jt ju jv lj jx jy jz lk kb kc kd ll kf kg kh lm kj kk kl hb bi translated">我们选择的损失函数是均方误差，大多数训练的优化器是随机梯度下降，但是我们也添加了使用Adam优化器的功能。</p><h1 id="c9c3" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">测试模型</h1><p id="6612" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">为了测试该模型，我们遵循了训练该模型的相同结构，但是确保从不调用反向传播。我们还有一个更强大的误差系统来衡量我们模型的准确性。误差函数如下图所示。</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lc ld l"/></div></figure><p id="b714" class="pw-post-body-paragraph jo jp hi jq b jr li jt ju jv lj jx jy jz lk kb kc kd ll kf kg kh lm kj kk kl hb bi translated">它返回均方误差、平均绝对误差、均方根误差和决定系数。</p><h1 id="7c57" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">超参数</h1><p id="bb30" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在训练模型时，调整了几个超参数以获得最佳模型。在我们的例子中，我们将模型的动量设置为0.09，并将学习率设置为0.001。我们决定在每个训练实例中随机化权重，而不是从0开始。我们为250个时期训练模型，批次大小为64。</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lc ld l"/></div></figure><h1 id="87b3" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">比较指标</h1><p id="bbc0" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">为了看看我们的模型是否真的有什么技巧，我们将它与其他几个度量标准和模型进行了比较。第一个模型是一个天真的模型。天真的模型总是在每次预测中使用平均汽车价格。如果我们的模型做得比这更好，那么我们知道这不仅仅是猜测。我们使用的第二个比较度量是查看正常方程权重和训练参数权重之间的余弦距离。法线方程是一个特殊的公式，仅用于线性回归，它为拟合数据的直线找到最佳参数。如果正常方程权重和训练权重之间的距离很小，我们知道我们的模型尽可能做得好。</p><h1 id="e094" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结果</h1><p id="f3ab" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">那么模型表现如何呢？从结果来看还不错！</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/60b21fe04aab2f5626eaf62d90b939d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MqY4ib-nG0F8FYGo"/></div></div></figure><p id="9e0b" class="pw-post-body-paragraph jo jp hi jq b jr li jt ju jv lj jx jy jz lk kb kc kd ll kf kg kh lm kj kk kl hb bi translated">它达到了相当高的r，非常接近正常的方程权重。</p><h1 id="fd03" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结束语</h1><p id="a6e9" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">最后，我们的模型做得很好。这绝不是线性回归的最佳实现，它只是一个基本实现，其目的是表明我们的线性回归算法是可行的。其他模型可能会做得更好，通过对此模型进行更好的调整，您可能会获得更好的结果。如果您发现我的代码有任何错误，找到更好的方法来实现代码，或者获得比我更好的结果，请随时告诉我。我很想听听这件事！我们使用PyTorch实现的下一个模型将是逻辑回归，请密切关注。</p><h1 id="0274" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">科布拉姆尔</h1><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/6b3e2c5746855940208c26786c5d905d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HtaKLWNlMFzH8MYD1mWFBg.png"/></div></div></figure><p id="bc0e" class="pw-post-body-paragraph jo jp hi jq b jr li jt ju jv lj jx jy jz lk kb kc kd ll kf kg kh lm kj kk kl hb bi translated">CobraML是一个开源的ML库，它在PyTorch中实现了机器学习算法，为最终用户提供了更多的可定制性以及GPU功能。如果你对这个图书馆感兴趣，请填写这张表格。</p><figure class="ky kz la lb fd ij"><div class="bz dy l di"><div class="lr ld l"/></div></figure><h1 id="14dc" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">资源</h1><p id="614a" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">查看这些令人敬畏的资源，不要羞于给CobraML一颗星，并连接到我们的LinkedIn</p><h2 id="5824" class="ls ir hi bd is lt lu lv iw lw lx ly ja jz lz ma je kd mb mc ji kh md me jm mf bi translated">资料组</h2><ul class=""><li id="cf83" class="mg mh hi jq b jr js jv jw jz mi kd mj kh mk kl ml mm mn mo bi translated"><a class="ae mp" href="https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/nehalbirla/vehicle-dataset-from-cardek ho</a></li></ul><h2 id="a128" class="ls ir hi bd is lt lu lv iw lw lx ly ja jz lz ma je kd mb mc ji kh md me jm mf bi translated">标准化资源</h2><ul class=""><li id="89b5" class="mg mh hi jq b jr js jv jw jz mi kd mj kh mk kl ml mm mn mo bi translated"><a class="ae mp" href="https://developers.google.com/machine-learning/data-prep/transform/normalization" rel="noopener ugc nofollow" target="_blank">https://developers . Google . com/machine-learning/data-prep/transform/normalization</a></li></ul><h2 id="3124" class="ls ir hi bd is lt lu lv iw lw lx ly ja jz lz ma je kd mb mc ji kh md me jm mf bi translated">ML教程，以便更好地理解</h2><ul class=""><li id="368c" class="mg mh hi jq b jr js jv jw jz mi kd mj kh mk kl ml mm mn mo bi translated">https://www.youtube.com/watch?v=kHwlB_j7Hkc&amp;list = pllsst 5 z _ DsK-H9 vyzkqkynwcitqhlrjln&amp;index = 5</li></ul><h2 id="b87f" class="ls ir hi bd is lt lu lv iw lw lx ly ja jz lz ma je kd mb mc ji kh md me jm mf bi translated">准确度测量</h2><ul class=""><li id="df70" class="mg mh hi jq b jr js jv jw jz mi kd mj kh mk kl ml mm mn mo bi translated"><a class="ae mp" href="https://machinelearningmastery.com/regression-metrics-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/regression-metrics-for-machine-learning/</a></li></ul><h2 id="5992" class="ls ir hi bd is lt lu lv iw lw lx ly ja jz lz ma je kd mb mc ji kh md me jm mf bi translated">CobraML GitHub(这也是本文中使用的相同代码，请查看分支算法-测试)</h2><ul class=""><li id="5746" class="mg mh hi jq b jr js jv jw jz mi kd mj kh mk kl ml mm mn mo bi translated"><a class="ae mp" href="https://github.com/govindansriram/CobraML" rel="noopener ugc nofollow" target="_blank">https://github.com/govindansriram/CobraML</a></li></ul><h2 id="c5da" class="ls ir hi bd is lt lu lv iw lw lx ly ja jz lz ma je kd mb mc ji kh md me jm mf bi translated">作者的LinkedIn</h2><ul class=""><li id="cd88" class="mg mh hi jq b jr js jv jw jz mi kd mj kh mk kl ml mm mn mo bi translated"><a class="ae mp" href="https://www.linkedin.com/in/saatvik-anumalasetty-8214b8167/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/saatvik-anumalasetty-8214b8167/</a></li><li id="2fc7" class="mg mh hi jq b jr mq jv mr jz ms kd mt kh mu kl ml mm mn mo bi translated"><a class="ae mp" href="https://www.linkedin.com/in/sriram-govindan/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/sriram-govindan/</a></li></ul></div></div>    
</body>
</html>