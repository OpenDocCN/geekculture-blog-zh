<html>
<head>
<title>NLP: Building a Basic “Automated Text Filler”- An Introduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP:构建一个基本的“自动文本填充器”——介绍</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/nlp-building-a-basic-automated-text-filler-an-introduction-d560ac2b5cdf?source=collection_archive---------31-----------------------#2021-08-31">https://medium.com/geekculture/nlp-building-a-basic-automated-text-filler-an-introduction-d560ac2b5cdf?source=collection_archive---------31-----------------------#2021-08-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/525ff2ead0a6c4e13e64e5ca9d28e2d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BR1RwH4jQNG9R_Hh_BcO_g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">SOURCE: <a class="ae iu" href="https://morioh.com/p/8bb5b207c3b9" rel="noopener ugc nofollow" target="_blank">Morioh (Website)</a></figcaption></figure><p id="0fe9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">自动文本填充器是一个非常受欢迎的自然语言处理应用，智能手机键盘和谷歌等公司使用它来预测或建议用户将输入的下一个单词/短语来完成一个句子。单词预测有广泛的应用:</p><ol class=""><li id="0cac" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">像谷歌搜索、Youtube这样的应用程序使用单词预测来推荐热门搜索，这启发了用户，也节省了时间。</li><li id="86ea" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">Gmail和Grammarly使用单词预测来纠正语法错误，并建议同义词，这有助于用户在撰写电子邮件和文章时更加专业和富有表现力。</li><li id="0b6d" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">Instagram、Twitter、LinkedIn等应用程序使用单词预测来建议标签，帮助提高用户帖子的可见性。</li></ol><p id="796c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">可能的应用点的列表是无穷无尽的，虽然可以使用长期短期记忆(LSTM)等深度学习算法来建立复杂的模型，但在本教程中，我们将使用<strong class="ix hj"> N-Grams +马尔可夫链</strong>方法来建立一个基本的下一个单词预测模型。</p><h1 id="13ff" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">什么是N-gram？</h1><blockquote class="lf lg lh"><p id="924f" class="iv iw li ix b iy iz ja jb jc jd je jf lj jh ji jj lk jl jm jn ll jp jq jr js hb bi translated">n元语法是来自给定文本或语音序列的n个项目的连续序列。——【Definitions.net T4】</p></blockquote><p id="18c8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">n-gram是你可以在源文本中找到的长度为<strong class="ix hj"> <em class="li"> n </em> </strong>的相邻单词或字母的组合。例如，给出这样一句话:</p><blockquote class="lf lg lh"><p id="12a1" class="iv iw li ix b iy iz ja jb jc jd je jf lj jh ji jj lk jl jm jn ll jp jq jr js hb bi translated">“祝你生日快乐，无名氏”。</p></blockquote><p id="61d9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这句话的2个字母是:</p><blockquote class="lf lg lh"><p id="e971" class="iv iw li ix b iy iz ja jb jc jd je jf lj jh ji jj lk jl jm jn ll jp jq jr js hb bi translated">“<strong class="ix hj">祝你</strong>”、“<strong class="ix hj">生日快乐</strong>”、<strong class="ix hj">“无名氏</strong>”。</p></blockquote><p id="22c7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这句话的三个字母是:</p><blockquote class="lf lg lh"><p id="be92" class="iv iw li ix b iy iz ja jb jc jd je jf lj jh ji jj lk jl jm jn ll jp jq jr js hb bi translated">”<strong class="ix hj">祝你快乐</strong>“<strong class="ix hj">生日无名氏</strong>”。</p></blockquote><p id="94e4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在本教程中，我们将使用三元模型构建一个基本的马尔可夫预测模型，三元模型将从1960年10月1日<strong class="ix hj">尼日利亚第一任总理哈吉·阿布巴卡尔·塔法瓦·巴勒瓦爵士的演讲中生成。</strong></p><h1 id="41b6" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">马尔可夫链概述</h1><p id="7d4a" class="pw-post-body-paragraph iv iw hi ix b iy lm ja jb jc ln je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">马尔可夫链是一个数学系统，它根据某些概率规则经历从一种状态到另一种状态的转换。它是描述一系列可能事件的随机模型，其中每个事件的概率仅取决于前一个事件达到的状态。— <a class="ae iu" href="https://en.wikipedia.org/wiki/Markov_chain#:~:text=A%20Markov%20chain%20is%20a,time%20Markov%20chain%20(DTMC)." rel="noopener ugc nofollow" target="_blank">维基百科</a></p><p id="7e1a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用N-Grams模型，序列中的一个项目(一个单词)可以被视为马尔可夫状态。这意味着一旦我们成功地构建了模型，我们将能够根据之前看到的数据中出现的单词来预测下一个单词。</p><h1 id="5755" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">入门指南</h1><p id="b3f9" class="pw-post-body-paragraph iv iw hi ix b iy lm ja jb jc ln je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">首先，我们导入所有需要的库，并使用漂亮的Soup Python库抓取数据(段落):</p><h2 id="3e02" class="lr ki hi bd kj ls lt lu kn lv lw lx kr jg ly lz kv jk ma mb kz jo mc md ld me bi translated">导入库</h2><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="e746" class="lr ki hi mk b fi mo mp l mq mr">from bs4 import BeautifulSoup<br/>from nltk.util import ngrams<br/>from collections import defaultdict<br/>from nltk import trigrams<br/>from nltk.tokenize import RegexpTokenizer<br/>import requests<br/><br/><em class="li">#load fetch speech text from blog</em><br/>response = requests.get("https://maxsiollun.wordpress.com/great-speeches-in-nigerias-history/")<br/>soup = BeautifulSoup(response.text,'html.parser')<br/>sentence = soup.find_all('p',text=True)<br/>print(sentence[1:3])</span></pre><h2 id="7842" class="lr ki hi bd kj ls lt lu kn lv lw lx kr jg ly lz kv jk ma mb kz jo mc md ld me bi translated">预处理文本</h2><p id="04ce" class="pw-post-body-paragraph iv iw hi ix b iy lm ja jb jc ln je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">下一步是预处理文本并删除不需要的字符。我们需要将文本输入到标记列表中，并删除所有点，这样所有输入三元语法模型的数据都是单词。</p><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="0a7d" class="lr ki hi mk b fi mo mp l mq mr">note=None </span><span id="019e" class="lr ki hi mk b fi ms mp l mq mr"><em class="li">#we will merge the list string values into a single string</em><br/>for line <strong class="mk hj">in</strong> sentence[1:3]:<br/>    note+=str(line)</span><span id="477f" class="lr ki hi mk b fi ms mp l mq mr"><em class="li">#convert text to lower case</em><br/>sentence=note.lower()</span><span id="74c1" class="lr ki hi mk b fi ms mp l mq mr"><em class="li">#convert Sentence into Tokens and extract all punctuations</em><br/>tokenizer = RegexpTokenizer(r'\w+')<br/>tk_sentence=tokenizer.tokenize(sentence)</span></pre><h2 id="fbe0" class="lr ki hi bd kj ls lt lu kn lv lw lx kr jg ly lz kv jk ma mb kz jo mc md ld me bi translated">创建三元模型</h2><p id="5419" class="pw-post-body-paragraph iv iw hi ix b iy lm ja jb jc ln je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">现在我们生成我们的三元模型:</p><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="f456" class="lr ki hi mk b fi mo mp l mq mr">gram_sentence=list(ngrams(tk_sentence, 3))</span></pre><h2 id="41ea" class="lr ki hi bd kj ls lt lu kn lv lw lx kr jg ly lz kv jk ma mb kz jo mc md ld me bi translated">建立模型</h2><p id="c5e2" class="pw-post-body-paragraph iv iw hi ix b iy lm ja jb jc ln je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">最后，我们现在可以使用我们的列表三元组来构建马尔可夫模型。</p><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="8e2e" class="lr ki hi mk b fi mo mp l mq mr"><em class="li"># Create Word Model</em><br/>word_model = defaultdict(lambda: defaultdict(lambda: 0))<br/><br/><br/>for sentence <strong class="mk hj">in</strong> tk_sentence:<br/>    for first_word, second_word, word_label <strong class="mk hj">in </strong>trigrams(tk_sentence,pad_left=True,pad_right=True):<br/>        word_model[(first_word, second_word)][word_label] += 1</span><span id="3d3b" class="lr ki hi mk b fi ms mp l mq mr">dict(word_model)</span></pre><p id="29b0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你想自己尝试或者查看模型的结果，可以查看我的<a class="ae iu" href="https://www.kaggle.com/nnitiwe/nlp-predicting-next-word" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> Kaggle笔记本</strong> </a>上的完整代码。</p><p id="33df" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于这个特定的预测，列出的单词集的概率得分是<strong class="ix hj"> <em class="li"> 0.33 </em> </strong>。然而，在得分大小不同的情况下，具有较高大小的得分是最优选的预测。</p><figure class="mf mg mh mi fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mt"><img src="../Images/7e6ee75b3be132e68248ffeff57756a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N7ksPJHDPdKlIzPKp6FOxQ.png"/></div></div></figure><p id="933f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你觉得这个教程有帮助，比如👏🏻👏🏻更多内容请关注我。</p></div></div>    
</body>
</html>