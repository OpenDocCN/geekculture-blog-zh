<html>
<head>
<title>Multi-armed Bandits Part II: What is Upper Confidence Bound (UCB) Algorithm?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多武装匪徒第二部分:什么是置信上限(UCB)算法？</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/multi-armed-bandits-what-is-upper-confidence-bound-ucb-algorithm-d72add30ee78?source=collection_archive---------27-----------------------#2021-07-29">https://medium.com/geekculture/multi-armed-bandits-what-is-upper-confidence-bound-ucb-algorithm-d72add30ee78?source=collection_archive---------27-----------------------#2021-07-29</a></blockquote><div><div class="ds hc hd he hf hg"/><div class="hh hi hj hk hl"><div class=""/><figure class="ev ex im in io ip er es paragraph-image"><div role="button" tabindex="0" class="iq ir di is bf it"><div class="er es il"><img src="../Images/9853c00dc54e8e47e023903cdc37fd97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bIcdx-oQPuq3IUwOG17g2A.png"/></div></div></figure><p id="f081" class="pw-post-body-paragraph iw ix ho iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hh bi translated">在<a class="ae ju" rel="noopener" href="/@thomaszyang/multi-armed-bandits-an-example-to-help-understand-reinforcement-learning-614e9e262919">第1部分:多臂强盗:一个介绍强化学习的例子</a>中，我们可以获得一些关于探索的高层次理解——开发有助于多臂代理获得最大回报。</p></div></div>    
</body>
</html>