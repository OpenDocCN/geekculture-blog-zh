<html>
<head>
<title>Steel Defect Detection — Image Segmentation using TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">钢铁缺陷检测——张量流图像分割</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/steel-defect-detection-image-segmentation-using-tensorflow-74e66c4279ca?source=collection_archive---------9-----------------------#2021-04-16">https://medium.com/geekculture/steel-defect-detection-image-segmentation-using-tensorflow-74e66c4279ca?source=collection_archive---------9-----------------------#2021-04-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/4ccd17d6a6ce7e8db2d4b984a776424e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xIs4-Ve3wSTbYq8m"/></div></div><figcaption class="iq ir et er es is it bd b be z dx"><a class="ae iu" href="https://www.kaggle.com/c/severstal-steel-defect-detection" rel="noopener ugc nofollow" target="_blank">Severstal: Steel Defect Detection</a></figcaption></figure><h1 id="145a" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">商业问题</h1><blockquote class="jt ju jv"><p id="3a40" class="jw jx jy jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku hb bi translated"><a class="ae iu" href="https://www.kaggle.com/c/severstal-steel-defect-detection" rel="noopener ugc nofollow" target="_blank">钢铁缺陷检测</a>是由最大的钢铁制造公司之一<a class="ae iu" href="https://www.severstal.com/eng/" rel="noopener ugc nofollow" target="_blank">谢韦尔钢铁公司</a>在Kaggle举办的竞赛。因为平板钢板的生产过程包括许多子过程，在这些子过程中，平板钢板在准备装运之前必须接触几台机器。因此，谢韦尔钢铁公司正在使用来自高频摄像头的图像来驱动缺陷检测算法。通过这次比赛，谢韦尔钢铁公司希望参赛者通过对钢板表面缺陷进行定位和分类来改进算法。</p><p id="e4df" class="jw jx jy jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku hb bi translated">本次比赛的目的是使用提供的图像预测钢铁制造中发现的缺陷的位置和类型。</p></blockquote><h1 id="29db" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">数据集详细信息</h1><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="b3a9" class="le iw hi la b fi lf lg l lh li">-Data<br/>  |- sample_submission.csv<br/>  |- train.csv<br/>  |- test_images/<br/>        |- 5506 nos. of .jpg files<br/>  |- train_images/<br/>        |- 12568 nos. of .jpg files</span></pre><blockquote class="jt ju jv"><p id="644e" class="jw jx jy jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku hb bi translated">为18074张(12568张训练图像和5506张测试图像)图像提供唯一的图像ID。每个图像可以没有缺陷、单一种类的缺陷或多种类的缺陷。有四类缺陷。</p><p id="a3d8" class="jw jx jy jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku hb bi translated">除了train和test images文件夹，还提供了train.csv，其中包含关于缺陷类型及其各自在train images中的位置的信息。train.csv的这些数据点(7095个)给出了缺陷图像的详细信息(6666个唯一id)。</p><p id="7c39" class="jw jx jy jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku hb bi translated">train.csv的3列是ImageId、ClassId和EncodedPixels:</p><p id="d901" class="jw jx jy jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku hb bi translated">i. ImageId:每个图像的唯一Id。</p><p id="140b" class="jw jx jy jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku hb bi translated">二。ClassId:图像在EncodedPixels列中提到的像素位置上的缺陷的类型/类别Id。</p><p id="8d00" class="jw jx jy jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku hb bi translated">三。EncodedPixels:该列给出了图像中缺陷的像素位置信息。缺陷像素位置列表被编码成值对列表(每对的第一个值代表起始位置，第二个值代表其游程长度)以减小文件大小。你可以在这里了解更多关于<a class="ae iu" href="https://www.kaggle.com/c/severstal-steel-defect-detection/overview/evaluation" rel="noopener ugc nofollow" target="_blank">的信息。</a></p><p id="5776" class="jw jx jy jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku hb bi translated">train.csv前几行的快照视图:</p></blockquote><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="e426" class="le iw hi la b fi lf lg l lh li">ImageId,ClassId,EncodedPixels<br/>0002cc93b.jpg,1,29102 12 29346 24 29602 24 ....... 192843 23 193099 14 193355 5<br/>0007a71bf.jpg,3,18661 28 18863 82 19091 110 ..... 298245 251 298564 188 298945 63<br/>000a4bcdd.jpg,1,37607 3 37858 8 38108 14 38359 20 ..... 117576 27 117843 16 118109 6<br/>000f6bf48.jpg,4,131973 1 132228 4 132483 6 132738 8 .... 289263 2 289519 2 289776 1</span></pre><h1 id="c859" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">将现实世界的问题映射到ML问题</h1><p id="3893" class="pw-post-body-paragraph jw jx hi jz b ka lj kc kd ke lk kg kh ll lm kk kl ln lo ko kp lp lq ks kt ku hb bi translated">这是一个图像分割问题，对于给定的图像，我们需要检测和定位钢板中的缺陷。</p><p id="9d9c" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">这场比赛是根据平均<a class="ae iu" href="https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient" rel="noopener ugc nofollow" target="_blank">骰子系数</a>来评估的。Dice系数可用于比较预测的分割与其对应的基本事实之间的逐像素一致性。该公式由下式给出:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/40aa29939d942be30f29706ec40741e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:230/format:webp/1*Vj04Xt3UzSoiBdYUKt9dnA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">Dice Coefficient Formulation</figcaption></figure><p id="7f7c" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">其中X是预测的像素组，Y是地面实况。当X和Y都为空时，Dice系数定义为1。</p><h1 id="c688" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">现有方法</h1><p id="6490" class="pw-post-body-paragraph jw jx hi jz b ka lj kc kd ke lk kg kh ll lm kk kl ln lo ko kp lp lq ks kt ku hb bi translated"><strong class="jz hj">【1】。</strong> <a class="ae iu" rel="noopener" href="/analytics-vidhya/severstal-steel-defect-detection-5e5b50fe21ce"> <strong class="jz hj">建立模型分类预测钢材中的缺陷</strong> </a> <strong class="jz hj"> : </strong></p><ul class=""><li id="b0e9" class="ls lt hi jz b ka kb ke kf ll lu ln lv lp lw ku lx ly lz ma bi translated">用二进制分类器训练全部数据，以对有缺陷和无缺陷的纸张图像进行分类。对于多标签分类器，只有缺陷图像用于训练。这种多标签分类器负责给每幅图像标注其所具有的缺陷类型。为每种缺陷类型训练四个单独的分割模型。标记有缺陷类型的图像被传递到相应的缺陷类型分割模型进行分割。</li><li id="2cff" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku lx ly lz ma bi translated">对于二进制和多标签分类，使用由Keras预先训练的InceptionResNetV2()模型，并且从图像网络数据训练权重。并且使用了来自<a class="ae iu" href="https://github.com/qubvel" rel="noopener ugc nofollow" target="_blank"> quvbel </a> —以resnet34为主干的U-Net的预先训练好的分割模型。</li></ul><p id="2d07" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated"><strong class="jz hj">【2】。</strong> <a class="ae iu" rel="noopener" href="/@guildbilla/steel-defect-detection-image-segmentation-using-keras-dae8b4f986f0"> <strong class="jz hj">钢材缺陷检测:使用Keras进行图像分割</strong> </a> <strong class="jz hj"> : </strong></p><ul class=""><li id="0e9c" class="ls lt hi jz b ka kb ke kf ll lu ln lv lp lw ku lx ly lz ma bi translated">这个解决方案流程类似于[1]。</li><li id="dada" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku lx ly lz ma bi translated">对于二元和多标签分类，使用来自Keras的预训练模型— <a class="ae iu" href="https://keras.io/applications/#xception" rel="noopener ugc nofollow" target="_blank">例外</a>。和U-Net的efficientnetb1主干用于细分模型。</li><li id="0cbc" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku lx ly lz ma bi translated">骰子系数(私分):0.88428。</li></ul><p id="b25d" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated"><strong class="jz hj">【3】。</strong> <a class="ae iu" href="https://towardsdatascience.com/semantic-image-segmentation-using-fully-convolutional-networks-bf0189fa3eb8" rel="noopener" target="_blank"> <strong class="jz hj">利用完全卷积网络进行语义图像分割</strong> </a> <strong class="jz hj"> : </strong></p><ul class=""><li id="f451" class="ls lt hi jz b ka kb ke kf ll lu ln lv lp lw ku lx ly lz ma bi translated">在这个解决方案中，二进制和多标记分类器不像[1]和[2]那样包括在流水线中。数据(作为X的纸张图像和作为Y的对应于4个类别的掩模图像)被直接馈送到仅仅一个分割模型。</li><li id="6dca" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku lx ly lz ma bi translated">尝试了两种细分模型:U-Net &amp; Deeplab V3+。Deeplab V3+表现不错，dice系数(私分)0.83763。</li><li id="5c91" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku lx ly lz ma bi translated">在此解决方案中实现的U-Net模型减少了过滤器的数量，并且用原始图像的一半来训练模型，以减少计算并更快地训练模型。即使在Deeplab V3+架构上也做了一些修改。</li></ul><p id="c088" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated"><strong class="jz hj">【4】。</strong> <a class="ae iu" rel="noopener" href="/@saivenkat_/a-detailed-case-study-on-severstal-steel-defect-detection-can-we-detect-and-classify-defects-in-2844402392cc"> <strong class="jz hj">谢韦尔钢铁(Severstal)详细案例分析:钢铁缺陷检测，能否对钢铁中的缺陷进行检测和分类？—从初级到高级！</strong> </a> <strong class="jz hj"> : </strong></p><ul class=""><li id="708e" class="ls lt hi jz b ka kb ke kf ll lu ln lv lp lw ku lx ly lz ma bi translated">在该解决方案中，流水线流程与[3]相同，即整个数据被送入一个分割模型进行分割。以主干resnet34为分割模型的U-Net导致dice系数(私人得分)为0.90305。</li></ul><p id="00c0" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated"><strong class="jz hj">【5】。</strong> <a class="ae iu" rel="noopener" href="/@gargishan209/detection-of-steel-defects-image-segmentation-using-keras-and-tensorflow-37e8ae8aabe8"> <strong class="jz hj">钢材缺陷检测:使用Keras和Tensorflow进行图像分割</strong> </a> <strong class="jz hj"> : </strong></p><ul class=""><li id="c9ac" class="ls lt hi jz b ka kb ke kf ll lu ln lv lp lw ku lx ly lz ma bi translated">在这个解决方案中，流程管道仅由两个模型组成。一个二元分类器，用于将纸张图像分类为有缺陷/无缺陷类别，一个分割模型用于所有4个缺陷类别。只有有缺陷的纸张图像用于训练分割模型。</li><li id="a7ef" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku lx ly lz ma bi translated">对于二元分类，使用异常模型以及从图像网络数据训练的权重。对于分割模型，使用具有EfficientNetB5主干模型的Unet架构以及从image-net数据训练的权重。</li></ul><h1 id="4ff1" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">电子设计自动化(Electronic Design Automation)</h1><figure class="kv kw kx ky fd ij"><div class="bz dy l di"><div class="mg mh l"/></div></figure><p id="f76e" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">从EDA可以清楚地看出，这些有缺陷的数据点是高度不平衡的。</p><ul class=""><li id="3eab" class="ls lt hi jz b ka kb ke kf ll lu ln lv lp lw ku lx ly lz ma bi translated">大多数数据点(72.6%)属于class id-3。和ClassId-1 &amp; 2的份额几乎相等(分别为12.6%和11.3%)。</li><li id="29ba" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku lx ly lz ma bi translated">ClassId-2的数据点在所有数据点中的份额最低。</li></ul><p id="7778" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated"><strong class="jz hj">显示一些有缺陷的图像:</strong></p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mi"><img src="../Images/60fa86986b6fefbda826c0e885a95987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K0nish7VPwC9JiT-7qRmrA.png"/></div></div></figure><p id="c0f4" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated"><strong class="jz hj">显示一些无缺陷图像:</strong></p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mi"><img src="../Images/f21a2cf1b7a67f8becaafe4acd363905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2RGzIliorKdv3eI1NCSavw.png"/></div></div></figure><p id="3a18" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">看起来，甚至来自非缺陷集(不在train.csv中的ImgaeIds)的一些图像也有缺陷。也许这些缺陷类不在ClassIds，2，3，4]中。</p><h1 id="c194" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">第一次切割溶液</h1><ul class=""><li id="d7bc" class="ls lt hi jz b ka lj ke lk ll mj ln mk lp ml ku lx ly lz ma bi translated">我会尝试单模型管道(4标签分割只有一个分割模型)，如[3] &amp; [4]。</li><li id="e018" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku lx ly lz ma bi translated">考虑到U-Net作为一个基本模型，我也会尝试任何其他可用的架构(LinkNet，FPN和PSPNet)。我还会通过替换这些架构可用主干模型来尝试其他变化。</li><li id="63d1" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku lx ly lz ma bi translated">我也会对训练和测试数据使用数据扩充技术。</li></ul><h1 id="6632" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">数据准备和培训验证分离</h1><p id="a0c9" class="pw-post-body-paragraph jw jx hi jz b ka lj kc kd ke lk kg kh ll lm kk kl ln lo ko kp lp lq ks kt ku hb bi translated">我们对提供的train.csv进行了格式化，以便每一行都包含ImageId及其对应的所有4个缺陷类的掩码编码，如下所示。</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="ecf7" class="le iw hi la b fi lf lg l lh li">╔═══════════════╦══════════════╦═══════╦══════════════╦═══════╗<br/>║    ImageId    ║    rle_1     ║ rle_2 ║    rle_3     ║ rle_4 ║<br/>╠═══════════════╬══════════════╬═══════╬══════════════╬═══════╣<br/>║ 0002cc93b.jpg ║ 29102 12 ... ║       ║              ║       ║<br/>║ 00031f466.jpg ║              ║       ║              ║       ║<br/>║ 0007a71bf.jpg ║              ║       ║ 18661 28 ... ║       ║<br/>╚═══════════════╩══════════════╩═══════╩══════════════╩═══════╝</span></pre><p id="63e2" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">整个数据以85:15的比例随机分割，分别用于训练和验证。</p><h1 id="83e5" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">深度学习模型/架构</h1><h1 id="9ef7" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">1.优信网</h1><p id="07ee" class="pw-post-body-paragraph jw jx hi jz b ka lj kc kd ke lk kg kh ll lm kk kl ln lo ko kp lp lq ks kt ku hb bi translated">这个<a class="ae iu" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> U-Net </a>架构最初是为生物医学图像分割而开发的。这个架构主要包含两条路径:编码器路径&amp;解码器路径。而每一级编码器&amp;解码器之间的连接是这种架构的关键特征。</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/4bdb8781cb7bf773b2bd7be35cf2576c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*amHtJ59LIH7DnLkM-dJR7A.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Architecture: U-Net</figcaption></figure><p id="3c19" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">编码器路径(或收缩路径)是卷积和最大池层的堆栈，有助于捕捉图像中的上下文。解码器路径(或扩展路径)是转置卷积和卷积层，这有助于定位捕获的上下文(在编码器路径中)。</p><p id="04ab" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">通过每一级的编码器和解码器之间的那些连接，传递那些编码器块的输出，并将它们连接到解码器块的输入张量。这有助于重建图像，并使其与图像的原始大小相匹配。</p><p id="fd4d" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">使用<a class="ae iu" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>实现了U-Net架构(参考作品<a class="ae iu" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> U-Net:用于生物医学图像分割的卷积网络</a>)，如下所示:</p><figure class="kv kw kx ky fd ij"><div class="bz dy l di"><div class="mg mh l"/></div></figure><h1 id="53e0" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">2.LinkNet</h1><p id="d063" class="pw-post-body-paragraph jw jx hi jz b ka lj kc kd ke lk kg kh ll lm kk kl ln lo ko kp lp lq ks kt ku hb bi translated">这个<a class="ae iu" href="https://arxiv.org/abs/1707.03718" rel="noopener ugc nofollow" target="_blank"> LinkNet </a>架构几乎和U-Net差不多，只是稍加修改。编码器和解码器路径结构与U-Net中的相同。但是编码器块的输出在通过连接之后被添加(在U-Net的情况下是级联)到解码器块的输入张量。</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/25d7d02d70701eaa3bd2690fd1a55e4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SToEDNyrXpYYTIfTD54RUA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Architecture: LinkNet</figcaption></figure><p id="3678" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">在这里，可训练参数的数量减少了，所以与U-Net相比，LinkNet是一个重量更轻的网络。</p><p id="3598" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">使用<a class="ae iu" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>实现LinkNet架构(参考作品<a class="ae iu" href="https://arxiv.org/abs/1707.03718" rel="noopener ugc nofollow" target="_blank"> LinkNet:利用编码器表示进行高效语义分割</a>),如下所示:</p><figure class="kv kw kx ky fd ij"><div class="bz dy l di"><div class="mg mh l"/></div></figure><h1 id="cdc9" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">3.带有ResNet主干网的U-Net</h1><p id="3c4f" class="pw-post-body-paragraph jw jx hi jz b ka lj kc kd ke lk kg kh ll lm kk kl ln lo ko kp lp lq ks kt ku hb bi translated">在这种架构中，我们将U-Net架构的每个编码器和解码器模块中的简单卷积替换为剩余模块，即在每个模块中添加跳过连接。</p><p id="02b8" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">请参考这篇文章来理解并更好地了解这个架构:<a class="ae iu" rel="noopener" href="/@nishanksingla/unet-with-resblock-for-semantic-segmentation-dd1766b4ff66">使用ResBlock进行语义分段的UNet</a>。</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/a591d9b97293801cf07cd340fa6bb713.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I_3khEWn6t1K9AdMUUEwSQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Architecture: U-Net with ResNet Backbone</figcaption></figure><p id="b4b3" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">实施(使用<a class="ae iu" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>)此架构，将UNet架构中的conv2D_block替换为ResBlock，如下所示:</p><figure class="kv kw kx ky fd ij"><div class="bz dy l di"><div class="mg mh l"/></div></figure><h1 id="e0c8" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">4.带有ResNet主干网的LinkNet</h1><p id="c1e5" class="pw-post-body-paragraph jw jx hi jz b ka lj kc kd ke lk kg kh ll lm kk kl ln lo ko kp lp lq ks kt ku hb bi translated">在这种架构中，我们将LinkNet架构的每个编码器&amp;解码器模块中的简单卷积替换为剩余模块(与ResNet主干的<em class="jy"> U-Net相同),即在每个模块中添加跳过连接。</em></p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/e46e823a3245ea742af0a55661777019.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6uoHODwefbXzZvYEoeYPJw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Architecture: LinkNet with ResNet Backbone</figcaption></figure><p id="16e1" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">通过将LinkNet架构中的conv2D_block替换为ResBlock来实现(使用<a class="ae iu" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>)该架构，如下所示:</p><figure class="kv kw kx ky fd ij"><div class="bz dy l di"><div class="mg mh l"/></div></figure><h1 id="842b" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">5.U-Net++</h1><p id="ff63" class="pw-post-body-paragraph jw jx hi jz b ka lj kc kd ke lk kg kh ll lm kk kl ln lo ko kp lp lq ks kt ku hb bi translated">参考工作<a class="ae iu" href="https://arxiv.org/abs/1807.10165" rel="noopener ugc nofollow" target="_blank"> UNet++:一种用于医学图像分割的嵌套U-Net架构</a>，实现了U-Net++架构。这是一个强大的图像分割架构。</p><p id="d987" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">在这种架构中，我们在编码器路径的每一层生成解码器路径。并且我们在每一层的所有块之间进行跳跃连接。这些有助于减少编码器路径和解码器子路径之间的语义差距。</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/166dd8d7a771f6926f131751083836bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ehjsy9epGg3wCu7uFMaRg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Architecture: UNet++</figcaption></figure><p id="0815" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">使用<a class="ae iu" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>实现了U-Net++架构，如下所示:</p><figure class="kv kw kx ky fd ij"><div class="bz dy l di"><div class="mg mh l"/></div></figure><p id="01bd" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">使用这些编译配置对上述每个模型进行60个时期的训练:</p><pre class="kv kw kx ky fd kz la lb lc aw ld bi"><span id="f793" class="le iw hi la b fi lf lg l lh li">loss: binary_crossentropy + dice_loss<br/>optimizer: tensorflow.keras.optimizers.Adam()<br/>metrics: dice_coefficient</span></pre><h1 id="50f1" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">结果和性能比较</h1><p id="0021" class="pw-post-body-paragraph jw jx hi jz b ka lj kc kd ke lk kg kh ll lm kk kl ln lo ko kp lp lq ks kt ku hb bi translated">每个经过训练的模型都被上传到Kaggle，并用公共和私有测试数据进行评估。结果列表如下:</p><figure class="kv kw kx ky fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/25e1c222f53b4c7fd8f6441034e8ba0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*nUOTDpPbLMRmq3siB21_Kg.png"/></div></figure><ul class=""><li id="853c" class="ls lt hi jz b ka kb ke kf ll lu ln lv lp lw ku lx ly lz ma bi translated">虽然验证分数是所有测试中最低的，但UNet++架构在最终测试数据上表现非常好。</li><li id="e2dc" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku lx ly lz ma bi translated">通过配置更多数量的过滤器，我们甚至可以期待UNet++架构带来更好的结果。</li></ul><p id="7d04" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">创建了一个简单的Flask应用程序来部署这个经过训练的U-Net ++模型:</p><figure class="kv kw kx ky fd ij"><div class="bz dy l di"><div class="mo mh l"/></div></figure><h1 id="25d0" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">训练后量化</h1><p id="3e2c" class="pw-post-body-paragraph jw jx hi jz b ka lj kc kd ke lk kg kh ll lm kk kl ln lo ko kp lp lq ks kt ku hb bi translated">使用<a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter" rel="noopener ugc nofollow" target="_blank"> tf.lite.TFLiteConverter </a>将训练好的Unet++ TensorFlow模型转换为TensorFlow Lite模型。这样，我们将模型的规模缩小了3倍，性能略有下降(在我们的例子中几乎可以忽略不计)。这种技术被称为训练后量化。点击阅读更多相关信息<a class="ae iu" href="https://www.tensorflow.org/lite/performance/post_training_quantization" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="aef3" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated">你可以在这里找到我们模型<a class="ae iu" href="https://github.com/AkhilPenta/Steel-Defect-Detection/blob/main/Quantization.ipynb" rel="noopener ugc nofollow" target="_blank">的量化代码执行。</a></p><h1 id="49bb" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">参考</h1><ol class=""><li id="9acc" class="ls lt hi jz b ka lj ke lk ll mj ln mk lp ml ku mp ly lz ma bi translated"><a class="ae iu" href="https://www.kaggle.com/c/severstal-steel-defect-detection" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/severstal-steel-defect-detection</a></li><li id="926a" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku mp ly lz ma bi translated"><a class="ae iu" href="https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47" rel="noopener" target="_blank">https://towards data science . com/understanding-semantic-segmentation-with-unet-6 be 4f 42 D4 b 47</a></li><li id="e7c7" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku mp ly lz ma bi translated"><a class="ae iu" href="https://www.tensorflow.org/tutorials/images/segmentation" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tutorials/images/segmentation</a></li><li id="4a4a" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku mp ly lz ma bi translated">https://github.com/qubvel/segmentation_models<a class="ae iu" href="https://github.com/qubvel/segmentation_models" rel="noopener ugc nofollow" target="_blank"/></li><li id="9250" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku mp ly lz ma bi translated"><a class="ae iu" href="https://naokishibuya.medium.com/up-sampling-with-transposed-convolution-9ae4f2df52d0" rel="noopener">https://naokishibuya . medium . com/up-sampling-with-transposed-convolution-9 AE 4 F2 df 52d 0</a></li><li id="c087" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku mp ly lz ma bi translated"><a class="ae iu" href="https://towardsdatascience.com/biomedical-image-segmentation-unet-991d075a3a4b" rel="noopener" target="_blank">https://towards data science . com/biomedical-image-segmentation-unet-991d 075 a3 a4b</a></li><li id="df0e" class="ls lt hi jz b ka mb ke mc ll md ln me lp mf ku mp ly lz ma bi translated"><a class="ae iu" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank">https://www.appliedaicourse.com</a></li></ol><p id="0876" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated"><strong class="jz hj">详细代码参考我的</strong><a class="ae iu" href="https://github.com/AkhilPenta/Steel-Defect-Detection" rel="noopener ugc nofollow" target="_blank"><strong class="jz hj">GitHub repo</strong></a><strong class="jz hj">。</strong></p><div class="mq mr ez fb ms mt"><a href="https://github.com/AkhilPenta/Steel-Defect-Detection" rel="noopener  ugc nofollow" target="_blank"><div class="mu ab dw"><div class="mv ab mw cl cj mx"><h2 class="bd hj fi z dy my ea eb mz ed ef hh bi translated">AkhilPenta/钢缺陷检测</h2><div class="na l"><h3 class="bd b fi z dy my ea eb mz ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="nb l"><p class="bd b fp z dy my ea eb mz ed ef dx translated">github.com</p></div></div><div class="nc l"><div class="nd l ne nf ng nc nh io mt"/></div></div></a></div><p id="ff97" class="pw-post-body-paragraph jw jx hi jz b ka kb kc kd ke kf kg kh ll kj kk kl ln kn ko kp lp kr ks kt ku hb bi translated"><strong class="jz hj">联系我上</strong><a class="ae iu" href="https://www.linkedin.com/in/akhil-penta-63468511a/" rel="noopener ugc nofollow" target="_blank"><strong class="jz hj">LinkedIn</strong></a><strong class="jz hj"/>🙂<strong class="jz hj">。</strong></p></div></div>    
</body>
</html>