<html>
<head>
<title>Dimensionality reduction with Factor Analysis on Student Performance data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于因子分析的学生成绩数据降维</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/dimensionality-reduction-with-factor-analysis-on-student-performance-data-fd4ca7082f63?source=collection_archive---------4-----------------------#2021-11-15">https://medium.com/geekculture/dimensionality-reduction-with-factor-analysis-on-student-performance-data-fd4ca7082f63?source=collection_archive---------4-----------------------#2021-11-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="ebcc" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">一种具有可解释输出的降维技术</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/31bad11fc9ade716660145837261481d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TaTSjVmNWgLMue0pKOJSHA.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@neonbrand?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">NeONBRAND</a> on <a class="ae jn" href="https://unsplash.com/s/photos/students?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="148f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">通常，我们用于数据分析和机器学习任务的数据集有几个变量。使用这样的数据集可能会破坏模型性能，并显著增加训练时间，或者使分析数据并从中获得洞察力变得极其困难。探索性因子分析(FA)是一种降维技术，它试图将相互关联的变量组合在一起，并产生可解释的输出。</p><p id="0a3c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在这篇文章中，我们将谈论因素分析背后的一般思想，并通过使用<a class="ae jn" href="https://archive.ics.uci.edu/ml/datasets/student+performance" rel="noopener ugc nofollow" target="_blank">学生表现数据集</a>的实践方法来理解它，以对学生是否会在数学课上取得成功进行分类。</p><h1 id="86b1" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">术语和一般概念</h1><p id="c465" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">为了应用因子分析，我们必须确保我们拥有的数据适合它。最简单的方法是查看特征的<strong class="jq hj">相关矩阵</strong>，并识别相关变量组。如果有一些相关度大于0.3的相关特征，使用因子分析可能会很有意思。高度相关的多组特征将被合并成一个变量潜势，称为<strong class="jq hj">因子</strong>。</p><p id="78d2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，获得的因子创建了一个新的维度来“解释”组成它的一组特征。一个变量的得分在一个因子上的投影称为<strong class="jq hj">因子得分</strong>，一个变量与一个因子的相关性称为<strong class="jq hj">因子加载</strong>。如果我们对变量的因子负载的平方求和，我们会得到一个称为<strong class="jq hj">公度</strong>的量，其范围从0到1，并测量变量的方差在多大程度上由因子解释。</p><p id="c65d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，因子分数可以在回归和分类任务中用作具有更少维度的空间的新特征。另一方面，因子载荷对于测量特定变量对因子的重要性特别有用。</p><h2 id="b6fd" class="lh kl hi bd km li lj lk kq ll lm ln ku jx lo lp kw kb lq lr ky kf ls lt la lu bi translated">程序</h2><p id="bb51" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">下图显示了如何执行因子分析的逐步过程。正如您肯定期望的那样，起点是通过进行特征编码、特征选择、去除异常值(FA模型对异常值非常敏感)以及您认为可以做的其他事情来预处理数据。</p><p id="993b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然后，我们进入检查数据是否适合FA的阶段。我之前提到过，你可以简单地看特征的相关矩阵。然而，这是相当简单的，如果你是认真的，你也应该检查样本大小是否足够，并进行一些统计测试。</p><p id="866f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在评估数据质量之后，现在我们真正期待做的是:拟合FA模型。与主成分分析(PCA)的情况一样，我们事先不知道需要多少个维度来精简数据集，以便保留相当数量的特征方差。因此，我们需要一个为数据集选择因子(维度)数量的标准，稍后我们将讨论Scree图和Kaiser标准。</p><p id="ac4f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">使用FA而不是PCA的主要优点是输出更容易解释。因此，自然地，FA的最后一步是利用每个因素试图解释的变量的信息来解释这些因素。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lv"><img src="../Images/6402cec1c506f876eeb082bcfd083a20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2xiBsqtes77-Tz1JZJRbkA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Factor Analysis Step-by-Step diagram</figcaption></figure><h1 id="61f1" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">预测学生表现</h1><p id="5c80" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">例如，我们将把上图中描述的过程应用于<a class="ae jn" href="https://archive.ics.uci.edu/ml/datasets/student+performance" rel="noopener ugc nofollow" target="_blank">学生成绩数据集</a>，解释输出因素，并在分类任务中使用它们来预测学生成绩。关于数据集的详细信息和完整的源代码可以在这个<a class="ae jn" href="https://www.kaggle.com/alexandrehsd/binary-multiclass-classification-factor-analysis" rel="noopener ugc nofollow" target="_blank"> Kaggle笔记本</a>中找到。</p><p id="ecd0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">该数据集最初有33个变量和来自两所葡萄牙学校的大约395名学生的数学课。这些功能包括学生成绩、人口统计、社会和学校相关信息。我们有关于一年级(G1)、二年级(G2)和三年级(G3)的信息，但是我们将尝试不使用G1和G2来预测G3，因为这些变量与G3高度相关，并且使用G1和G2是没有用的，因为我们想要专门掌握其他变量与G3的关系。</p><pre class="iy iz ja jb fd lw lx ly lz aw ma bi"><span id="c053" class="lh kl hi lx b fi mb mc l md me"># Load the dataset<br/>DATASET = "student-mat.csv"<br/>data = pd.read_csv(DATASET, sep=",")</span><span id="12d3" class="lh kl hi lx b fi mf mc l md me">#-------- perform feature encoding -------#<br/># ...<br/>#-------- end of feature encoding -------#</span><span id="3a25" class="lh kl hi lx b fi mf mc l md me"># split X and y<br/>X = data.drop(labels=["G1", "G2", "G3"], axis=1)<br/>y = data[["G3"]]</span></pre><h2 id="1a3f" class="lh kl hi bd km li lj lk kq ll lm ln ku jx lo lp kw kb lq lr ky kf ls lt la lu bi translated">假设—评估数据适用性</h2><p id="b68a" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">为了适合因子分析，数据集必须满足几个假设:</p><ol class=""><li id="1d33" class="mg mh hi jq b jr js ju jv jx mi kb mj kf mk kj ml mm mn mo bi translated">正态性:具有正态分布的特征大大改善了统计检验的结果。此外，这使得有可能将分析结果推广到所收集的样本之外。</li><li id="8831" class="mg mh hi jq b jr mp ju mq jx mr kb ms kf mt kj ml mm mn mo bi translated">线性关系:变量对之间不能有<strong class="jq hj">完美的</strong>相关性，如果有，从每对中去掉一个变量。</li><li id="a330" class="mg mh hi jq b jr mp ju mq jx mr kb ms kf mt kj ml mm mn mo bi translated">可分解性:检查数据集的至少一些变量是否相关，它们是否可以变成连贯的因子。</li><li id="eed1" class="mg mh hi jq b jr mp ju mq jx mr kb ms kf mt kj ml mm mn mo bi translated">样本量:应该足够大，以产生可靠的估计。理想情况下，数据集的每个变量必须至少有20条记录。</li></ol><p id="704e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">有关该主题的详细信息，请访问本页。</p><h2 id="e482" class="lh kl hi bd km li lj lk kq ll lm ln ku jx lo lp kw kb lq lr ky kf ls lt la lu bi translated">可分解性</h2><p id="1171" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">可分解性是FA最重要的假设之一。有3种评估可分解性的方法:</p><blockquote class="mu mv mw"><p id="6f6b" class="jo jp mx jq b jr js ij jt ju jv im jw my jy jz ka mz kc kd ke na kg kh ki kj hb bi translated"><strong class="jq hj">相关矩阵</strong></p></blockquote><p id="e5b9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">要验证数据是否适合FA，可以验证是否至少有一些相关性&gt; 0.3。如果是这样的话，FA的算法将能够找到相互关联的变量组。这种方法的一个局限性是，随着数据集中变量数量的增加，实际上不可能跟踪变量之间的关系。</p><blockquote class="mu mv mw"><p id="7d16" class="jo jp mx jq b jr js ij jt ju jv im jw my jy jz ka mz kc kd ke na kg kh ki kj hb bi translated"><strong class="jq hj">球度的巴特利特检验</strong>T2</p></blockquote><p id="74f4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">Bartlett的球形度检验表明相关矩阵是否是一个恒等式，相应地，检验的p值应该是显著的(<em class="mx"> p &lt; 0.05 </em>)。学生成绩数据集的p值为0。</p><pre class="iy iz ja jb fd lw lx ly lz aw ma bi"><span id="f86c" class="lh kl hi lx b fi mb mc l md me">chi_square_value, p_value = calculate_bartlett_sphericity(X)<br/>chi_square_value, p_value<br/># (3375.41, 0.0)</span></pre><blockquote class="mu mv mw"><p id="f54c" class="jo jp mx jq b jr js ij jt ju jv im jw my jy jz ka mz kc kd ke na kg kh ki kj hb bi translated"><strong class="jq hj">凯泽-迈耶-奥尔金(KMO)试验</strong></p></blockquote><p id="26b9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">KMO检验衡量数据的抽样充分性。它有助于确定整个数据集以及每个变量的适当程度。KMO值介于0和1之间。在这个问题上没有普遍的一致意见，但是许多人认为小于0.5的KMO值是不够的。</p><p id="dfb0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">数据集的总体KMO值为0.489，这并不好。然而，在去除所有变量后，KMO &lt; 0.5, the overall KMO was 0.639:</p><pre class="iy iz ja jb fd lw lx ly lz aw ma bi"><span id="794e" class="lh kl hi lx b fi mb mc l md me"># Compute KMO for the original dataset<br/>kmo_all, kmo_model = calculate_kmo(X)</span><span id="ac13" class="lh kl hi lx b fi mf mc l md me">print("Overall KMO = {:.3f}".format(kmo_model))<br/># Overall KMO = 0.489</span><span id="2443" class="lh kl hi lx b fi mf mc l md me"># Select only adequate variables and recompute KMO<br/>kmo_passed = list(X.columns[kmo_all &gt;= 0.5])<br/>X_kmo = X[kmo_passed]<br/>kmo_all, kmo_model = calculate_kmo(X_kmo)</span><span id="d7ea" class="lh kl hi lx b fi mf mc l md me">print("Overall KMO = {:.3f}".format(kmo_model))<br/># Overall KMO = 0.639</span><span id="75c8" class="lh kl hi lx b fi mf mc l md me">X = X_kmo.copy() # overwrite the dataset</span></pre><h2 id="531b" class="lh kl hi bd km li lj lk kq ll lm ln ku jx lo lp kw kb lq lr ky kf ls lt la lu bi translated">Choosing the number of factors</h2><p id="42ef" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">Now we have a suitable dataset, it is time to fit a model. The <a class="ae jn" href="https://factor-analyzer.readthedocs.io/en/latest/factor_analyzer.html#factor-analyzer-analyze-module" rel="noopener ugc nofollow" target="_blank">因子分析器</a>包可能是你的最佳选择。它的接口基于Scikit-Learn估算器。因此，代码遵循相同的逻辑。</p><p id="6de7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">拟合模型后，您将获得因子相关矩阵的特征值。根据Kaiser标准，您的模型将具有的因子数量由大于1的特征值数量决定。</p><p id="80e5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在这种情况下，您首先拟合一个因子数量等于变量数量的模型:</p><pre class="iy iz ja jb fd lw lx ly lz aw ma bi"><span id="fa86" class="lh kl hi lx b fi mb mc l md me"><strong class="lx hj">n_variables = len(X.columns)</strong><br/>factor_model = FactorAnalyzer(<strong class="lx hj">n_factors=n_variables</strong>, rotation="promax")</span><span id="cee2" class="lh kl hi lx b fi mf mc l md me">factor_model.fit(X)</span></pre><p id="8837" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然后，您将检查有多少特征值大于1:</p><pre class="iy iz ja jb fd lw lx ly lz aw ma bi"><span id="40f7" class="lh kl hi lx b fi mb mc l md me">eigenvalues, _ = factor_model.get_eigenvalues()</span><span id="53a9" class="lh kl hi lx b fi mf mc l md me"># count eigenvalues &gt; 1<br/><strong class="lx hj">number_of_factors = sum(eigenvalues &gt; 1)</strong></span></pre><p id="d514" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">并且重新训练模型来指示这些因素的数量:</p><pre class="iy iz ja jb fd lw lx ly lz aw ma bi"><span id="616a" class="lh kl hi lx b fi mb mc l md me">factor_model = FactorAnalyzer(<strong class="lx hj">n_factors=number_of_factors</strong>, rotation="promax")</span><span id="6a0b" class="lh kl hi lx b fi mf mc l md me">factor_model.fit(X)</span></pre><p id="9e2e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">另一种广泛使用的选择因子数量的方法是Scree图分析。这是一个选择许多因素的可视化工具。你也可以像我上面所做的那样通过编程来实现。绘制特征值与因子数量的关系图，并计算有多少特征值大于1。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nb"><img src="../Images/0efe38efd8ca5ee6318d28ae2e1dc27e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*65UDpX2CoJix-V_8H8q7XQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Scree Plot</figcaption></figure><p id="1ef2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">变量编码后的原始数据集有38个特征。然后，在除去那些被KMO测试认为不充分的特征后，我们剩下了22个特征。最后，使用Kaiser标准，我们将特征的数量(在本例中是因子)减少到9。</p><h2 id="9fde" class="lh kl hi bd km li lj lk kq ll lm ln ku jx lo lp kw kb lq lr ky kf ls lt la lu bi translated">因素解释</h2><p id="398d" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">一旦我们有了新的模型，我们必须解释这些因素。事实上(<em class="mx">我想强调这一点</em>)，这就是使用因子分析进行降维的全部意义:拥有一个具有更少特征的可解释数据集。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nc"><img src="../Images/61221f6bf3fde38e4eee10a33ee85df3.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*zMvvXw_ZRJEfg1lJfPly7w.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Factor loadings heatmap</figcaption></figure><p id="8e58" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在左图中，您可以看到因子加载热图。每个变量与每个因素的关系强度由因素负荷决定。</p><p id="3e11" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因子载荷的范围从-1到1，可以解释为变量与因子的相关性。因此，我们将每个变量分配给绝对值最相关的因子。通过这样做，我们可以:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nd"><img src="../Images/333aaef57e8d75f32e0254c8962ea4d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pPUuI6FiYRYjPjLq2ri8mQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Variables grouped into factors</figcaption></figure><p id="17f6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这些变量组多少有些意义。看看每个因子表示下都分组了哪些变量:</p><ul class=""><li id="c6e6" class="mg mh hi jq b jr js ju jv jx mi kb mj kf mk kj ne mm mn mo bi translated"><strong class="jq hj"> <em class="mx"> Factor0 </em> </strong>:工作日和周末饮酒量。</li><li id="1efd" class="mg mh hi jq b jr mp ju mq jx mr kb ms kf mt kj ne mm mn mo bi translated"><strong class="jq hj"> <em class="mx"> Factor1 </em> </strong>:父母学历，是否上过幼儿园。</li><li id="7d11" class="mg mh hi jq b jr mp ju mq jx mr kb ms kf mt kj ne mm mn mo bi translated"><strong class="jq hj"> <em class="mx"> Factor2 </em> </strong>:家中已上网或母亲在家工作。</li><li id="52ef" class="mg mh hi jq b jr mp ju mq jx mr kb ms kf mt kj ne mm mn mo bi translated"><strong class="jq hj"> <em class="mx"> Factor3 </em> </strong>:学生地址和家到学校的乘车时间。</li><li id="bd5a" class="mg mh hi jq b jr mp ju mq jx mr kb ms kf mt kj ne mm mn mo bi translated"><strong class="jq hj"> <em class="mx"> Factor4 </em> </strong>:每周学习时间，以往上课失败次数，学生是否想接受高等教育。</li><li id="0484" class="mg mh hi jq b jr mp ju mq jx mr kb ms kf mt kj ne mm mn mo bi translated"><strong class="jq hj"> <em class="mx">因素5 </em> </strong>:家庭教育支持和学生是否参加额外付费课程。</li><li id="00d1" class="mg mh hi jq b jr mp ju mq jx mr kb ms kf mt kj ne mm mn mo bi translated"><strong class="jq hj"> <em class="mx">因素6 </em> </strong>:学生的年龄以及学生是否有额外的教育学校支持。</li><li id="323a" class="mg mh hi jq b jr mp ju mq jx mr kb ms kf mt kj ne mm mn mo bi translated"><strong class="jq hj"> <em class="mx"> Factor7 </em> </strong>:放学后的自由时间以及学生与朋友外出的频率。</li><li id="4410" class="mg mh hi jq b jr mp ju mq jx mr kb ms kf mt kj ne mm mn mo bi translated"><strong class="jq hj"> <em class="mx"> Factor8 </em> </strong>:学生性别、父母同居状况、学生是否参加课外活动、缺课次数。</li></ul><p id="30c5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">一旦我们对因子解释感到满意，我们就可以通过对原始数据集应用变换来获得新的数据集:</p><pre class="iy iz ja jb fd lw lx ly lz aw ma bi"><span id="3e3f" class="lh kl hi lx b fi mb mc l md me">X.shape<br/># (395, 22)</span><span id="0b0b" class="lh kl hi lx b fi mf mc l md me">X_latent = factor_model.transform(X)<br/>X_latent.shape<br/># (395, 9)</span></pre><h1 id="fd54" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">二元和多元分类结果</h1><p id="0174" class="pw-post-body-paragraph jo jp hi jq b jr lc ij jt ju ld im jw jx le jz ka kb lf kd ke kf lg kh ki kj hb bi translated">最后，有了新的数据集，我们可以执行监督学习任务。我们可以完成3种类型的任务:</p><ol class=""><li id="2624" class="mg mh hi jq b jr js ju jv jx mi kb mj kf mk kj ml mm mn mo bi translated">二元分类法:试着预测一个学生是否会成功。</li><li id="4e1a" class="mg mh hi jq b jr mp ju mq jx mr kb ms kf mt kj ml mm mn mo bi translated">多级分类:尝试根据基于Erasmus等级转换系统的5级分类对学生表现进行分类:不及格、足够、满意、良好和非常好。</li><li id="869c" class="mg mh hi jq b jr mp ju mq jx mr kb ms kf mt kj ml mm mn mo bi translated">回归:尝试预测学生的最终成绩。</li></ol><p id="35ee" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在这项研究中，我只做了前两个分类任务，并将它们与<a class="ae jn" href="http://www3.dsi.uminho.pt/pcortez/student.pdf" rel="noopener ugc nofollow" target="_blank">原始论文</a>中报告的结果以及使用数据集获得的结果进行了比较。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nf"><img src="../Images/604d3c0aa560d70666aebe0aa406d12f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*r1R1cL2sBVu28fEH4I5mpg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Binary classification results</figcaption></figure><p id="4484" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">正如我们所看到的，在二元分类设置中使用因子分析被证明是更有价值的。与原始论文的结果相比，我们成功地将性能提高了11.2%。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ng"><img src="../Images/c92ac5f796ccb417a952e265a2b290ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*FygjKo-Ufx9Y4xtW0yP1Gw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Multiclass classification results</figcaption></figure><p id="18bc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">同时，在多类分类设置中，我们还设法提高了分类器的准确性，尽管它并不比使用数据集而不应用因子分析更好。然而，您必须记住，带有FA的数据集的要素要少得多。因此，训练时间和CPU资源消耗要低得多。</p></div><div class="ab cl nh ni gp nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="hb hc hd he hf"><p id="845b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">感谢您的时间，我将感谢您的反馈。带注释的源代码和完整的探索性因素分析可从<a class="ae jn" href="https://www.kaggle.com/alexandrehsd/binary-multiclass-classification-factor-analysis" rel="noopener ugc nofollow" target="_blank">这里</a>获得。编码快乐！</p></div></div>    
</body>
</html>