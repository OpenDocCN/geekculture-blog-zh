<html>
<head>
<title>Singular Value Decomposition: Calculation using EigenValues and EigenVectors in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">奇异值分解:使用Python中的特征值和特征向量进行计算</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/singular-value-decomposition-calculation-using-eigenvalues-and-eigenvectors-in-python-dde785559174?source=collection_archive---------5-----------------------#2022-12-29">https://medium.com/geekculture/singular-value-decomposition-calculation-using-eigenvalues-and-eigenvectors-in-python-dde785559174?source=collection_archive---------5-----------------------#2022-12-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="967f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">嗯，我看过很多文章解释什么是PCA，以及如何找到特征矩阵的主成分。几乎都是讲特征向量和特征值看主成分。然后我看了python <code class="du jd je jf jg b">SKlearn</code>库<a class="ae jh" href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" rel="noopener ugc nofollow" target="_blank"> PCA类</a>的文档，讲的是奇异值分解(SVD)寻找主成分。我真的很困惑SVD和特征值，以及特征向量是如何相互关联的。</p><p id="5b47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文将包含SVD的定义。以及如何将SVD问题转化为特征值问题，然后使用特征值和特征向量求解。这篇文章将更倾向于线性代数，但我们也会看到求特征值、特征向量和奇异值分解的pythonic方法。在下一篇文章中，我们将关注PCA以及如何使用协方差矩阵来获得SVD的分解矩阵。</p><h2 id="3b05" class="ji jj hi bd jk jl jm jn jo jp jq jr js iq jt ju jv iu jw jx jy iy jz ka kb kc bi translated">奇异值分解</h2><p id="c4e1" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated"><strong class="ih hj">定理</strong> : SVD定理陈述了每一个矩阵都可以分解成三个初等变换的序列:输入空间U中的旋转，缩放矩阵σ，输出空间v中的旋转矩阵</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ki"><img src="../Images/008af35b57af3f81a7deb8a962d5a352.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/format:webp/1*rZf7-C3z5o8nbruHLUc7sw.png"/></div></figure><blockquote class="kq kr ks"><p id="f82b" class="if ig kt ih b ii ij ik il im in io ip ku ir is it kv iv iw ix kw iz ja jb jc hb bi translated">其中A的大小为mxn，U的大小为mxm，σ的大小为mxn，V的大小为nxn。</p><p id="bea2" class="if ig kt ih b ii ij ik il im in io ip ku ir is it kv iv iw ix kw iz ja jb jc hb bi translated">u和V在线性代数术语中称为酉矩阵。</p></blockquote><h2 id="39fd" class="ji jj hi bd jk jl jm jn jo jp jq jr js iq jt ju jv iu jw jx jy iy jz ka kb kc bi translated">奇异值分解的几何推断；</h2><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es kx"><img src="../Images/59f899f17acd3c3c156dbee1be3b62b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*WJ3B4HxHzlKoK6wT2o0chQ.png"/></div></figure><p id="a763" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">u和V_transpose是酉矩阵或旋转矩阵，因此它们保持向量之间的角度。这里我们用v1和v2向量表示一个圆。因此，首先，V的特征向量v1和v2(它们是正交的)映射到两个正交基向量e1和e2，然后通过σ缩放到正交σ1e1、σ2e2，再通过酉U映射到σ1u1、σ2u2。线性映射A完全由这些向量的变换来定义，因为每个向量都可以由V的基来分解，并且我们知道基向量的线性映射规则。</p><p id="2435" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">U和V的正交性质:</strong></p><blockquote class="kq kr ks"><p id="7316" class="if ig kt ih b ii ij ik il im in io ip ku ir is it kv iv iw ix kw iz ja jb jc hb bi translated">从SVD获得的u和V矩阵总是正交的。它们保持长度，保持角度，并且不放大误差。当一个矩阵的转置等于它的逆矩阵时，称它是正交的。</p></blockquote><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es ky"><img src="../Images/2641826b872de0dd4b3c56d74f2b1fc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hCsPxxlHgQraeeuAJdewTw.png"/></div></div></figure><p id="e4e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个类有直接计算给定矩阵的奇异值和奇异值的方法，但是符号略有不同，这可能会让你感到困惑。</p><p id="d3ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当您调用<code class="du jd je jf jg b">svd()</code>函数时，它返回三个矩阵:<strong class="ih hj"> U、</strong><strong class="ih hj">σ_ array和V_transpose </strong>，其中U和V_transpose是SVD定理中定义的同一个矩阵，但σ是包含特征值的奇异值或平方的一维数组。因此，当你乘这些返回的矩阵时，你得不到原来的矩阵，大多数时候你会得到错误，因为这些返回的矩阵顺序不同，因此不能相乘。</p><p id="c581" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑下面的SVD示例，我们取大小为2x3的矩阵A，将使用NumPy库执行SVD，并检查所获得的分解矩阵的形状:</p><pre class="kj kk kl km fd ld jg le bn lf lg bi"><span id="bf80" class="lh jj hi jg b be li lj l lk ll">import numpy as np<br/>A = np.array([[1,4,1],[-4,-7,1]], dtype = float)<br/>U, Σ_array, V_transpose = np.linalg.svd(A)<br/><br/>print("U shape:{}, Σ_array shape:{}, and V_transpose shape:{}".format(U.shape, Σ_array.shape, V_transpose.shape))<br/>print("U is:\n{},\n Σ_array is:\n {},\n and V_transpose is:\n {}".format(U, Σ_array, V_transpose))</span></pre><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lm"><img src="../Images/06c29162eefc797976f2ff9f5963e56d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*6dLaVkPOH3W9DqiQTDFxFw.png"/></div></figure><p id="008c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如上所述，U和V是正方形和正交矩阵。</p><p id="f6fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是，当我们将这些返回的矩阵相乘以返回矩阵A时，我们会得到错误:</p><pre class="kj kk kl km fd ld jg le bn lf lg bi"><span id="dd39" class="lh jj hi jg b be li lj l lk ll">U@Σ_array@V_transpose # @ is used to perform dot product </span></pre><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es ln"><img src="../Images/81f2895f23d8de55bfefe4be7bec0344.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YXcTiWwwEqjqH2JL-bNxLA.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx">Error</figcaption></figure><p id="d101" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">NumPy库的<code class="du jd je jf jg b">svd()</code>函数并不像定理中所说的那样直接返回σ，但是我们可以从返回的σ_ array中获得σ。现在，我们的任务是从σ_ array中获取σ。我们知道σ是<code class="du jd je jf jg b">mxn </code>矩阵。σ_ array的值是σ的对角元素。因此，我们将首先用全零初始化大小为<code class="du jd je jf jg b">mxn</code>的σ，然后形成σ_ array的对角矩阵，然后将其分配给σ的顶部方阵。</p><pre class="kj kk kl km fd ld jg le bn lf lg bi"><span id="8b7f" class="lh jj hi jg b be li lj l lk ll">m = A.shape[0]<br/>n = A.shape[1]<br/>Σ = np.zeros((m,n))<br/>Σ[0: len(Σ_array), 0: len(Σ_array)] =  np.diag(Σ_array)<br/>print(Σ)</span></pre><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es ls"><img src="../Images/b9823a9cfaea4d00ffbdb25bf7dd7969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ntpQrfdYQ0GuKPQEpI4m0Q.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx">Σ</figcaption></figure><p id="53be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们可以将U、σ和V_transpose相乘，我们将得到原始矩阵A:</p><pre class="kj kk kl km fd ld jg le bn lf lg bi"><span id="d2e1" class="lh jj hi jg b be li lj l lk ll">print("Matrix constructed from original matrix:\n {}".format(U@Σ@V_transpose))<br/>print("Original Matrix:\n{}".format(A))</span></pre><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lt"><img src="../Images/62abeed363e4deb63996b61301239966.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ec3qN0Q-7yFaePu66rl6EQ.png"/></div></div></figure><h2 id="25ae" class="ji jj hi bd jk jl jm jn jo jp jq jr js iq jt ju jv iu jw jx jy iy jz ka kb kc bi translated">我们已经得到了这些分解矩阵，但是我们如何计算它们呢？</h2><p id="c71d" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">我们知道U和V是正交矩阵，因此利用它们的特性，SVD分解问题被转化为特征值和特征向量问题。因此我们可以用特征值和特征向量找到U和V矩阵。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lu"><img src="../Images/1b56584383ece4b16ba3e88423b452ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fas-l_o6zFRVRSv98-A5Uw.png"/></div></div></figure><p id="237b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用类似的方法，我们可以计算V:</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lv"><img src="../Images/3466e8c27dd5822544cad912026fcb23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dzNLCk2Wg_ypnNfUKjsvRA.png"/></div></div></figure><p id="a5b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">计算U: </strong></p><p id="22e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">#注:从<code class="du jd je jf jg b"><strong class="ih hj">AA^T = (np.dot(A,A.T)) </strong></code>的特征向量接收的U_按特征值降序重新排列，得到SVD方程中的U。</p><pre class="kj kk kl km fd ld jg le bn lf lg bi"><span id="c455" class="lh jj hi jg b be li lj l lk ll">eigen_values_U, eigen_vectors_U = np.linalg.eig(np.dot(A, A.T))  # gives U<br/># Sorting eigen_values_U and eigen_vectors_U in descending order of eigen_values_U<br/>idx = eigen_values_U.argsort()[::-1]   <br/>eigen_values_U = eigen_values_U[idx]<br/>eigen_vectors_U = eigen_vectors_U[:,idx]<br/>print("eigen_values_U received from AA^T:\n{}".format(eigen_values_U))<br/>print("eigen_vectors_U received from AA^T:\n{} which is same as U obtained in SVD except in sign:\n{}".format(eigen_vectors_U, U))</span></pre><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lw"><img src="../Images/e9ab1658c5dbaae8667c1b06cbe8ba67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*umX0FwQVudVZKnekalhJGw.png"/></div></div></figure><p id="a848" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">计算V: </strong>对从矩阵<code class="du jd je jf jg b">A^TA</code>接收的特征值V进行转置，得到SVD方程中的V转置。</p><pre class="kj kk kl km fd ld jg le bn lf lg bi"><span id="f5f7" class="lh jj hi jg b be li lj l lk ll">eigen_values_V, eigen_vectors_V = np.linalg.eig(np.dot(A.T, A)) # gives V<br/># Sorting eigen_values_V and eigen_vectors_V in descending order of eigen_values_U<br/>idx = eigen_values_V.argsort()[::-1]   <br/>eigen_values_V = eigen_values_V[idx]<br/>eigen_vectors_V = eigen_vectors_V[:,idx]<br/>print("eigen_values_V received from A^TA:\n{}".format(eigen_values_V))<br/>print("eigen_vectors_V received from A^TA:\n{}".format(eigen_vectors_V))<br/>print("SVD return V_transpose, therefore taking transpose of eigen_vectors_V:\n{} which is same as V_transpose obtained in SVD:\n{}".format(eigen_vectors_V.T, V_transpose))</span></pre><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lx"><img src="../Images/b955c200b1fb2c31c50524c9aedc9031.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wf8Ykv9m2sxOJ-LPPZ2-4A.png"/></div></div></figure><p id="a574" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">计算σ:</strong></p><p id="133a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">σ是对角矩阵，包含对角线上的奇异值，这是通过取出按降序排列的<code class="du jd je jf jg b">AA^T</code>和<code class="du jd je jf jg b">A^TA</code>的公共特征值的平方根来实现的，因为我们得到的特征值是<strong class="ih hj">σ</strong>的平方，因此我们必须取从<strong class="ih hj"> </strong> <code class="du jd je jf jg b"><strong class="ih hj">AA^T and A^TA</strong></code>接收的特征值的平方根:</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ly"><img src="../Images/0ef61aa1a4ea8435dce5afc3eb9e879d.png" data-original-src="https://miro.medium.com/v2/resize:fit:290/format:webp/1*lxgavBUEZxgsdRvi7W9LLA.png"/></div></figure><pre class="kj kk kl km fd ld jg le bn lf lg bi"><span id="6787" class="lh jj hi jg b be li lj l lk ll"># eigen_values_U, eigen_values_V are the Σ^2<br/># taking the min(m,n) and truncate the eigen_values_V or eigne_values_U as both will return same result<br/>Σ_array_cal = np.sqrt(eigen_values_V[:min(m,n)])<br/>print("Σ_array_cal:{}\nis as same as Σ_array received from SVD() function of numpy:{}".format(Σ_array_cal, Σ_array))</span></pre><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lz"><img src="../Images/d9cf911a7beae808ff365e9a53c06eec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u-PriIAjOUPmBgyNoZbQjA.png"/></div></div></figure></div><div class="ab cl ma mb gp mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hb hc hd he hf"><p id="7f40" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以在这里找到本文所用代码的<a class="ae jh" href="https://github.com/grgupta13/machine-learning/blob/main/Linear_algebra/SVD.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub链接。</a></p><p id="190e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在下一篇文章中，我们将看到如何在PCA中使用SVD，以及如何使用协方差矩阵计算SVD的分解矩阵。如果你喜欢这篇文章，那么不要忘记鼓掌，评论，并关注我的媒体，关注未来的帖子。</p><p id="b1a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">参考文献:</strong></p><p id="3141" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jh" href="https://insightsanalytics.in/do-standardization-and-normalization-transform-the-data-into-normal-distribution/" rel="noopener ugc nofollow" target="_blank">https://insightsanalytics . in/do-标准化和规范化-将数据转换为正态分布/ </a></p><div class="mh mi ez fb mj mk"><a href="https://insightsanalytics.in/" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hj fi z dy mp ea eb mq ed ef hh bi translated">主页-洞察分析</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">在您的数据科学之旅中，我们是您的伴侣。我们提供关于SQL和python的博客，让您快速入门…</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">洞察分析</p></div></div><div class="mt l"><div class="mu l mv mw mx mt my ko mk"/></div></div></a></div><div class="mh mi ez fb mj mk"><a href="https://gregorygundersen.com/blog/2018/12/10/svd/" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hj fi z dy mp ea eb mq ed ef hh bi translated">尽可能简单的奇异值分解</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">其中是酉矩阵是对角矩阵并且是酉矩阵。是的共轭转置。取决于…</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">gregorygundersen.com</p></div></div><div class="mt l"><div class="mz l mv mw mx mt my ko mk"/></div></div></a></div><div class="mh mi ez fb mj mk"><a href="https://math.stackexchange.com/questions/3309124/singular-value-decomposition-understanding-the-geometric-visualisation" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hj fi z dy mp ea eb mq ed ef hh bi translated">奇异值分解-理解几何可视化</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">begingroup$矩阵A的奇异值分解满足$ \ mathbf A = \ mathbf U \ mathbf \适马\mathbf…</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">math.stackexchange.com</p></div></div><div class="mt l"><div class="na l mv mw mx mt my ko mk"/></div></div></a></div><figure class="kj kk kl km fd kn"><div class="bz dy l di"><div class="nb nc l"/></div></figure></div></div>    
</body>
</html>