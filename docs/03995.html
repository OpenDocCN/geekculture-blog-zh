<html>
<head>
<title>Shapley Value: Explaining AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">沙普利价值:解释人工智能</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/shapley-value-explaining-ai-190cd836a045?source=collection_archive---------4-----------------------#2021-06-19">https://medium.com/geekculture/shapley-value-explaining-ai-190cd836a045?source=collection_archive---------4-----------------------#2021-06-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/174b49cbb96a9ba553ab25b8c84e3a12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CwRGWk38tllaRQZ6"/></div></div><figcaption class="iq ir et er es is it bd b be z dx"><a class="ae iu" href="https://www.reddit.com/r/IndiaSpeaks/comments/man3x9/this_is_the_scenic_beauty_of_coastal_karnataka/" rel="noopener ugc nofollow" target="_blank">https://www.reddit.com/r/IndiaSpeaks/comments/man3x9/this_is_the_scenic_beauty_of_coastal_karnataka/</a></figcaption></figure><p id="9f7b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">机器学习正逐渐成为生活的重要部分。从推荐电影到自动驾驶汽车，人工智能正在各行各业发挥作用。</p><p id="4abb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于ML模型正在作出关键决策，逐渐需要解释这些模型作出的决策。这些模型中大多数倾向于黑盒。</p><blockquote class="jt ju jv"><p id="4f6b" class="iv iw jw ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated">虽然准确的毁灭有所帮助，但回答“为什么它是这样决定的”同样重要。</p></blockquote><h1 id="24bb" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">为什么要解释这个预测</h1><ol class=""><li id="1581" class="ky kz hi ix b iy la jc lb jg lc jk ld jo le js lf lg lh li bi translated">在为网飞的用户预测推荐电影的用例中，如果没有关于为什么模型选择了某个东西的解释，那也没问题。</li><li id="5430" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">可以进一步训练/调整这些模型，以便为用户提供更好的推荐。</li><li id="bb63" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">但是，在某些情况下，如分析客户的贷款资格，理解为什么某些客户被认为没有资格获得贷款是很重要的。这对银行了解拒绝贷款的标准是很重要的。</li><li id="88dd" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">在某些地区/国家，法律强制要求给出原因。</li><li id="bb8c" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">ML模型中可能存在某种“非预期偏差”。对预测的解释有助于消除这种偏见</li></ol><h1 id="de73" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">ML模型的类型</h1><p id="3b67" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">从可解释性的角度来看，模型可以大致分为几种类型</p><h2 id="d33c" class="lr kb hi bd kc ls lt lu kg lv lw lx kk jg ly lz ko jk ma mb ks jo mc md kw me bi translated">白盒/灰盒型号:</h2><p id="78c5" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">这些模型包括线性回归、逻辑回归、决策树、朴素贝叶斯和k近邻等。这些模型被认为至少在理论上更容易解释。</p><p id="7bba" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而在现实生活中，即使解释白盒模型也是困难的，主要是由于大量的输入特征。正则化可以在一定程度上有所帮助，但简化模型有时会失去准确性。这导致了<a class="ae iu" href="https://www.darpa.mil/attachments/XAIProgramUpdate.pdf" rel="noopener ugc nofollow" target="_blank">可解释性和准确性的权衡</a>。</p><p id="a494" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">底像仅仅用白盒或灰盒模型是无法解释的。</p><h2 id="7407" class="lr kb hi bd kc ls lt lu kg lv lw lx kk jg ly lz ko jk ma mb ks jo mc md kw me bi translated">黑盒模型:</h2><p id="380a" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">另一方面，深度学习、随机森林、梯度增强非常难以解释或诠释。</p><p id="408b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">除了输入特性之外，它们还有非常多的内部变量。这一切使得人类无法解释决策的“为什么”。</p><p id="0f30" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，这些模型是非常精确的，并且主要用于现实生活条件中。他们需要使用外部方法/技术来解释决策。</p><h1 id="9dfb" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">模型不可知的可解释性方法</h1><figure class="mg mh mi mj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/e0f24056ca39aa80aa3cc9fc6cd6dfd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vNyHGjIomoNghWj7.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Source:<a class="ae iu" href="https://christophm.github.io/interpretable-ml-book/agnostic.html" rel="noopener ugc nofollow" target="_blank">https://christophm.github.io/interpretable-ml-book/agnostic.html</a></figcaption></figure><p id="875b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有多种技术来解释黑色模型。其中一些列举如下:</p><ol class=""><li id="f651" class="ky kz hi ix b iy iz jc jd jg mk jk ml jo mm js lf lg lh li bi translated">部分相关图</li><li id="99fe" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">局部可解释的模型不可知解释(LIME)</li><li id="14f4" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">个体条件期望</li><li id="6796" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">置换特征重要性</li><li id="68a4" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">沙普利值</li></ol><p id="eb89" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将讨论Shapley值。</p><h1 id="df8e" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">沙普利值</h1><p id="71eb" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">请参考下面的维基百科文章，了解Shapley值的介绍。</p><blockquote class="jt ju jv"><p id="91bf" class="iv iw jw ix b iy iz ja jb jc jd je jf jx jh ji jj jy jl jm jn jz jp jq jr js hb bi translated"><a class="ae iu" href="https://en.wikipedia.org/wiki/Shapley_value" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">沙普利值</strong> </a>是合作<a class="ae iu" href="https://en.wikipedia.org/wiki/Game_theory" rel="noopener ugc nofollow" target="_blank">博弈论</a>中的一个<a class="ae iu" href="https://en.wikipedia.org/wiki/Solution_concept" rel="noopener ugc nofollow" target="_blank">解概念</a>。它是为了纪念劳埃德·沙普利(Lloyd Shapley)而命名的，他在1951年提出了这一理论，并因此在2012年获得了诺贝尔经济学奖。对于每一个<a class="ae iu" href="https://en.wikipedia.org/wiki/Cooperative_game_theory" rel="noopener ugc nofollow" target="_blank">合作游戏</a>，它分配一个由所有玩家的联盟产生的总盈余的唯一分配(在玩家之间)。Shapley值的特征在于一系列理想的性质。</p></blockquote><p id="5464" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">简而言之，它试图在不同的参与者合作时找到收益(盈余)的公平分配。玩家会遵循合作行为的外在强制。</p><h1 id="51a2" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">沙普利值:简单的例子</h1><p id="2894" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">假设甲、乙和丙想拼车。让我们做如下假设</p><p id="cd93" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一个-&gt;光是去他家就要付50</p><p id="ce80" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">B-&gt;光是回家就要付60</p><p id="b3f0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">仅C-&gt;就要付80英镑去他家</p><p id="fcae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果A和B共乘一辆车，他们要付70英镑。</p><p id="b39c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果A和C拼车，他们要付100英镑。</p><p id="0909" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果B和C拼车，他们要付90英镑。</p><p id="bd13" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">假设A、B和C共乘一辆车，付给司机120英镑。</p><h2 id="4dbb" class="lr kb hi bd kc ls lt lu kg lv lw lx kk jg ly lz ko jk ma mb ks jo mc md kw me bi translated">什么是公平分配？</h2><p id="ec4f" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">让我们先尝试一下:</p><p id="d327" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jw">假设A先下车，他大概能付50(因为他本来是一个人付的)。b可以支付60英镑(因为他会独自支付)，C可以支付剩余的10英镑。</em></p><p id="0a6f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但这可能并不公平。如果我们改变下降的顺序，谁支付多少变化。可能有各种方法来划分总和。</p><p id="2259" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jw">让我们用沙普利值来理解什么是公平分配。</em> </strong></p><p id="9532" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这方面，我们尝试所有的排列</p><p id="28e6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，以下是所有可能的家庭投递顺序</p><ol class=""><li id="5c89" class="ky kz hi ix b iy iz jc jd jg mk jk ml jo mm js lf lg lh li bi translated">甲、乙、丙</li><li id="4690" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">乙，甲，丙</li><li id="5d41" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">甲、丙、乙</li><li id="e4d1" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">丙、甲、乙</li><li id="b897" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">b，C，A</li><li id="f666" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">丙、乙、甲</li></ol><p id="c5b5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们计算一下每个人要付多少钱。</p><p id="6e98" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们以第一个例子A，B，c为例，A和B一起支付70英镑。作为第一个落点，他将支付50英镑(因为他在独自前往时支付)。b将支付剩余的70–50 = 20。c将支付剩余的120–70 = 50</p><p id="8d06" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以支出将是50(A)+20(B)+50(C)。</p><p id="7f2b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在第二种情况B中，A和C是删除顺序。甲和乙合起来要付70英镑。当B第一次下降时，他将支付60英镑(因为他在独自走时支付)。a将支付剩余的70–60 = 10。c将支付剩余的120–70 = 50</p><p id="4a30" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">将类似的逻辑应用于其他组合，我们得到以下分布。</p><figure class="mg mh mi mj fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/806f99b7b580383dc8c26998b8fb45a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*brlcXF98aXqQCqNWuXoBHA.png"/></div></figure><h1 id="0342" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">解释ML模型的Shapley值</h1><p id="fa44" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">ML模型可以用Shapley值来解释模型。要在高层次上理解这一点，只需将播放器替换为特性。</p><p id="baef" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过观察各种特征和预测的组合，我们可以找到每个特征的基本贡献。特征的实际值可以解释预测高于或低于基本预测的原因。</p><p id="7efb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们用<a class="ae iu" href="https://www.kaggle.com/c/titanic" rel="noopener ugc nofollow" target="_blank">泰坦尼克号数据集</a>来理解这一点。</p><p id="82b5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在泰坦尼克号的数据集中，我们查看乘客信息，如船票等级、性别、年龄、票价、出发港口等。预测乘客的生存机会。</p><p id="ce34" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果我们应用随机森林或XGBoost，预测是准确的，但它变得难以解释。</p><p id="04df" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Python有SHAP库来解释这些模型。这不需要开发人员编写任何额外的代码。</p><div class="mo mp ez fb mq mr"><a href="https://shap.readthedocs.io/en/latest/index.html" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab dw"><div class="mt ab mu cl cj mv"><h2 class="bd hj fi z dy mw ea eb mx ed ef hh bi translated">欢迎来到SHAP文档- SHAP最新文档</h2><div class="my l"><h3 class="bd b fi z dy mw ea eb mx ed ef dx translated">SHAP是一种博弈论的方法来解释任何机器学习模型的输出…</h3></div><div class="mz l"><p class="bd b fp z dy mw ea eb mx ed ef dx translated">shap.readthedocs.io</p></div></div><div class="na l"><div class="nb l nc nd ne na nf io mr"/></div></div></a></div><h1 id="3688" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">让我们看看代码</h1><p id="a6f1" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">1.从csv文件准备数据。</p><pre class="mg mh mi mj fd ng nh ni nj aw nk bi"><span id="9c2d" class="lr kb hi nh b fi nl nm l nn no">def pre_process_data(df1):<br/>    <br/>    df1['title'] = df1.apply(lambda row: re.split('[,.]+', row['Name'])[1], axis=1)<br/>    <br/>    df1['family'] = df1['SibSp'] + df1['Parch'] + 1<br/>    <br/>    df1 = pd.get_dummies(df, columns=['Sex', 'Embarked', 'title'])<br/>    <br/>    # Drop columns unwanted columns<br/>    # I'm dropping "Cabin" because it has too much missing data.<br/>    df1 = df1.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)</span><span id="d926" class="lr kb hi nh b fi np nm l nn no">return df1</span><span id="ea32" class="lr kb hi nh b fi np nm l nn no"># value from labels<br/><br/>labels = train['Survived']<br/>train.drop(['Survived'], axis=1, inplace=True)<br/># Get test ids<br/>test_ids = test['PassengerId'].values</span><span id="aaa6" class="lr kb hi nh b fi np nm l nn no">train = pre_process_data(train)<br/>test = pre_process_data(test)</span><span id="5444" class="lr kb hi nh b fi np nm l nn no"><br/>train, test = train.align(test, join='outer', axis=1)</span><span id="8e7a" class="lr kb hi nh b fi np nm l nn no"><br/>train.replace(to_replace=np.nan, value=0, inplace=True)<br/>test.replace(to_replace=np.nan, value=0, inplace=True)</span></pre><p id="f729" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.查看加载的数据，并将其分为测试和训练</p><pre class="mg mh mi mj fd ng nh ni nj aw nk bi"><span id="c2de" class="lr kb hi nh b fi nl nm l nn no">train.describe()<br/>X_train, X_val, Y_train, Y_val = train_test_split(train, labels, test_size=0.3, random_state=1)</span></pre><figure class="mg mh mi mj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nq"><img src="../Images/0287a02540d27f44695184edbaf861e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x01hCGLRqIPepQHyKHTRbw.png"/></div></div></figure><p id="db02" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.使用随机森林模型</p><pre class="mg mh mi mj fd ng nh ni nj aw nk bi"><span id="cb4d" class="lr kb hi nh b fi nl nm l nn no">clf=RandomForestClassifier(n_estimators=100)<br/>clf.fit(X_train, Y_train)</span><span id="7b14" class="lr kb hi nh b fi np nm l nn no">y_pred=clf.predict(X_val)<br/>print("Accuracy:",metrics.accuracy_score(Y_val, y_pred))</span><span id="32ec" class="lr kb hi nh b fi np nm l nn no">Accuracy: 0.7653631284916201</span></pre><p id="8959" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">4.用SHAP图书馆解释特征的模型和重要性</p><pre class="mg mh mi mj fd ng nh ni nj aw nk bi"><span id="d1eb" class="lr kb hi nh b fi nl nm l nn no">explainer = shap.TreeExplainer(clf)<br/>shap_values = shap.TreeExplainer(clf).shap_values(X_train)<br/>shap.summary_plot(shap_values, X_train, plot_type="bar")</span></pre><p id="a5c6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出</p><figure class="mg mh mi mj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nr"><img src="../Images/39865fd0d54a80cadb880085747b38f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y07hzt1qA1esCjBjcBgqlQ.png"/></div></div></figure><p id="fec5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它也可以用来解释一个单独的预测。下图显示了各种输入特征如何导致某些预测。</p><figure class="mg mh mi mj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ns"><img src="../Images/c7f5ebdb6891f1ac8f7128d9a0cf200a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CSHmuo1o4TIcCZpMlJY4lw.png"/></div></div></figure><p id="f42a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Shap库还提供高级功能，如功能之间的部分依赖图。</p><h1 id="15c3" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">进一步阅读</h1><div class="mo mp ez fb mq mr"><a href="https://christophm.github.io/interpretable-ml-book/shapley.html" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab dw"><div class="mt ab mu cl cj mv"><h2 class="bd hj fi z dy mw ea eb mx ed ef hh bi translated">5.9 Shapley值|可解释的机器学习</h2><div class="my l"><h3 class="bd b fi z dy mw ea eb mx ed ef dx translated">预测可以通过假设实例的每个特征值是游戏中的“玩家”来解释，其中…</h3></div><div class="mz l"><p class="bd b fp z dy mw ea eb mx ed ef dx translated">christophm.github.io</p></div></div><div class="na l"><div class="nt l nc nd ne na nf io mr"/></div></div></a></div><div class="mo mp ez fb mq mr"><a href="https://www.analyticsvidhya.com/blog/2019/11/shapley-value-machine-learning-interpretability-game-theory/" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab dw"><div class="mt ab mu cl cj mv"><h2 class="bd hj fi z dy mw ea eb mx ed ef hh bi translated">机器学习可解释性的独特方法:博弈论和Shapley值！</h2><div class="my l"><h3 class="bd b fi z dy mw ea eb mx ed ef dx translated">概述了解如何使用Shapley值在博弈论的机器学习可解释性这是一个独特的和…</h3></div><div class="mz l"><p class="bd b fp z dy mw ea eb mx ed ef dx translated">www.analyticsvidhya.com</p></div></div><div class="na l"><div class="nu l nc nd ne na nf io mr"/></div></div></a></div><p id="8e99" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">想进一步了解深度学习，请关注我的</strong><a class="ae iu" href="https://smverma.medium.com/" rel="noopener"><strong class="ix hj"/></a><strong class="ix hj">。</strong></p></div></div>    
</body>
</html>