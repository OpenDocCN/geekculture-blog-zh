<html>
<head>
<title>PyTorch — Training Fruit 360 Classifier Under 5 mins</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch —在5分钟内训练Fruit 360分类器</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/pytorch-training-fruit-360-classifier-under-5-mins-23153b46ec88?source=collection_archive---------10-----------------------#2021-05-30">https://medium.com/geekculture/pytorch-training-fruit-360-classifier-under-5-mins-23153b46ec88?source=collection_archive---------10-----------------------#2021-05-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="9b7e" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">在Kaggle上可用的Fruit 360数据集上实现了CNN神经网络</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/b42392f11261d091e906e46b8ddbf3be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*S3rQKVps7s3Zb8eA"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@ja_ma?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">ja ma</a> on <a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="d955" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们经常面临这样一种情况:在试图提高神经网络的准确性时，我们最终会使模型过度适应训练数据。当我们运行测试数据的模型时，这导致了不良的预测。因此，我采用了一个数据集，并应用这些技术，不仅提高了精度，而且还处理了过拟合问题。</p><p id="b4b4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在本文中，我们将使用以下技术在不到5分钟的时间内训练一个最先进的模型，以实现对来自Fruit 360数据集的图像进行分类的95%以上的准确率:</p><ol class=""><li id="4b75" class="kk kl hi jq b jr js ju jv jx km kb kn kf ko kj kp kq kr ks bi translated"><strong class="jq hj">数据扩充</strong> <br/>数据分析中的数据扩充是通过添加已有数据的稍微修改的副本或从已有数据中新创建的合成数据来增加数据量的技术。它充当正则化器，有助于在训练机器学习模型时减少过拟合。</li><li id="b8c8" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><strong class="jq hj">批量标准化</strong> <br/>批量标准化是一种用于训练深度神经网络的技术，它将每个小批量的输入标准化到一个层。这具有稳定学习过程和显著减少训练深度网络所需的训练时期的效果。</li><li id="78e4" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><strong class="jq hj">学习率计划</strong> <br/>学习率计划旨在通过根据预定义的计划降低学习率来调整训练期间的学习率。常见的学习率时间表包括基于时间的衰减、阶跃衰减和指数衰减。</li><li id="b9b2" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><strong class="jq hj">权重衰减</strong> <br/>我们使用权重衰减来保持权重较小，避免爆发渐变。因为权重的L2范数被添加到损失中，所以除了损失之外，网络的每次迭代将尝试优化/最小化模型权重。这将有助于保持权重尽可能小，防止权重增长失控，从而避免爆炸梯度。</li><li id="217c" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><strong class="jq hj">梯度裁剪</strong> <br/>使用梯度裁剪可以防止神经网络中的梯度爆炸。渐变裁剪限制了渐变的幅度。有许多方法来计算梯度裁剪，但一个常见的是重新调整梯度，使他们的规范最多是一个特定的值。</li><li id="1533" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><strong class="jq hj">自适应优化器</strong> <br/>该系列优化器用于解决梯度下降算法的问题。它们最重要的特点是不需要调整学习率值。实际上，一些库——比如Keras——仍然允许你手动调整它来进行更高级的测试</li></ol><h1 id="0c50" class="ky kz hi bd la lb lc ld le lf lg lh li io lj ip lk ir ll is lm iu ln iv lo lp bi translated">关于数据集</h1><p id="fd0b" class="pw-post-body-paragraph jo jp hi jq b jr lq ij jt ju lr im jw jx ls jz ka kb lt kd ke kf lu kh ki kj hb bi translated">水果在当今世界非常普遍——尽管有大量的快餐和精制糖，水果仍然是广泛消费的食物。举一个例子，在生产水果的过程中，可能需要对它们进行分类。传统上是机械地执行，今天，基于深度学习的技术<em class="lv">可以</em>增强甚至接管这一过程。</p><h1 id="d146" class="ky kz hi bd la lb lc ld le lf lg lh li io lj ip lk ir ll is lm iu ln iv lo lp bi translated">目录</h1><ol class=""><li id="23e4" class="kk kl hi jq b jr lq ju lr jx lw kb lx kf ly kj kp kq kr ks bi translated"><a class="ae jn" href="#f4a1" rel="noopener ugc nofollow">简介</a></li><li id="b418" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><a class="ae jn" href="#a300" rel="noopener ugc nofollow">数据预处理</a> <br/> 2.1 <a class="ae jn" href="#168a" rel="noopener ugc nofollow">导入所需库</a> <br/> 2.2 <a class="ae jn" href="#724f" rel="noopener ugc nofollow">下载数据集</a></li><li id="74b1" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><a class="ae jn" href="#7860" rel="noopener ugc nofollow">探索数据集</a> <br/> 3.1 <a class="ae jn" href="#96bf" rel="noopener ugc nofollow">训练和测试数据集包含多少幅图像？</a> <br/> 3.2 <a class="ae jn" href="#4567" rel="noopener ugc nofollow">数据集包含多少个输出类？</a> <br/> 3.3 <a class="ae jn" href="#39ef" rel="noopener ugc nofollow">来自数据集的图像张量的形状是什么？</a> <br/> 3.4 <a class="ae jn" href="#1f6f" rel="noopener ugc nofollow">你能确定属于每一类的图像数量吗？</a></li><li id="efbd" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><a class="ae jn" href="#d0b6" rel="noopener ugc nofollow">应用数据扩充</a> <br/> 4.1 <a class="ae jn" href="#776c" rel="noopener ugc nofollow">构建数据转换</a> <br/> 4.2 <a class="ae jn" href="#c7bf" rel="noopener ugc nofollow">将转换应用于数据集</a> <br/> 4.3 <a class="ae jn" href="#0a35" rel="noopener ugc nofollow">拆分数据集</a></li><li id="ef56" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><a class="ae jn" href="#e4e1" rel="noopener ugc nofollow">访问少量样本图像</a></li><li id="f01e" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><a class="ae jn" href="#c779" rel="noopener ugc nofollow">访问GPU </a></li><li id="2527" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><a class="ae jn" href="#05e1" rel="noopener ugc nofollow">配置模型</a></li><li id="510e" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><a class="ae jn" href="#3755" rel="noopener ugc nofollow">模型训练和结果</a> <br/> 8.1 <a class="ae jn" href="#1d3d" rel="noopener ugc nofollow">训练前设置参数</a> <br/> 8.2 <a class="ae jn" href="#e4d6" rel="noopener ugc nofollow">运行模型4个周期</a> <br/> 8.3 <a class="ae jn" href="#1c8d" rel="noopener ugc nofollow">精度vs周期数</a> <br/> 8.4 <a class="ae jn" href="#0090" rel="noopener ugc nofollow">损失vs周期数</a> <br/> 8.5 <a class="ae jn" href="#0f3d" rel="noopener ugc nofollow">学习率与批次号</a></li><li id="4153" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><a class="ae jn" href="#81ec" rel="noopener ugc nofollow">预测</a></li><li id="9773" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><a class="ae jn" href="#6dde" rel="noopener ugc nofollow">总结</a></li><li id="eb45" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj kp kq kr ks bi translated"><a class="ae jn" href="#febf" rel="noopener ugc nofollow">参考文献</a></li></ol><h1 id="f4a1" class="ky kz hi bd la lb lc ld le lf lg lh li io lj ip lk ir ll is lm iu ln iv lo lp bi translated">№1:简介</h1><p id="e965" class="pw-post-body-paragraph jo jp hi jq b jr lq ij jt ju lr im jw jx ls jz ka kb lt kd ke kf lu kh ki kj hb bi translated">图像总数:90483。</p><p id="4805" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">训练集大小:67692个图像(每个图像一个水果或蔬菜)。</p><p id="9866" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">测试集大小:22688幅图像(每幅图像一个水果或蔬菜)。</p><p id="ea46" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">班级人数:131人(水果和蔬菜)。</p><p id="303b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">图像尺寸:100x100像素。</p><p id="fc7b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">同一种水果的不同品种(例如苹果)被存储为属于不同的类。</p><h1 id="a300" class="ky kz hi bd la lb lc ld le lf lg lh li io lj ip lk ir ll is lm iu ln iv lo lp bi translated">№2:数据预处理</h1><h2 id="168a" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">导入所需的库</h2><p id="2134" class="pw-post-body-paragraph jo jp hi jq b jr lq ij jt ju lr im jw jx ls jz ka kb lt kd ke kf lu kh ki kj hb bi translated">因为我们用PyTorch来构建神经网络。我一次性导入了所有相关的库。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h2 id="724f" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">下载数据集</h2><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="2ed6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在我们运行任何探索之前，数据集必须被加载到数据加载器。我们使用PyTorch中的ImageFolder将图像加载到数据加载器中。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h1 id="7860" class="ky kz hi bd la lb lc ld le lf lg lh li io lj ip lk ir ll is lm iu ln iv lo lp bi translated">№3:探索数据集</h1><h2 id="96bf" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">问:训练和测试数据集包含多少幅图像？</h2><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h2 id="4567" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">问:数据集包含多少个输出类？</h2><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h2 id="39ef" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">问:来自数据集的图像张量的形状是什么？</h2><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="09e9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们打印一个样本图像及其类别和标签。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h2 id="1f6f" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">问:您能确定属于每个类别的图像数量吗？</h2><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mp"><img src="../Images/2229aebcea028b4fd9178c1170b6589c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wM8ACOkKdupLcOCrCM1jUA.png"/></div></div></figure><h1 id="d0b6" class="ky kz hi bd la lb lc ld le lf lg lh li io lj ip lk ir ll is lm iu ln iv lo lp bi translated">№4:应用数据扩充</h1><h2 id="776c" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">构建数据转换</h2><p id="473e" class="pw-post-body-paragraph jo jp hi jq b jr lq ij jt ju lr im jw jx ls jz ka kb lt kd ke kf lu kh ki kj hb bi translated">我们将首先编写转换函数，以便可以实现数据扩充。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="ea09" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">请随意尝试其他参数，如tt。tt随机旋转。随机调整，tt。颜色抖动(我已经在代码中添加了它们)</p><h2 id="c7bf" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">将变换应用于数据集</h2><p id="8318" class="pw-post-body-paragraph jo jp hi jq b jr lq ij jt ju lr im jw jx ls jz ka kb lt kd ke kf lu kh ki kj hb bi translated">我们构建的转换需要应用于训练和测试数据集。<strong class="jq hj">注意</strong> —我们不在测试数据集中应用数据扩充。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h2 id="0a35" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">分割数据集</h2><p id="fd50" class="pw-post-body-paragraph jo jp hi jq b jr lq ij jt ju lr im jw jx ls jz ka kb lt kd ke kf lu kh ki kj hb bi translated">我们将使用来自训练集的20%的验证集。为了确保每次都得到相同的验证集，我们将PyTorch的随机数生成器设置为种子值43。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h1 id="e4e1" class="ky kz hi bd la lb lc ld le lf lg lh li io lj ip lk ir ll is lm iu ln iv lo lp bi translated">№5:访问样本</h1><p id="06e7" class="pw-post-body-paragraph jo jp hi jq b jr lq ij jt ju lr im jw jx ls jz ka kb lt kd ke kf lu kh ki kj hb bi translated">让我们使用Torchvision的make_grid helper函数来可视化一批数据。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mq"><img src="../Images/183afa1bede3af5b4d600a854623a413.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*GgPEzz7cAZJL9iOPwg_QVw.png"/></div></figure><p id="b142" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">你能通过观察给所有的图片贴上标签吗？尝试手动标记数据的随机样本是估计问题难度和识别标记错误(如果有的话)的好方法</p><h1 id="c779" class="ky kz hi bd la lb lc ld le lf lg lh li io lj ip lk ir ll is lm iu ln iv lo lp bi translated">№6:访问GPU</h1><p id="bdc6" class="pw-post-body-paragraph jo jp hi jq b jr lq ij jt ju lr im jw jx ls jz ka kb lt kd ke kf lu kh ki kj hb bi translated">如果您的执行平台连接到NVIDIA制造的图形处理器，您可以使用图形处理器(GPU)来更快地训练您的模型。按照以下说明在您选择的平台上使用GPU:</p><ul class=""><li id="d858" class="kk kl hi jq b jr js ju jv jx km kb kn kf ko kj mr kq kr ks bi translated">Google Colab:使用菜单选项“运行时&gt;更改运行时类型”，并从“硬件加速器”下拉列表中选择“GPU”。</li><li id="3855" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated">Kaggle:在侧边栏的“设置”部分，从“加速器”下拉列表中选择“GPU”。使用右上角的按钮打开侧边栏。</li><li id="c72d" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated">Binder:运行Binder的笔记本不能使用GPU，因为支持Binder的机器没有连接到任何GPU。</li><li id="4fe6" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated">Linux:如果你的笔记本电脑/台式机有NVIDIA GPU(显卡)，确保你已经安装了NVIDIA CUDA驱动程序。</li><li id="9908" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated">Windows:如果你的笔记本电脑/台式机有NVIDIA GPU(显卡)，请确保你已经安装了NVIDIA CUDA驱动程序。macOS: macOS与NVIDIA GPUs不兼容</li><li id="2fc9" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated">如果您无法访问GPU或者不确定它是什么，不要担心，您可以在没有GPU的情况下执行本教程中的所有代码。</li></ul><p id="e6f5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们从安装和导入所需的库开始。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="0905" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，我使用<code class="du ms mt mu mv b">DeviceDataLoader</code>函数将训练和验证加载器加载到GPU</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h1 id="05e1" class="ky kz hi bd la lb lc ld le lf lg lh li io lj ip lk ir ll is lm iu ln iv lo lp bi translated">№7:配置模型</h1><h2 id="ed86" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">设置精度函数和图像基类</h2><p id="b3af" class="pw-post-body-paragraph jo jp hi jq b jr lq ij jt ju lr im jw jx ls jz ka kb lt kd ke kf lu kh ki kj hb bi translated">两者都是通用函数，无论数据集如何，都不需要进行任何更改。这两个函数是计算准确性的辅助函数，实现了计算模型的训练和验证损失的损失函数。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h2 id="cdc4" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">实现批处理规范化和删除</h2><p id="16a4" class="pw-post-body-paragraph jo jp hi jq b jr lq ij jt ju lr im jw jx ls jz ka kb lt kd ke kf lu kh ki kj hb bi translated">我们使用<code class="du ms mt mu mv b">nn.Squential</code>将神经网络的各层链接在一起。为了简化理解，我在代码中添加了注释。<strong class="jq hj">注意</strong>——这里我在每一层的末尾使用<code class="du ms mt mu mv b">nn.BatchNorm2d</code>模块实现了批量规范化。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h2 id="f31e" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">训练时实现权重衰减、梯度裁剪、Adam优化器</h2><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="ad59" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">模特在训练前的表现似乎很差。如下所示，由于模型试图随机猜测输出，因此模型的精度低于1%。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h1 id="3755" class="ky kz hi bd la lb lc ld le lf lg lh li io lj ip lk ir ll is lm iu ln iv lo lp bi translated">№8:训练模型和结果分析</h1><h2 id="1d3d" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">训练前设置参数</h2><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h2 id="e4d6" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">运行模型4个时期</h2><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="6069" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们在4分钟内的4个时期内取得了非常好的准确性。这就是我们实现的所有技术的力量。</p><h2 id="1c8d" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">精确度与纪元数量</h2><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mw"><img src="../Images/ad525524b84874385f0274cc43be90a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*QjRAIFlrio9f12mAODfDaw.png"/></div></figure><h2 id="0090" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">损失与时代</h2><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mx"><img src="../Images/43d7b363a3eba2181ee78b546d8d076c.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*_lw1-HJHuGmZy9e-Evs4cw.png"/></div></figure><p id="05a2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">由于训练和验证损失不是发散而是收敛，这表明我们没有过度拟合我们的模型</p><h2 id="0f3d" class="lz kz hi bd la ma mb mc le md me mf li jx mg mh lk kb mi mj lm kf mk ml lo mm bi translated">批次号的学习率</h2><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es my"><img src="../Images/420d9b3a5e49c06881e303054994ce43.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*SCB_9DN53Op7Z2m_qVd06Q.png"/></div></figure><p id="a8d7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">正如所料，学习率从一个低值开始，并在30%的迭代中逐渐增加到最大值0.01，然后逐渐减少到一个非常小的值。</p><h1 id="81ec" class="ky kz hi bd la lb lc ld le lf lg lh li io lj ip lk ir ll is lm iu ln iv lo lp bi translated">№9:预测</h1><p id="0fde" class="pw-post-body-paragraph jo jp hi jq b jr lq ij jt ju lr im jw jx ls jz ka kb lt kd ke kf lu kh ki kj hb bi translated">让我们在测试数据集上测试模型预测</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="37f6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">验证精度超过了<strong class="jq hj"> 98% </strong>，我们编写了一个获取图像并应用于模型的辅助函数</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><p id="7fea" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们现在测试样本图像上的预测</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mn mo l"/></div></figure><h1 id="6dde" class="ky kz hi bd la lb lc ld le lf lg lh li io lj ip lk ir ll is lm iu ln iv lo lp bi translated">№10:摘要</h1><p id="3114" class="pw-post-body-paragraph jo jp hi jq b jr lq ij jt ju lr im jw jx ls jz ka kb lt kd ke kf lu kh ki kj hb bi translated">以下是本教程中用于提高模型性能和减少训练时间的不同技术的总结:</p><ul class=""><li id="06ac" class="kk kl hi jq b jr js ju jv jx km kb kn kf ko kj mr kq kr ks bi translated"><strong class="jq hj">数据扩充</strong>:我们在从训练数据集中加载图像时应用了随机变换。具体来说，我们将每个图像填充4个像素，然后随机截取大小为100 x 100像素的图像，然后以50%的概率水平翻转图像。</li><li id="1eb5" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated"><strong class="jq hj">批量归一化</strong>:在每个卷积层之后，我们增加了一个批量归一化层，对前一层的输出进行归一化。这有点类似于数据归一化，只是它应用于图层的输出，而平均值和标准差是学习参数。</li><li id="1033" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated"><strong class="jq hj">学习率调度</strong>:我们不使用固定的学习率，而是使用学习率调度器，它会在每一批训练后改变学习率。在训练期间有许多改变学习率的策略，我们使用了“一个周期学习率策略”。</li><li id="d8b9" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated"><strong class="jq hj">权重衰减</strong>:我们在优化器中加入了权重衰减，这是另一种正则化技术，通过在损失函数中加入额外的项来防止权重变得过大。</li><li id="e1e3" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated"><strong class="jq hj">渐变裁剪</strong>:我们还增加了渐变裁剪，有助于将渐变的值限制在一个很小的范围内，以防止在训练过程中由于大的渐变值而导致模型参数发生不希望的变化。</li><li id="e293" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated"><strong class="jq hj"> Adam optimizer </strong>:我们使用了Adam optimizer，而不是SGD(随机梯度下降)，它使用了动量和自适应学习率等技术来加快训练速度。还有许多其他优化器可以选择格式并进行实验。</li></ul><h1 id="febf" class="ky kz hi bd la lb lc ld le lf lg lh li io lj ip lk ir ll is lm iu ln iv lo lp bi translated">№11:参考</h1><ul class=""><li id="b107" class="kk kl hi jq b jr lq ju lr jx lw kb lx kf ly kj mr kq kr ks bi translated">我的笔记本可以在这里访问<br/><a class="ae jn" href="https://jovian.ai/hargurjeet/fruit-360-classification-v1-2204a" rel="noopener ugc nofollow" target="_blank">https://jovian . ai/hargurjeet/fruit-360-分类-v1-2204a </a></li><li id="1596" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated"><a class="ae jn" href="https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans/lesson/lesson-5-data-augmentation-regularization-and-resnets" rel="noopener ugc nofollow" target="_blank">https://jovian . ai/learn/deep-learning-with-py torch-zero-to-gans/lesson/lesson-5-data-augmentation-regularity-and-resnets</a></li><li id="3c58" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated"><a class="ae jn" href="https://jovian.ai/outlink?url=https%3A%2F%2Ftowardsdatascience.com%2F7-tips-to-choose-the-best-optimizer-47bb9c1219e" rel="noopener ugc nofollow" target="_blank">https://towards data science . com/7-tips-to-choose-the-best-optimizer-47 bb9c 1219 e</a></li><li id="03c2" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated"><a class="ae jn" href="https://jovian.ai/outlink?url=https%3A%2F%2Fandroidkt.com%2Fhow-to-apply-gradient-clipping-in-pytorch%2F" rel="noopener ugc nofollow" target="_blank">https://androidkt . com/how-to-apply-gradient-clipping-in-py torch/</a></li><li id="aa7b" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated"><a class="ae jn" href="https://jovian.ai/outlink?url=https%3A%2F%2Fmedium.com%2Fanalytics-vidhya%2Fdeep-learning-basics-weight-decay-3c68eb4344e9" rel="noopener ugc nofollow" target="_blank">https://medium . com/analytics-vid hya/deep-learning-basics-weight-decay-3c 68 EB 4344 e 9</a></li><li id="671a" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated"><a class="ae jn" href="https://jovian.ai/outlink?url=https%3A%2F%2Ftowardsdatascience.com%2Flearning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1" rel="noopener ugc nofollow" target="_blank">https://towards data science . com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f 433990 D1</a></li><li id="49db" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated"><a class="ae jn" href="https://jovian.ai/outlink?url=https%3A%2F%2Fmachinelearningmastery.com%2Fbatch-normalization-for-training-of-deep-neural-networks%2F" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/batch-normalization-for-training-of-deep-neural-networks/</a></li><li id="1bd2" class="kk kl hi jq b jr kt ju ku jx kv kb kw kf kx kj mr kq kr ks bi translated">【https://neptune.ai/blog/data-augmentation-in-python T4】</li></ul><p id="c829" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我真的希望你们能从这篇文章中学到一些东西。随意👏如果你喜欢你所学的。如果有什么需要我帮忙的，请告诉我。</p></div></div>    
</body>
</html>