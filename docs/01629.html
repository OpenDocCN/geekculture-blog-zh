<html>
<head>
<title>Simple Data Cleaning and EDA for a Baseline Logistic Regression.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基线逻辑回归的简单数据清理和EDA。</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/simple-data-cleaning-and-eda-for-a-baseline-logistic-regression-8b01e78e2f73?source=collection_archive---------6-----------------------#2021-04-18">https://medium.com/geekculture/simple-data-cleaning-and-eda-for-a-baseline-logistic-regression-8b01e78e2f73?source=collection_archive---------6-----------------------#2021-04-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="e9d9" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">为逻辑回归准备Kaggle数据集</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ix"><img src="../Images/7d9035a2c0a736140cb8034984b9d7b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*HXz2vvpWU9l9WNcnsvi7Tg.png"/></div></figure><h1 id="1f11" class="jf jg hi bd jh ji jj jk jl jm jn jo jp io jq ip jr ir js is jt iu ju iv jv jw bi translated">数据</h1><p id="6e1f" class="pw-post-body-paragraph jx jy hi jz b ka kb ij kc kd ke im kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">对于这个快速演练，我从Kaggle选择了一个笔划数据集。美国每年有超过70万人患中风。有多种因素导致某人患中风的风险。了解患者中风的潜在风险可能有助于医生实施预防性护理。借助机器学习的力量，中风患者数据可以用来建立中风风险分类模型。这个模型可以作为一个应用程序或工具来帮助用户了解他们中风的风险。在这篇博客中，我将向你展示如何读入数据集，进行快速探索性数据分析，并为基线逻辑回归准备数据框架。</p><h1 id="7439" class="jf jg hi bd jh ji jj jk jl jm jn jo jp io jq ip jr ir js is jt iu ju iv jv jw bi translated">第一步</h1><p id="a76b" class="pw-post-body-paragraph jx jy hi jz b ka kb ij kc kd ke im kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">让我们从导入我们的包和读取熊猫数据集开始。</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="ffd8" class="ky jg hi ku b fi kz la l lb lc">import pyforest<br/>import warnings<br/>warnings.filterwarnings("ignore")<br/>from sklearn import metrics<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import mean_squared_error<br/>from sklearn.dummy import DummyClassifier<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn import metrics<br/>from sklearn.linear_model import LogisticRegression<br/><br/>pd.set_option('display.max_columns', 300)</span></pre><p id="7f39" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">对于我的包，我使用pyforest作为我的通用包，并导入必要的sklearn包用于逻辑回归。</p><p id="645b" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">下一步是读入数据并检查数据集的形状和类型。</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="5e06" class="ky jg hi ku b fi kz la l lb lc">df = pd.read_csv('healthcare-dataset-stroke-data.csv')<br/>df.head()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es li"><img src="../Images/ed3e6f33d2d3408bc2ff8ba39068d287.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WNRkC4l_O7sO9ZrGrmacIw.png"/></div></div></figure><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="8c25" class="ky jg hi ku b fi kz la l lb lc">df.shape<br/>##########<br/>df.dtypes</span></pre><p id="95e3" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">在对数据集有所了解之后，下一步是检查空值。</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="5290" class="ky jg hi ku b fi kz la l lb lc">df.isna().sum()</span></pre><p id="ee65" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">bmi中有200个缺失值。因为丢失的值只占整个数据集的0.04%，所以我决定删除丢失的值。</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="dc53" class="ky jg hi ku b fi kz la l lb lc">df.dropna(inplace=True)</span></pre><h1 id="b043" class="jf jg hi bd jh ji jj jk jl jm jn jo jp io jq ip jr ir js is jt iu ju iv jv jw bi translated">下一步EDA</h1><p id="f2ba" class="pw-post-body-paragraph jx jy hi jz b ka kb ij kc kd ke im kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">在一些简单的清理之后，是时候将数据可视化并理解某些值是如何分布的了。</p><p id="9a07" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">首先是数据帧的散布矩阵。这是查看数据中是否有任何趋势的好方法。您还可以通过该图发现分类数据模式</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="a707" class="ky jg hi ku b fi kz la l lb lc">pd.plotting.scatter_matrix(df, figsize = [30,30]);<br/>plt.show()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es ln"><img src="../Images/fbc3f6e305715e4a99368671597ff016.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xoTUokmU4pj7NLPTBBTSOg.png"/></div></div></figure><p id="5ee7" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">通过该图，您可以看到每个特征之间的关系。</p><p id="0d10" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">接下来，我检查了特征的直方图分布。</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="5fa0" class="ky jg hi ku b fi kz la l lb lc">df.hist(bins=50, figsize=(20,15))<br/>plt.show()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es lo"><img src="../Images/8da3c18af5a1ae2cf4ebdb2f3add4d57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Y95dEYsyQDJ_VKvcBoxDA.png"/></div></div></figure><p id="0a10" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">这是查看是否有分类数据或连续数据的另一个好方法。您还可以使用这种可视化来查看潜在的异常值。</p><p id="8ab8" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">接下来是与目标变量相比的所有特征的散布矩阵。在这种情况下，目标变量是中风或没有中风。</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="851e" class="ky jg hi ku b fi kz la l lb lc">stroke_pred = df.drop(['id','stroke'],1)</span><span id="9d36" class="ky jg hi ku b fi lp la l lb lc">pd.plotting.scatter_matrix(stroke_pred, figsize = [30,30]);<br/>plt.show()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es lq"><img src="../Images/48eb1ecb82c4da03b7bb1e9a0e217952.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vJfoFnMkYa7QpaKr5J2OzA.png"/></div></div></figure><p id="5369" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">这是查看特征与目标变量的相关性中是否有任何清晰模式的最佳方式。</p><p id="8812" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">为了获得良好的测量结果，我还检查了预测要素之间是否存在共线性。</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="8bd2" class="ky jg hi ku b fi kz la l lb lc">stroke_pred.corr()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es lr"><img src="../Images/956f9044e85f8b9741dd061807f4f653.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mF6nOthi00qwYTZI6U5UgA.png"/></div></div></figure><p id="b114" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">为了更好地显示关联表，您可以将其绘制为热图</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="2bf4" class="ky jg hi ku b fi kz la l lb lc">sns.heatmap(stroke_pred.corr(), center=0);</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ls"><img src="../Images/3ac8b07ad53fd06f71593d7c822a8640.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*tge_VNYmRx9qQkzPwduBxg.png"/></div></figure><p id="feaa" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">这张热图表明所有的功能都是相互独立的。</p><p id="de2b" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">接下来让我们仔细看看目标变量的分布。</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="7e1c" class="ky jg hi ku b fi kz la l lb lc">sns.set_style('darkgrid')<br/>plt.figure(figsize = (10,5))<br/>sns.countplot(df['stroke'], alpha = 1, palette= ['aquamarine','magenta'])<br/>plt.title('Stroke Class')<br/>plt.ylabel('Patients')</span><span id="174a" class="ky jg hi ku b fi lp la l lb lc">plt.show()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lt"><img src="../Images/b51ce6c062a02d412c0ccba42980941f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*SpxBirGj68hBwr-r-b2gXQ.png"/></div></figure><p id="5ffe" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">这个数据集中存在着巨大的阶级不平衡。在检查了基线模型后，我将最大胆地解决未来模型的不平衡。</p><h1 id="09f5" class="jf jg hi bd jh ji jj jk jl jm jn jo jp io jq ip jr ir js is jt iu ju iv jv jw bi translated">为逻辑回归准备数据</h1><p id="f2c9" class="pw-post-body-paragraph jx jy hi jz b ka kb ij kc kd ke im kf kg kh ki kj kk kl km kn ko kp kq kr ks hb bi translated">在运行模型之前，我们需要对数据集做一些工作。数据集有几个包含分类字符串数据点的要素。这些不适用于逻辑回归，所以我们必须用二元选项来模拟这些特征。</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="9735" class="ky jg hi ku b fi kz la l lb lc">#Dummy catagories dataframe<br/>smoke_dummie = pd.get_dummies(df.smoking_status,prefix='smoker',drop_first=True)<br/>married_dummie = pd.get_dummies(df.ever_married,prefix='married',drop_first=True)<br/>work_dummie = pd.get_dummies(df.work_type,prefix='work',drop_first=True)<br/>residnece_dummie = pd.get_dummies(df.Residence_type,prefix='residence',drop_first=True)<br/>gender_dummie = pd.get_dummies(df.gender,prefix='gender',drop_first=True)</span><span id="dcf7" class="ky jg hi ku b fi lp la l lb lc">dummie_data = pd.concat([smoke_dummie,married_dummie,work_dummie],axis=1)</span><span id="7246" class="ky jg hi ku b fi lp la l lb lc">df_2 = df.drop(['work_type','ever_married',<br/>                  'Residence_type','smoking_status',<br/>                  'gender','id'],axis=1)</span><span id="8b2b" class="ky jg hi ku b fi lp la l lb lc">df_3 = pd.concat([df_2,dummie_data],axis=1)<br/>df_3.head()</span></pre><p id="3172" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">在这段代码中，我模拟了分类数据，删除了那些列，并将模拟数据连接到原始数据帧。</p><p id="70d9" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">我们的数据准备好了，是时候开始基线模型了。</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="9b11" class="ky jg hi ku b fi kz la l lb lc">X = df_3<br/>y= df.stroke</span><span id="61ec" class="ky jg hi ku b fi lp la l lb lc">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)</span></pre><p id="7030" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">首先我们做一个训练测试分割，这样我们就可以用测试集来衡量模型的有效性。</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="f17c" class="ky jg hi ku b fi kz la l lb lc">def evaluation(y_test, y_pred):<br/>    print('Accuracy: '  + str(metrics.accuracy_score(y_test, y_pred)))<br/>    print('Recall: ' + str(metrics.recall_score(y_test, y_pred)))<br/>    print('F1 Score: ' + str(metrics.f1_score(y_test, y_pred)))<br/>    print('Precision: ' + str(metrics.precision_score(y_test, y_pred)))</span></pre><p id="4dbe" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">这是一些评估指标的快速函数，现在是时候运行我们的逻辑回归基线模型了。</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="a6ae" class="ky jg hi ku b fi kz la l lb lc">lr = LogisticRegression()<br/>lr.fit(X_train,y_train)</span><span id="dbd3" class="ky jg hi ku b fi lp la l lb lc">y_pred = lr.predict(X_test)<br/>evaluation(y_test, y_pred)</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lu"><img src="../Images/f290ce4258bc7a17b69fd66ab54d86af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*4G2qJhLOHuqBjScVMku3GA.png"/></div></figure><p id="1e75" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">这个模型的指标非常高。这可能是由于分类不平衡造成的偏差，但这是创建有效中风风险分类模型的一个很好的切入点。</p><p id="74e0" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">在进行更深入的建模过程之前，我的最后一步是检查逻辑回归的系数权重。</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="945e" class="ky jg hi ku b fi kz la l lb lc">coef_table = pd.DataFrame(list(X_train.columns)).copy()<br/>coef_table.insert(len(coef_table.columns),"Coefs",lr.coef_.transpose())<br/>coef_table</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lv"><img src="../Images/dbdac0492b8aab891a5bc3e4d0398f49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*ybsw-euyjhFM38nQKJ1poQ.png"/></div></figure><p id="6986" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">从这个表中，我们可以看到逻辑回归的系数权重。从该表中可以看出，高血压、吸烟者吸烟和童工似乎是对分类影响最大的特征。</p><p id="81be" class="pw-post-body-paragraph jx jy hi jz b ka ld ij kc kd le im kf kg lf ki kj kk lg km kn ko lh kq kr ks hb bi translated">我希望你喜欢快速浏览一些简单的建模步骤。有一些更深入的数据清理和EDA可以做，但这些步骤应该足以让你快速基线模型。</p></div></div>    
</body>
</html>