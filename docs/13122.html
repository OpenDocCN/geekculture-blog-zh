<html>
<head>
<title>Exploring the Text Generation with OPT (Open Pre-trained Transformers)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">探索用OPT(开放预训练变压器)生成文本</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/exploring-the-text-generation-with-opt-open-pre-trained-transformers-989135756479?source=collection_archive---------16-----------------------#2022-06-18">https://medium.com/geekculture/exploring-the-text-generation-with-opt-open-pre-trained-transformers-989135756479?source=collection_archive---------16-----------------------#2022-06-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/97522e850ac2d89d750f270055254cbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KGqHdOv-aWy-Fxdx.jpg"/></div></div></figure><h1 id="b5bc" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">介绍</h1><p id="447f" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">脸书/meta AI已经推出了一个新的大型语言模型，它训练了数十亿个参数，称为OPT(开放式预训练变压器)，参数范围从125M到175B。它可以用于生成创造性的文本、解决简单的数学问题、回答阅读理解问题以及解决其他自然语言处理相关的问题。</p><p id="49d6" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们用OPT模型尝试了一些不同的东西来生成文本。按照下面的说明，我们将学习如何使用OPT-350M模型生成多达30个单词。</p><h1 id="8ba3" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">所需资源</h1><p id="a1b4" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我们在Google Colab pro上用一个GPU测试了125M、350M和1.3B模型，在两个T4 AWS GPU实例上测试了2.7模型。我们也尝试过测试6.7B模型，但是2个T4 GPU是不够的。</p><p id="0054" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">Colab Pro:</strong><br/>1.10 GB RAM<br/>2个vCPU <br/> T4 GPU</p><p id="c359" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> AWS实例:</strong> <br/> 8.89 GB RAM <br/> 32个vCPU <br/> 2个T4 GPU</p><h1 id="8a78" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">先决条件</h1><p id="6166" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在使用OPT模型之前，必须确保系统中安装了所有必需的软件包。执行以下操作来安装所有必需的软件包:</p><p id="bcb9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> 1。安装Pytorch </strong></p><pre class="kr ks kt ku fd kv kw kx bn ky kz bi"><span id="1b77" class="la ir hi kw b be lb lc l ld le">pip3 install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio==0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html</span></pre><p id="0a90" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> 2。安装威震天</strong></p><pre class="kr ks kt ku fd kv kw kx bn ky kz bi"><span id="ddac" class="la ir hi kw b be lb lc l ld le">git clone https://github.com/patrickvonplaten/Megatron-LM.git<br/>cd Megatron-LM<br/>pip3 install six regex<br/>pip3 install -e .</span></pre><p id="382a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> 3。安装公平秤</strong></p><pre class="kr ks kt ku fd kv kw kx bn ky kz bi"><span id="0138" class="la ir hi kw b be lb lc l ld le">pip install fairscale==0.4.1</span></pre><p id="6f37" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> 4。安装metaseq </strong></p><pre class="kr ks kt ku fd kv kw kx bn ky kz bi"><span id="a5b2" class="la ir hi kw b be lb lc l ld le">git clone https://github.com/patrickvonplaten/metaseq.git<br/>cd metaseq<br/>pip3 install -e .</span></pre><p id="536c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> 5。安装变压器</strong></p><pre class="kr ks kt ku fd kv kw kx bn ky kz bi"><span id="d850" class="la ir hi kw b be lb lc l ld le">pip install transformers</span></pre><h1 id="1c8c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">克隆模型的Github存储库</h1><p id="ad8b" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在我们的包成功安装之后，是时候克隆模型库了。在本教程中，我们将使用350M，您可以从<a class="ae lf" href="https://huggingface.co/models?other=opt_metasq" rel="noopener ugc nofollow" target="_blank"> OPT型号</a>中克隆您需要的模式回购，如下所示:</p><p id="81aa" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">要克隆350万型号的回购:</p><pre class="kr ks kt ku fd kv kw kx bn ky kz bi"><span id="3011" class="la ir hi kw b be lb lc l ld le">git lfs install<br/>git clone https://huggingface.co/patrickvonplaten/opt_metaseq_350m</span></pre><p id="0382" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">要克隆150万型号的回购:</p><pre class="kr ks kt ku fd kv kw kx bn ky kz bi"><span id="05ed" class="la ir hi kw b be lb lc l ld le">git lfs install<br/>git clone https://huggingface.co/patrickvonplaten/opt_metaseq_150m</span></pre><p id="f3d6" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">要克隆1.3B型号的回购:</p><pre class="kr ks kt ku fd kv kw kx bn ky kz bi"><span id="92c8" class="la ir hi kw b be lb lc l ld le">git lfs install<br/>git clone https://huggingface.co/patrickvonplaten/opt_metaseq_1300m</span></pre><p id="3338" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">要克隆2.7B型号的回购，请执行以下操作:</p><pre class="kr ks kt ku fd kv kw kx bn ky kz bi"><span id="d102" class="la ir hi kw b be lb lc l ld le">git lfs install<br/>git clone https://huggingface.co/patrickvonplaten/opt_metaseq_2700m</span></pre><h1 id="3e37" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">加载OPT模型并将其用于文本生成</h1><p id="fa8b" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">现在，我们将重点关注如何加载模型以及如何生成多达30个单词的下一个单词。请创建一个名为“run_model.py”的python文件，并将下面的代码粘贴到该文件中。</p><pre class="kr ks kt ku fd kv kw kx bn ky kz bi"><span id="d821" class="la ir hi kw b be lb lc l ld le">import os<br/>from transformers import AutoTokenizer, GPT2Tokenizer<br/>from megatron.initialize import initialize_megatron<br/>from metaseq import checkpoint_utils<br/>import torch<br/><br/>path = "/content/opt_metaseq_350m/model"<br/>metaseq_path = "/content/metaseq"<br/><br/># arguments taken from: https://arxiv.org/pdf/2205.01068.pdf | table 1<br/>initialize_megatron(args_defaults={<br/>    "micro_batch_size": 1, <br/>    "num_layers": 24, <br/>    "hidden_size": 1024, <br/>    "num_attention_heads": 16,<br/>    "max_position_embeddings": 2048, # TODO check if it is the correct args<br/>    "encoder_seq_length": 2048 # TODO check if it is the correct args<br/>})<br/><br/>tokenizer = GPT2Tokenizer.from_pretrained("facebook/bart-large")<br/>tokenizer.save_pretrained(path)<br/><br/>checkpoint = checkpoint_utils.load_model_ensemble_and_task(<br/>    [os.path.join(path, "reshard.pt")],<br/>#    [os.path.join(path, "reshard-model_part-0.pt"), os.path.join(path, "reshard-model_part-1.pt")],<br/>    arg_overrides={<br/>        "vocab_filename": os.path.join(path, "vocab.json"),<br/>        "merges_filename": os.path.join(path, "merges.txt"),<br/>    }<br/>)<br/><br/>model = checkpoint[0][0].eval()<br/>model.to('cuda')<br/>start = 'Natural language processing is a subfield of'<br/>indexed_tokens = tokenizer.encode(start)<br/>for i in range(30):<br/>  tokens_tensor = torch.tensor([indexed_tokens])<br/>  tokens_tensor = tokens_tensor.to('cuda')<br/>  with torch.no_grad():<br/>    outputs = model(tokens_tensor)<br/>    predictions = outputs[0]<br/>    predicted_index = torch.argmax(predictions[0, -1, :]).item()<br/>    # print(i,tokenizer.decode(predicted_index))<br/>    indexed_tokens = indexed_tokens + [predicted_index]<br/><br/>predicted_text = tokenizer.decode(indexed_tokens)<br/>print("------------------------------------")<br/>print(start)<br/>print("------------------------------------")<br/>print(predicted_text)Run the following command</span></pre><h1 id="2597" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">运行以下命令</h1><pre class="kr ks kt ku fd kv kw kx bn ky kz bi"><span id="8c7c" class="la ir hi kw b be lb lc l ld le">torchrun run_model.py --pipeline-model-parallel-size 1 --tensor-model-parallel-size 1 </span></pre><h1 id="ac82" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结果</h1><p id="9a13" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">结果将向我们显示我们使用350M提供的句子旁边可能出现的单词。输出应该如下图所示。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/d859dc9caa2d6c06ccca461f2683c987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4b5mh3C-xWirF-5A.png"/></div></div></figure><p id="38ea" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们将相同的文本作为输入，并对不同的模型进行测试。这是结果。</p><h1 id="3d87" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">OPT-125M的结果</h1><p id="bbd5" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">测试1:<br/>———<br/>输入:自然语言处理是<br/>———<br/>的一个子领域输出:自然语言处理是语言学的一个子领域4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090</p><p id="fe62" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">测试2:<br/>———<br/>输入:今天是美好的一天，我想<br/>————<br/>输出:今天是美好的一天，我想感谢所有参与的人！“惊呼4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090 4090</p><p id="c092" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">测试3:<br/>———<br/>输入:文本分类是一种机器学习技术<br/>—————<br/>输出:文本分类是一种机器学习技术，通过这种技术，算法基于从概率中导出的概率来计算概率，所述概率从概率中导出，所述概率从概率中导出，所述概率从概率中导出，所述概率从</p><h1 id="4953" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">OPT-350M的结果</h1><p id="a48c" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">— — — — <br/>输入:自然语言处理是<br/>———<br/>输出:自然语言处理是计算机科学的一个分支，专注于开发可用于处理和解释文本的计算机程序。<br/>使用术语“语言处理”</p><p id="0ca0" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">输入:今天是美好的一天，我想……输出:今天是美好的一天，我想感谢你为我们做的一切。我爱你。我爱你。我爱你。我爱</p><p id="a32e" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">— — — — <br/>输入:文本分类是一种机器学习技术<br/>———<br/>输出:文本分类是一种机器学习技术，利用机器学习对数据进行分类。分类过程基于使用一组规则对数据进行的分类。分类过程基于</p><h1 id="5a67" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">OPT-1.3B的结果</h1><p id="5aa7" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">— — — — <br/>输入:自然语言处理是<br/>———<br/>输出:自然语言处理是机器学习的一个子领域，它使用人工智能技术分析文本文档，从中提取含义。自然语言处理技术用于分析诸如电子邮件的文本文档</p><p id="c074" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">输入:今天是美好的一天，我想分享一些我们昨天下午去约塞米蒂山谷旅行的照片。我们从约塞米蒂瀑布路开车到约塞米蒂山谷路，停在约塞米蒂瀑布路停车场</p><p id="8904" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">— — — — <br/>输入:文本分类是一种机器学习技术<br/>————<br/>输出:文本分类是一种机器学习技术，它使用统计模型来识别数据集中的模式。分类算法基于数据集之间的相似性对数据集进行分类。分类算法基于相似性对数据集进行分类</p><h1 id="9d2b" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">OPT-2.7B的结果</h1><p id="bd54" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">输入:自然语言处理是<br/>———<br/>的一个子领域输出:自然语言处理是人工智能的一个子领域，涉及将语言翻译成可理解的形式。不同文化中的语言差异很大，不同语言中的语言差异也很大。不同文化中的语言差异很大，语言也各不相同</p><p id="0c19" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">— — — — <br/>输入:今天是美好的一天，我想<br/>———<br/>输出:今天是美好的一天，我想和你一起庆祝！她对他灿烂地笑了笑。他感激地回以微笑。他们一起向湖边的小路走去</p><p id="a48a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">— — — — <br/>输入:文本分类是一种机器学习技术<br/>———<br/>输出:文本分类是一种机器学习技术，计算机根据从安装在汽车顶部的摄像机捕获的图像中提取的属性对对象进行分类。分类算法基于从摄像机捕获的图像中提取的属性对对象进行分类</p><p id="ae43" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们希望您喜欢我们的OPT模型实验，现在您能够按照给定的步骤生成文本。如果您在遵循该文档时遇到任何问题，请在下面评论。我们正在进一步利用OPT模型生成更多的文本，并对其进行微调。</p></div><div class="ab cl lg lh gp li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="hb hc hd he hf"><p id="999b" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><em class="ln">原载于2022年6月18日</em> <a class="ae lf" href="https://www.pragnakalp.com/exploring-the-text-generation-with-opt-open-pre-trained-transformers/" rel="noopener ugc nofollow" target="_blank"> <em class="ln">用OPT(打开预训练变形金刚)</em> </a> <em class="ln">探索文本生成。</em></p></div></div>    
</body>
</html>