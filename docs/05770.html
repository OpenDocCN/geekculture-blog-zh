<html>
<head>
<title>Multi-armed Bandits Part III: Thompson Sampling based on Bayesian Posterior Probability</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多武装匪徒第三部分:基于贝叶斯后验概率的汤普森抽样</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/multi-armed-bandits-thompson-sampling-based-on-bayesian-posterior-probability-6decec423a2d?source=collection_archive---------22-----------------------#2021-07-29">https://medium.com/geekculture/multi-armed-bandits-thompson-sampling-based-on-bayesian-posterior-probability-6decec423a2d?source=collection_archive---------22-----------------------#2021-07-29</a></blockquote><div><div class="ds hc hd he hf hg"/><div class="hh hi hj hk hl"><div class=""/><figure class="ev ex im in io ip er es paragraph-image"><div role="button" tabindex="0" class="iq ir di is bf it"><div class="er es il"><img src="../Images/6ec4a5ec4d215a4ec20404d5e2a368af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*whuIGuGQ-1-qKvGHg_gSUA.png"/></div></div></figure><p id="63a5" class="pw-post-body-paragraph iw ix ho iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hh bi translated">在前一节:<a class="ae ju" rel="noopener" href="/@thomaszyang/multi-armed-bandits-what-is-upper-confidence-bound-ucb-algorithm-d72add30ee78">多武装匪徒:什么是置信上限(UCB)算法</a>，我们基于赫夫丁不等式实现了一个非常一般的估计。这主要是因为我们没有对报酬分布做任何先验假设。如果我们能预先做一些假设，我们肯定能做出更好的界限估计。</p></div></div>    
</body>
</html>