<html>
<head>
<title>The NLP Cypher | 07.04.21</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP密码| 07.04.21</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/the-nlp-cypher-07-04-21-f1d45e3d5df1?source=collection_archive---------24-----------------------#2021-07-04">https://medium.com/geekculture/the-nlp-cypher-07-04-21-f1d45e3d5df1?source=collection_archive---------24-----------------------#2021-07-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/5e16c532939a8352c8dcf0e827f71907.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yHGS7LJdbMqVVKqA.jpg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">Stellaris Art</figcaption></figure><h2 id="477a" class="hv hw hx bd b fp hy hz ia ib ic id dx ie translated" aria-label="kicker paragraph">自然语言处理每周时事通讯</h2><div class=""/><div class=""><h2 id="e1cf" class="pw-subtitle-paragraph jd ig hx bd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju dx translated">老鹰敢去的地方🦅</h2></div></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><p id="ef77" class="pw-post-body-paragraph kc kd hx ke b kf kg jh kh ki kj jk kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated">嘿欢迎回来！我想祝所有美国人7月4日快乐🎆🎇！此外，我想快速提一下，NLP指数的规模已经翻了一番(自成立以来)，现在拥有超过6，000个回购，非常酷！！！😎和往常一样，它每周都会更新。但首先，本周我们问了100名NLP开发者:说出微软为GitHub支付75亿美元，为OpenAI支付10亿美元得到的一件事？调查显示:</p><figure class="ky kz la lb fd hk"><div class="bz dy l di"><div class="lc ld l"/></div></figure><p id="cecb" class="pw-post-body-paragraph kc kd hx ke b kf kg jh kh ki kj jk kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated">7.5B + 1B = GitHub副驾驶👍</p><p id="d419" class="pw-post-body-paragraph kc kd hx ke b kf kg jh kh ki kj jk kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated">如果你想听GitHub对他们的新代码生成助手的看法，请点击这里:</p><div class="hh hi ez fb hj le"><a href="https://docs.github.com/en/github/copilot/research-recitation" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd ih fi z dy lj ea eb lk ed ef ig bi translated">研究朗诵</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">作者:Albert Ziegler (@wunderalbert)首先看看GitHub Copilot建议中的死记硬背。GitHub Copilot是…</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">docs.github.com</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls hp le"/></div></div></a></div><p id="7041" class="pw-post-body-paragraph kc kd hx ke b kf kg jh kh ki kj jk kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated">还有…原来副驾驶是个连环杀手👀，但至少代码是可读的。💪</p><figure class="ky kz la lb fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lt"><img src="../Images/17d56aec1036c02ae13eb33532ef4b79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ngD_OrclnAaSvZj6"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx">from <a class="ae lu" href="http://twitter.com/minimaxir" rel="noopener ugc nofollow" target="_blank">@minimaxir</a></figcaption></figure><h1 id="3613" class="lv lw hx bd lx ly lz ma mb mc md me mf jm mg jn mh jp mi jq mj js mk jt ml mm bi translated">微软的好东西中心</h1><p id="a7c8" class="pw-post-body-paragraph kc kd hx ke b kf mn jh kh ki mo jk kk kl mp kn ko kp mq kr ks kt mr kv kw kx hb bi translated">嘿，你知道微软在他们的仓库里藏了一堆模型吗？包括NLU、文档理解、跨语言等等。如果您对这些模型感兴趣，请访问本页:</p><blockquote class="ms mt mu"><p id="0255" class="kc kd mv ke b kf kg jh kh ki kj jk kk mw km kn ko mx kq kr ks my ku kv kw kx hb bi translated"><a class="ae lu" href="https://github.com/microsoft/unilm/tree/master/unilm" rel="noopener ugc nofollow" target="_blank"><em class="hx">UniLM</em></a><em class="hx">(</em><code class="du mz na nb nc b"><em class="hx">v1@NeurIPS'19 | v2@ICML'20 | v3@ACL'21</em></code><em class="hx">):语言理解和生成的统一预训练</em></p><p id="51cc" class="kc kd mv ke b kf kg jh kh ki kj jk kk mw km kn ko mx kq kr ks my ku kv kw kx hb bi translated"><a class="ae lu" href="https://github.com/microsoft/unilm/tree/master/infoxlm" rel="noopener ugc nofollow" target="_blank"><em class="hx">InfoXLM</em></a><em class="hx">(</em><code class="du mz na nb nc b"><em class="hx">v1@NAACL'21 | v2@ACL'21</em></code><em class="hx">):语言理解和生成的多语种/跨语种预训练模型</em></p><p id="2223" class="kc kd mv ke b kf kg jh kh ki kj jk kk mw km kn ko mx kq kr ks my ku kv kw kx hb bi translated"><a class="ae lu" href="https://github.com/microsoft/unilm/tree/master/deltalm" rel="noopener ugc nofollow" target="_blank"><em class="hx">DeltaLM</em></a><em class="hx">(</em><code class="du mz na nb nc b"><em class="hx">NEW</em></code><em class="hx">):通过扩充预训练的多语言编码器，为语言生成和翻译进行编码器-解码器预训练</em></p><p id="8c4b" class="kc kd mv ke b kf kg jh kh ki kj jk kk mw km kn ko mx kq kr ks my ku kv kw kx hb bi translated"><a class="ae lu" href="https://github.com/microsoft/unilm/tree/master/minilm" rel="noopener ugc nofollow" target="_blank"><em class="hx">MiniLM</em></a><em class="hx">(</em><code class="du mz na nb nc b"><em class="hx">v1@NeurIPS'20 | v2@ACL'21</em></code><em class="hx">):用于语言理解和生成的小型快速预训练模型</em></p><p id="2843" class="kc kd mv ke b kf kg jh kh ki kj jk kk mw km kn ko mx kq kr ks my ku kv kw kx hb bi translated"><a class="ae lu" href="https://github.com/microsoft/unilm/tree/master/adalm" rel="noopener ugc nofollow" target="_blank"><em class="hx">AdaLM</em></a><em class="hx">(</em><code class="du mz na nb nc b"><em class="hx">v1@ACL'21</em></code><em class="hx">):预训练模型的领域、语言、任务适配</em></p><p id="783c" class="kc kd mv ke b kf kg jh kh ki kj jk kk mw km kn ko mx kq kr ks my ku kv kw kx hb bi translated"><a class="ae lu" href="https://github.com/microsoft/unilm/tree/master/layoutlm" rel="noopener ugc nofollow" target="_blank"><em class="hx">layout lm</em></a><em class="hx">(</em><code class="du mz na nb nc b"><em class="hx">v1@KDD'20 | v2@ACL'21</em></code><em class="hx">):多模态(文本+布局/格式+图像)文档理解预训练(如扫描文档、PDF等。)</em></p><p id="ee4c" class="kc kd mv ke b kf kg jh kh ki kj jk kk mw km kn ko mx kq kr ks my ku kv kw kx hb bi translated"><a class="ae lu" href="https://github.com/microsoft/unilm/tree/master/layoutxlm" rel="noopener ugc nofollow" target="_blank"><em class="hx">layout xlm</em></a><em class="hx">(</em><code class="du mz na nb nc b"><em class="hx">NEW</em></code><em class="hx">):多模态(文本+布局/格式+图像)多语言文档理解预训练</em></p><p id="7321" class="kc kd mv ke b kf kg jh kh ki kj jk kk mw km kn ko mx kq kr ks my ku kv kw kx hb bi translated"><a class="ae lu" href="https://github.com/microsoft/unilm/tree/master/beit" rel="noopener ugc nofollow" target="_blank"> <em class="hx">拜特</em> </a> <em class="hx"> ( </em> <code class="du mz na nb nc b"><em class="hx">NEW</em></code> <em class="hx">):影像变形金刚的伯特预训</em></p><p id="b83d" class="kc kd mv ke b kf kg jh kh ki kj jk kk mw km kn ko mx kq kr ks my ku kv kw kx hb bi translated"><a class="ae lu" href="https://github.com/microsoft/unilm/tree/master/s2s-ft" rel="noopener ugc nofollow" target="_blank"> <em class="hx"> s2s-ft </em> </a> <em class="hx">:序列间微调工具包</em></p><p id="61e7" class="kc kd mv ke b kf kg jh kh ki kj jk kk mw km kn ko mx kq kr ks my ku kv kw kx hb bi translated"><a class="ae lu" href="https://github.com/microsoft/unilm/tree/master/xlmt" rel="noopener ugc nofollow" target="_blank"><em class="hx">XLM-T</em></a><em class="hx">(</em><code class="du mz na nb nc b"><em class="hx">NEW</em></code><em class="hx">):多语言NMT，带预训练跨语言编码器</em></p></blockquote><div class="hh hi ez fb hj le"><a href="https://github.com/microsoft/unilm" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd ih fi z dy lj ea eb lk ed ef ig bi translated">微软/unilm</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">跨任务(理解、生成和翻译)、语言和模态的预训练模型</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">github.com</p></div></div><div class="ln l"><div class="nd l lp lq lr ln ls hp le"/></div></div></a></div><h1 id="92ac" class="lv lw hx bd lx ly lz ma mb mc md me mf jm mg jn mh jp mi jq mj js mk jt ml mm bi translated">使用冻结语言模型的多模态少镜头学习</h1><p id="451b" class="pw-post-body-paragraph kc kd hx ke b kf mn jh kh ki mo jk kk kl mp kn ko kp mq kr ks kt mr kv kw kx hb bi translated">DeepMind采用了GPT 3等模型的少量学习能力，并应用于多模态领域。</p><figure class="ky kz la lb fd hk"><div class="bz dy l di"><div class="ne ld l"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><a class="ae lu" href="https://arxiv.org/pdf/2106.13884.pdf" rel="noopener ugc nofollow" target="_blank">LINK</a></figcaption></figure><h1 id="de87" class="lv lw hx bd lx ly lz ma mb mc md me mf jm mg jn mh jp mi jq mj js mk jt ml mm bi translated">拥抱脸课程笔记摘要</h1><p id="e2e6" class="pw-post-body-paragraph kc kd hx ke b kf mn jh kh ki mo jk kk kl mp kn ko kp mq kr ks kt mr kv kw kx hb bi translated">HF的自由变压器NLP课程概述；</p><ul class=""><li id="712d" class="nf ng hx ke b kf kg ki kj kl nh kp ni kt nj kx nk nl nm nn bi translated"><a class="ae lu" href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html#Chapter-0-(Setup):" rel="noopener ugc nofollow" target="_blank">第0章(设置):</a></li><li id="5f61" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><a class="ae lu" href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html#Chapter-1" rel="noopener ugc nofollow" target="_blank">第一章</a></li><li id="c90c" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><a class="ae lu" href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html#Introduction" rel="noopener ugc nofollow" target="_blank">简介</a></li><li id="7bda" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><a class="ae lu" href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html#Natural-Language-Processing" rel="noopener ugc nofollow" target="_blank">自然语言处理</a></li><li id="fba1" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><a class="ae lu" href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html#Transformers,-what-can-they-do?" rel="noopener ugc nofollow" target="_blank">变形金刚，他们能做什么？</a></li><li id="4770" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><a class="ae lu" href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html#Working-with-Pipelines,-with-Sylvain" rel="noopener ugc nofollow" target="_blank">使用管道，使用Sylvain </a></li><li id="0cb1" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><a class="ae lu" href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html#Zero-Shot-Classification" rel="noopener ugc nofollow" target="_blank">零射击分类</a></li><li id="f48f" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><a class="ae lu" href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html#Text-Generation" rel="noopener ugc nofollow" target="_blank">文本生成</a></li><li id="e9cb" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><a class="ae lu" href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html#Use-any-model-from-the-Hub-in-a-pipeline" rel="noopener ugc nofollow" target="_blank">使用来自管道中枢的任何模型</a></li><li id="4821" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><a class="ae lu" href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html#Mask-Filling" rel="noopener ugc nofollow" target="_blank">面具填充</a></li><li id="2a86" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><a class="ae lu" href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html#Named-Entity-Recognition-(NER)" rel="noopener ugc nofollow" target="_blank">命名实体识别(NER) </a></li><li id="d223" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><a class="ae lu" href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html#Question-Answering-(QA)" rel="noopener ugc nofollow" target="_blank">问答(QA) </a></li><li id="321f" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><a class="ae lu" href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html#Summarization" rel="noopener ugc nofollow" target="_blank">总结</a></li><li id="d010" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><a class="ae lu" href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html#Translation" rel="noopener ugc nofollow" target="_blank">翻译</a></li></ul><div class="hh hi ez fb hj le"><a href="https://muellerzr.github.io/fastblog/huggingface/2021/06/14/HuggingFaceLesson1.html" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd ih fi z dy lj ea eb lk ed ef ig bi translated">拥抱脸课程笔记，第1章(和零)，第1部分</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">由于高频本身没有依赖性的要求，他们建议我们安装变压器[开发]所以它得到所有的…</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">muellerzr.github.io</p></div></div><div class="ln l"><div class="nt l lp lq lr ln ls hp le"/></div></div></a></div><h1 id="5d7b" class="lv lw hx bd lx ly lz ma mb mc md me mf jm mg jn mh jp mi jq mj js mk jt ml mm bi translated">变形金刚游戏攻略</h1><p id="cd0d" class="pw-post-body-paragraph kc kd hx ke b kf mn jh kh ki mo jk kk kl mp kn ko kp mq kr ks kt mr kv kw kx hb bi translated">Paperspace对视觉变形器内部工作原理的概述。</p><div class="hh hi ez fb hj le"><a href="https://blog.paperspace.com/vision-transformers/" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd ih fi z dy lj ea eb lk ed ef ig bi translated">视觉变形金刚解说| Paperspace博客</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">介绍了在该文件中，一个图像是值得16x16字:变压器的图像识别在规模，视觉…</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">blog.paperspace.com</p></div></div><div class="ln l"><div class="nu l lp lq lr ln ls hp le"/></div></div></a></div><h1 id="b849" class="lv lw hx bd lx ly lz ma mb mc md me mf jm mg jn mh jp mi jq mj js mk jt ml mm bi translated">用LM-BFF提示</h1><p id="a042" class="pw-post-body-paragraph kc kd hx ke b kf mn jh kh ki mo jk kk kl mp kn ko kp mq kr ks kt mr kv kw kx hb bi translated">在阅读了上面的DeepMind论文后，下面的文章很好地吻合了提示(谢谢GPT-3)。博客由<a class="ae lu" href="https://thegradient.pub/author/tianyu/" rel="noopener ugc nofollow" target="_blank">天宇高</a>撰写，其论文曾在ACL 2021上发表:</p><p id="60ed" class="pw-post-body-paragraph kc kd hx ke b kf kg jh kh ki kj jk kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated"><strong class="ke ih">论文【https://arxiv.org/pdf/2012.15723.pdf】:<a class="ae lu" href="https://arxiv.org/pdf/2012.15723.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></strong></p><p id="4065" class="pw-post-body-paragraph kc kd hx ke b kf kg jh kh ki kj jk kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated">论文讨论了一种新的用于小型模型的提示技术LM-BFF。</p><p id="bc0b" class="pw-post-body-paragraph kc kd hx ke b kf kg jh kh ki kj jk kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated"><strong class="ke ih">渐变博客</strong></p><div class="hh hi ez fb hj le"><a href="https://thegradient.pub/prompting/" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd ih fi z dy lj ea eb lk ed ef ig bi translated">提示:为NLP任务使用语言模型的更好方法</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">从BERT ( Devlin等人，2019年)开始，微调预训练语言模型(LMs ),以特定任务为导向…</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">thegradient.pub</p></div></div><div class="ln l"><div class="nv l lp lq lr ln ls hp le"/></div></div></a></div><p id="e011" class="pw-post-body-paragraph kc kd hx ke b kf kg jh kh ki kj jk kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated"><strong class="ke ih">代码</strong></p><div class="hh hi ez fb hj le"><a href="https://github.com/princeton-nlp/LM-BFF" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd ih fi z dy lj ea eb lk ed ef ig bi translated">普林斯顿-nlp/LM-BFF</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">这是论文的实现，使预先训练的语言模型更好的少镜头学习者。LM-BFF简称…</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">github.com</p></div></div><div class="ln l"><div class="nw l lp lq lr ln ls hp le"/></div></div></a></div><h1 id="628b" class="lv lw hx bd lx ly lz ma mb mc md me mf jm mg jn mh jp mi jq mj js mk jt ml mm bi translated">70多个Python项目</h1><p id="268b" class="pw-post-body-paragraph kc kd hx ke b kf mn jh kh ki mo jk kk kl mp kn ko kp mq kr ks kt mr kv kw kx hb bi translated">一个Python项目教程的集合，范围从web报废、构建区块链、人脸检测、构建自己的密码等等…</p><div class="hh hi ez fb hj le"><a href="https://www.theinsaneapp.com/2021/06/list-of-python-projects-with-source-code-and-tutorials.html" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd ih fi z dy lj ea eb lk ed ef ig bi translated">70多个Python项目，面向初学者、中级和有经验的开发人员</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">👉使用Python的比特币价格通知本项目摘要:在本项目中，您将了解HTTP请求…</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">www.theinsaneapp.com</p></div></div><div class="ln l"><div class="nx l lp lq lr ln ls hp le"/></div></div></a></div><h1 id="4780" class="lv lw hx bd lx ly lz ma mb mc md me mf jm mg jn mh jp mi jq mj js mk jt ml mm bi translated">回购密码👨‍💻</h1><h2 id="3da0" class="ny lw hx bd lx nz oa ob mb oc od oe mf kl of og mh kp oh oi mj kt oj ok ml id bi translated">一组最近发布的回购引起了我们的关注👁</h2></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><h2 id="7191" class="ny lw hx bd lx nz oa ob mb oc od oe mf kl of og mh kp oh oi mj kt oj ok ml id bi translated"><a class="ae lu" href="https://arxiv.org/pdf/2106.12672.pdf" rel="noopener ugc nofollow" target="_blank"> Charformer </a></h2><blockquote class="ms mt mu"><p id="9ebc" class="kc kd mv ke b kf kg jh kh ki kj jk kk mw km kn ko mx kq kr ks my ku kv kw kx hb bi translated">一种无标记转换器模型，在字节级集成了基于梯度的子词标记化(GBST)。在GLUE基准测试中，它的表现与亚世界级别的变形金刚不相上下(有时甚至击败它们)，尽管速度要快得多。</p></blockquote><div class="hh hi ez fb hj le"><a href="https://github.com/google-research/google-research/tree/master/charformer" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd ih fi z dy lj ea eb lk ed ef ig bi translated">谷歌研究/谷歌研究</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">这个库包含Charformer:快速字符转换器的网格张量流实现。</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">github.com</p></div></div><div class="ln l"><div class="ol l lp lq lr ln ls hp le"/></div></div></a></div><p id="7f05" class="pw-post-body-paragraph kc kd hx ke b kf kg jh kh ki kj jk kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated"><a class="ae lu" href="https://www.connectedpapers.com/main/55bcfdd926f065be5c7066902280be4c080234af/Charformer-Fast-Character-Transformers-via-Gradientbased-Subword-Tokenization/graph" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ih">连接论文</strong> </a>📈</p><h2 id="affe" class="ny lw hx bd lx nz oa ob mb oc od oe mf kl of og mh kp oh oi mj kt oj ok ml id bi translated"><a class="ae lu" href="https://arxiv.org/pdf/2106.16163.pdf" rel="noopener ugc nofollow" target="_blank">多栏</a></h2><blockquote class="ms mt mu"><p id="0b57" class="kc kd mv ke b kf kg jh kh ki kj jk kk mw km kn ko mx kq kr ks my ku kv kw kx hb bi translated">具体而言，该版本包括三个部分:</p></blockquote><ul class=""><li id="f500" class="nf ng hx ke b kf kg ki kj kl nh kp ni kt nj kx nk nl nm nn bi translated"><em class="mv">一组25个基于BERT的模型(英文，无大小写)，使用相同的超参数但不同的随机种子进行训练。</em></li><li id="abde" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><em class="mv">对于前五个模型，在预训练过程中捕获了28个检查点(总共140个检查点)。</em></li><li id="c145" class="nf ng hx ke b kf no ki np kl nq kp nr kt ns kx nk nl nm nn bi translated"><em class="mv">一个统计库和一个演示其使用的Colab笔记本。</em></li></ul><div class="hh hi ez fb hj le"><a href="https://github.com/google-research/language/tree/master/language/multiberts" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd ih fi z dy lj ea eb lk ed ef ig bi translated">谷歌-研究/语言</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">MultiBERTs是一个检查点集合和一个统计库，用于支持对BERT的稳健研究。特别是…</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">github.com</p></div></div><div class="ln l"><div class="om l lp lq lr ln ls hp le"/></div></div></a></div><p id="57f1" class="pw-post-body-paragraph kc kd hx ke b kf kg jh kh ki kj jk kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated"><a class="ae lu" href="https://www.connectedpapers.com/main/646fc03a20a6a00304d9768621a8b864aa769f21" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ih">连接论文</strong> </a> <strong class="ke ih">📈</strong></p></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><h2 id="febb" class="ny lw hx bd lx nz oa ob mb oc od oe mf kl of og mh kp oh oi mj kt oj ok ml id bi translated"><a class="ae lu" href="https://arxiv.org/pdf/2106.15561.pdf" rel="noopener ugc nofollow" target="_blank">文本到语音转换调查</a></h2><figure class="ky kz la lb fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es on"><img src="../Images/be9856f9523ee87a417ed82cbf6dec12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mwhYDdRipm8kZTiZ.jpg"/></div></div></figure><div class="hh hi ez fb hj le"><a href="https://github.com/tts-tutorial/survey" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd ih fi z dy lj ea eb lk ed ef ig bi translated">TTS-教程/调查</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">许坦、陶秦、宋楚瑜、刘铁燕</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">github.com</p></div></div><div class="ln l"><div class="oo l lp lq lr ln ls hp le"/></div></div></a></div><p id="f6f8" class="pw-post-body-paragraph kc kd hx ke b kf kg jh kh ki kj jk kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated"><a class="ae lu" href="https://www.connectedpapers.com/main/35b69cdfde432872e06a22b0548a408ca66a7083" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ih">连接论文</strong> </a> <strong class="ke ih">📈</strong></p><h2 id="1fa0" class="ny lw hx bd lx nz oa ob mb oc od oe mf kl of og mh kp oh oi mj kt oj ok ml id bi translated"><a class="ae lu" href="https://arxiv.org/pdf/2106.13822.pdf" rel="noopener ugc nofollow" target="_blank">XL-Sum:44种语言的大规模多语言抽象摘要</a></h2><div class="hh hi ez fb hj le"><a href="https://github.com/csebuetnlp/xl-sum" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd ih fi z dy lj ea eb lk ed ef ig bi translated">csebuetnlp/xl-sum</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">这个存储库包含题为“XL-Sum:大规模多语言抽象…”的论文的代码、数据和模型</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">github.com</p></div></div><div class="ln l"><div class="op l lp lq lr ln ls hp le"/></div></div></a></div><p id="1daf" class="pw-post-body-paragraph kc kd hx ke b kf kg jh kh ki kj jk kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated"><a class="ae lu" href="https://www.connectedpapers.com/main/ecf5618b513aa5c4d5bf62ca251923a188251117" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ih">连接论文</strong> </a>📈</p></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><h2 id="45e4" class="ny lw hx bd lx nz oa ob mb oc od oe mf kl of og mh kp oh oi mj kt oj ok ml id bi translated"><a class="ae lu" href="https://arxiv.org/pdf/2106.14726.pdf" rel="noopener ugc nofollow" target="_blank">科学文献检索的关键词生成</a></h2><div class="hh hi ez fb hj le"><a href="https://github.com/boudinfl/ir-using-kg" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd ih fi z dy lj ea eb lk ed ef ig bi translated">boud infl/IR-使用-kg</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">这个库包含了从论文中复制实验的代码:科学的关键短语生成…</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">github.com</p></div></div><div class="ln l"><div class="oq l lp lq lr ln ls hp le"/></div></div></a></div><p id="9290" class="pw-post-body-paragraph kc kd hx ke b kf kg jh kh ki kj jk kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated"><a class="ae lu" href="https://www.connectedpapers.com/main/0077fd6a31cf638a316d35d50cb5e7d26c63dfc6" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ih">连接论文</strong> </a> <strong class="ke ih">📈</strong></p></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><h2 id="ff81" class="ny lw hx bd lx nz oa ob mb oc od oe mf kl of og mh kp oh oi mj kt oj ok ml id bi translated">本周数据集:</h2><p id="f695" class="pw-post-body-paragraph kc kd hx ke b kf mn jh kh ki mo jk kk kl mp kn ko kp mq kr ks kt mr kv kw kx hb bi translated">行动基因组问答(AGQA)</p><h2 id="80c7" class="ny lw hx bd lx nz oa ob mb oc od oe mf kl of og mh kp oh oi mj kt oj ok ml id bi translated">这是什么？</h2><p id="3a96" class="pw-post-body-paragraph kc kd hx ke b kf mn jh kh ki mo jk kk kl mp kn ko kp mq kr ks kt mr kv kw kx hb bi translated">组合时空推理的基准。AGQA <br/>包含9.6K <br/>视频的192M不平衡问答对。平均每个视频30秒。很长。</p><h2 id="c9a3" class="ny lw hx bd lx nz oa ob mb oc od oe mf kl of og mh kp oh oi mj kt oj ok ml id bi translated">样品</h2><figure class="ky kz la lb fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es or"><img src="../Images/44c0faaf4b19083b2e2069ebccdb4400.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_wW3QHmsACL1IMq_.jpg"/></div></div></figure><h2 id="e700" class="ny lw hx bd lx nz oa ob mb oc od oe mf kl of og mh kp oh oi mj kt oj ok ml id bi translated">它在哪里？</h2><p id="5637" class="pw-post-body-paragraph kc kd hx ke b kf mn jh kh ki mo jk kk kl mp kn ko kp mq kr ks kt mr kv kw kx hb bi translated"><strong class="ke ih">论文</strong>:<a class="ae lu" href="https://arxiv.org/pdf/2103.16002.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2103.16002.pdf</a></p><div class="hh hi ez fb hj le"><a href="https://cs.stanford.edu/people/ranjaykrishna/agqa/" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab dw"><div class="lg ab lh cl cj li"><h2 class="bd ih fi z dy lj ea eb lk ed ef ig bi translated">AGQA:组合时空推理的基准</h2><div class="ll l"><h3 class="bd b fi z dy lj ea eb lk ed ef dx translated">视觉事件是时间动作的组合，包括演员与物体的空间互动。当…</h3></div><div class="lm l"><p class="bd b fp z dy lj ea eb lk ed ef dx translated">cs.stanford.edu</p></div></div><div class="ln l"><div class="os l lp lq lr ln ls hp le"/></div></div></a></div></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><blockquote class="ot"><p id="b330" class="ou ov hx bd ow ox oy oz pa pb pc kx dx translated">每周日，我们都会对来自世界各地研究人员的NLP新闻和代码进行一次每周综述。</p><p id="8639" class="ou ov hx bd ow ox oy oz pa pb pc kx dx translated">如需完整报道，请关注我们的推特:<a class="ae lu" href="http://twitter.com/Quantum_Stat" rel="noopener ugc nofollow" target="_blank"> @Quantum_Stat </a></p></blockquote><figure class="pe pf pg ph pi hk er es paragraph-image"><div class="er es pd"><img src="../Images/605d15bdf547bb10223a0601abc84af6.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/0*vgf45g9haG4f6VcH"/></div><figcaption class="hr hs et er es ht hu bd b be z dx"><a class="ae lu" href="https://quantumstat.com/" rel="noopener ugc nofollow" target="_blank">Quantum Stat</a></figcaption></figure></div></div>    
</body>
</html>