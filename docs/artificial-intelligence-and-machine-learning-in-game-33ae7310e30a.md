# 游戏中的人工智能和机器学习

> 原文：<https://medium.com/geekculture/artificial-intelligence-and-machine-learning-in-game-33ae7310e30a?source=collection_archive---------13----------------------->

![](img/4dc097854900344361a1fb1666ef02fe.png)

Photo by [Pawel Kadysz](https://unsplash.com/@pawelkadysz?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

从童年开始，每当我看到有人玩任何种类的电子游戏，我就非常着迷。想想 20 年前，视频游戏虽然基于人工智能，但并不那么智能。我们大多数人都玩过马里奥、魂斗罗、吃豆人或者更多。这些游戏是基于某种算法，没有从错误中学习，在马里奥的情况下，我们必须完成某些任务，如收集硬币，从隐藏的敌人那里拯救我们自己，但是，如果在第一个例子中死亡，那么那些敌人的位置不会改变，机器没有从错误中学习，那个时代的游戏是无可挑剔的，但是后来它变得单调，玩家的胜率继续增加。

> 现在我们来谈谈技术术语:

**人工智能**

在字典中，人工智能被定义为“计算机或其他机器执行那些通常被认为需要智力的行为的能力。”人工智能，根据一些参考资料，是开发智能机器的过程或科学。

从不同的角度来看，人工智能可以被认为是由被构造的机器显示的智能行为，或者可能是负责智能行为的人工大脑。尽管如此，这也不是一个完整的解释。有些人认为，研究人工智能主要是为了更好地理解人类智能的本质，而不是为了开发智能计算机。

这就带来了“什么是智能”的问题根据一些人的说法，人工智能的真正衡量标准是它与人类智力的接近程度。另一些人认为机器必须满足额外的标准才能被称为智能的。一些人认为智力需要良心，情感与智力有着千丝万缕的联系，而另一些人则认为解决一个如果由人类来处理就需要智力的问题是不够的；人工智能还必须学习和适应，才能被视为智能。强人工智能被定义为满足所有这些标准的人工智能。与强人工智能相反，弱人工智能包括更广泛的应用和技术，以赋予机器专门的智能。弱 AI 是一个用来描述游戏 AI 的术语。

![](img/d55037aa3f4ce7ba8db3fd47e8c04803.png)

Photo by [Andrea De Santis](https://unsplash.com/@santesson89?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

**游戏中使用的 AI 类型:**

*   确定性——确定性性能或行为是预先确定和可预测的。没有任何歧义。基本的追踪算法是确定性行为的一个例子。通过沿着 x 和 y 坐标轴前进，直到角色的 x 和 y 坐标与目标位置相对应，可以指定将非玩家角色编码为向目标点前进。

游戏人工智能的面包和黄油是确定性的人工智能方法。这些技术易于构建、理解、测试和调试，因为它们是可预测的、快速的和简单的。尽管有这些好处，确定性方法将预测所有环境和明确编写所有行为的任务放在了开发人员的肩上。此外，确定性技术阻碍了学习和进化。确定性的活动在稍加实践后往往会变得可预测。从某种意义上说，这缩短了游戏的寿命。

*   不确定性——与确定性行为相对应的是不确定性行为。在行为中有一定程度的不确定性，而且有些不可预测(不确定性的程度取决于所采用的人工智能方法以及对该方法的理解程度)。非玩家角色学习适应玩家的战斗技术是非决定性行为的一个例子。在这种类型的学习中，可以使用神经网络、贝叶斯方法或遗传算法。

非确定性方法使学习和意外游戏变得更容易。此外，开发人员不需要在所有可能的实例前显式编码所有行为。不确定性方法也可以自己学习和推断，以及培养在没有明确指示的情况下发生的紧急行为。非确定性人工智能包括学习和对角色行为做出反应的方法。非确定性人工智能在许多流行的游戏中得到了应用，包括《生物》、《黑白》、《战列舰 3000AD》、《土路赛车》、《战场》和《重型装备》。他们的成功重新点燃了人们对人工智能技术的兴趣，如决策树、神经网络、遗传算法和概率方法。

***建立游戏中的 AI***

# 游戏——计算机处于优势——只要在这里想一想任何战争游戏，然后继续阅读。

![](img/92632728279dde84ae27ae09030fe36d.png)

Photo by [Sigmund](https://unsplash.com/@sigmund?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

*   ***作弊*** —作弊一直是游戏中使用最广泛的人工智能方法。例如，在一个战争模拟游戏中，计算机团队可以访问对手基地的所有信息；单位的类型、数量和位置等等，而不需要像人类玩家那样派出侦察兵。这种类型的作弊是经常发生的，它帮助机器在与聪明的人类游戏玩家的竞争中获得优势。

不平衡的作弊也会给计算机对手带来不公平的优势，使玩家不可能击败他们。如果玩家看到自己的努力是徒劳的，他很可能会失去兴趣。作弊必须被平衡，以便给玩家提供足够的挑战，让游戏变得有趣。

*   ***精细状态机*** —有限状态机(FSM)是一种抽象机器，可以存在于多个指定状态之一。有限状态机还可以为状态何时改变指定一组标准。状态机的行为由其当前状态决定。
    有限状态机从一开始就被用于电脑游戏。例如，《吃豆人》中的幽灵就是有限状态机。他们有完全的自由去探索、追逐或躲避玩家。它们在每个状态下的行为不同，它们的转换由玩家的活动决定。例如，如果玩家服用强力药丸，鬼魂的状态可能会从追逐变为躲避。这可以通过[马尔可夫模型](/analytics-vidhya/markov-chain-algorithm-in-sports-a54d086c155e)解释清楚。

马尔可夫回报过程(MRP)是一个马尔可夫模型，其中转换可能具有相关的回报或成本。具体来说，MRP 是一个元组(S，P，R，γ),其中 S 是状态集，P: S × S → [0，1]是转移函数，R: S × S → R 是与每个转移相关联的奖励函数，γ ∈ [0，1]是折扣因子。

一个板球击球手的例子，关于什么将是下一个国家的三个国家错过，出局和运行。

```
import numpy as np
class Cricket:# A function that implements the Markov model to forecast the state/mood.
    def batting_forecast(bowl):

            # The statespace
        states = ["Miss","Out","Run"]# Possible sequences of events
        transitionName = [["MM","MO","MR"],["OM","OR","OO"],["RM","RO","RR"]]# Probabilities matrix (transition matrix)
        transitionMatrix = [[0.2,0.6,0.2],[0.1,0.6,0.3],[0.2,0.7,0.1]]# Choose the starting state
        nextbowl = "Miss"
        print("Start state: " + nextbowl)
        # Shall store the sequence of states taken. So, this only has the starting state for now.
        activityList = [nextbowl]
        i = 0
        # To calculate the probability of the next bowl
        prob = 1
        while i != bowl:
            if nextbowl == "Miss":
                change = np.random.choice(transitionName[0],replace=True,p=transitionMatrix[0])
                if change == "MM":
                    prob = prob * 0.2
                    activityList.append("Miss")
                    pass
                elif change == "MO":
                    prob = prob * 0.6
                    nextbowl = "Out"
                    activityList.append("Out")
                else:
                    prob = prob * 0.2
                    nextbowl = "Run"
                    activityList.append("Run")
            elif nextbowl == "Out":
                change = np.random.choice(transitionName[1],replace=True,p=transitionMatrix[1])
                if change == "OM":
                    prob = prob * 0.5
                    activityList.append("Miss")
                    pass
                elif change == "OR":
                    prob = prob * 0.2
                    nextbowl = "Run"
                    activityList.append("Run")
                else:
                    prob = prob * 0.3
                    nextbowl = "Out"
                    activityList.append("Out")
            elif nextbowl == "Run":
                change = np.random.choice(transitionName[2],replace=True,p=transitionMatrix[2])
                if change == "RM":
                    prob = prob * 0.1
                    activityList.append("Miss")
                    pass
                elif change == "RO":
                    prob = prob * 0.2
                    nextbowl = "Out"
                    activityList.append("Out")
                else:
                    prob = prob * 0.7
                    nextbowl = "Run"
                    activityList.append("Run")
            i += 1  
        a = str(activityList)
        b = str(bowl) 
        c= nextbowl
        d =  str(prob)

        forecast = {"Possible states": a, "End state after": b, " activity": c,
                    "Probability of the possible sequence of states":d }

        return forecast
```

*   ***追逐与逃避—*** 追逐/逃避问题有两个要素。第一阶段包括决定是追捕还是逃跑。第二步是进行追逐或躲避，要么让你的捕食者接近猎物，要么让猎物在不被捕获的情况下尽可能远离捕食者。在某些方面，追逐/逃避的困境可以说有第三个组成部分:障碍回避。在追逐或逃跑时避开障碍物增加了算法的复杂性，使它们更难开发。
*   ***模式移动—*** 简单的模式移动可以用来创造智能行为的假象。本质上，计算机控制的人物以预定的方式移动，给人的印象是他们正在进行复杂的、计划周密的行动。

通常通过获取所需的模式并将控制数据编码到一个数组或一系列数组中来实现模式移动。控制数据由特定的移动指令组成，如前进和转弯，迫使计算机控制的对象或角色以适当的方式移动。您可以使用这些算法来制作圆形、方形、之字形、曲线或任何其他可以编码为一组简短运动指令的设计。

*   ***寻路—*** 寻路简单来说就是将游戏角色的位置从其初始位置移动到期望目的地的过程。

面包屑寻路 —因为玩家无意中为电脑控制的角色建立了路径，面包屑寻路可以让电脑控制的角色看起来非常复杂。玩家每走一步，都会在游戏世界中留下一个看不见的标记，或者面包屑。当一个游戏角色与面包屑互动时，面包屑只是跟着痕迹走。在到达玩家之前，游戏角色将跟随玩家的脚步。路径的复杂性和路线中障碍的数量并不重要。因为玩家已经创建了路径，所以不需要复杂的计算。

寻路是一个 CPU 密集型且耗时的过程。尽可能预先计算路径是缓解这一问题的一种方法。*航路点*导航通过在游戏环境中仔细建立节点，然后使用预先计算的路径或低成本的寻路方法在它们之间移动来解决这一挑战。

游戏内人工智能最根本的困难之一是寻路。寻路不好会让游戏角色显得机器人化，无脑。没有什么比游戏角色无法克服简单的障碍更能破坏游戏的沉浸感了。寻路是一个很难解决的话题，但它可能会让游戏对用户来说更有趣，更身临其境。

# A*算法

幸运的是，A*算法是寻路问题的可行解决方案。A*算法无疑是当今游戏中最广泛使用的寻路方法之一。A*方法很吸引人，因为它保证确定任何起点和终点之间的最佳路径，只要这样的路径存在。这也是一个相当有效的算法，这有助于它的吸引力。事实上，你应该尽可能地使用它，除非你正在处理一个独特的情况。

**步骤:**

1.  定义搜索区域
2.  开始搜索
3.  得分
4.  找到一个死胡同
5.  地形成本

在其最基本的版本中，典型的 A*算法只是基于行进的距离来计算路径成本。较长的路径被认为更昂贵，因此不太理想。一个好的寻路算法通常被认为是发现最短路径的算法。

*   ***模糊逻辑*** —模糊逻辑是一种向计算机提出问题的方式，类似于人解决问题的方式。模糊逻辑的核心思想是，一切都是程度的问题。当“以类似于人类解决问题的方式将问题交给计算机”时，这到底意味着什么？前提是人类经常以草率的方式评估情况或解决问题。我们可能没有所有的信息，或者事实可能是模糊的，或者我们可能只能在没有精确数据或测量的情况下概括事实。模糊逻辑允许你使用和你可能使用的语言词汇来提出和回答问题。

事实上，任何事情都可以用模糊逻辑来思考，并且在不同程度上是真实的。在模糊逻辑中，任何事情都是完全真实的，如果我们声明它在 1 度上是真实的。绝对错误是绝对正确。在模糊逻辑中，我们可以有绝对真实或完全不真实的东西，或者介于 0 和 1 之间的任何程度的东西。

模糊逻辑可以在游戏中以多种方式使用。模糊逻辑可以用来控制机器人或其他非玩家角色单元。你也可以用它来评估玩家造成的危害。此外，可以使用模糊逻辑对玩家和非玩家角色进行分类。

*   ***基于规则的人工智能***——对于现实世界和游戏人工智能应用来说，基于规则的人工智能系统可能是应用最广泛的人工智能系统。基于规则的系统由一系列 if-then 风格的规则组成，这些规则用于以最基本的形式进行推理或行动决策。

工作记忆和规则记忆是基于规则系统的两个主要组成部分。规则的断言和已知事实存储在工作记忆中。规则记忆，或简称为规则，是对工作记忆中的事实进行操作的 if-then 风格规则的集合。当规则被触发时，或者用基于规则的系统术语来说，它们可以执行一个动作或者改变系统的状态，例如在有限状态机中，或者它们可以通过添加新的断言来修改工作存储器的内容。

***正向链接*** 是基于规则的系统最常用的推理算法。这种方法有三个基本阶段。将规则与存储在工作记忆中的事实相匹配是初始阶段。这是通过将每个规则的 if 部分与存储在工作记忆中的事实或断言集进行比较来实现的。触发规则时，将执行规则的下一部分。在工作记忆中，不止一个规则可能与一组给定的事实相匹配。在这种情况下，我们必须确定撤销哪个规则。接下来是所谓的冲突解决阶段。我们必须在冲突解决阶段分析所有匹配的规则，并决定触发哪一个。

这个决定可以通过多种方式做出。通常首先触发第一个匹配规则。你有时可以随机选择一个。在其他情况下，将对规则进行排名，并选择得分最高的规则。在冲突解决步骤完成并且选择了一个规则之后，我们触发规则。规则的 then 部分只是在触发时执行。在工作记忆中，规则可能陈述一些新的事实。它可以启动一个事件或调用另一个函数来执行某种处理。重复该方法，直到在这三个阶段完成后不再有规则被触发。当这种情况发生时，工作记忆应该存储基于规则的系统根据初始事实可以推断出的任何东西。

***反向链接*** 是正向链接的反义词。我们仍然有工作记忆和规则记忆，但我们努力将规则的当时部分与工作记忆相匹配，而不是如果部分。换句话说，在反向链接中，我们从一个目的或目标开始，并试图找出必须触发哪些规则才能达到目的。

关于 ***神经网络*** 和**遗传算法**的一些附加术语

与游戏中更传统的人工智能技术相比，神经网络有许多优势。首先，通过将重要的决策过程委托给一个或多个经过训练的神经网络，游戏开发者可以简化复杂状态机或基于规则的系统的编码。其次，神经网络为游戏的人工智能提供了适应游戏的能力。

尽管有这些好处，神经网络仍然没有在视频游戏中广泛使用。虽然神经网络已经在一些流行的游戏中使用，但它们在游戏中的使用仍然有限。这很可能是由于许多变量，其中两个我将在下面讨论。

1.  神经网络擅长解决用标准方法难以解决的极端非线性问题。这使得很难准确掌握网络正在做什么，以及它是如何得到结果的，这对于一个潜在的测试人员来说是一个警告。
2.  预测神经网络将产生什么输出有时会很棘手，特别是如果网络是为了在游戏中学习或适应而构建的。由于这两个因素，测试和调试神经网络比测试和调试有限状态机更复杂。

为玩家提供高要求的游戏体验是游戏设计者的责任。在现实中，平衡游戏环境是游戏制作的重要组成部分。对参与者来说，它必须足够难，否则，游戏对他们来说会显得太容易，他们会失去兴趣。如果太有挑战性，另一方面，游戏玩家会感到沮丧。玩家有时可以找到漏洞，或利用，他们可以通过本质上的欺骗。这可能是游戏设计缺陷的结果，而制作者没有注意到。游戏设计的另一个问题是，不同玩家的技能水平可能非常不同。

为不同技能水平的玩家创造一个平衡且具有挑战性的游戏是一项艰巨的任务。 ***遗传算法*** ，幸好可以辅助。在真实的电脑游戏中，真实的基因模型不太可能有用或可行。相反，我们将要讨论的系统只是基于生物遗传系统。在某些方面是相似的，但是我们不会害怕违反规则。如果对游戏设计过程有利，规则可能会被打破。

你可以把**遗传算法**在游戏中的实现分解成四个步骤。

1.  第一代
2.  等级适合度
3.  选择
4.  演变

创造第一代是初始阶段。一组初始品质在整个群体中播种。当大众开始与周围环境互动时，我们需要对个体进行排序的方法。这就是你对自己健康状况的排名。这告诉我们人口中最成功的人。健康排名帮助我们进入下一个阶段，那就是选择。我们在选择过程中选择特定的个体来产生下一代。上一代人最成功的品质，本质上都是用来生产下一代的。进化是整合这些特征以产生新的、更健康的一代的过程。遗传算法本质上是优化过程，其中我们的目标是确定最合适的质量集，以便找到某个问题的最佳解决方案。

在任何计算机控制的对手必须根据玩家的活动做出反应和改变的情况下，遗传算法都是有价值的。

![](img/56de79e99ff757abad476e800f7653c7.png)

Photo by [WTFast](https://unsplash.com/@wtfast?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

**一些事实**，如果你在 PUBG 或使命召唤中玩过战场，在初始阶段会有一个游戏区域圈的形成，这个圈是使用 K-Means 聚类和类似的红区开发的。在游戏中，只有少数玩家是弱的——人工智能玩家，因为他们是弱学习者。在《使命召唤》中的死亡之战中，随着等级的上升，由于人工智能的影响，难度也随之上升。在童年早期，当你们玩真人快打的时候，很少有角色是很难被击败的，因为它是在人类通过的水平的基础上发展起来的，同样在国际足联，EA 板球，et Cetra。

**外卖:**

*   游戏中的人工智能
*   游戏中人工智能的类型
*   在游戏中建立人工智能
*   一些事实