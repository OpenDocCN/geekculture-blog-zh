<html>
<head>
<title>Deep Learning — ‘Hello World!’</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习——“你好，世界！”</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/deep-learning-a-to-z-part-2-mnist-the-hello-world-of-neural-networks-2429c4367086?source=collection_archive---------0-----------------------#2020-12-03">https://medium.com/geekculture/deep-learning-a-to-z-part-2-mnist-the-hello-world-of-neural-networks-2429c4367086?source=collection_archive---------0-----------------------#2020-12-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/03c4f5af2ff7afd1260c37402563464d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cx8P2_tLOhWPvXjIc2xP9A.jpeg"/></div></div></figure><p id="6e15" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是我上一篇文章的延续。如果你还没有读过，我强烈建议你先读一下，以获得深度学习概念的高层次概述。这是第一部分的链接(<a class="ae jo" href="https://srinivas-kulkarni.medium.com/deep-learning-a-to-z-part-1-1d5bd4e9944c" rel="noopener">深度学习——初学者指南</a>)</p><p id="cd7d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我本可以深入到激活函数、损失函数、优化器等更多的理论和数学部分。但是我认为，这是一个好主意，让我们动手实现第一个人工神经网络(ANN)来了解工具集。所以让我们开始吧。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="a291" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">安装软件和设置环境</h1><p id="c817" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb kw jd je jf kx jh ji jj ky jl jm jn hb bi translated">首先，您需要在您的计算机上安装Anaconda发行版。如果您还没有，请从<a class="ae jo" href="https://www.anaconda.com/products/individual" rel="noopener ugc nofollow" target="_blank"> Anaconda </a>网站下载。安装完成后，您需要设置环境。conda环境通常是一组相互兼容的相关软件。当您创建一个环境时，anaconda会创建一个目录，并将该环境的所有相关软件存储在该目录中。按照以下步骤创建环境。</p><ol class=""><li id="95b0" class="kz la hi is b it iu ix iy jb lb jf lc jj ld jn le lf lg lh bi translated">打开Anaconda提示符(默认环境显示为(base))并键入以下内容:</li></ol><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="a21a" class="lr jx hi ln b fi ls lt l lu lv">conda create -n helloworld python==3.6.9<strong class="ln hj"><br/></strong>conda activate helloworld</span></pre><p id="5d00" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="lw">你可以在这里</em>  <em class="lw">找到不同conda命令</em> <a class="ae jo" href="https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lw">的cheetsheet。</em></a></p><p id="d2c4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.一旦创建并激活了环境，您需要安装以下软件，这些软件是我们第一次实施ANN所需要的。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="c37d" class="lr jx hi ln b fi ls lt l lu lv">pip install jupyter<strong class="ln hj"><br/></strong>pip install pandas<br/>pip install matplotlib<br/>pip install seaborn<br/>pip install tensorflow</span></pre><p id="a0d0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上述软件的快速介绍。</p><p id="7e08" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"><em class="lw">Jupyter Notebook</em></strong><em class="lw"/>允许你编写现场代码，并与他人分享笔记本。今后你会经常用到它。</p><p id="eee1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lw">熊猫</em> </strong>是一个python数据分析库。关键数据结构是数据帧。</p><p id="4491" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lw"> Matplotlib </em> </strong>和<strong class="is hj"> <em class="lw"> Seaborn </em> </strong>是数据可视化库，对于探索性数据分析非常有效。</p><p id="8048" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lw"> Tensorflow </em> </strong>是Google开发的机器学习和深度学习库。默认情况下，它将安装tensorflow的第2版。请注意，tensorflow的b/w版本1和版本2略有不同。我建议你使用最新版本。</p><p id="eb6f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lw"> Keras </em> </strong>提供高级API，并与tensorflow 2集成。它是一个构建在tensorflow之上的API包装器。</p><p id="989b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.一旦所有的软件安装完毕，在anaconda提示符下输入<code class="du lx ly lz ln b">jupyter notebook</code>。这将打开一个浏览器窗口。右上方会有一个<em class="lw">【新建】</em>下拉。从下拉列表中选择<em class="lw">“Python 3”</em>。从文件菜单中选择<em class="lw">“另存为”</em>，将笔记本另存为“hello world”。您可以使用以下语句检查tensorflow和Keras的版本。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="be74" class="lr jx hi ln b fi ls lt l lu lv">import tensorflow as tf<br/>print(f"tensorflow version: {tf.__version__}")<br/>print(f"Keras version: {tf.keras.__version__}")</span></pre><p id="9a01" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你已经走了这么远，管道工程就完成了😌我们现在准备实现我们的第一个人工神经网络。但首先，让我们看看MNIST数据集。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="2e0f" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><strong class="ak"> MNIST数据集</strong></h1><p id="2c07" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb kw jd je jf kx jh ji jj ky jl jm jn hb bi translated">MNIST数据集包含60，000幅训练图像和10，000幅测试图像。数据集包含从0到9的手写数字。每个数据点是28×28大小的2D阵列。我们将使用这个数据集来训练我们的模型，以预测手写数字。这是数据集的视觉图像(来源:<a class="ae jo" href="https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png" rel="noopener ugc nofollow" target="_blank">维基百科</a>)</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/e7620493a3de60425cfd89c7d99be1f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*Ft2rLuO82eItlvJn5HOi9A.png"/></div><figcaption class="mb mc et er es md me bd b be z dx">Figure 1 — MNIST Dataset</figcaption></figure></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><h1 id="89d0" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated"><strong class="ak">我们的第一个安实现</strong></h1><p id="e595" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb kw jd je jf kx jh ji jj ky jl jm jn hb bi translated">现在，我们准备出发了😃我只是想让你知道，现在可能还有一些事情没有被很好地理解。我将试着简要地写一下它们。在接下来的文章中将会更详细地介绍它们。这里的目的是向您介绍深度学习工具集的世界以及如何使用它们。</p><p id="9fd0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">加载库并导入MINST数据集:</strong>第一步是加载库并导入数据集。MNIST数据集现在作为Keras数据集的一部分捆绑在一起。下面是执行此操作的代码:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="e2e7" class="lr jx hi ln b fi ls lt l lu lv">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd<br/>import os<br/>import tensorflow as tf<br/>import seaborn as sns</span><span id="c831" class="lr jx hi ln b fi mf lt l lu lv"># Step 1. Load train and test data set.<br/>mnist = tf.keras.datasets.mnist<br/>(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data() </span><span id="adc6" class="lr jx hi ln b fi mf lt l lu lv"># Step 2. check the size of training and test datasets print(X_train_full.dtype, "-", X_train_full.shape)<br/>print(y_train_full.dtype, "-", y_train_full.shape)<br/>print(X_test.dtype, "-", X_test.shape)<br/>print(y_test.dtype, "-", y_test.shape)</span><span id="729b" class="lr jx hi ln b fi mf lt l lu lv"># Step 3. Randomly check one of the data points.<br/>X_train_full[30]<br/>y_train_full[30]</span></pre><p id="8eb9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">代码是自我解释的，没有什么复杂的。当您执行<code class="du lx ly lz ln b">X_train_full[30],</code>时，它将显示一个28 X 28的2D数组，数值范围从b/w 0到255，因为每个数据点的大小都是28 X 28。<code class="du lx ly lz ln b">dtype</code>是<code class="du lx ly lz ln b">unit8</code>，它保存值b/w 0和255。</p><p id="736e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">缩放数据并创建验证集:</strong>下一步是缩放数据b/w 0和1并创建验证数据集。对于验证数据集，我们将把<code class="du lx ly lz ln b">X_train_full, y_train_full</code>分为<code class="du lx ly lz ln b">X_valid, X_train</code>和<code class="du lx ly lz ln b">y_valid, y_train</code>两组。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="3dbe" class="lr jx hi ln b fi ls lt l lu lv"># Scale the data b/w 0 and 1 by dividing it by 255 as its unsigned int<br/>X_train_full = X_train_full/255.<br/>X_test = X_test/255.</span><span id="e78c" class="lr jx hi ln b fi mf lt l lu lv"># View the matrix now. The values will be b/w 0 and 1 X_train_full[30]</span><span id="326f" class="lr jx hi ln b fi mf lt l lu lv"># Create the validation data from training data.<br/>X_valid, X_train = X_train_full[:5000], X_train_full[5000:]<br/>y_valid, y_train = y_train_full[:5000], y_train_full[5000:]</span><span id="b1d1" class="lr jx hi ln b fi mf lt l lu lv">X_train.shape<br/># should give o/p of (55000, 28, 28)</span><span id="39d1" class="lr jx hi ln b fi mf lt l lu lv">X_valid.shape<br/># should give o/p of (5000, 28, 28)</span></pre><p id="6be5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们有5000条记录的验证集和55000条记录的训练集。对了，我们到现在都没用过matplotlib和seaborn。让我们用它们来看看朱庇特笔记本中的图像。执行下面的代码来查看实际图像的输出以及图像的热图。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="bca3" class="lr jx hi ln b fi ls lt l lu lv"># view the actual image at index 30<br/>plt.imshow(X_train[30], cmap='binary')</span></pre><p id="9187" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上面的输出将如下所示:</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/f87bb2f41ca4fb43891679552c5ccd15.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*OoIh4no0GoV_sG4VhEb_vw.png"/></div><figcaption class="mb mc et er es md me bd b be z dx">Figure 2: visual image at index 30</figcaption></figure><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="6046" class="lr jx hi ln b fi ls lt l lu lv"># Lets look at the pixels in detail using SNS</span><span id="fd28" class="lr jx hi ln b fi mf lt l lu lv">plt.figure(figsize=(15,15))<br/>sns.heatmap(X_train[30], annot=True, cmap='binary')</span></pre><p id="df5c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这段代码显示了完整的28 X 28网格，每个像素的数据如下。</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es mh"><img src="../Images/d5f56a458d91325fa25d3ec0b226a911.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*t--5f0uHKovfeWZUlqfamw.png"/></div><figcaption class="mb mc et er es md me bd b be z dx">Figure 3: Pixel view of the image</figcaption></figure><p id="8672" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">模型构建:</strong>现在是时候构建我们的模型了。我第一篇文章中的概念将有助于更好地理解它。下面是构建模型的代码。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="aff6" class="lr jx hi ln b fi ls lt l lu lv"># lets create the model<br/># Flatten = make the array to sequential layer<br/># Dense = creating a hidden OR output layer</span><span id="bc53" class="lr jx hi ln b fi mf lt l lu lv">LAYERS = [tf.keras.layers.Flatten(input_shape=[28,28],<br/>name="inputLayer"),<br/>         tf.keras.layers.Dense(300, activation="relu", name="hiddenLayer1"),<br/>         tf.keras.layers.Dense(100, activation="relu", name="hiddenLayer2"),<br/>         tf.keras.layers.Dense(10, activation="softmax", name="outputLayer")]</span><span id="6382" class="lr jx hi ln b fi mf lt l lu lv">model = tf.keras.models.Sequential(LAYERS)</span></pre><p id="6211" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里发生了很多事情。让我解释一下</p><p id="0404" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输入层:我们已经展平了28 X 28的输入矩阵。这意味着每幅图像将有28 x 28 = 784个输入值。</p><p id="7b24" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">隐藏层:我们使用“密集”来创建隐藏和输出层。在上面的代码中，我们创建了两个隐藏层。我们在隐藏层1和2中有300和100个神经元。这些只是我选的随机值。现在，您可以选择任何其他值。在后面的教程中，我将展示如何使用Keras tuner获得这些值。我在隐藏层中使用“relu”激活功能。再说一次，从现在开始就这样做。随着我们对激活函数的了解，我们会发现更多的激活函数。</p><p id="90eb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输出层:输出层有10个神经元，因为我们的数据集中有值b/w 0和9。由于我们正在处理多类分类问题，所以我们在输出层使用“softmax”作为激活。</p><p id="013c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你可以想象我们的神经网络如下:</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/da872e87ef9ee16b96d8e6e6d7bfa9d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*dztDg7mB2zes2p9CZxeY6Q.png"/></div><figcaption class="mb mc et er es md me bd b be z dx">Figure 4: Deep neural network with 2 hidden layers</figcaption></figure><p id="7c19" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们看看模型的概要。它有很多信息需要消化。执行jupyter笔记本中的代码<code class="du lx ly lz ln b">model.summary()</code>。您应该会看到下面的输出。</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/ba942ca6ce69c869136c858ec72ce06d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*6qo0N_b-xK8d0vJNKClmog.png"/></div><figcaption class="mb mc et er es md me bd b be z dx">Figure 5: Model Summary</figcaption></figure><p id="46fb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它显示了3列。“层”列显示了层的名称。“输出形状”栏显示每层中的神经元数量。“Param #”是需要理解的列。里面有一些随机数。让我解释一下。</p><p id="b430" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Param #是权重和偏差的计算。在hiddenLayer1中，我们有300个神经元从inputLayer的784个神经元接收输入。这意味着我们有300 X 784 = 235200个重量。偏差等于该层中神经元的数量。在hiddenLayer1，是300。所以，如果你把权重和偏差加起来，你会得到235500 (235200 + 300)。类似地，其他层的值可以计算如下:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="e456" class="lr jx hi ln b fi ls lt l lu lv"># Param # (Nodes in layer A * Nodes in layer B + Bias)<br/># hiddenLayer1 = 784*300 + 300 = 235500<br/># hiddenLayer2 = 300*100 + 100 = 30100<br/># outputLayer = 100*10 + 10 = 1010</span><span id="75bb" class="lr jx hi ln b fi mf lt l lu lv"># Trainable Params = 235500 + 30100 + 1010 = 266610</span></pre><p id="50d5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">可训练参数是可以被修改以训练模型的权重和偏差的总数。如果你把以上数字加起来，你会得到266，610。我希望这一点现在已经非常清楚了。让我们继续。</p><p id="c94e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">权重和偏差:</strong>让我们来看看权重和偏差。我们可以使用下面的代码来查看初始分配的权重和偏差。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="8b04" class="lr jx hi ln b fi ls lt l lu lv">hidden1 = model.layers[1]<br/>weights, biases = hidden1.get_weights()</span><span id="4113" class="lr jx hi ln b fi mf lt l lu lv">#weights should be a metrics of 784 X 300 and biases should be 300<br/>weights.shape<br/>biases.shape</span><span id="633a" class="lr jx hi ln b fi mf lt l lu lv">print(weights)<br/>print(biases)</span></pre><p id="e87f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当您执行print语句时，您将看到权重的随机值和所有偏差的0值。当模型在反向传播期间开始学习时，这些信息被更新。</p><p id="0a96" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">损失函数，反向传播优化器:</strong>我们现在需要定义反向传播的操作。我们需要设置要使用的损失函数、更新权重和偏差的优化器以及准确性的度量标准。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="dc31" class="lr jx hi ln b fi ls lt l lu lv">LOSS_FUNCTION = "sparse_categorical_crossentropy"<br/>OPTIMIZER = "SGD"<br/>METRICS = ["accuracy"]</span><span id="672b" class="lr jx hi ln b fi mf lt l lu lv">model.compile(loss=LOSS_FUNCTION,<br/>             optimizer=OPTIMIZER,<br/>             metrics=METRICS)</span></pre><p id="ab17" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我使用<code class="du lx ly lz ln b">sparse_catagorical_crossentropy</code>作为损失函数，使用<code class="du lx ly lz ln b">stochastic gradient descent</code>作为优化器。我将在以后的文章中写更多关于这些的内容。指标指定了我们想要用来作为评估模型性能的度量的参数。一旦所有这些都选择好了，我们就在模型上调用编译方法。</p><p id="d3e2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">模特训练:</strong>是时候训练我们的模特了，看看她的表现如何。我们需要理解一个新术语，它叫做纪元。简单地说，epoch是模型在训练期间必须被评估的次数。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="c11f" class="lr jx hi ln b fi ls lt l lu lv">EPOCHS = 30<br/>VALIDATION_SET = (X_valid, y_valid)</span><span id="1b55" class="lr jx hi ln b fi mf lt l lu lv">history = model.fit(X_train, y_train, epochs=EPOCHS,<br/>                   validation_data=VALIDATION_SET)</span></pre><p id="eede" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的代码中，我们定义了30个历元，这意味着模型必须进行30次正向传播和反向传播。验证集用于对照训练数据集验证模型。当执行代码时，您将看到如下输出:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="9940" class="lr jx hi ln b fi ls lt l lu lv">Epoch 1/30<br/>1719/1719 [==============================] - 5s 3ms/step - loss: 0.6110 - accuracy: 0.8479 - val_loss: 0.3095 - val_accuracy: 0.9162<br/>Epoch 2/30<br/>1719/1719 [==============================] - 5s 3ms/step - loss: 0.2867 - accuracy: 0.9175 - val_loss: 0.2354 - val_accuracy: 0.9360<br/>Epoch 3/30<br/>1719/1719 [==============================] - 5s 3ms/step - loss: 0.2328 - accuracy: 0.9341 - val_loss: 0.2017 - val_accuracy: 0.9450<br/>Epoch 4/30<br/>1719/1719 [==============================] - 6s 3ms/step - loss: 0.1986 - accuracy: 0.9433 - val_loss: 0.1725 - val_accuracy: 0.9506<br/>...<br/>...<br/>...<br/>...<br/>Epoch 30/30<br/>1719/1719 [==============================] - 6s 3ms/step - loss: 0.0285 - accuracy: 0.9937 - val_loss: 0.0681 - val_accuracy: 0.9808</span></pre><p id="38dc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">批次大小和批次数量:</strong>当模型被训练时，它不会在每次迭代中传递一个输入。相反，它需要批量大小。<code class="du lx ly lz ln b">fit</code>方法有一个batch_size参数，如果没有指定，这个参数默认为32。因此，在我们的例子中，考虑到批量大小为32，训练集为55000，我们得到的批量数为1719。</p><p id="648b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是输出的所有参数的简要说明:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="ab60" class="lr jx hi ln b fi ls lt l lu lv"># Epoch 1/30<br/># 1719/1719 [==============================] - 5s 3ms/step - loss: 0.6110 - accuracy: 0.8479 - val_loss: 0.3095 - val_accuracy: 0.9162</span><span id="811d" class="lr jx hi ln b fi mf lt l lu lv"># default batch size=32<br/># No. of batches = X_train.shape/batch_size = 55000/32 = 1719</span><span id="37ed" class="lr jx hi ln b fi mf lt l lu lv"># 1719 = No of batches<br/># 5s = 5 seconds for one single Epoch<br/># 3ms/step = time taken for one batch<br/># loss: 0.6110 = training loss (summation of all losses in all batches)<br/># accuracy: 0.8479 = training accuracy (summation for all batches)<br/># val_loss: 0.3095 = validation loss<br/># val_accuracy: 0.9162 = validation accuracy</span></pre><p id="c768" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当您观察模型训练的输出时，您可以看到准确性在每个历元之后都在提高。这表明该模型通过调整作为可训练参数的权重和偏差来学习。我们可以直观地看到模型如何使用我们在模型训练期间捕获的<code class="du lx ly lz ln b">history</code>来减少损失和提高准确性。下面是代码和可视化表示</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="0e62" class="lr jx hi ln b fi ls lt l lu lv">pd.DataFrame(history.history).plot(figsize=(8,5))<br/>plt.grid(True)<br/>plt.gca().set_ylim(0,1)<br/>plt.show()</span></pre><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/5cd0f0a85ff8f47a735e45d5422a6ffd.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*9kWtARMMH1rCNM-RiVwKow.png"/></div><figcaption class="mb mc et er es md me bd b be z dx">Figure 5: loss and accuracy</figcaption></figure><p id="7c82" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上图可以清楚地看出，在20个时期(x轴)之后，模型没有学到多少东西。我们有优化的方法，我们将在接下来的文章中讨论如何优化。</p><p id="8a9c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">模型测试:现在让我们根据我们在开始时创建的测试数据来测试我们的模型，看看它的表现如何。实现这一点的代码非常简单。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="c4a5" class="lr jx hi ln b fi ls lt l lu lv"># validate against test data now<br/>model.evaluate(X_test, y_test)</span><span id="c508" class="lr jx hi ln b fi mf lt l lu lv">#Output:<br/>#313/313 [==============================] - 1s 2ms/step - loss: #0.0734 - accuracy: 0.9763</span></pre><p id="c96f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从输出中可以看出，损失和精度非常接近验证数据集(val _ loss:0.0681-val _ accuracy:0.9808)。我们可以对此进行调整，但这超出了本文的范围。</p><p id="ac1a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们从测试数据集中抽取一些样本，看看我们是否得到了正确的预测:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="624e" class="lr jx hi ln b fi ls lt l lu lv">X_new = X_test[:3]<br/>y_pred = np.argmax(model.predict(X_new), axis=-1)<br/>y_test_new = y_test[:3]</span><span id="ba79" class="lr jx hi ln b fi mf lt l lu lv">for data, pred, actual in zip(X_new, y_pred, y_test_new):<br/>    plt.imshow(data, cmap="binary")<br/>    plt.title(f"Predicted: {pred}, Actual: {actual}")<br/>    plt.axis('off')<br/>    plt.show()<br/>    print("---"*20)</span></pre><p id="c7e8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们从测试数据中提取前3个值，并尝试预测这些值。然后，我们将预测值与循环中的实际值进行比较。我的3个预测都是正确的。你可以尝试一些其他的随机样本，或者将一些手写的图像转换成28 X 28像素，看看这个模型的表现如何。</p><p id="1d9e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这就完成了我们深度学习的<em class="lw">‘hello world’</em>。在结束这篇文章之前，我想展示另一个工具，它可以非常方便地可视化检查模型。这个工具叫做<strong class="is hj"><em class="lw">‘Netron’。你既可以从<a class="ae jo" href="https://github.com/lutzroeder/netron" rel="noopener ugc nofollow" target="_blank"> github </a>位置下载，也可以使用网址<a class="ae jo" href="https://netron.app/" rel="noopener ugc nofollow" target="_blank">https://netron.app/</a>直接在浏览器窗口打开你保存的模型。我将让您更多地探索这个工具，它对于初次学习来说非常方便。</em></strong></p><p id="e521" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你可以参考jupyter笔记本的MNIST实现<a class="ae jo" href="https://github.com/srinivaskulkarni2020/deep-learning/blob/main/MyFirstANN.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="4002" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">嗯……如果你读到这一行，并且至少理解了文章的40%,你就已经达到了前进的目标。不断学习。</p></div></div>    
</body>
</html>