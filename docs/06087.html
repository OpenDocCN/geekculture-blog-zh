<html>
<head>
<title>How To Get Data From (any) Website</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何从(任何)网站获取数据</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/how-to-get-data-from-any-website-483365e1b66?source=collection_archive---------21-----------------------#2021-08-05">https://medium.com/geekculture/how-to-get-data-from-any-website-483365e1b66?source=collection_archive---------21-----------------------#2021-08-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e83c6eb188cb7b9dcaa801ca7521d316.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nJyp-M7pO5CP3ZmU.png"/></div></div></figure><p id="5061" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">众所周知，网络数据几乎触及了我们日常生活的方方面面。当我们工作、购物、旅行和放松时，我们创造、消费并与它互动。毫不奇怪，网络数据对公司的创新和领先于竞争对手产生了影响。但是你如何从网站上获取数据呢？这个叫做“网络抓取”的东西是什么？</p><h1 id="fa41" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">为什么要从网站中提取数据？</h1><p id="65b1" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">来自其他网站的最新、可信的数据是火箭燃料，可以推动每个组织的成功发展，包括您自己的组织。</p><p id="3646" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你可能想在流行的电子商务网站上比较竞争对手产品的价格。你可以通过在新闻文章和博客中搜索你的品牌的名字来监控顾客的情绪——不管是好是坏。或者你可能正在收集某个特定行业或市场领域的信息，以指导关键的投资决策。</p><p id="1e52" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">保险承保和信用评分就是web数据在金融服务行业中发挥越来越重要作用的一个具体例子。无论是发展中市场还是成熟市场，全球都有数十亿“无形信贷”。虽然这些人没有标准的信用记录，但有大量的“替代数据”来源，可以帮助贷款人评估风险，并有可能将这些人作为客户。这些来源包括借记卡交易和公用事业付款、调查反馈、特定主题的社交媒体帖子以及产品评论。阅读我们的博客，它解释了<a class="ae ks" href="https://www.zyte.com/blog/insurance-credit-scoring-enhanced-with-alternative-data/" rel="noopener ugc nofollow" target="_blank">公共网络数据如何为金融服务</a>提供商提供精确、有洞察力的备选数据集。</p><p id="a723" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">同样在金融领域，对冲基金经理正在转向替代数据——超越公司报告和公告等传统来源的范围——以帮助他们做出投资决策。我们最近在博客上讨论了<a class="ae ks" href="https://www.zyte.com/blog/alternative-data-for-hedge-funds-portfolio-management/" rel="noopener ugc nofollow" target="_blank">网络数据</a>在这个领域的价值，以及Zyte如何帮助提供符合标准的定制数据馈送，以补充传统的研究方法。</p><p id="2434" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">简而言之，在了解客户、了解竞争对手的动向，或者根据确凿的事实而非直觉做出任何商业决策时，数据是公司的差异化因素。</p><p id="c569" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">网络上有所有这些问题的答案，还有数不清的答案。把它想象成世界上最大、发展最快的研究图书馆。外面有数十亿的网页。然而，与静态库不同的是，当产品价格等细节定期变化时，许多页面会呈现一个移动的目标。无论您是开发人员还是营销经理，获得可靠、及时的网络数据似乎就像在巨大、不断变化的数字大海里捞针。</p><h1 id="eef7" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">什么是网页抓取？</h1><p id="4265" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">所以你知道你的业务需要网络数据。接下来会发生什么？通过从其他网站剪切和粘贴您需要的相关信息，没有什么可以阻止您从任何网站手动收集数据。但是这很容易出错，而且对任何负责这项工作的人来说，这都是一项复杂、重复和耗时的工作。当你收集了你需要的所有数据时，不能保证某个特定产品的价格或可用性没有变化。</p><p id="792e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于除了最小的项目之外的所有项目，你都需要求助于某种[自动化？]提取液。通常被称为“网络抓取”，<a class="ae ks" href="https://www.zyte.com/data-extraction/" rel="noopener ugc nofollow" target="_blank">数据提取</a>是抓取相关网络数据的艺术和科学——可能来自几个页面，也可能来自几十万个页面——并以一种组织有序的结构提供给你的企业。</p><p id="0867" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">那么数据提取是如何工作的呢？简而言之，它利用计算机来模仿人类在网站上快速、准确、大规模地查找特定信息时的行为。网页主要是为人类的利益而设计的。他们倾向于以我们容易处理、理解和互动的方式呈现信息。例如，如果是一个产品页面，一本书或一双运动鞋的名字很可能会显示在顶部附近，价格也在旁边，可能还有产品的图片。连同隐藏在该网页的HTML代码中的大量其他线索，这些视觉指针可以帮助机器以令人印象深刻的准确度找到您想要的数据。</p><p id="6e25" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有各种实用的方法来应对提取挑战。最简单的方法是利用现有的各种开源工具。本质上，这些是现成的代码块，它们扫描网页的HTML内容，提取出你需要的部分，并将它们归档到某种结构化输出中。走开源路线有一个明显的吸引力，那就是“免费”。但这不是胆小的人的任务，您自己的开发人员将花费大量时间编写脚本和调整现成的代码来满足特定工作的需求。</p><h1 id="502e" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">如何从产品页面提取web数据的步骤</h1><p id="f882" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">好了——是时候将这些网络抓取理论付诸实践了。这里有一个工作示例，说明了现实世界提取项目中的三个关键步骤。</p><h1 id="35d8" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">1.创建提取脚本</h1><p id="8738" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">为了简单起见，我们将使用<a class="ae ks" href="https://docs.python-requests.org/en/master/" rel="noopener ugc nofollow" target="_blank">请求</a>和<a class="ae ks" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"> beautifulsoup </a>库来创建我们的脚本。</p><p id="47a7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">例如，我将从这个网站提取产品数据:books.toscrape.com</p><p id="5ceb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">提取脚本将包含两个函数:</p><ol class=""><li id="f3ba" class="kt ku hi is b it iu ix iy jb kv jf kw jj kx jn ky kz la lb bi translated">寻找产品网址的爬虫</li><li id="0c50" class="kt ku hi is b it lc ix ld jb le jf lf jj lg jn ky kz la lb bi translated">一个真正提取数据的刮刀</li></ol><p id="fc09" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">发出请求是脚本的一个重要部分:用于查找产品URL和获取产品HTML文件。首先，让我们从创建一个新类开始，并添加网站的基本URL:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="f6a8" class="lq jq hi lm b fi lr ls l lt lu">class ProductExtractor(object): <br/>BASE_URL = 'http://books.toscrape.com'</span></pre><p id="318f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，让我们创建一个简单的函数来帮助我们发出请求:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="1890" class="lq jq hi lm b fi lr ls l lt lu">import requests <br/>def make_request(self, url): <br/>return requests.get(url)</span></pre><p id="e530" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">函数<em class="jo"> requests.get() </em>本身相当简单，但是如果您想用代理扩展您的请求，您只需要修改这部分代码，而不是所有调用<em class="jo"> requests.get() </em>的地方。</p><p id="4036" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">提取产品URL</p><p id="4c04" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我将只从名为Travel的一个类别中提取产品，以获得一些样本数据。在这里，任务基本上是找到这个类别页面上的所有产品URL，并以某种可迭代的格式返回它们，这样我们就有每个URL来请求:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="c9b6" class="lq jq hi lm b fi lr ls l lt lu">from urllib.parse import urljoin <br/>from bs4 import BeautifulSoup <br/>def extract_urls(self, start_url): <br/>response = self.make_request(start_url) <br/>parser = BeautifulSoup(response.text, 'html.parser') <br/>product_links = parser.select('article.product_pod &gt; h3 &gt; a') <br/>for link in product_links: <br/>relative_url = link.attrs.get('href') <br/>absolute_url = urljoin(self.BASE_URL, relative_url.replace('../../..', 'catalogue')) <br/>yield absolute_url</span></pre><p id="90cf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个函数的作用是这样的，一行一行地:</p><p id="dd15" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们发出一个普通的请求来访问类别页面(start_url)</p><p id="20b6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建一个BeautifulSoup对象，它将帮助我们解析类别页面的HTML</p><p id="be2c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们使用指定的选择器识别页面上的每个产品URL是可用的</p><p id="a5ff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">迭代提取的链接——此时是<a>元素</a></p><p id="308f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通过解析href属性，从<a>元素中提取相对URL</a></p><p id="7165" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将相对URL转换为绝对URL</p><p id="6d56" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">返回一个带有绝对URL的生成器</p><h1 id="c816" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">2.提取产品字段</h1><p id="4963" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">我们脚本的另一个重要部分是产品提取器函数。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="7b8d" class="lq jq hi lm b fi lr ls l lt lu">def extract_product(self, url): <br/>response = self.make_request(url) <br/>parser = BeautifulSoup(response.text, 'html.parser') <br/>book_title = parser.select_one('div.product_main &gt; h1').text price_text = parser.select_one('p.price_color').text <br/>stock_info = parser.select_one('p.availability').text.strip() product_data = { <br/>'title': book_title, <br/>'price': self.clean_price(price_text), <br/>'stock': stock_info <br/>} <br/>return product_data</span></pre><p id="3c17" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如您在上面看到的，对于price字段，我需要做一些清理，因为它包含货币和其他字符。幸运的是，有一个开源库可以帮我们解析价格值，它叫做price_parser(由Zyte创建):</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="c7c1" class="lq jq hi lm b fi lr ls l lt lu">from price_parser import Price <br/>def clean_price(self, price_text): <br/>return Price.fromstring(price_text).amount_float</span></pre><p id="d379" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该函数以浮点值的形式返回从文本中提取的产品价格。</p><h1 id="58e3" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">3.主要功能</h1><p id="396f" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">最后—这是我们将extract_urls()和extract_product()放在一起的主函数。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="3241" class="lq jq hi lm b fi lr ls l lt lu">def main(): <br/>extractor = ProductExtractor() <br/>product_urls = extractor.extract_urls('http://books.toscrape.com/catalogue/category/books/travel_2/index.html') </span><span id="ffd0" class="lq jq hi lm b fi lv ls l lt lu">extracted_data = [] <br/>for url in product_urls: <br/>product_data = extractor.extract_product(url) extracted_data.append(product_data) extractor.export_json(extracted_data, 'data.json') <br/>And the export_json() function: <br/>import json <br/>def export_json(self, data, file_name): <br/>with open(file_name, 'w') as f: <br/>json.dump(data, f) <br/>The end result is a clean json data file, something like this: <br/>[ <br/>{ <br/>"title": "It's Only the Himalayas", <br/>"price": 45.17, <br/>"stock": "In stock (19 available)" <br/>}, <br/>{ <br/>"title": "Full Moon over Noah\u00e2\u0080\u0099s Ark: An Odyssey to Mount Ararat and Beyond", <br/>"price": 49.43, <br/>"stock": "In stock (15 available)" <br/>}, <br/>{ <br/>"title": "See America: A Celebration of Our National Parks &amp; Treasured Sites", <br/>"price": 48.87, <br/>"stock": "In stock (14 available)" <br/>}, <br/>{ <br/>"title": "Vagabonding: An Uncommon Guide to the Art of Long-Term World Travel", <br/>"price": 36.94, <br/>"stock": "In stock (8 available)" <br/>}, <br/>{ <br/>"title": "Under the Tuscan Sun", <br/>"price": 37.33, <br/>"stock": "In stock (7 available)" <br/>}, <br/>{ <br/>"title": "A Summer In Europe", <br/>"price": 44.34, <br/>"stock": "In stock (7 available)" <br/>}, <br/>{ <br/>"title": "The Great Railway Bazaar", <br/>"price": 30.54, <br/>"stock": "In stock (6 available)" <br/>}, <br/>{ <br/>"title": "A Year in Provence (Provence #1)", <br/>"price": 56.88, <br/>"stock": "In stock (6 available)" <br/>}, <br/>{ <br/>"title": "The Road to Little Dribbling: Adventures of an American in Britain (Notes From a Small Island #2)", <br/>"price": 23.21, <br/>"stock": "In stock (3 available)" <br/>}, <br/>{ <br/>"title": "Neither Here nor There: Travels in Europe", <br/>"price": 38.95, <br/>"stock": "In stock (3 available)" <br/>}, <br/>{ <br/>"title": "1,000 Places to See Before You Die", <br/>"price": 26.08, <br/>"stock": "In stock (1 available)" <br/>} <br/>]</span></pre><h1 id="d688" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">为什么您需要使用智能代理进行web抓取？</h1><p id="a1e5" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">在任何网络抓取项目的过程中，都有很多陷阱需要解决。当你试图提取大规模数据时，最大的挑战之一就来了。</p><p id="609c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在Zyte，我们经常与那些每天成功从一百或一千个网页中提取数据的客户交谈。他们肯定会问，每天从一百万页中获取数据一定很容易吧？</p><p id="6541" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">许多网站使用“反机器人”技术来阻止自动抓取。有很多方法可以解决这个问题，最有效的方法是使用智能旋转代理。这是一种有效地哄骗目标网站的技术，让它认为它正在被一个人无害地访问，而不是一个提取脚本。</p><p id="49b0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里有一个例子，展示了Zyte的<a class="ae ks" href="https://www.zyte.com/smart-proxy-manager/" rel="noopener ugc nofollow" target="_blank">智能代理管理器</a>如何集成到数据提取脚本中，以增加你被禁止的机会。</p><p id="983c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">还记得我们在开始时创建了一个make_request()函数，以便它处理脚本中的所有请求吗？现在，如果我们想使用智能代理管理器，我们只需要在这个功能上做一个小的改变。其他一切都会很好。要集成智能代理管理器，请更改此功能:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="e3b1" class="lq jq hi lm b fi lr ls l lt lu">def make_request(self, url): return requests.get(url)</span></pre><p id="7722" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对此:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="2b4e" class="lq jq hi lm b fi lr ls l lt lu">def make_request(self, url): <br/>zyte_apikey = 'apikey' <br/>proxy_url = 'proxy.zyte.com:8011' <br/>return requests.get( <br/>url, <br/>proxies={ <br/>"http": "http://{}:@{}".format(zyte_apikey, proxy_url), <br/>}, <br/>)</span></pre><p id="5a76" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这段代码中，我们添加智能代理管理器端点作为代理，并使用Zyte API密钥进行身份验证。</p><p id="b247" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您想了解更多关于<a class="ae ks" href="https://www.zyte.com/blog/alternative-data-for-hedge-funds-portfolio-management/" rel="noopener ugc nofollow" target="_blank">智能代理管理器以及它如何帮助您扩展</a>，请查看我们的网络研讨会。</p><h2 id="8531" class="lq jq hi bd jr lw lx ly jv lz ma mb jz jb mc md kd jf me mf kh jj mg mh kl mi bi translated">Zyte如何帮助你提取你想要的web数据？</h2><p id="102a" class="pw-post-body-paragraph iq ir hi is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hb bi translated">在Zyte，我们花了十年的大部分时间专注于提取公司需要的所有重要的网络数据。我们的国际开发人员和数据科学家团队包括分析、人工智能和机器学习领域的一些最大的大脑。在这一过程中，我们开发了一些强大的工具，其中一些受到国际专利保护，以帮助我们的客户快速、可靠且经济高效地实现数据提取目标。</p></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><p id="5c96" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">【https://www.zyte.com】最初发表于<a class="ae ks" href="https://www.zyte.com/blog/how-to-extract-data-from-a-website/" rel="noopener ugc nofollow" target="_blank"><em class="jo"/></a><em class="jo">。</em></p></div></div>    
</body>
</html>