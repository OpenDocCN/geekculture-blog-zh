<html>
<head>
<title>Dynamic web scraping using selenium : scrape protected websites</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用selenium的动态网页抓取:抓取受保护的网站</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/dynamic-web-scraping-using-selenium-scrape-protected-websites-401de3497939?source=collection_archive---------2-----------------------#2022-06-22">https://medium.com/geekculture/dynamic-web-scraping-using-selenium-scrape-protected-websites-401de3497939?source=collection_archive---------2-----------------------#2022-06-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/bb202319cab1345a965173a5854b9c43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v7z2ER4MOcqaJJGDy6DhQg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Designed by upklyak</figcaption></figure><h2 id="babc" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">但是！我们上次已经讨论过了！😤</h2><p id="c0ae" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km hb bi translated">在我的上一篇文章中，我们使用beautiful soup从网页中抓取信息，我们可能已经覆盖了几乎每个重要的方面和方法，包括包括所有不同的类型，爬行，僵尸保护，自动化，通过NLP抓取，但是！美汤只能处理静态网页，不能处理动态*麦克风掉落*🎤</p><blockquote class="kn ko kp"><p id="d64a" class="js jt kq ju b jv kr jx jy jz ks kb kc kt ku ke kf kv kw kh ki kx ky kk kl km hb bi translated">如果你是刮擦的新手，或者需要了解一些高级概念，可以看看这篇文章</p></blockquote><p id="e0bf" class="pw-post-body-paragraph js jt hi ju b jv kr jx jy jz ks kb kc jf ku ke kf jj kw kh ki jn ky kk kl km hb bi translated"><a class="ae kz" rel="noopener" href="/geekculture/getting-started-with-web-scraping-for-data-analysis-fe55cc0b8d61">https://medium . com/geek culture/get-started-with-web-scraping-for-data-analysis-Fe 55 cc 0 b 8d 61</a></p><h2 id="7d2e" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">🥲，静态和动态网页有什么区别</h2><p id="fd5b" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km hb bi translated">你问了一个很棒的问题！静态网页使用直接嵌入你代码中的内容，而在动态网页中，<strong class="ju hj">从javascript生成</strong>数据，并将它们放入DOM元素中。保持简单</p><h2 id="a3b9" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">好的场景时间🫣</h2><p id="1463" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km hb bi translated">考虑你正在抓取使用分页元素的网站，但是你猜对了，当我们点击链接时，url没有更新。这意味着我们不能使用爬行！😣也就是说，我们试着用美丽的汤做每一件可能的事情，但它不起作用！😖这意味着您没有找到根据请求加载数据的HTML片段！😫也就是说没有Nutella了😩…等等，纳特拉是爱</p><h2 id="60ad" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">为什么是硒呢🤔</h2><p id="237d" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km hb bi translated">很高兴你问了🤗不仅仅是硒，还有硒+美丽的汤*旧爱仍然有一些踢它*硒在简单的术语中模拟用户与浏览器的交互。更广泛地说，selenium是一个框架，它可以运行和执行脚本，并通过向连接您的浏览器和Selenium的web驱动程序发送和接收方法调用和数据来控制您的Web浏览器。所以是的，我必须安装Chrome，但是是的，如果你没有Chrome或者Firefox，现在就安装它们。有趣的是，你知道的各种自动化应用程序都使用selenium。</p><h2 id="fad6" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">开始前的测验时间😌</h2><p id="4ba0" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km hb bi translated">如果你去过地球，你可能知道澳大利亚，那里有一个拥有仓库的化学家。恭喜你知道我们正在刮的网站！🥳</p><h2 id="cb65" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">安装先决条件🛠</h2><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="abf4" class="iu iv hi lf b fi lj lk l ll lm"># Run the commands below once <br/>!pip install beautifulsoup4<br/>!pip install requests<br/>!pip install selenium<br/>!pip install webdriver-manager</span></pre><h2 id="fef7" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">获得我们的进口😌</h2><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="ca4f" class="iu iv hi lf b fi lj lk l ll lm">import requests<br/>from bs4 import BeautifulSoup<br/>import pandas<br/>import time<br/>from selenium import webdriver<br/>#dynamic scraping using selenium and beautiful soup<br/>options = webdriver.ChromeOptions()<br/>options.add_argument('--ignore-certificate-errors')<br/>options.add_argument('--incognito')<br/>options.add_argument('--headless')<br/>driver = webdriver.Chrome("*insert_your_directory*/chromedriver", chrome_options=options)<br/>from selenium import webdriver<br/>from webdriver_manager.chrome import ChromeDriverManager<br/>from selenium.webdriver.common.by import By<br/>driver = webdriver.Chrome(ChromeDriverManager().install())</span></pre><p id="e16f" class="pw-post-body-paragraph js jt hi ju b jv kr jx jy jz ks kb kc jf ku ke kf jj kw kh ki jn ky kk kl km hb bi translated">请确保您拥有正确的webdriver路径。我更喜欢从网上手动下载网络驱动程序并保存在pwd中。</p><h2 id="0967" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">召唤3硒让我做到了这一点👻</h2><p id="1908" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km hb bi translated">我们将让浏览器点击下一步按钮，通过selenium从<strong class="ju hj"> Selenium获取源代码，而不是像上次那样请求</strong>。这应该可行，因为我们正在模拟浏览器，就像如果每页有63页，我们将单击“下一步”按钮“抓取”!*java脚本加载内容*刮！java脚本加载内容再次刮！重复好硒将开始使用您的浏览器，现在它的拥有</p><pre class="la lb lc ld fd le lf lg lh aw li bi"><span id="1254" class="iu iv hi lf b fi lj lk l ll lm">driver.get("The_link_that_you_found_via_quiz")<br/>src = driver.page_source<br/>soup = BeautifulSoup(src, 'lxml')<br/>final_list = []<br/>df = []<br/>for i in range(62):<br/>    src = driver.page_source<br/>    soup = BeautifulSoup(src, 'lxml')<br/>    product = soup.find_all('div', class_='product')<br/>    l = []<br/>    for item in product:<br/>        d={}<br/>        d["Name"] = (item.find('div', class_ ='product__title').text.replace("[","").replace("]",""))<br/>        d["Price"] = (item.find('span', class_ ='product__price-current').text.replace("[","").replace("]",""))<br/>        d["Discount"] = (item.find('em', class_ ='product__price-discount'))<br/>        l.append(d)<br/>        <br/>    final_list.extend(l)<br/>    <br/>    next_button = driver.find_elements(by=By.CLASS_NAME, value="pager__button--next")</span><span id="d9d5" class="iu iv hi lf b fi ln lk l ll lm">try:<br/>        if next_button[0].is_displayed():<br/>            driver.execute_script("arguments[0].click();",next_button[0])<br/>            time.sleep(1)<br/>    except:<br/>        pass<br/>    <br/>df = pandas.DataFrame(final_list)</span><span id="5737" class="iu iv hi lf b fi ln lk l ll lm">df.to_csv("xoxo.csv")<br/>df.to_excel("xoxo.xlsx")</span></pre><h2 id="d75e" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">再见👋</h2><p id="6dda" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km hb bi translated">总结一下，没有太多要解释的了，但这只是深入了解selenium的开始，因为selenium不仅仅限于web抓取，还记得每次GPU在1秒内售罄吗？甚至是NFT氏症？硒你弄脏了我的朋友。但是每天都是学习新东西和快乐编码🫡的机会</p></div></div>    
</body>
</html>