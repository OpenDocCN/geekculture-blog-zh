<html>
<head>
<title>Intent classification and slot filling: managing web pages with natural language</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">意图分类和空位填充:用自然语言管理网页</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/intent-classification-and-slot-filling-managing-web-pages-with-natural-language-4d21d5cee4e3?source=collection_archive---------6-----------------------#2022-12-05">https://medium.com/geekculture/intent-classification-and-slot-filling-managing-web-pages-with-natural-language-4d21d5cee4e3?source=collection_archive---------6-----------------------#2022-12-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="d500" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">构建用于确定用户意图、搜索命名实体和提取用户问题答案的解决方案</h2></div><p id="8376" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了让人们远离繁琐的日常事务，降低交易成本，提高我们业务的效率，我们致力于自动化，包括最具创新性的方法，如深度学习。深度学习的一个领域，自然语言处理，最近取得了令人难以置信的发展。我们有许多强大、复杂和惊人的自然语言理解模型，或NLU，从人类语言中提取有用的信息。现在，我们可以为诸如确定用户意图、搜索命名实体、提取用户问题的答案，甚至在类似人类的水平上生成我们自己的文本等问题构建具有强大泛化能力的复杂非确定性解决方案。</p><p id="75b1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在<a class="ae jt" href="https://quantumobile.com/" rel="noopener ugc nofollow" target="_blank"> Quantum </a>时，我们面临的任务是创建一个代理来自动操作网页。我们希望自动化整个用户与网站的交互过程，将其限制为只能用自然语言输入命令。我们的任务是创建一个统一的系统——它不需要绑定到一个特定的网站就可以工作。我们在这方面已经做了很多工作。例如，你可以看看我们为汉堡数据科学社区举办的讲座“<a class="ae jt" href="https://youtu.be/pGGyz564yO8" rel="noopener ugc nofollow" target="_blank">web应用测试的模仿学习</a>”。我们可以看到这个解决方案在网页测试中的许多应用，从创建稳定的测试用例来抵抗站点标记的变化到提供一个包容的QA工作流。</p><h1 id="10dd" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">IC和SF的核心概念</h1><p id="4540" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">这一次，我们决定尝试这个领域的意图分类和空位填充(IC&amp;SF)模型。IC&amp;SF任务在创建聊天机器人和其他用自然语言与用户自动交互的情况下很普遍。</p><p id="843c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">意图分类是基于客户目标的文本查询的自动分类。本质上，意图分类器自动分析文本并将它们分类成意图。了解客户查询背后的意图、自动化流程并获得有价值的见解非常有用。在我们的领域中，我们将与不同UI元素的交互视为不同的意图。我们将根据意图决定要执行的操作——点击、键入文本等。</p><p id="164a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">槽填充的目标是识别对应于用户查询的不同参数的槽。在填充模型的帮助下，我们可以了解查询中的每个单词是否对我们有有用的语义意义。因此，槽填充任务中的主要挑战是提取目标实体。槽填充任务类似于命名实体识别(NER)。这两项任务都使用序列标签作为一种方法。虽然科幻小说的目标是寻找与某事物相关的实体，但NER更通用，只寻找有名字的“事物”，如人、公司、地点等。，但没有告诉我们这个实体指的是什么。我们可以很容易地为NER问题重新设计模型，但是在我们的例子中，我们选择SF作为提供更多输出信息的模型。我们将插槽视为需要交互的UI对象，以及各种引用UI对象。</p><p id="7a8b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">综合所有这些，我们可以考虑这个例子中IC&amp;SF的问题——“请按下密码字段下的这个蓝色登录按钮。”对于这个查询，意图是“按下按钮”，槽是“登录”(按钮名称)和“密码”(文本框名称锚)。因此，意图分类侧重于预测查询的意图，而槽填充提取语义概念。使用关于用户意图和提供的槽的信息，我们可以确定代理必须执行哪个动作，以及这个动作必须执行哪个UI对象。</p><h1 id="5f5e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">模型</h1><p id="ad2d" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">在本文中，我们考虑了IC&amp;SF任务的两个模型——joint Bert和DIET，它们是开放基准测试的最新水平。他们解决相同的问题，但使用相反的方法，所以将他们与我们的领域进行比较是有趣的。但是首先，我们需要定义我们正在解决的问题。因此，意图分类是输入序列的多类分类任务。反过来，槽填充是多类标记分类的任务，即输入序列的类分配。我们将使用IOB符号来标记插槽填充任务的序列，其中B代表插槽的开始，I代表内部，O代表外部。例如，在句子“按下大保存文件图标”中，槽标签将如下——“O O B-图标-名称I-图标-名称O。”</p><h1 id="fe4e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">琼伯特</h1><p id="c307" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">你可以在这篇文章中找到完整的JointBERT描述。还有一个github <a class="ae jt" href="https://github.com/monologg/JointBERT" rel="noopener ugc nofollow" target="_blank">库</a>用于完全实现Pytorch模型。</p><p id="8007" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">JointBERT的本质是用两个头微调BERT主干，这两个头是简单的全连接层，一个用于意图分类，另一个用于槽填充。在JointBERT中，联合目标是通过最小化交叉熵损失来最大化意图和每个时隙的条件概率。你可以在下面找到JointBERT模型架构。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es kr"><img src="../Images/2e3d542648700646c047f37182631f8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wQCT52j23jaBzbup"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">Fig 1. JointBERT model architecture</figcaption></figure><h1 id="2ee3" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">规定饮食</h1><p id="eec5" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">在最初的<a class="ae jt" href="https://arxiv.org/pdf/2004.09936.pdf" rel="noopener ugc nofollow" target="_blank">文章</a>中，DIET(Dual Intent and Entity Transformer)的作者将该模型定位为重型模型的替代方案，使用复杂的方法来构建分类头，并为输入序列的特征化转移学习，而不是像JointBERT那样为特定任务微调主干。</p><p id="cc21" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">作者使用具有一般NLU模型的迁移学习来获得密集特征，并将它们与稀疏单词和字符级n-gram特征组合在一起，然后将该序列表示传递给具有相对位置注意的2层变换器。他们还创建了一个复杂的培训目标，包括三个部分—命名实体识别、意图分类和屏蔽。</p><p id="8c38" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，与JointBERT不同，DIET模型有一个更复杂的头部，并且不执行脊椎的微调。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es lh"><img src="../Images/a98e73eb7f29bc0e1f395564e96f2a06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*97pno6prQjEgZ8aM"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">Fig 2. DIET model architecture</figcaption></figure><h1 id="94b0" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">数据</h1><h2 id="2978" class="li jv hi bd jw lj lk ll ka lm ln lo ke jg lp lq kg jk lr ls ki jo lt lu kk lv bi translated">开源数据</h2><p id="40fd" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">对于IC&amp;SF任务，有两个常见的开放基准——SNIPS和ATIS。ATIS数据集包含来自航班信息请求的音频记录的抄本，而SNIPS数据集由用于个人语音助理的定制意图引擎收集。尽管两者都在NLU基准测试中广泛使用，但ATIS要小得多——几乎是示例的三倍，包含的单词也少s倍。然而，它有更丰富的标签集，21个意向和120个时段类别，而SNIPS有7个意向和72个时段。</p><h2 id="b925" class="li jv hi bd jw lj lk ll ka lm ln lo ke jg lp lq kg jk lr ls ki jo lt lu kk lv bi translated">网络领域的综合数据</h2><p id="d8df" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">对于我们的领域，没有IC&amp;SF任务的数据集。因此，我们决定通过使用不同的语法方案生成句子来创建一个合成数据集。</p><p id="2b8c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，我们写下了对我们的任务感兴趣的意图和位置。因此，我们的意图是:</p><ul class=""><li id="9009" class="lw lx hi iz b ja jb jd je jg ly jk lz jo ma js mb mc md me bi translated">按钮_按压</li><li id="c5b7" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">复选_复选框</li><li id="8161" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">输入文本</li><li id="8ee5" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">扩展下拉列表</li><li id="3949" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">文件_上传</li><li id="32bf" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">图标_点击</li><li id="151f" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">link_click</li><li id="f15a" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">单选按钮_单击</li></ul><p id="31f7" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">和插槽:</p><ul class=""><li id="b538" class="lw lx hi iz b ja jb jd je jg ly jk lz jo ma js mb mc md me bi translated">按钮名称</li><li id="84a5" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">复选框名称</li><li id="75df" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">下拉列表名称</li><li id="518a" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">图标名称</li><li id="ade0" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">链接_文本</li><li id="152e" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">位置_锚点</li><li id="9597" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">单选按钮_标签</li><li id="8e89" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">文本框名称</li><li id="912e" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">文本框_文本</li><li id="4614" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">上传姓名</li></ul><p id="af96" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于作为UI元素名称(按钮名称、复选框名称等)的槽。)，我们还创建了额外的“锚”槽(button_name_anchor、checkbox_name_anchor等)。).Anchor是为了更精确地指定目标而给出的UI元素。虽然大多数槽表示UI元素的名称，但是textbox_text表示要插入到指定文本字段中的文本，location_anchor表示目标和锚UI元素之间的相对位置(左、下等。).因此，我们的数据集中有8个意向和18个位置。</p><p id="8229" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，针对每个意图，我们准备了3个语法方案(共24个)。每个模式都是一个句子模板，它的各个部分——主语、谓语等等——都是从语义相似的单词列表中随机选择的。同一个意图中的方案在句子次要成分的位置、字数和锚插入的位置上有所不同。您可以在下面找到此类方案的示例:</p><ul class=""><li id="9294" class="lw lx hi iz b ja jb jd je jg ly jk lz jo ma js mb mc md me bi translated">检测and，查找and(slot-O)</li><li id="57ba" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">单击、按下、点击(slot-O)</li><li id="9b23" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">圆形、黑色、大、小(插槽-O)</li><li id="0c08" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">提交、创建、加载、添加、下一步、新建、清除(插槽—按钮名称)</li><li id="b16a" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">按钮名称—文件、历史、顺序、页面(槽—按钮名称)</li><li id="5733" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">按钮(插槽— O)</li><li id="f4d7" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated"><anchor subquery=""/></li></ul><p id="d2e8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">锚子查询是一个单独生成并插入到主查询中的句子模式。例如:</p><ul class=""><li id="82e0" class="lw lx hi iz b ja jb jd je jg ly jk lz jo ma js mb mc md me bi translated">位于下方、下方、上方、旁边、旁边(槽-位置_锚点)</li><li id="f0b5" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">使用、添加、清除、选择(插槽—图标名称锚记)</li><li id="fa4f" class="lw lx hi iz b ja mf jd mg jg mh jk mi jo mj js mb mc md me bi translated">全部、任务、日期、文件(位置—图标名称锚记)</li></ul><h1 id="63ad" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">结果</h1><p id="5ab0" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">首先，我们可以在公共基准上比较模型的质量。下面来自DIET paper的比较表显示了这两种模型在意图分类方面的准确性和在填充位置方面的微观平均F1分数。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mk"><img src="../Images/306c83ac2d04c7ef84fc1b6205c852f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hmzW9gZGPiSmqBIl0JCgNA.png"/></div></div></figure><p id="4f11" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如我们所看到的，JointBERT在这些基准测试中的质量稍好一些。这两个模型都在接近100%的水平上执行，这些结果是令人满意的。</p><h1 id="ac76" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">非分层数据</h1><p id="76de" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">在这个阶段，我们从所有三个方案中生成了17，000个示例，从所有可能的同义词组合中随机抽取示例。我们用了15000个例子进行训练，1000个例子进行验证，1000个例子进行模型测试。</p><p id="1689" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，我们使用默认设置训练JointBERT和DIET。我们获得了出色的结果——在测试集上，意图分类准确率和空位填充F1得分均为1.0。JointBERT比DIET更快地训练到最高确认分数，我们将在下一章讨论这个问题。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es ml"><img src="../Images/453e5360f351f413a10df28057d7b038.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uVosCMf4ESInBH6J19kcUg.png"/></div></div></figure><p id="5a86" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在推理过程中，我们在用其他同义词构成的查询上测试了模型。这些模型抵制单词替换，正如人们从它们的架构中所期望的那样。</p><h1 id="bff6" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">分层实验</h1><p id="e39e" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">在下一个研究阶段，我们决定测试该模型对不熟悉的方案生成的查询的鲁棒性。我们的目标是确定该模型如何处理不寻常的公式。我们知道，训练样本的多样性问题是合成用于NLP任务的数据集的相关障碍。例如，在最初的SNIP <a class="ae jt" href="https://arxiv.org/pdf/1805.10190.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中有所描述。这个问题通过文本扩充和使用部分手动标记来解决。但我们感兴趣的是确定模型对数据集中这种变化的初始鲁棒性。</p><p id="cfa0" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们再次抽取了15，000个样本来训练实验模型，1，000个样本用于验证，1，000个样本用于测试。但这一次，我们用语法模式对子样本进行了分层——我们为每个意图仅使用2个语法模式生成了一个训练样本，并搁置了第三个方案来从中生成验证和测试子样本。</p><p id="0d4b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在实验过程中，我们发现模型表现不稳定。我们在10个不同的数据生成(折叠)上对这两个模型进行了训练，发现模型之间F1的中值差异为3.5%，JointBERT的优势更明显，如图3所示。此外，JointBERT的性病评分为8.4%，DIET为4.2%。请注意，饮食模型是在RASA框架中提供的。然而，度量计算不同于JointBERT实现，因此我们重新计算了DIET模型的微观平均值F1，并在图3中显示了它们与原始RASA的估计值。</p><p id="76b7" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">此外，JoinBERT在一个文件夹中有相同的STD，如图4所示。随着训练和验证子集规模的增加，情况并没有改变。因此，3.5%的差异并不能回答哪个模型更好的问题——它们都表现得不稳定。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mm"><img src="../Images/be757e4572e7925f11273f20038337ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6l3yaDstee1kP-n4"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">Fig 3. DIET and JointBERT performance on 10 folds with stratification.</figcaption></figure><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mn"><img src="../Images/cc91dd15becd9faa5ff906e256e22324.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KqmhammnKR0k3sGw"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">Fig 4. JointBERT performance on 10 repeats on the same stratified fold.</figcaption></figure><p id="f4f9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">需要注意的是，在训练样本上，两个模型的得分总是100%。由此，我们可以得出结论，模型是过度拟合的，我们的模型的复杂性导致了不稳定性。此外，由于JointBERT的训练损失达到平台期的速度要快得多，我们看到该模型的过度训练比节食更快。对此有一个解释，因为在JointBERT中，我们微调所有BERT层，而在DIET中，骨干层被冻结。</p><p id="5c12" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们决定用冻僵的冻土层做实验。首先，我们用非分层数据的冻结主干训练JointBERT。因此，唯一改变的权重是在完全连接的头部层中。收敛的次数显著增加，而指标显著下降，如图5所示。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mo"><img src="../Images/85db5698f33ad210ca60bb4cae286b93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VFpK11VXB1RisjdA"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">Fig 5. JointBERT performance without stratification. Frozen backbone.</figcaption></figure><p id="cff0" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从图6中可以看出，冻结JointBERT的主干导致了网络的稳定。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mn"><img src="../Images/22a43fd10e5e1147d88221dae3ddd039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*s5cNlBuYUe5XYwq1"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">Figure 6. JointBERT performance on 5 folds with stratification. Frozen backbone.</figcaption></figure><p id="53d9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，我们决定解冻主干的最后几层，并为Intent和Slot分类头添加新层。经过几次反复的实验，我们得到了图7中的结果。如你所见，分数增加了，尤其是意图分类。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mp"><img src="../Images/8884762ad6903264ae0405c1d48d0ec9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4ASJjbviW6ndMSfG"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">Fig 7. JointBERT performance without stratification. Partially frozen backbone and complex head.</figcaption></figure><p id="6210" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下一步是根据分层数据训练修改后的模型。训练结果如图8所示。我们看到，与最初的冻结模型相比，意向准确率达到了90 %, F1时段增长了10%。我们可以理解，修改JointBERT最后几层的进一步实验将有助于我们实现更高的泛化能力，并防止过度拟合。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mq"><img src="../Images/7dbad898c6b565b64498e8b58de0fa27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KU_ZcKnWfHntJFAy"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">Fig 8. JointBERT performance with stratification. Partially frozen backbone and complex head.</figcaption></figure><p id="a295" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当在不同的褶皱上运行部分冻结的模型时，我们将得到图9中的结果。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mr"><img src="../Images/1e93033bdf0cf69b2a13ca4f78622a7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*m880Iq7yMD8kWMi2"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx">Figure 9. JointBERT performance on 5 folds with stratification. Partially frozen backbone and complex head.</figcaption></figure><h1 id="072c" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">结论</h1><p id="25ba" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">在这项研究中，我们研究了一种使用自然语言在用户和网站之间建立交互系统的方法。我们在开放基准上测试了几个最先进的NLP模型，用于联合意图分类和槽填充任务。我们还生成了一个合成数据集，并针对我们的领域测试了模型的性能。</p><p id="16de" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，我们看到，如果我们可以为合成数据生成建立详尽的语法模板，我们就可以为我们的任务获得出色的结果，并将类似的系统嵌入不同自动化系统的管道中，如聊天机器人。</p><p id="bcc6" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们还研究了所选模型对未知语法结构的敏感性。我们获得的结果表明，我们可以通过修改特定数据集的网络来部分解决该问题。结合文本数据多样化的其他方法，我们可以使用所选择的模型为不同的领域构建用于意图分类和槽填充的健壮的解决方案。</p></div></div>    
</body>
</html>