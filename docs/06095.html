<html>
<head>
<title>How to Implement Web Scraping Using BeautifulSoup and Python?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用BeautifulSoup和Python实现网页抓取？</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/how-to-implement-web-scraping-using-beautifulsoup-and-python-351610481dbe?source=collection_archive---------29-----------------------#2021-08-05">https://medium.com/geekculture/how-to-implement-web-scraping-using-beautifulsoup-and-python-351610481dbe?source=collection_archive---------29-----------------------#2021-08-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e9fcb2d295e4ec4000bd8e77671e8164.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QD0jOygrq6hQ9Ug_Jq9RVA.jpeg"/></div></div></figure><p id="92a0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">从网站上抓取数据主要有两种方式:</strong></p><p id="d1b6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用网站API:(如果已经存在)。例如，脸书有自己的<a class="ae jo" href="https://www.webscreenscraping.com/facebook-scraper.php" rel="noopener ugc nofollow" target="_blank">脸书</a>图形API，允许检索脸书上发布的数据。</p><p id="84f7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">访问网页的HTML，并从中抓取有用的数据。该方法被称为网络数据提取或网络采集或网络搜集。</p><p id="1694" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这篇博客讨论了使用Python的Web抓取框架BeautifulSoup的实现进行数据抓取的相关步骤。</p><h1 id="d8cf" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">网页抓取的相关步骤:</h1><ul class=""><li id="052b" class="kn ko hi is b it kp ix kq jb kr jf ks jj kt jn ku kv kw kx bi translated">将HTTP请求发送到您希望访问的网页URL。服务器通过返回网页的HTML内容来响应请求。对于该任务，我们将利用第三方HTTP库来处理Python请求。</li><li id="7252" class="kn ko hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">当我们获得HTML内容的访问权限时，我们的工作将是解析数据。由于大多数HTML数据是嵌套的，所以我们不能使用字符串处理来抓取数据。我们需要一个能够生成HTML数据的树结构的解析器。有许多HTML解析器库可用，但是最优秀的是HTML5lib。</li><li id="659e" class="kn ko hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">现在，我们需要导航和搜索我们所做的解析树，即树遍历。对于该任务，我们将使用其他名为Beautiful Soup的第三方Python库。这是一个从XML和HTML文件中提取数据的Python库。</li></ul><h1 id="4f6c" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">步骤1:安装必要的第三方库</h1><p id="29e4" class="pw-post-body-paragraph iq ir hi is b it kp iv iw ix kq iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">在<a class="ae jo" href="https://www.webscreenscraping.com/hire-python-developers.php" rel="noopener ugc nofollow" target="_blank"> Python </a>中安装外部库最简单的方法是使用pip。Pip是软件包管理系统，用于安装和管理用Python编写的软件包。</p><p id="d8d3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你只需要这样:</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="17c1" class="lp jq hi ll b fi lq lr l ls lt">pip install requests pip install html5lib pip install bs4</span></pre><h1 id="6ef8" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">步骤2:从网页访问HTML内容</h1><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="e79a" class="lp jq hi ll b fi lq lr l ls lt">import requests URL = "https://www.geeksforgeeks.org/data-structures/" r = requests.get(URL) print(r.content)</span></pre><p id="d288" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">是时候知道这段代码了。</p><ul class=""><li id="ca23" class="kn ko hi is b it iu ix iy jb lu jf lv jj lw jn ku kv kw kx bi translated">最初，导入一个请求库。</li><li id="2b51" class="kn ko hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">之后，确定需要提取的网页网址。</li><li id="e579" class="kn ko hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">将HTTP请求发送到任何指定的URL，并将来自服务器的响应保存在名为r的响应对象中。</li><li id="019c" class="kn ko hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">现在，让print r.content获取原始网页HTML内容。这是“字符串”类型。</li></ul><h1 id="148e" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">步骤3:解析HTML网页内容</h1><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="6d1b" class="lp jq hi ll b fi lq lr l ls lt">#This will not run on online IDE import requests from bs4 import BeautifulSoup URL = "http://www.values.com/inspirational-quotes" r = requests.get(URL) soup = BeautifulSoup(r.content, 'html5lib') # If this line causes an error, run 'pip install html5lib' or install html5lib print(soup.prettify())</span></pre><p id="bd5d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">BeautifulSoup库的一个优点是，它是在HTML解析库(如html.parser、lxml、html5lib等)的基础上创建的。因此，可以同时制作漂亮的对象和识别解析器库。</p><p id="81b2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在给定的例子中，</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="5128" class="lp jq hi ll b fi lq lr l ls lt">soup = BeautifulSoup(r.content, 'html5lib')</span></pre><p id="d429" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们通过传递两个不同的参数创建了一个BeautifulSoup对象:</p><p id="83b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是一个原始的HTML内容。</p><p id="d422" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">html5lib:识别我们希望使用的html解析器。</p><p id="3cf4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，随着soup.prettify()的产生，它提供了一个由原始HTML内容构成的解析树的可视化表示。</p><h1 id="b4ca" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">步骤4:使用解析树进行搜索和导航</h1><p id="19d4" class="pw-post-body-paragraph iq ir hi is b it kp iv iw ix kq iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">现在，我们想从HTML内容中获取一些有用的数据。soup对象在嵌套结构中包含数据，这些数据可能是以编程方式收集的。在这个例子中，我们抓取了一个有一些引用的网页。因此，我们很想做一个程序来保存这些报价(以及所有相关数据)。</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="1f6a" class="lp jq hi ll b fi lq lr l ls lt">#Python program to scrape website #and save quotes from website import requests from bs4 import BeautifulSoup import csv URL = "http://www.values.com/inspirational-quotes" r = requests.get(URL) soup = BeautifulSoup(r.content, 'html5lib') quotes=[] # a list to store quotes table = soup.find('div', attrs = {'id':'all_quotes'}) for row in table.findAll('div', attrs = {'class':'col-6 col-lg-3 text-center margin-30px-bottom sm-margin-30px-top'}): quote = {} quote['theme'] = row.h5.text quote['url'] = row.a['href'] quote['img'] = row.img['src'] quote['lines'] = row.img['alt'].split(" #")[0] quote['author'] = row.img['alt'].split(" #")[1] quotes.append(quote) filename = 'inspirational_quotes.csv' with open(filename, 'w', newline='') as f: w = csv.DictWriter(f,['theme','url','img','lines','author']) w.writeheader() for quote in quotes: w.writerow(quote)</span></pre><p id="ac33" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们继续之前，我们建议您体验我们通过soup.prettify()技术打印的网页HTML内容，并尝试找到导航报价的模式或方法。</p><p id="612b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以看到所有的引号都在div容器中，该容器的id包括' all_quotes '。因此，我们通过find()技术获得div组件(在给定代码中称为table ):</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="0092" class="lp jq hi ll b fi lq lr l ls lt">table = soup.find('div', attrs = {'id':'all_quotes'})</span></pre><p id="44de" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">第一个参数是您希望搜索的HTML标记，第二个参数是dictionary kind元素，用于指定与标记相关的额外属性。find()技术返回初始匹配元素a。您可以尝试打印table.prettify()来了解代码的作用。</p><p id="fbb2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，在这些表元素中，可以注意到每个引用都在div容器中，并且class被引用。因此，我们在引用该类的每个div容器中重复。</p><p id="a338" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们利用findAll()技术，它类似于查找参数的方法，但是它返回不同匹配元素的列表。每个引用都使用名为row的变量进行迭代。</p><p id="21ac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里给出了行HTML内容的示例，以便更好地理解:</p><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/1574c9c6a7b7fff0b40da324af19230e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Zoo7qXIGp5WM-aL4.jpg"/></div></div></figure><p id="5938" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，考虑这里给出的代码:</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="9ccd" class="lp jq hi ll b fi lq lr l ls lt">for row in table.find_all_next('div', attrs = {'class': 'col-6 col-lg-3 text-center margin-30px-bottom sm-margin-30px-top'}): quote = {} quote['theme'] = row.h5.text quote['url'] = row.a['href'] quote['img'] = row.img['src'] quote['lines'] = row.img['alt'].split(" #")[0] quote['author'] = row.img['alt'].split(" #")[1] quotes.append(quote)</span></pre><p id="529e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们制作了一个字典来保存关于报价的所有数据。它的嵌套结构可以与点符号一起使用。为了在HTML元素中使用文本，我们使用了。文本:</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="74d3" class="lp jq hi ll b fi lq lr l ls lt">quote['theme'] = row.h5.text</span></pre><p id="6a8b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以添加、修改、访问或删除标签的功能。这是通过像对待字典一样对待标签来实现的:</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="7755" class="lp jq hi ll b fi lq lr l ls lt">quote['url'] = row.a['href']</span></pre><p id="a0fd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，所有报价都被添加到名为quotes的列表中。</p><p id="60b3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">总之，我们希望将所有数据保存在CSV文件中。</p><pre class="lg lh li lj fd lk ll lm ln aw lo bi"><span id="c5d4" class="lp jq hi ll b fi lq lr l ls lt">filename = 'inspirational_quotes.csv' with open(filename, 'w', newline='') as f: w = csv.DictWriter(f,['theme','url','img','lines','author']) w.writeheader() for quote in quotes: w.writerow(quote)</span></pre><p id="f8c4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们已经创建了一个名为inspirational_quotes.csv的CSV文件，并将所有报价保存在该文件中以供将来使用。</p><p id="622b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，这是一个关于如何使用Python制作web scraper的简单例子。从那里，你可以试着删除你选择的其他网站。对于所有的查询，您可以使用评论部分。</p></div><div class="ab cl ly lz gp ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="hb hc hd he hf"><p id="c6a9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="mf">最初发表于</em><a class="ae jo" href="https://www.webscreenscraping.com/how-to-implement-web-scraping-using-beautifulsoup-and-python.php" rel="noopener ugc nofollow" target="_blank"><em class="mf">【https://www.webscreenscraping.com】</em></a><em class="mf">。</em></p></div></div>    
</body>
</html>