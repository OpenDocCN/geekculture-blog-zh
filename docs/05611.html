<html>
<head>
<title>A Primer On Machine Learning and Data Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习和数据分析入门</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/a-primer-on-machine-learning-and-data-analysis-5f19fd734c5a?source=collection_archive---------25-----------------------#2021-07-26">https://medium.com/geekculture/a-primer-on-machine-learning-and-data-analysis-5f19fd734c5a?source=collection_archive---------25-----------------------#2021-07-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="cd93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大家好，我是Shaythuram，一名新加坡ReactJS开发人员，对机器学习、数据分析和所有技术都有浓厚的兴趣。这是我进入科技博客世界的第一步，我决定用Medium来记录我在ML/AI和数据分析领域的学习之旅。</p><p id="5463" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章是解决我在Kaggle上发现的这个问题的指南。我希望你能像我喜欢制作它一样喜欢阅读它。</p><p id="1076" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这方面的原始代码是用GoogleColab编写的，因此某些细微差别可能是特定于该环境的。尽管如此，这些代码在其他地方应该也能很好地工作。请随时给我发邮件，在shaythuram@gmail.com寻求任何帮助、澄清和最重要的改进。关于这一点的完整代码可以在<a class="ae jd" href="https://github.com/shaythuram/Predicting-Test-Scores" rel="noopener ugc nofollow" target="_blank">这里</a>连同数据集一起找到。</p><p id="ee6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将数据集上传到工作目录后，我们可以导入我们将使用的所有模块。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="5f4f" class="jn jo hi jj b fi jp jq l jr js">import os<br/>import urllib<br/>import urllib.request<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import sklearn<br/>from pandas.plotting import scatter_matrix<br/>from google.colab import files<br/>from sklearn.preprocessing import OrdinalEncoder<br/>from sklearn.preprocessing import OneHotEncoder<br/>from sklearn.model_selection import StratifiedShuffleSplit<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.impute import  SimpleImputer<br/>from sklearn.compose import ColumnTransformer<br/>from sklearn.base import BaseEstimator, TransformerMixin<br/>from sklearn.ensemble import RandomForestRegressor<br/>from sklearn.metrics import mean_squared_error<br/>from sklearn.model_selection import GridSearchCV<br/>from sklearn.model_selection import cross_val_score<br/>import warnings<br/>warnings.filterwarnings("ignore")<br/>os.listdir()</span></pre><p id="b588" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">os.listdir()函数只是告诉我们数据集在我们的工作目录中。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="fd2b" class="jn jo hi jj b fi jp jq l jr js">data_location = 'test_scores.csv' #location of Data/csv filedef load_test_scores(data = data_location ):<br/>    #function to load data into pandas DataFrame<br/>    df = pd.read_csv(data_location)<br/>    return df<br/>df = load_test_scores()</span></pre><p id="4a30" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">n_student指的是这个学生班级的学生人数。我们可以将此列名更改为n_students_in_class。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="8283" class="jn jo hi jj b fi jp jq l jr js">df.rename(columns={"n_student":'n_students_in_class'} ,inplace=True)</span></pre><p id="bc3b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">inplace=True参数允许我们改变当前的df，如果没有它，我们将不得不创建一个新的变量并将改变后的df赋给它。</p><figure class="je jf jg jh fd ju er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es jt"><img src="../Images/da7ea2c09bd9037ae16e17a2dd8227f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jGAAmwRzGsmYelD0g3aH_g.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx">This line of code allows us to check if we have any missing values in our dataset. Thanks to the contributor, the issues of incomplete data is not present here.</figcaption></figure><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="82ce" class="jn jo hi jj b fi jp jq l jr js">%matplotlib inline #This line of code just makes our plot more #easily viewable<br/>df.hist(bins=50 , figsize=(20,15) )<br/>plt.show()</span></pre><p id="c79d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的代码帮助我们可视化非分类数据，即n_students_in_class以及前测和后测分数。后测分数是我们想要预测的，从现在开始将被称为标签。</p><figure class="je jf jg jh fd ju er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es kf"><img src="../Images/ec5a1e584869981fddbade3c7b3774a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R7FtQKLg4m3ka-P5KeOBsg.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx">You should get an output like this upon running the code above.</figcaption></figure><p id="dbf6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一步是找出这些特征中哪些与我们的标签最相关，即后测分数。为此，我们将使用一个叫做<a class="ae jd" href="https://www.spss-tutorials.com/pearson-correlation-coefficient/" rel="noopener ugc nofollow" target="_blank">皮尔逊相关系数</a>的指标。(PCC)简单地说，这为我们提供了一个介于-1和+1之间的值范围。+1表示某个特征与我们的目标特征非常正相关，而-1表示某个特征非常负相关。正负之间的差值就是斜率的方向。-0.7和+0.7都表示相关性值得研究，而PCC为-0.1和+0.1的特征将被视为低相关性特征。完成这项工作的代码如下。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="9bc7" class="jn jo hi jj b fi jp jq l jr js">corr_matrix = df.corr()<br/>corr_matrix['posttest'].sort_values(ascending=False)</span></pre><p id="ad3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">除了PCC之外，我们还可以想出一个我们所有特征的散点图，来挖掘一些其他关系或关于我们数据的有趣事实。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="4f85" class="jn jo hi jj b fi jp jq l jr js">%matplotlib inline<br/>pd.plotting.scatter_matrix(df, figsize=(20,15) )<br/>plt.show()</span></pre><figure class="je jf jg jh fd ju er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es kg"><img src="../Images/fce3d0dddf2896a89e094a69780de9af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g3Rp4uWDHSqiTMXFIpdeRg.png"/></div></div></figure><p id="8c51" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从PCC和上面的图中，我们可以推断出前测和后测结果高度相关。PCC应该已经揭示了班级中的n个学生和标签之间的中度负相关。然而，仅仅从散点图很难推断出这一点。</p><p id="5b9a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">需要注意的一点是，n_students_in_class和教室特征本质上揭示了相同的信息。这是因为，对于任何给定的数据点，比如教室A和班级B中的n个学生，这两个值是恒定的。(教室A将总是有B个学生在里面)。</p><p id="3e1b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，去掉这些特性就可以了。我们将从数据框架中删除n_students_in_class列。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="b87e" class="jn jo hi jj b fi jp jq l jr js">df.drop('n_students_in_class', inplace=True , axis=1)</span></pre><p id="b6cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">axis=1表示列，而axis=0表示水平行，即单个数据点。</p><p id="c101" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们必须将数据集分为训练集和测试集。根据皮尔逊相关系数，前测成绩是后测成绩的一个很强的指标。因此，我们将使用分层洗牌来分割我们的数据集。这样，我们的模型将根据与实际数据分布相似的数据进行训练。</p><p id="d0ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了做到这一点，我们可以将预测试分数分割成箱或阈值。箱子之间相隔10分，下限包含任何低于30分的分数。</p><p id="7a0e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">直方图的每一条都告诉我们有多少学生的预测试成绩在给定的范围内。我们将在训练和测试集中对这种分布预测试得分进行建模。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="8d84" class="jn jo hi jj b fi jp jq l jr js">model_this_distribution = pd.cut(df['pretest'],bins=[0 , 30. , 40. , 50. , 60. , 70. ,80. , 90. ,np.inf ],labels = ['&lt;30' , '&lt;40','&lt;50','&lt;60','&lt;70','&lt;80','&lt;90' , '&lt;100'])</span><span id="94fc" class="jn jo hi jj b fi kh jq l jr js">%matplotlib inline<br/>model_this_distribution.hist(grid=True, bins=20, rwidth=0.9)<br/>plt.show()</span></pre><figure class="je jf jg jh fd ju er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es ki"><img src="../Images/cb09cd14ffa141e97dd9cc87ceabcb33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X3P1jrYp7Ptp74VugCc4wA.png"/></div></div></figure><p id="c376" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们使用上面的分布将数据集分成训练集和测试集。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="362b" class="jn jo hi jj b fi jp jq l jr js">split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)</span><span id="2678" class="jn jo hi jj b fi kh jq l jr js">for train,test in split.split(df , model_this_distribution):<br/>    strat_train_set = df.loc[train]<br/>    strat_test_set = df.loc[test]</span></pre><p id="a627" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据处理和转换</strong></p><p id="5ac2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">前面我们谈到了拥有一个没有缺失值或空值的完整数据集是多么幸运。然而，即使我们这样做了，scikit-learn也为我们提供了简单的工具来帮助填补这些缺失的数据。这叫做简单估算器。它可以使用均值、中值或众数策略来填充缺失的数值数据，或者对分类数据使用“最频繁”策略。</p><p id="4b2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于分类数据，大多数机器学习算法更喜欢数字输入而不是文本输入。为了解决这个问题，我们可以使用<a class="ae jd" href="https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/" rel="noopener ugc nofollow" target="_blank"> OneHotEncoding </a>。</p><p id="5d3b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要编码的列:</p><p id="50eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.性别</p><p id="f79f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.学校类型</p><p id="4903" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.教学方法</p><p id="7da6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.午餐(无论学生是否有资格享受减价/免费午餐)</p><p id="cec5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.学校环境</p><p id="81de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于第1-4项，值是二进制的，因此我们可以从对4列中的每一列进行编码时产生的2列中删除每一列。对于school_settings列，我们不需要这样做。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="0a56" class="jn jo hi jj b fi jp jq l jr js">OneHotEncoder_Instance = OneHotEncoder()</span><span id="13be" class="jn jo hi jj b fi kh jq l jr js">df_Encoded = OneHotEncoder_Instance.fit_transform(df[['gender' , 'school_type' , 'teaching_method' , 'lunch' , 'school_setting' ]])</span><span id="83ac" class="jn jo hi jj b fi kh jq l jr js">df_Encoded = pd.DataFrame.sparse.from_spmatrix(df_Encoded ).drop(axis=1 , columns=[0,2,4,6]).rename(columns={1: "gender", 3: "school_type" , 5:'teaching_method' , 7:'lunch' , 8:'Rural' , 9:'Suburban' , 10:'Urban'} )</span></pre><figure class="je jf jg jh fd ju er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es kj"><img src="../Images/3f24e9066906e2617091c113a5e18896.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oB6kzUFK7JtXEWXZhSlY4w.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx">df_Encoded should look like this.</figcaption></figure><p id="70d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面这组代码运行良好。我们将把这一点纳入一个定制的变压器。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="ec5a" class="jn jo hi jj b fi jp jq l jr js">class HotEncodingCleaner(BaseEstimator, TransformerMixin):</span><span id="2ec1" class="jn jo hi jj b fi kh jq l jr js">  def fit(self, X, y=None):<br/>    return self  # nothing else to do</span><span id="561e" class="jn jo hi jj b fi kh jq l jr js">  def transform(self, X):<br/>    df = pd.DataFrame.sparse.from_spmatrix(X )<br/>    df.drop(axis=1 , columns=[0,2,4,6]  , inplace=True)<br/>    return df</span></pre><p id="0a50" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过导入BaseEstimator，TransformerMixin，我们有了一个现成的带有fit_transform函数的转换器。我们需要做的就是定义转换方法的作用，即删除虚拟列。fit函数应该总是返回self。</p><p id="a3ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以在函数中删除上面的列，并在编码后将其应用到我们的数据帧中。使用这种方法，我们可以将它插入scikit-learn为我们提供的管道特性中。</p><p id="6d4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还必须对学校和教室的特征进行编码，因为我们只需要给我们的算法输入数值。然而，这些功能包含许多独特的价值，因此使用OneHotEncoding将是对空间的巨大浪费。相反，我们将使用OrdinalEncoding，这将只为每个唯一值分配一个唯一的整数值，列中的数据将被相应的整数替换。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="670b" class="jn jo hi jj b fi jp jq l jr js">categorical_attributes = ['gender' , 'school_type' , 'teaching_method' , 'lunch' , 'school_setting' ]<br/>Ordinal_encoding_attributes = ['school' , 'classroom']<br/>num_attributes = ['pretest' , 'posttest']</span><span id="b829" class="jn jo hi jj b fi kh jq l jr js">cat_pipeline = Pipeline([</span><span id="c0fd" class="jn jo hi jj b fi kh jq l jr js">("cat", OneHotEncoder()),<br/>('custom' , HotEncodingCleaner())</span><span id="1e74" class="jn jo hi jj b fi kh jq l jr js">])</span><span id="4231" class="jn jo hi jj b fi kh jq l jr js">Ordinal_pipeline = Pipeline([</span><span id="acea" class="jn jo hi jj b fi kh jq l jr js">('ordinal' ,  OrdinalEncoder()),</span><span id="3921" class="jn jo hi jj b fi kh jq l jr js">])</span><span id="7775" class="jn jo hi jj b fi kh jq l jr js">full_pipeline = ColumnTransformer( [</span><span id="142f" class="jn jo hi jj b fi kh jq l jr js">("cat_pipeline", cat_pipeline,  categorical_attributes ),("Ordinal_pipeline", Ordinal_pipeline ,Ordinal_encoding_attributes),('imputer', SimpleImputer(strategy="median") , num_attributes ),</span><span id="347e" class="jn jo hi jj b fi kh jq l jr js">] , remainder='passthrough')</span></pre><p id="5c63" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们创建了两个管道来处理两组不同的列，因为一组列需要进行一次性编码和清理，而另一组列(Ordinal_encoding_attributes)只需要进行顺序编码。然后，我们使用ColumnTransformer将这两个管道合并成一个管道。</p><p id="2454" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们也做了(' imputer '，simple imputr(strategy = ' median ')，num_attributes)。这是为了处理我们的前测和后测列中任何缺失的数据。我们使用了中位数策略，但你也可以使用“均值”或“众数”策略。</p><p id="d2a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">remainder='passthrough '很重要，因为它确保了未被'触动'的列，不在num_attributes、categorical _ attributes或Ordinal_encoding_attributes中的列仍然保留在数据帧中。默认情况下，该值为'<em class="kk"> drop '。</em></p><p id="e5ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将把这个完整的流水线应用到我们的分层训练集中，然后我们将使转换后的数据帧更加直观。我们还将隔离输入数据和标签。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="b409" class="jn jo hi jj b fi jp jq l jr js">strat_train_treated = full_pipeline.fit_transform(strat_train_set)</span><span id="1127" class="jn jo hi jj b fi kh jq l jr js">strat_train_treated_df = pd.DataFrame(strat_train_treated , columns=['gender' , 'school_type' , 'teaching_method' , 'lunch' , 'Rural' , 'Suburban' , 'Urban' , 'school' , 'classroom' , 'pretest' , 'posttest' ,  'student_id' ] )</span><span id="20f6" class="jn jo hi jj b fi kh jq l jr js">strat_train_treated_prepared  = strat_train_treated_df.drop(columns=['posttest' , 'student_id'   ])</span><span id="5684" class="jn jo hi jj b fi kh jq l jr js">strat_train_treated_labels  = strat_train_treated_df.loc[:,['posttest']]</span></pre><p id="a440" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">df.iloc[:，-1]选择最后一列，这是测试后的值，我们希望隔离这些值，因为它们是测试分数的“正确值”。</p><p id="0a47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这个问题，我们将使用随机森林回归。这是一个广泛使用的算法，更多细节可以在<a class="ae jd" href="https://www.google.com/search?q=randomm+forest&amp;sxsrf=ALeKk00NQBf_e8QCRT1iG56r9bau87oX1w%3A1627244850120&amp;ei=Msn9YObhBo70rAGu7bioBA&amp;oq=randomm+forest&amp;gs_lcp=Cgdnd3Mtd2l6EAMyBAgAEEMyBAgAEEMyBAgAEEMyBAgAEEMyBAgAEEMyBAgAEEMyBAgAEEMyBAgAEEMyBAgAEAoyBAgAEApKBAhBGABQxSxYxSxgoC5oAHABeACAAXGIAb0BkgEDMS4xmAEAoAEBqgEHZ3dzLXdpesABAQ&amp;sclient=gws-wiz&amp;ved=0ahUKEwjmwoO6h__xAhUOOisKHa42DkUQ4dUDCA8&amp;uact=5" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="b51d" class="jn jo hi jj b fi jp jq l jr js">forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)</span><span id="1389" class="jn jo hi jj b fi kh jq l jr js">forest_reg.fit(strat_train_treated_prepared , strat_train_treated_labels)</span><span id="9bae" class="jn jo hi jj b fi kh jq l jr js">predictions_train_set = forest_reg.predict(strat_train_treated_prepared)</span><span id="d5e1" class="jn jo hi jj b fi kh jq l jr js">forestreg_rmse_train = np.sqrt(mean_squared_error(strat_train_treated_labels , predictions_train_set  ))</span><span id="6a5a" class="jn jo hi jj b fi kh jq l jr js">print('The RMSE on the training set is {}'.format(forestreg_rmse_train))</span></pre><p id="4a59" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还可以看到这个模型在测试集上的表现。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="93dd" class="jn jo hi jj b fi jp jq l jr js">strat_test_treated = full_pipeline.transform(strat_test_set)</span><span id="4f31" class="jn jo hi jj b fi kh jq l jr js">strat_test_treated_df = pd.DataFrame(strat_test_treated , columns=['gender' , 'school_type' , 'teaching_method' , 'lunch' , 'Rural' , 'Suburban' , 'Urban' , 'school' , 'classroom' , 'pretest' , 'posttest' ,  'student_id' ] )</span><span id="159a" class="jn jo hi jj b fi kh jq l jr js">strat_test_treated_prepared  = strat_test_treated_df.drop(columns=['student_id' , 'posttest' ])</span><span id="7784" class="jn jo hi jj b fi kh jq l jr js">strat_test_treated_labels  = strat_test_treated_df.loc[:,['posttest']]</span></pre><p id="ef38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们不必对我们的strat_test_set进行fit_transform，这是因为我们希望我们的管道只适合于我们的训练集，并将这些转换应用于我们的测试集。</p><p id="1ff2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">永远不要将管道或模型安装到测试设备上！！！</strong></p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="4662" class="jn jo hi jj b fi jp jq l jr js">predictions_test_set = forest_reg.predict(strat_test_treated_prepared)</span><span id="145c" class="jn jo hi jj b fi kh jq l jr js">forestreg_rmse_test = np.sqrt(mean_squared_error(strat_test_treated_labels , predictions_test_set  ))</span><span id="3147" class="jn jo hi jj b fi kh jq l jr js">print('The RMSE on the test set is {}'.format(forestreg_rmse_test))</span></pre><p id="cc8c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">单独的RMSE是不够好的指标来评估我们的模型，我们可以使用K倍交叉验证。</p><p id="2f8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">使用K倍交叉验证进行评估</strong></p><p id="5b8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在K折叠交叉验证中，我们将训练集随机分成K个大小相等或相近的折叠。(K在cross_val_score实例中设置为cv)然后我们训练并评估我们的lin_regressor 10次。每次，我们选择9个折叠来训练lin_regressor，然后在我们没有选择的折叠上测试它。</p><p id="30c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于K倍交叉验证，Scikit-Learn期望效用函数(越大越好)而不是成本函数(越小越好)。root_mean_squared_error是一个成本函数，因此在交叉验证器计算时，它的值将为负。因此，scoring = " neg _ root _ mean _ squared _ error "。如下所示，有一个简单的解决方法。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="59ec" class="jn jo hi jj b fi jp jq l jr js">def scores_breakdown(scores_Linear , name=''): <br/>  #A simple function to evaluate our K-fold Cross-Validation scores</span><span id="807a" class="jn jo hi jj b fi kh jq l jr js">  scores_mean = scores_Linear.mean()</span><span id="58b0" class="jn jo hi jj b fi kh jq l jr js">  scores_std = scores_Linear.std()</span><span id="c5d2" class="jn jo hi jj b fi kh jq l jr js">  print('Mean and Standard deviation of the k-fold scores of the {}        <br/>  set is {} and {} respectively'.format(name , scores_mean , <br/>  scores_std ))</span><span id="1cb0" class="jn jo hi jj b fi kh jq l jr js">cross_val_score_train = cross_val_score(forest_reg, strat_train_treated_prepared , strat_train_treated_labels , scoring="neg_root_mean_squared_error", cv=10)</span><span id="b65e" class="jn jo hi jj b fi kh jq l jr js">cross_val_score_train = -cross_val_score_train<br/>#Workaround for the negative values problem<br/>scores_breakdown(cross_val_score_train , name='train')</span><span id="43c3" class="jn jo hi jj b fi kh jq l jr js">cross_val_score_test = cross_val_score(forest_reg, strat_test_treated_prepared , strat_test_treated_labels , scoring="neg_root_mean_squared_error", cv=10)<br/>cross_val_score_test = -cross_val_score_test<br/>#Workaround for the negative values problemscores_breakdown(cross_val_score_test , name='test')</span></pre><p id="320b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在执行上述步骤时，我注意到，我们的训练集的平均k倍分数并不是很大。</p><p id="e5e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">更好的是，我们的训练集和测试集的平均k倍分数之间的差异并不太大。这意味着算法没有过度适应我们的训练集。</p><p id="990b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">微调</strong></p><p id="3d15" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以手动调整算法的超参数，给我们一个更好的模型，从而得到更好的预测。</p><p id="5f65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于RandomForest算法，这些是超参数。</p><p id="1720" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">RandomForestRegressor(bootstrap = True，CCP _阿尔法=0.0，criterion='mse '，max_depth=None，max_features='auto '，max_leaf_nodes=None，max_samples=None，min _ infinity _ decrease = 0.0，min_samples_leaf=1，min_samples_split=2，min_weight_fraction_leaf=0.0，n_estimators=100，n_jobs=None，oob_score=False，random_state=42，verbose</p><p id="aeff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">手动更改这些特征中的每一个都将花费大量时间，但是我们可以使用GridSearchCV来探索上述超参数的任何组合，并使用给定的一组超参数进行K重交叉验证来评估模型。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="e9e1" class="jn jo hi jj b fi jp jq l jr js">param_grid = [</span><span id="dcef" class="jn jo hi jj b fi kh jq l jr js"># try 24 (2×3×4) combinations of hyperparameters</span><span id="0f30" class="jn jo hi jj b fi kh jq l jr js">{'bootstrap': [False,True], 'n_estimators': [30,45,50], 'max_features': [2, 4, 6, 8]},</span><span id="74e8" class="jn jo hi jj b fi kh jq l jr js"># then try 12 (2×2×3) combinations with bootstrap set as False</span><span id="4a4a" class="jn jo hi jj b fi kh jq l jr js">{'bootstrap': [False,True], 'n_estimators': [3, 10], 'max_features': [8,11 ,7 ]},</span><span id="49ff" class="jn jo hi jj b fi kh jq l jr js">]</span><span id="4f79" class="jn jo hi jj b fi kh jq l jr js">forest_reg_GCSV = RandomForestRegressor(random_state=42)</span><span id="0b81" class="jn jo hi jj b fi kh jq l jr js"># train across 5 folds, that's a total of (36)*5=180 rounds of training</span><span id="24bf" class="jn jo hi jj b fi kh jq l jr js">RF_grid_search = GridSearchCV(forest_reg_GCSV, param_grid, cv=5,<br/>scoring='neg_root_mean_squared_error',<br/>return_train_score=True)</span><span id="ca97" class="jn jo hi jj b fi kh jq l jr js">RF_grid_search.fit(strat_train_treated_prepared , strat_train_treated_labels)</span></pre><p id="c45c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过以下步骤，我们可以从我们的RF_grid_search中获得参数的最佳组合、最佳估计值和最佳得分</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="dea1" class="jn jo hi jj b fi jp jq l jr js">print('Best Parameters are: {}, \nthe  best estimator is: {} \nand the best score is: {}'.format(RF_grid_search.best_params_  , RF_grid_search.best_estimator_ , -RF_grid_search.best_score_) )</span></pre><p id="a4b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们研究超参数的大量组合时，这种方法是很好的。为了扩大搜索范围，我们可以使用<a class="ae jd" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html" rel="noopener ugc nofollow" target="_blank">randomzedsearchcv</a>来代替。</p><p id="84f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">分析模型及其误差</strong></p><p id="a559" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">RandomForestRegressor可以告诉我们每个特征在做出准确预测的过程中有多重要。</p><p id="3a54" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以通过下面的步骤来想象每个特征在决策过程中的相对重要性。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="a17e" class="jn jo hi jj b fi jp jq l jr js">relative_feature_importance = RF_grid_search.best_estimator_.feature_importances_.tolist()</span><span id="6880" class="jn jo hi jj b fi kh jq l jr js">feature_dict = dict(zip(strat_train_treated_prepared.columns, relative_feature_importance))</span><span id="7c37" class="jn jo hi jj b fi kh jq l jr js">feature_dict = sorted(feature_dict.items(), key=lambda x: x[1] , reverse=True) #Sorted</span><span id="8a32" class="jn jo hi jj b fi kh jq l jr js">feature_dict_df = pd.DataFrame.from_dict(feature_dict )</span><span id="531f" class="jn jo hi jj b fi kh jq l jr js">feature_dict_df.rename(inplace=True , columns={0:'features' , 1:'feature_importance'})</span><span id="3ff7" class="jn jo hi jj b fi kh jq l jr js">%matplotlib inline</span><span id="815c" class="jn jo hi jj b fi kh jq l jr js">feature_dict_df.plot.bar(x='features' , y='feature_importance' , figsize=(15,15) )</span><span id="4111" class="jn jo hi jj b fi kh jq l jr js">plt.show()</span></pre><p id="e57a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">前3行代码从RandomForest回归器的实例中提取相对特征重要性，并为每一列及其相应的重要性创建一个字典。随后，我们订购了这本字典，并将数值绘制成条形图。</p><figure class="je jf jg jh fd ju er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es kl"><img src="../Images/a66e5eeed8b7591ec3e81daac0015cdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*apRlyRsj7VlZnt5GI0tKEQ.png"/></div></div></figure><p id="9fd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了结束这一点，我们现在将在我们的火车和测试集上尝试我们最好的模型，看看它的表现如何。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="97bf" class="jn jo hi jj b fi jp jq l jr js">best_model = RF_grid_search.best_estimator_</span><span id="50f9" class="jn jo hi jj b fi kh jq l jr js">cross_val_score_train = cross_val_score(best_model, strat_train_treated_prepared , strat_train_treated_labels , scoring="neg_root_mean_squared_error", cv=10 )<br/>cross_val_score_train = -cross_val_score_train<br/>scores_breakdown(cross_val_score_train , name='train')</span><span id="e0fe" class="jn jo hi jj b fi kh jq l jr js">cross_val_score_test = cross_val_score(best_model, strat_test_treated_prepared , strat_test_treated_labels , scoring="neg_root_mean_squared_error", cv=10)<br/>cross_val_score_test = -cross_val_score_test<br/>scores_breakdown(cross_val_score_test , name='test')</span></pre><p id="a500" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们想象一下我们在训练集和测试集上的预测分数和实际分数之间的差异。</p><p id="ee2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们使用我们的best_model，在我们的训练集上做一些预测。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="6a26" class="jn jo hi jj b fi jp jq l jr js">best_model = RF_grid_search.best_estimator_<br/>predictions_train_set = best_model.predict(strat_train_treated_prepared)</span><span id="de03" class="jn jo hi jj b fi kh jq l jr js">train_labels = strat_train_treated_labels.iloc[:,0].astype('int')</span><span id="5849" class="jn jo hi jj b fi kh jq l jr js">predictions_test_set = best_model.predict(strat_test_treated_prepared)</span><span id="c7e7" class="jn jo hi jj b fi kh jq l jr js">test_labels = strat_test_treated_labels.iloc[:,0].astype('int')</span></pre><p id="e925" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">strat _ train _ treated _ labels . iloc[:，0])将返回一系列对象，这些对象就是我们的标签。然而，为了绘制这些值，我们需要它们是整数，因此我们这样做了。astype('int ')将系列值转换为整数类型。</p><p id="e767" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面我们有一个自定义函数，可以帮助我们将预测分数和标签(实际或“正确的”后测分数)绘制成线形图。</p><pre class="je jf jg jh fd ji jj jk jl aw jm bi"><span id="176d" class="jn jo hi jj b fi jp jq l jr js">def plot_comparison(predictions,labels , split_plots=False ):</span><span id="1130" class="jn jo hi jj b fi kh jq l jr js">   data_dict_predictedvactual = {</span><span id="9bf9" class="jn jo hi jj b fi kh jq l jr js">      'predicted':predictions,<br/>      'actual':labels<br/>       }</span><span id="06ff" class="jn jo hi jj b fi kh jq l jr js">   predictedvactual =      <br/>   pd.DataFrame.from_dict(data_dict_predictedvactual )<br/>   %matplotlib inline<br/>   predictedvactual.plot.line(figsize=(20,15) ,     <br/>   subplots=split_plots)<br/>   return plt.show()</span><span id="b5fd" class="jn jo hi jj b fi kh jq l jr js">plot_comparison(predictions_test_set ,test_labels )</span></pre><p id="a062" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们有一个接受3个输入的函数，预测(由模型做出的预测)，标签和一个名为split_plots的布尔变量。默认情况下，split_plots设置为False。我个人认为，在同一个图表上查看两个预测值可以直观地看出我们的模型是好是坏，但你可以通过将该变量设置为True，将它们显示在两个不同的图表上。</p><figure class="je jf jg jh fd ju er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es km"><img src="../Images/ff5f9fa969a67fcef84e450eadc1be9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y5KWWnWVsXlK_2fpk1Ok_Q.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx">The Predicted and Actual values plotted on the same graph</figcaption></figure><p id="ab4c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">文章到此结束。我希望你喜欢跟随，我的github回购的链接可以在这里找到。它包含这个完整的脚本作为一个. ipynb和。py文件以及数据集。</p><p id="43ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如有任何澄清或反馈，请随时给我发电子邮件到Shaythuram@gmail.com。这也是我的<a class="ae jd" href="https://www.linkedin.com/in/shaythuram-elangkovan-2b4007202/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>！！</p></div></div>    
</body>
</html>