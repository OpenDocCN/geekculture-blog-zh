<html>
<head>
<title>3 Overlooked things Deepmind Flamingo: A Large Model for Computer Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">3个被忽视的东西:计算机视觉的大型模型</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/3-overlooked-things-deepminds-flamingo-a-large-model-for-computer-vision-84cd9d2f738c?source=collection_archive---------11-----------------------#2022-05-26">https://medium.com/geekculture/3-overlooked-things-deepminds-flamingo-a-large-model-for-computer-vision-84cd9d2f738c?source=collection_archive---------11-----------------------#2022-05-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="e006" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">继谷歌的Pathways之后，这进一步表明了多模态训练的潜力。还有更多</h2></div><p id="e236" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">4月下旬，Deepmind发布了用单一视觉语言模型处理多项任务的<a class="ae jt" href="https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model" rel="noopener ugc nofollow" target="_blank"/>。他们的结果显示，他们提出的模型Flamingo在各种任务上都优于之前的SOTA模型。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es ju"><img src="../Images/c06805a5aa691c33b8eb9bcf4345f36e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*Dk5uP-gIk123F5V5JoIGlw.png"/></div><figcaption class="kc kd et er es ke kf bd b be z dx">These results are exciting for a variety of reasons. They also carry interesting implications. We will discuss this further on.</figcaption></figure><p id="8ce2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这篇文章中，我将从这本超级激动人心的出版物中回顾一些有趣的内容(以及他们详细的预印本，<a class="ae jt" href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/tackling-multiple-tasks-with-a-single-visual-language-model/flamingo.pdf" rel="noopener ugc nofollow" target="_blank"> Flamingo:一个用于少量学习的视觉语言模型</a>)。特别是他们的模型设置非常有趣，因为他们实施的设计选择以及他们可能如何影响人工智能/大规模机器学习的未来。然而，人们忽略了一些重要的细节，这是我想重点介绍的。要想很好地理解这一点，我们先来了解一下该领域背后的脉络。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es kg"><img src="../Images/626115d4ebea0231485b439967f68f35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*q_zJebS5CZwEryF7n_I_Cw.png"/></div><figcaption class="kc kd et er es ke kf bd b be z dx">This level of recognition is staggering. Certainly worth getting excited about</figcaption></figure><h1 id="50f8" class="kh ki hi bd kj kk kl km kn ko kp kq kr io ks ip kt ir ku is kv iu kw iv kx ky bi translated">LLMs的历史</h1><p id="ffec" class="pw-post-body-paragraph ix iy hi iz b ja kz ij jc jd la im jf jg lb ji jj jk lc jm jn jo ld jq jr js hb bi translated">在过去的几个月里，我们已经看到了NLP中大型语言模型的巨大潜力。以超过1000亿个参数的神经网络为例，我们可以将这些LLM用于各种任务。这使得我们能够创建具有更深层次的知识表示和大量功能的模型。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es le"><img src="../Images/87ec92425f52593c92425a4dc4be1fbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*mHF49xdtMbP_GsxPcjCxyw.gif"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx">How adding parameters to the PaLM model adds to the capabilities of the model. Source: <a class="ae jt" href="http://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html" rel="noopener ugc nofollow" target="_blank">Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance</a></figcaption></figure><p id="fe4d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，所有这些模型主要集中在NLP任务上。<a class="ae jt" href="https://openai.com/blog/gpt-3-apps/" rel="noopener ugc nofollow" target="_blank"> GPT </a>、<a class="ae jt" href="https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html" rel="noopener ugc nofollow" target="_blank"> PaLM </a>和<a class="ae jt" rel="noopener" href="/discourse/metas-challenge-to-gpt-3-and-open-ai-149c9a1f766f">脸书的OPT </a>都主要是语言模型，尽管它们在视觉任务方面取得了一些成功。这些任务对于NLP和视觉的结合来说是非常特殊的。最近，我们已经看到了很多从标题生成图像的例子。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lj"><img src="../Images/d0e7221281db8c08ccd887a00b601d71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x2teuHuKJ4yxuZvYUmuGsQ.png"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx">Taken from Make-A-Scene. The quality of images that Meta’s AI generates is stunning. <a class="ae jt" rel="noopener" href="/geekculture/machine-learning-for-the-metaverse-why-metas-ai-lab-is-so-random-42975ab28a26">Read about how this ties into their MetaVerse aspiration</a></figcaption></figure><p id="f950" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Deepmind团队在视觉和语言模型的训练中采取了类似的方法。然而，他们把注意力集中在视觉任务上。下面是他们的模型在非常有趣的汤怪测试中的一个例子。</p><div class="lk ll ez fb lm ln"><a href="https://youtube.com/shorts/5wIzbZi5Tuc?feature=share" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hj fi z dy ls ea eb lt ed ef hh bi translated">Open AI的DALL-E 2打造的DeepMind火烈鸟vs汤怪</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">摘自:https://www . deep mind . com/blog/用单一视觉语言处理多项任务-像视频和…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">youtube.com</p></div></div><div class="lw l"><div class="lx l ly lz ma lw mb ka ln"/></div></div></a></div><p id="e4c9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所有的背景都清楚了，让我们来深入了解一些让我印象深刻的事情。</p><h1 id="8120" class="kh ki hi bd kj kk kl km kn ko kp kq kr io ks ip kt ir ku is kv iu kw iv kx ky bi translated">多模态训练继续不负众望。但是…</h1><p id="82d6" class="pw-post-body-paragraph ix iy hi iz b ja kz ij jc jd la im jf jg lb ji jj jk lc jm jn jo ld jq jr js hb bi translated">对于那些最近一直关注我的内容的人，你知道我对这个想法越来越感兴趣。传统上，我们为不同的任务开发不同的模型。每个数据集/任务都有自己的定制模型。我们还意识到，我们可以使用定制的网络来完成不同的任务。这导致了用于视觉的CNN和用于NLP的RNNs的发展。这些都是专门为他们的领域。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mc"><img src="../Images/b6f9fb756e6c5bce143433ce08d5b4aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*PoksLkeQD2axl5QR6uzBRw.png"/></div><figcaption class="kc kd et er es ke kf bd b be z dx">Obviously, Random Forests are the greatest technique known to man. All other ideas are fighting for second place. For more wisdom, check out my Twitter.</figcaption></figure><p id="5342" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，《变形金刚》对此颇有微词。<a class="ae jt" rel="noopener" href="/p/f98f684db34f">正如我在这里详细介绍的那样</a>，注意力机制在NLP和CV中都有很大的用处。这使它们成为大规模多模态训练的理想选择，这种训练在深度学习中获得了更多的牵引力。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es md"><img src="../Images/d848ac1cbe092393239909a7d1d879e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*fOJxtLr4Lx9JIVuXfJwgBg.png"/></div><figcaption class="kc kd et er es ke kf bd b be z dx">The guiding property is interesting. As we scale into more abilities, we might just see one final model do everything. <a class="ae jt" rel="noopener" href="/geekculture/google-ai-sparks-a-revolution-in-machine-learning-403f4dbf3e70">This would align well with Google’s Pathways vision</a></figcaption></figure><p id="971d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">多模态训练简单地说就是用多种输入来训练你的模型。例如，我们可以看到，我们同时使用文本和图像来获得最终结果。这种系统的优点是模型有更多的信息来运行。这使得他们对领域有了更深入的了解。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es me"><img src="../Images/6937214a2327e8df23133e64aab3708d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*aym-6PJmvAMz-X5vkPi4YA.png"/></div><figcaption class="kc kd et er es ke kf bd b be z dx">Taken from Introducing <a class="ae jt" href="https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/" rel="noopener ugc nofollow" target="_blank">Pathways: A next-generation AI architecture</a></figcaption></figure><p id="6f2e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我感兴趣的是，多模态训练的程序似乎会导致一个与我们现有的非常不同的结果。与人类不同，<a class="ae jt" href="https://youtube.com/shorts/WQknR9SgpHE" rel="noopener ugc nofollow" target="_blank">火烈鸟不受斯特鲁普测试</a>的影响。如果非要我猜的话，这是因为人类不用“冷冻”模型，这让我们更容易被影响。对这一点和这种差异的可能后果进行更深入的分析将是重要的。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mf"><img src="../Images/9efb453654876102b54e7489a08930c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CpPtuuPdMRQ372JCdcUc-g.png"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx"><a class="ae jt" href="https://metodorf.com/tests/stroop_matches_colors.php" rel="noopener ugc nofollow" target="_blank">Taken from here</a></figcaption></figure><h1 id="d822" class="kh ki hi bd kj kk kl km kn ko kp kq kr io ks ip kt ir ku is kv iu kw iv kx ky bi translated">模型冷冻难题</h1><p id="503c" class="pw-post-body-paragraph ix iy hi iz b ja kz ij jc jd la im jf jg lb ji jj jk lc jm jn jo ld jq jr js hb bi translated">团队分享的结果无疑是令人兴奋的。Flamingo正在实现一些在5年前被认为是不真实的事情。这仅仅是开始。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mg"><img src="../Images/50db449d4f71574d0354fcd1adde567b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*tv2g8lMTR669Qg5YMa7SRg.png"/></div><figcaption class="kc kd et er es ke kf bd b be z dx">Think of how many use-cases just the examples in this image have.</figcaption></figure><p id="4cc2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，这篇论文的作者提出了两个有趣的事情。为了理解它们之间的关系和重要性，我们先来理解一下模型冻结的概念。冻结模型只是阻止新的输入数据改变其权重。这用于迁移学习等领域，我们使用基线预训练模型，并针对特定情况对其进行微调。这已经有了很大的成果，火烈鸟也不例外。</p><blockquote class="mh mi mj"><p id="ccb5" class="ix iy mk iz b ja jb ij jc jd je im jf ml jh ji jj mm jl jm jn mn jp jq jr js hb bi translated">如果从头开始训练，两种情况下的性能都会大幅下降(视觉编码器下降11.8%，LM下降10.2%)，这再次凸显了预训练的重要性。有趣的是，从我们良好的初始化开始，同时还允许解冻权重，也会导致性能下降(解冻视觉编码器时下降3.9%，解冻LM时下降5.5%)。这是一个“灾难性遗忘”的例子(McCloskey和Cohen，1989)，其中模型在训练新目标时逐渐忘记其预训练。</p></blockquote><p id="dbc1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以冻结预训练模型可以提高性能？没什么令人震惊的。然而，在他们的预印本的第33页(不，这不是打印错误)，作者提出了一个中肯的观点，“<em class="mk">我们的模型建立在强大的预训练因果语言模型的基础上，作为一个副作用，直接继承了它们的弱点</em>”。这显然是我们需要调查的事情。特别是当我们得到有偏见的数据集，或者旧模型面临的其他潜在问题时，这可能会成为一个问题。把握这一点至关重要。</p><blockquote class="mh mi mj"><p id="8b3c" class="ix iy mk iz b ja jb ij jc jd je im jf ml jh ji jj mm jl jm jn mn jp jq jr js hb bi translated">另一方面，虽然我们的消融证明了从冻结语言模型中继承的语言模型先验的重要性，但我们怀疑它们可能在开放式对话环境中观察到的偶然幻觉和无根据猜测中起作用</p></blockquote><h1 id="337a" class="kh ki hi bd kj kk kl km kn ko kp kq kr io ks ip kt ir ku is kv iu kw iv kx ky bi translated">ML模型需要一个“我不知道”</h1><p id="664a" class="pw-post-body-paragraph ix iy hi iz b ja kz ij jc jd la im jf jg lb ji jj jk lc jm jn jo ld jq jr js hb bi translated">作者们出色地涵盖了他们作品的各个方面。我真正欣赏的一件事是他们如何报道Flamingo在对抗测试中的表现。这里我们可以看到，当被问及有意误导的问题时，Flamingo给出了一些有趣的答案。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es me"><img src="../Images/7fb05443c55a6da7a60e242ba41c410e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*QBXmpvlU06qHHx4d4A3aYA.png"/></div><figcaption class="kc kd et er es ke kf bd b be z dx">This is likely due to the fact that during training the model is forced to answer something</figcaption></figure><p id="9d08" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">诊断这些问题对于将解决方案集成到更敏感的用例中非常重要。中间的“幻觉”可能是总是假设提示总是真实的结果。加入一定程度的“怀疑”或许有助于解决这个问题。另外两个原因可能是因为ML模型通常没有“我不知道”的选项。这需要整合。目前的goto，模型置信度，还不够好。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mo"><img src="../Images/aeab32137624994045b4f4055f0f887b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*mZGMGYuwjerXrNAz7uW3Jg.png"/></div></figure><p id="a4fa" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我的管道中，我通常使用非确定性模型和/或估计量集合来量化预测的可靠性。<a class="ae jt" rel="noopener" href="/mlearning-ai/evaluating-label-dispersion-is-it-the-best-metric-for-evaluating-model-uncertainty-e4a2b52c7fa1">这是受标签分散背后的想法的启发，我在这里讨论</a>。然而，测试Big Tech ML的规模非常不同。所以不确定可行性会有多大。如果你对如何解决这个问题有任何想法，请在下面的评论中分享。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mp"><img src="../Images/336182608e9076fb75f3bc37e461492f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jombJkSsDZBqvXVnk7GQtQ.png"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx">Maybe I’m making too much of it. These results are insane.</figcaption></figure><p id="2e40" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">不过，不要误会。《火烈鸟》的作者们所取得的成果简直令人震惊。但是每个人和他们的妈妈都可以告诉你。这就是为什么，我想把我的文章集中在这些我认为需要更多关注的领域。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mq"><img src="../Images/ca69c457ba7e0b7f8b780e6150bf7f89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VhD3M-s-G-H3CfGEws4Q3A.png"/></div></div></figure><p id="a19b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">本文到此为止。如果你想进入ML，t <a class="ae jt" rel="noopener" href="/geekculture/how-to-learn-machine-learning-in-2022-9ef2ea904986">他的文章给了你一个逐步发展机器学习能力的计划</a>。它使用免费资源。与其他训练营/课程不同，该计划将帮助你发展基本技能，并为你在该领域的长期成功做好准备。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es mr"><img src="../Images/54732a2d97b2a1597200ebfd18e2b28c.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*sWg-aE5NoahuxugUrmrNWQ.png"/></div></div><figcaption class="kc kd et er es ke kf bd b be z dx">Thank you all for the love.</figcaption></figure><p id="41b2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于机器学习来说，软件工程、数学和计算机科学的基础至关重要。它将帮助你概念化，建立和优化你的ML。我的每日时事通讯，<a class="ae jt" href="https://codinginterviewsmadesimple.substack.com/" rel="noopener ugc nofollow" target="_blank">Coding interview make simpled</a>涵盖了算法设计、数学、最近的技术事件、软件工程等主题，让你成为更好的开发人员。<a class="ae jt" href="https://codinginterviewsmadesimple.substack.com/subscribe?coupon=1e0532f2" rel="noopener ugc nofollow" target="_blank"> <strong class="iz hj">我目前正在进行全年八折优惠，所以一定要去看看。</strong> </a></p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es ms"><img src="../Images/c47fe6c7e9487fbe25cce19e1064b4d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/0*6NkYEzVGSdBNeopR.png"/></div></figure><p id="76f9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我创建了<a class="ae jt" href="https://codinginterviewsmadesimple.substack.com/p/faqs-and-about-this-newsletter?r=4tnbw&amp;s=w&amp;utm_campaign=post&amp;utm_medium=web" rel="noopener ugc nofollow" target="_blank">编码面试，使用通过指导多人进入顶级科技公司而发现的新技术，使面试变得简单</a>。时事通讯旨在帮助你成功，避免你在Leetcode上浪费时间。我有一个100%满意的政策，所以你可以尝试一下，没有任何风险。<a class="ae jt" href="https://codinginterviewsmadesimple.substack.com/p/faqs-and-about-this-newsletter?r=4tnbw&amp;s=w&amp;utm_campaign=post&amp;utm_medium=web" rel="noopener ugc nofollow" target="_blank">您可以阅读常见问题解答，并在此了解更多信息</a></p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mt"><img src="../Images/bdbb064de0b5bda6348be3dd7671a246.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/0*EwHuBysKEb0GdQms.png"/></div></figure><p id="0e62" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你也有任何有趣的工作/项目/想法给我，请随时联系我。总是很乐意听你说完。</p><p id="f98f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以下是我的Venmo和Paypal对我工作的金钱支持。任何数额都值得赞赏，并有很大帮助。捐赠解锁独家内容，如论文分析、特殊代码、咨询和特定辅导:</p><p id="ce56" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">https://account.venmo.com/u/FNU-Devansh</p><p id="130c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">贝宝:<a class="ae jt" href="https://www.paypal.com/paypalme/ISeeThings" rel="noopener ugc nofollow" target="_blank">paypal.me/ISeeThings</a></p><h1 id="9dc8" class="kh ki hi bd kj kk kl km kn ko kp kq kr io ks ip kt ir ku is kv iu kw iv kx ky bi translated">向我伸出手</h1><p id="f563" class="pw-post-body-paragraph ix iy hi iz b ja kz ij jc jd la im jf jg lb ji jj jk lc jm jn jo ld jq jr js hb bi translated">使用下面的链接查看我的其他内容，了解更多关于辅导的信息，或者只是打个招呼。另外，查看免费的罗宾汉推荐链接。我们都得到一个免费的股票(你不用放任何钱)，对你没有任何风险。<strong class="iz hj">所以不使用它只是损失免费的钱。</strong></p><p id="f30f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">查看我在Medium上的其他文章。https://rb.gy/zn1aiu</p><p id="f5e3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我的YouTube:<a class="ae jt" href="https://rb.gy/88iwdd" rel="noopener ugc nofollow" target="_blank">https://rb.gy/88iwdd</a></p><p id="e7b6" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在LinkedIn上联系我。我们来连线:<a class="ae jt" href="https://rb.gy/f7ltuj" rel="noopener ugc nofollow" target="_blank">https://rb.gy/m5ok2y</a></p><p id="e00a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我的insta gram:<a class="ae jt" href="https://rb.gy/gmvuy9" rel="noopener ugc nofollow" target="_blank">https://rb.gy/gmvuy9</a></p><p id="ba18" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我的推特:【https://twitter.com/Machine01776819 T2】</p><p id="895c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你正在准备编码/技术面试:【https://codinginterviewsmadesimple.substack.com/ T4】</p><p id="128b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">获得罗宾汉的免费股票:<a class="ae jt" href="https://join.robinhood.com/fnud75/" rel="noopener ugc nofollow" target="_blank">https://join.robinhood.com/fnud75</a></p></div></div>    
</body>
</html>