<html>
<head>
<title>Review — Exemplar-CNN: Discriminative Unsupervised Feature Learning with Convolutional Neural Networks (Self-Supervised Learning)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回顾——Exemplar-CNN:卷积神经网络的判别无监督特征学习(自我监督学习)</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/review-exemplar-cnn-discriminative-unsupervised-feature-learning-with-convolutional-neural-fa68abe937cc?source=collection_archive---------29-----------------------#2021-08-24">https://medium.com/geekculture/review-exemplar-cnn-discriminative-unsupervised-feature-learning-with-convolutional-neural-fa68abe937cc?source=collection_archive---------29-----------------------#2021-08-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="bd62" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">Exemplar-CNN:通过数据转换使用代理类在无标签数据上训练</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/fabd09a93a4dbf71ed97312476ceba94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SghbRd7QQJe1P2hW.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx"><strong class="bd jn">Surrogate classes are generated by data transformation using unlabeled data</strong></figcaption></figure><p id="5c78" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi kk translated"><span class="l kl km kn bm ko kp kq kr ks di">在</span>这篇报道中，回顾了弗赖堡大学的<strong class="jq hj">利用卷积神经网络</strong>(Exemplar-CNN)进行的判别无监督特征学习。在本文中:</p><ul class=""><li id="235f" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj ky kz la lb bi translated"><strong class="jq hj">使用未标记的数据生成代理类。</strong></li><li id="1275" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated">每个代理类都是通过对随机采样的“种子”图像块应用各种变换而形成的。</li><li id="f000" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated">CNN被训练来区分一组代理类。</li></ul><p id="01eb" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这是一篇发表在<strong class="jq hj"> 2014 NIPS </strong>的论文，被引用超过<strong class="jq hj"> 600次</strong>。(<a class="lh li ge" href="https://medium.com/u/aff72a0c1243?source=post_page-----fa68abe937cc--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h1 id="07ec" class="lq lr hi bd jn ls lt lu lv lw lx ly lz io ma ip mb ir mc is md iu me iv mf mg bi translated">概述</h1><ol class=""><li id="6bcd" class="kt ku hi jq b jr mh ju mi jx mj kb mk kf ml kj mm kz la lb bi translated"><strong class="jq hj">创建代理训练数据&amp;学习算法</strong></li><li id="266f" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj mm kz la lb bi translated"><strong class="jq hj"> CNN架构&amp;实验设置</strong></li><li id="b5c4" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj mm kz la lb bi translated"><strong class="jq hj">实验结果</strong></li></ol></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h1 id="bdbb" class="lq lr hi bd jn ls lt lu lv lw lx ly lz io ma ip mb ir mc is md iu me iv mf mg bi translated"><strong class="ak"> 1。创建代理训练数据&amp;学习算法</strong></h1><blockquote class="mn mo mp"><p id="e458" class="jo jp mq jq b jr js ij jt ju jv im jw mr jy jz ka ms kc kd ke mt kg kh ki kj hb bi translated"><strong class="jq hj">随机变换应用于补丁。来自同一原始“种子”图像的所有变换的小块具有与原始“种子”图像相同的代理类。</strong></p><p id="5af6" class="jo jp mq jq b jr js ij jt ju jv im jw mr jy jz ka ms kc kd ke mt kg kh ki kj hb bi translated">如果有8000个“种子”图像，那么就有8000个代理类。</p></blockquote><h2 id="15f2" class="mu lr hi bd jn mv mw mx lv my mz na lz jx nb nc mb kb nd ne md kf nf ng mf nh bi translated">1.1.创建代理培训数据</h2><ul class=""><li id="1466" class="kt ku hi jq b jr mh ju mi jx mj kb mk kf ml kj ky kz la lb bi translated">训练程序的输入是<strong class="jq hj">一组未标记的图像</strong>。</li><li id="04f8" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated"><strong class="jq hj"> <em class="mq"> N个</em>∈【50，32000】大小为<strong class="jq hj">32×32</strong>像素的面片</strong>在<strong class="jq hj">不同的位置和尺度</strong>从不同的图像中随机采样，形成初始<strong class="jq hj">训练集<em class="mq"> X </em> = { <em class="mq"> x </em> 1，…，<em class="mq"> xN </em> } </strong>。</li><li id="218c" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated">我们对包含对象或对象部分的<strong class="jq hj">面片感兴趣</strong>，因此我们<strong class="jq hj">只从包含相当大梯度的区域进行采样</strong>。</li><li id="5ed5" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated"><strong class="jq hj">一族变换{<em class="mq">tα</em>|<em class="mq">α</em>∈<em class="mq">A</em>}</strong>由向量∈ <em class="mq"> A </em>参数化定义，其中<em class="mq"> A </em>是所有可能的参数向量的集合。每个变换<em class="mq"> T </em>都是下列基本变换的组合:</li></ul><ol class=""><li id="624a" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj mm kz la lb bi translated"><strong class="jq hj">平移</strong>:垂直或水平平移<strong class="jq hj">一段距离，在贴片尺寸的0.2 </strong>以内；</li><li id="3f22" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj mm kz la lb bi translated"><strong class="jq hj">缩放</strong>:通过<strong class="jq hj">以0.7到1.4 </strong>之间的因子缩放面片；</li><li id="abaa" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj mm kz la lb bi translated"><strong class="jq hj">旋转</strong>:图像旋转一个角度<strong class="jq hj">到20度</strong>；</li><li id="4c08" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj mm kz la lb bi translated"><strong class="jq hj">对比度1 </strong> : <strong class="jq hj">将每个斑块像素在所有像素集合的<strong class="jq hj">主成分</strong>上的投影</strong>乘以<strong class="jq hj">一个介于0.5和2之间的因子</strong>。</li><li id="b168" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj mm kz la lb bi translated"><strong class="jq hj">对比度2 </strong> : <strong class="jq hj">将所有像素的饱和度和值</strong>(HSV的S和V分量)提高到<strong class="jq hj">0.25和4 </strong>之间的幂(对于一个片内的所有像素都一样)，将这些值乘以0.7和1.4之间的因子，将它们加上-0.1和0.1之间的值；</li><li id="fae4" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj mm kz la lb bi translated"><strong class="jq hj">颜色</strong>:将一个介于<strong class="jq hj"> -0.1和0.1之间的值加到补片中所有像素的色相</strong>(HSV的H分量)上。</li></ol><ul class=""><li id="d356" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj ky kz la lb bi translated">对于每个初始面片<em class="mq"> xi </em> ∈ <em class="mq"> X </em>，<em class="mq">K</em>∈【1300】个随机参数向量{ <em class="mq"> α </em> 1i，…，<em class="mq"> αKi </em> }被采样:</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ni"><img src="../Images/74c930753f649ca2eff8ef9e9df11d92.png" data-original-src="https://miro.medium.com/v2/resize:fit:262/format:webp/1*JqjNthzFiVOpuFxr7TmdRg.png"/></div></figure><ul class=""><li id="682d" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj ky kz la lb bi translated">以及{ <em class="mq"> T_α </em> 1i，…，<em class="mq"> T_αKi </em> }到面片<em class="mq"> xi </em>的对应变换。(简而言之，对每个面片应用随机变换)</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nj"><img src="../Images/ac4a51c268b94818cc41c4ab2c63e763.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/format:webp/1*xmNR__J9hg9aSMT8mRBKMA.png"/></div></figure><ul class=""><li id="6e61" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj ky kz la lb bi translated">这就产生了它的<strong class="jq hj">变换版本集<em class="mq">Sxi</em></strong>=<em class="mq">Tixi</em>= {<em class="mq">Txi</em>|<em class="mq">T</em>∈<em class="mq">Ti</em>}。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nk"><img src="../Images/b215f97a7e6ada49a40bcbc456de1d9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*tNKa_gQ_j4Nteq_z_smwAg.png"/></div></figure><ul class=""><li id="3966" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj ky kz la lb bi translated">然后，减去整个结果数据集上每个像素的平均值，并且不进行任何其他预处理。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nl"><img src="../Images/fc7a8015a9f7f82f815f737cd267b9c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*aPeX8bhno1VvtLayh9XUpA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx"><strong class="bd jn">Exemplary patches sampled from the STL unlabeled dataset which are later augmented by various transformations to obtain surrogate data for the CNN training.</strong></figcaption></figure><ul class=""><li id="73fd" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj ky kz la lb bi translated"><strong class="jq hj">从STL-10未标记数据集中采样的示例性补丁</strong>如上所示。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nm"><img src="../Images/226fca4a8e21df7ee45716c3e1429ae4.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*WMn10zm44L-2YytRVH9gHA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx"><strong class="bd jn">Several random transformations applied to one of the patches extracted from the STL unlabeled dataset. The original (’seed’) patch is in the top left corner.</strong></figcaption></figure><ul class=""><li id="98a5" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj ky kz la lb bi translated"><strong class="jq hj">上图显示了一个补丁</strong>的变形版本。</li></ul><h2 id="8e11" class="mu lr hi bd jn mv mw mx lv my mz na lz jx nb nc mb kb nd ne md kf nf ng mf nh bi translated"><strong class="ak"> 1.2。学习算法</strong></h2><blockquote class="mn mo mp"><p id="f0e8" class="jo jp mq jq b jr js ij jt ju jv im jw mr jy jz ka ms kc kd ke mt kg kh ki kj hb bi translated">有了生成的代理类，CNN就可以训练了。</p></blockquote><ul class=""><li id="213c" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj ky kz la lb bi translated">CNN被训练来区分这些代理类。</li><li id="6266" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated">形式上，我们最小化以下损失函数:</li><li id="5ab4" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated">通过将标签<em class="mq"> i </em>分配给类别<em class="mq"> Sxi </em>，这些集合中的每一个都成为一个类别。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nn"><img src="../Images/6273807b39a2ad9ac7044f5a7a9dc066.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*-uIN4bQIglTr-o3m6bG4SQ.png"/></div></figure><ul class=""><li id="2a1f" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj ky kz la lb bi translated">其中<em class="mq"> l </em> ( <em class="mq"> i </em>，<em class="mq"> Txi </em>)为转换后的样本<em class="mq"> Txi </em>与(代理)真标签<em class="mq"> i </em>上的损失。</li></ul><blockquote class="mn mo mp"><p id="9dfb" class="jo jp mq jq b jr js ij jt ju jv im jw mr jy jz ka ms kc kd ke mt kg kh ki kj hb bi translated">直观上，上述分类问题用于确保<strong class="jq hj">不同的输入样本可以被区分。</strong>同时，<strong class="jq hj">它对指定的变换实施不变性。</strong></p><p id="54fc" class="jo jp mq jq b jr js ij jt ju jv im jw mr jy jz ka ms kc kd ke mt kg kh ki kj hb bi translated"><strong class="jq hj">在使用未标记数据集训练CNN之后，CNN特征被汇集用于为目标数据集训练线性SVM</strong>，这将在下面更详细地提及。</p></blockquote></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h1 id="36fd" class="lq lr hi bd jn ls lt lu lv lw lx ly lz io ma ip mb ir mc is md iu me iv mf mg bi translated"><strong class="ak"> 2。CNN架构&amp;实验设置</strong></h1><h2 id="87e6" class="mu lr hi bd jn mv mw mx lv my mz na lz jx nb nc mb kb nd ne md kf nf ng mf nh bi translated">2.1.代理类的未标记数据集</h2><ul class=""><li id="9fe8" class="kt ku hi jq b jr mh ju mi jx mj kb mk kf ml kj ky kz la lb bi translated"><strong class="jq hj"> STL </strong>特别适合无监督学习，因为它包含了一大组<strong class="jq hj"> 10万个未标记样本</strong>。</li><li id="2da5" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated"><strong class="jq hj">代理训练数据</strong>从STL-10 的<strong class="jq hj">未标记子集中提取。</strong></li></ul><h2 id="2423" class="mu lr hi bd jn mv mw mx lv my mz na lz jx nb nc mb kb nd ne md kf nf ng mf nh bi translated">2.2.两个CNN</h2><ul class=""><li id="678c" class="kt ku hi jq b jr mh ju mi jx mj kb mk kf ml kj ky kz la lb bi translated">使用两个网络:一个是小网络，一个是大网络。</li><li id="78cd" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated"><strong class="jq hj">“小”网络</strong>:由<strong class="jq hj">两个卷积层</strong>组成，每个卷积层有64个滤波器，后面是<strong class="jq hj">一个全连接层</strong>，有128个神经元。</li><li id="167f" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated"><strong class="jq hj">“大型”网络</strong>:由<strong class="jq hj">三个卷积层</strong>组成，分别具有64、128和256个滤波器，后面是<strong class="jq hj">一个具有512个神经元的全连接层</strong>。</li><li id="2465" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated">所有卷积都是5×5滤波器。第一次和第二次卷积后使用2×2最大池。脱落应用于完全连接的层。</li></ul><h2 id="1e44" class="mu lr hi bd jn mv mw mx lv my mz na lz jx nb nc mb kb nd ne md kf nf ng mf nh bi translated">2.3.线性SVM的池化要素</h2><ul class=""><li id="839f" class="kt ku hi jq b jr mh ju mi jx mj kb mk kf ml kj ky kz la lb bi translated">对于STL-10和CIFAR-10，对于每个特征图，使用<strong class="jq hj"> 4象限最大池</strong>，导致每个特征图有4个值。</li><li id="10f3" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated">对于Caltech-101，使用了<strong class="jq hj"> 3层空间金字塔</strong>，即整个图像以及4个象限和4×4网格单元内的最大池，导致每个特征地图有<strong class="jq hj"> 1 + 4 + 16 = 21个值。</strong></li><li id="c366" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated">在汇集的特征上训练<strong class="jq hj">线性支持向量机(SVM) </strong>。</li></ul></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h1 id="8f6b" class="lq lr hi bd jn ls lt lu lv lw lx ly lz io ma ip mb ir mc is md iu me iv mf mg bi translated">3.实验结果</h1><h2 id="abef" class="mu lr hi bd jn mv mw mx lv my mz na lz jx nb nc mb kb nd ne md kf nf ng mf nh bi translated">3.1.SOTA比较</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es no"><img src="../Images/7ba4088310a380e04b00ec3dda3fb576.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CskO7Psyy1hEez-SoDZ5Ww.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx"><strong class="bd jn">Classification accuracies on several datasets</strong></figcaption></figure><blockquote class="mn mo mp"><p id="9fd4" class="jo jp mq jq b jr js ij jt ju jv im jw mr jy jz ka ms kc kd ke mt kg kh ki kj hb bi translated"><strong class="jq hj">从大型网络中提取的特征在所有数据集上匹配或优于最佳先验结果。</strong></p></blockquote><ul class=""><li id="9ea7" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj ky kz la lb bi translated">尽管<strong class="jq hj">特征向量的维数小于大多数其他方法的维数</strong>，并且<strong class="jq hj">网络是在STL-10未标记数据集</strong>上训练的(即，当应用于CIFAR-10和Caltech 101时，它们以迁移学习的方式使用)。</li></ul><h2 id="eee9" class="mu lr hi bd jn mv mw mx lv my mz na lz jx nb nc mb kb nd ne md kf nf ng mf nh bi translated">3.2.代理类的数量</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es np"><img src="../Images/db56c56bef7595122f6b66741a96a770.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*-JkMDFg24ocy4ej4rv5t7g.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx"><strong class="bd jn">Influence of the number of surrogate training classes</strong></figcaption></figure><ul class=""><li id="1585" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj ky kz la lb bi translated">代理类的数量在50到32000之间变化。</li></ul><blockquote class="mn mo mp"><p id="9ad2" class="jo jp mq jq b jr js ij jt ju jv im jw mr jy jz ka ms kc kd ke mt kg kh ki kj hb bi translated"><strong class="jq hj">分类精度随着代理类数量的增加而增加，直到在大约8000个代理类时达到最优，之后不变甚至下降。</strong></p></blockquote><ul class=""><li id="7756" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj ky kz la lb bi translated">这是可以预料的:代理类的数量越大，就越有可能得出非常相似甚至完全相同的样本，这是很难或者不可能区分的。</li><li id="4ddd" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated">这也证明了我们随机采样“种子”补丁的方法的主要局限性:它不能扩展到任意大量的未标记数据。</li></ul><h2 id="ccca" class="mu lr hi bd jn mv mw mx lv my mz na lz jx nb nc mb kb nd ne md kf nf ng mf nh bi translated">3.3.每个代理类别的样本数</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nq"><img src="../Images/dc66f9a0dcfe87a9239c71a7ff4f65b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*rMwqEUF34XwiA9byMzo8YQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx"><strong class="bd jn">Classification performance on STL for different numbers of samples per class</strong></figcaption></figure><ul class=""><li id="fe7e" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj ky kz la lb bi translated">当每个代理类的训练样本的数量<em class="mq"> K </em>在1和300之间变化时，显示了分类精度。</li><li id="96d7" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated">如所见，如果样本数量太少，则没有足够的数据来学习期望的不变性。</li></ul><blockquote class="mn mo mp"><p id="ac6c" class="jo jp mq jq b jr js ij jt ju jv im jw mr jy jz ka ms kc kd ke mt kg kh ki kj hb bi translated"><strong class="jq hj">性能随着每个代理类中样本的增加而提高，在大约100个样本时达到饱和。</strong></p></blockquote><h2 id="5ca6" class="mu lr hi bd jn mv mw mx lv my mz na lz jx nb nc mb kb nd ne md kf nf ng mf nh bi translated">3.4.转换的类型</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nr"><img src="../Images/d75cf0361980c0690efcd6514d1eb728.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*pC17yFeiwhmcpBj_kokTVQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx"><strong class="bd jn">Influence of removing groups of transformations during generation of the surrogate training data.</strong></figcaption></figure><ul class=""><li id="b35c" class="kt ku hi jq b jr js ju jv jx kv kb kw kf kx kj ky kz la lb bi translated"><strong class="jq hj">值“0”</strong>对应于应用<strong class="jq hj">所有基本变换</strong>的随机合成:缩放、旋转、平移、颜色变化和对比度变化。</li><li id="a9ca" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated"><strong class="jq hj">图中不同的列</strong>显示了当我们<strong class="jq hj">放弃一些类型的基本变换时，分类准确度的差异。</strong></li><li id="0f72" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated">首先，<strong class="jq hj">旋转</strong>和<strong class="jq hj">缩放</strong>对性能只有<strong class="jq hj">微小影响</strong>，而<strong class="jq hj">平移、颜色变化</strong>和<strong class="jq hj">对比度变化</strong>明显更重要。</li><li id="8325" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated">其次，<strong class="jq hj"> STL-10 </strong>和<strong class="jq hj"> CIFAR-10 </strong>上的结果一致表明<strong class="jq hj">空间不变性和颜色对比度不变性对于分类性能来说几乎同等重要</strong>。</li><li id="f857" class="kt ku hi jq b jr lc ju ld jx le kb lf kf lg kj ky kz la lb bi translated">第三，在<strong class="jq hj"> Caltech-101、</strong> <strong class="jq hj">上，与空间变换相比，颜色和对比度变换</strong>比在其他两个数据集上重要得多，因为Caltech-101图像通常对齐得很好，这种数据集偏差使得空间不变性不太有用。</li></ul></div><div class="ab cl lj lk gp ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="hb hc hd he hf"><h2 id="5258" class="mu lr hi bd jn mv mw mx lv my mz na lz jx nb nc mb kb nd ne md kf nf ng mf nh bi translated">参考</h2><p id="0320" class="pw-post-body-paragraph jo jp hi jq b jr mh ij jt ju mi im jw jx ns jz ka kb nt kd ke kf nu kh ki kj hb bi translated">【2014 NIPS】【Exemplar-CNN】<br/><a class="ae nv" href="https://papers.nips.cc/paper/5548-discriminative-unsupervised-feature-learning-with-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">利用卷积神经网络的判别无监督特征学习</a></p><h2 id="d9f7" class="mu lr hi bd jn mv mw mx lv my mz na lz jx nb nc mb kb nd ne md kf nf ng mf nh bi translated">自我监督学习</h2><p id="b01a" class="pw-post-body-paragraph jo jp hi jq b jr mh ij jt ju mi im jw jx ns jz ka kb nt kd ke kf nu kh ki kj hb bi translated"><strong class="jq hj">2014</strong>[<a class="ae nv" href="https://sh-tsang.medium.com/review-exemplar-cnn-discriminative-unsupervised-feature-learning-with-convolutional-neural-fa68abe937cc" rel="noopener">Exemplar-CNN</a><strong class="jq hj">2015</strong>[<a class="ae nv" href="https://sh-tsang.medium.com/review-unsupervised-visual-representation-learning-by-context-prediction-self-supervised-51a1d7ce6aff" rel="noopener">上下文预测</a> ]</p></div></div>    
</body>
</html>