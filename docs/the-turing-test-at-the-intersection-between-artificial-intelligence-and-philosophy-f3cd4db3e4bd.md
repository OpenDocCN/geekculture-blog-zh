# 图灵测试:在人工智能和哲学的交叉点

> 原文：<https://medium.com/geekculture/the-turing-test-at-the-intersection-between-artificial-intelligence-and-philosophy-f3cd4db3e4bd?source=collection_archive---------43----------------------->

![](img/134858b4bfd6f5b6fd6fec3f40607fe3.png)

Photo by [JJ Ying](https://unsplash.com/@jjying?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/network?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

**用图灵测试定义智力**

如果你曾经做过这样的测试，要求你在图片中识别一些自行车或消防栓，或者打出潦草笔记中显示的字母，那么你就做了一个完全自动化的区分计算机和人类的图灵测试(CAPTCHA)。几年前，我第一次验证码测试失败，这让我想知道我是不是一个非常愚蠢的人类，或者我实际上是一个有自我意识的机器人，最终被暴露了。这真的会让你停下来想一想，我们的计算机程序已经变得如此复杂，以至于那些旨在区分计算机和人类的测试都无法一次性完成。其中一个主要原因是，构成我们对人类智力理解的特征还没有完全定义。没有明确的方程式来描述它，只有一堆模糊的规则和直觉。在最广泛的系统之下，仍然存在有争议的哲学问题，这正是人工智能研究和围绕它的辩论如此有趣的原因。

在 1950 年发表在 *Mind* 的一篇论文中，图灵提出了一个“解决方案”来解决备受争议的实际定义智力的问题，这个解决方案现在已经成为一个被广泛研究和采用的基准，被称为图灵测试[【1】](#_edn1)。验证码的想法是后来出现的，但动机是一样的——找到一种评估主题“人性”的方法。目前对图灵测试的现代解释是这样一种情况，玩家 A 和 B 与玩家 C(也称为询问者)进行单独的基于文本的对话，并试图用他们给出的回答说服玩家 C 他们是人类。然而，其中一个玩家，A 或 B，是一台试图模仿人类的计算机。假设玩家 C 知道 A 或 B 是一台计算机，但不知道是哪一台(与玩家 C 不知道计算机存在的测试的变体相反)。询问器的作用是在通常几分钟的有限交互时间内辨别哪个玩家是人，哪个是计算机。

由于决策完全基于人类和计算机的行为，图灵测试可以方便地忽略大脑、情感和潜意识的内部状态，并有效地关注思维过程的有形结果，使其成为计算机/人类不可区分性的操作测试。

纵观历史，有几个程序令人信服地接近通过图灵测试，如 1991 年约瑟夫·温特劳布的 PC 治疗师和 2011 年罗洛·卡彭特的智能机器人。第一个被广泛接受的成功是由 2014 年在伦敦皇家学会的计算机程序 Eugene Goostman 取得的。对结果的分析认为尤金·古斯曼的成功有以下几个特点:机器有个性，经常向询问者提问，偶尔会出现拼写错误。这使得与审讯者的对话丰富多彩，有时会从两个真实的人之间相对沉闷的对话中脱颖而出，这是一些错误识别的原因。

**我们应该首先使用这样的测试吗？**

图灵测试因其简单性和广度而受到称赞。它允许测量人工智能的性能，尽管是从一个不涉及思维和智能的精确定义的倾斜角度。它还允许无限制的话题范围，就像两个人之间的正常对话一样。最后，它强调类似人类的思维和情商，而不是只关注推理智能。

图灵测试的一个被广泛研究的方面是联盟效应及其逆效应，伊莱扎效应。前者是法官把一个人误认为是机器，后者是当一个机器成功地通过了人类。对 2003 年罗布纳奖[【3】](#_edn3)(图灵测试的一个实例)结果的研究表明，人类玩家的平均分数低于 4.0，这表明大多数询问者不能肯定地识别他们是人，并标记他们为“可能是人”。在我们通过短信与其他人的日常互动中，我们能否分辨出对方是否已经被聪明的聊天机器人所取代？什么样的行为会泄露秘密，我们应该注意什么？毕竟，一些智能行为是非人类的，例如进行快速算术计算，而一些不智能或不合逻辑的行为是人类的，如非逻辑推理，超过某一点后，机器人思维的不足之处开始与它试图模仿的人类思维的古怪行为相吻合。

![](img/5520791f232acd5b87754a1bcdb932e6.png)

Photo by [Christian Wiediger](https://unsplash.com/@christianw?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/phone-message?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

一个常见的批评是，测试导致团队专注于创造人工智能，唯一的目标是通过测试，而不是专注于真正的智能。专门为测试设计的机器通常使用各种策略进行优化，这些策略旨在故意误导人类法官，而实际上并没有提高系统的实际智能。例如，Eugene Goostman 程序使用各种问题偏转技术和俏皮话来掩盖它不知道简单基本问题的答案的事实。创建一个可以愚弄人类的聊天机器人与创建真正的人工智能(如可以阅读报纸并根据报纸内容回答问题的程序)是不同的，因为无论多少回避策略最终都无法补偿推理和语义理解等技能。

此外，人工智能的广阔领域涉及与自然语言处理和对话不直接相关但仍然需要机器智能的领域，例如，机器视觉和机器人技术。使用图灵测试为该领域的成功定义设定了一个误导性的标准，并淡化了人工智能在从股票市场到自动驾驶汽车的各种应用中的贡献。

反对这项测试的另一个论点声称，将人工智能的发展归咎于模仿人脑是没有依据的。大脑可以用作神经网络发展的模型，但它不一定是神经网络发展的终点或总目标。一个经常被引用的类比是对飞行的研究，它过去一直致力于再现鸟类翅膀的拍打运动，但未能取得任何重大成功。然而，一旦科学家不再试图模仿自然，转而真正理解飞行背后的物理和理论，该领域就取得了更大的进展。因此，研究人员不去试图完善一个类似人类的机器人，而是根据基本理论和第一智能原则来建造一个机器人，可能会受益更多。

如果它走路和说话都像鸭子，那它是鸭子吗？

关于图灵测试的争论很自然地导致了使用这种技术来测量人类智力的合法性，以及我们是否能够首先测量它。

有一种观点认为，在图灵测试中，仅仅根据行为表现来判断智力是荒谬的，因为仅仅根据机器行为收集的结果无法完全描述思维。像鸭子一样走路和说话等外部可观察到的行为不是识别鸭子的严格基础。反对的实质是，图灵测试最终是基于对思维概念的行为解释，而这种解释没有强有力的基础。

然而，当我们缺乏对大脑更复杂的理解时，行为分析是我们严格研究智力的唯一方法。事实上，模仿游戏的形式也经常被用来评估人类——例如以口头形式的评估，想想博士答辩，目的是发现一个人是否真正理解了内容，而不仅仅是鹦鹉学舌般地记忆。这种评估自然是基于行为的，因为我们没有批判思维的方法。

即使一台机器能够通过图灵测试，它也不一定是智能的。1980 年，约翰·塞尔引入了中文房间思维实验[【4】](#_edn4):一个不懂中文的人坐在一个房间里，按照一套指令发出中文输出，会给外界观察者一种机器懂中文的印象。塞尔断言，仅仅遵循指令的计算机永远不可能真正获得对某一主题的智能理解。它们充其量只是一个模拟——塞尔称之为“弱人工智能”。因此，当 IBM 的“深蓝”在国际象棋中击败加里·卡斯帕罗夫时，这台机器可能看起来很聪明，但它对国际象棋的理解就像塞尔对中国象棋的理解一样，也就是说，一点也不理解。

塞尔的哲学遵循的理念是，智慧的头脑不能被简化为我们可以定义的算法。此外，创造一个与人类思维相当的人工智能将涉及对情感、自我意识、灵魂、创造力和人类意识的所有其他多方面以及智力的测试。罗伯特·弗伦奇在 1990 年提出类似的观点，认为图灵测试是有局限性的，因为它只能测量由人类文化和经验定义的智力。因此，除了图灵测试之外，还需要其他测试来衡量这些思想家眼中的“真正智能”。

当然，相反的观点认为，人类的所有行为，从烹饪到学习，都可以简化为仅仅执行储存在大脑中的算法，因此可以被机器有效地复制。人类只不过是有血有肉的计算机，每一个决定都源于相互作用的原子的确定性系统，与我们建造的机器没有什么不同。

说到底，图灵测试在帮助我们理解智能的真正本质方面没有什么作用，这更像是哲学家和心理学家的问题。它可以帮助作为机器智能成就的基准，但它绝对不应该被视为人工智能有效性的单一衡量标准。今天，图灵测试有几种替代方法，包括洛夫莱斯测试、全图灵测试、沃兹尼亚克测试以及原始图灵测试本身的变体。这些测试有助于评估有助于智力的其他标准。最近的进步使我们接近创造真正的“人类式”思维，但今天最好的机器，如 OpenAI 的 GPT 3 号，仍然显示出普遍缺乏常识，并依赖各种可疑的策略来冒充我们中的一员。最终，今天这项测试的重要性似乎是基于我们在定义智力和人类思维的本质时遇到的困难。因此，除非哲学家和心理学家在这个领域获得更大的清晰度，否则图灵测试的意义和相关性对任何人来说都是公平的。

**参考文献**

[【1】](#_ednref1)图灵，艾伦 M. 1950。计算机器和智能。mind lix(236):433–460。

[【2】](#_ednref2)沃里克和沙阿，2016 年。机器会思考吗？皇家学会图灵测试实验报告。理论人工智能实验杂志，28(6)，第 989–1007 页。

沙阿，h，2005 年。人机文本交互中的联盟效应。WSEAS ISCA，可在:[https://www . research gate . net/publication/236889402 _ The _ conventant _ Effect _ in _ Human-Machine _ Textual _ Interaction。](https://www.researchgate.net/publication/236889402_The_Confederate_Effect_in_Human-Machine_Textual_Interaction.)

[【4】](#_ednref4)塞尔，j，1980。思想，大脑和程序。行为和脑科学。行为与脑科学，3(3)，第 417-424 页。

[【5】](#_ednref5)法文版，r，1990。子认知和图灵测试的极限。心灵，99(393)，第 53-65 页。