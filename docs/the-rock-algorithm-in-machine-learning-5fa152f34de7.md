# 机器学习中的 ROCK 算法

> 原文：<https://medium.com/geekculture/the-rock-algorithm-in-machine-learning-5fa152f34de7?source=collection_archive---------18----------------------->

![](img/fbc2023d83651b506c637379e65b8cd8.png)

Image Credits: AP Images for WWE

> ***‘如果你闻到，岩石在煮什么！’***

当我第一次读到一种叫做“ROCK”的分层聚类算法时，我的脑海中就出现了这种想法。这种技术的创造者不知不觉地在多才多艺的美国*演员、制片人、退休职业摔跤手、前美国足球和加拿大足球运动员*道恩·强森和聚类技术之间进行了类比，这解决了在聚类练习中使用数据(如他的**长成就列表)作为变量的问题。
换句话说， **ROCK** ，不是 Johnson 先生，而是**RObust Clustering using LinKs**，是一种帮助我们对分类数据进行聚类的新技术。**

# **介绍**

**聚类是一种将相似类型的数据或查询分组在一起的数据挖掘技术，有助于识别相似的主题领域。主要问题是识别经常被询问的不同主题领域。有许多用于聚类数据的凝聚聚类算法或层次聚类算法。这些算法中的大多数利用距离度量来计算数据点之间的相似性。当我们的数据包含许多/所有的分类变量时，这种方法就成了障碍。**

**最近，我的团队中的一些成员正在处理 *Experian* 数据，这些数据有 300 多个变量，并且所有变量都是分类的。第一个，我们提出的解决方案是一个混合的热点编码，基于信息增益的分桶和基于简单多数的分桶。这导致了近 2000 个编码变量。数据科学领域的专家会建议执行某种特征重要性，并控制这种变量爆炸。消除重要性/影响较低的特性有助于我们限制输入变量的数量，并获得更好的同质聚类。项目交付了，客户对结果很满意。**

**然而，我想到如果我们能有一个更复杂的方法来解决分类变量聚类的问题。这让我想到了《岩石》。**

**ROCK 算法使用 Lp^3 度量或 Jaccard 系数，而不是使用距离度量来查找数据点之间的相似性。对于具有离散非数字属性的域，Lp 距离度量和 Jaccard 系数作为聚类之间相似性的估计是不合适的。随着属性/维度数量的增加，这些距离度量的情况进一步恶化。因此，我们引入了数据点之间的**链接**的概念，这有助于我们克服 Lp 距离和 Jaccard 系数的问题。**

# **说明**

**如果一对点的相似度超过某个阈值，则让它们成为*邻居*。点对的相似性值可以基于 Lp 距离、Jaccard 系数或任何其他非度量相似性函数。一对点之间的链接数量就是这些点的*公共邻居*的数量。属于单个聚类的点通常会有大量的共同邻居，因此会有更多的*链接*。以这种方式，首先合并具有最多链接的聚类/点将导致更好和更有意义的聚类。**

**不像一对点之间的距离或相似性是仅涉及所讨论的两个点的局部属性，链接概念结合了关于两个点的邻域中的其他点的全局信息。一对点之间的链接数量越多，它们属于同一个聚类的可能性就越大。因此，使用链接的聚类将全局知识注入到过程中，因此更加健壮。**

**![](img/5f7a7d7fee362bec9d52307b79d20cd7.png)**

**Image Credits: [https://slideplayer.com](https://slideplayer.com/)**

**ROCK 算法分为三个常规部分:**

1.  **获取数据的随机样本。**
2.  **使用链接凝聚方法对数据执行聚类。使用品质度量来确定在每一步合并哪一对点。**
3.  **使用三个集群，剩余的数据点被分配给它们。**
4.  **堆中的所有信息都根据优度进行排序:**

**![](img/826ff11e2b13c1c9382e352afbf6ade4.png)**

**5.这里 link (Ki，Kj)是两个集群之间的链接数。ni 和 nj 也是每个聚类中的点数。函数 f(θ)依赖于数据，但是发现它满足这样的性质，即 Ki 中的每个项目在聚类中具有大约 ni 个^ f(θ)邻居。**

**根据点 4 的优度测量值最大的聚类对是在任何给定步骤要合并的最佳聚类对。基于链接的逻辑，具有大量交叉链接的集群对是合并的良好候选。但是，这种仅使用聚类对之间的交叉链接的简单方法可能适用于分离良好的聚类，但是在离群点或具有相邻点的聚类的情况下，大的聚类可能会吞噬其他聚类，因此，来自不同聚类的点可能会合并到单个聚类中。这是因为大型集群通常会有大量与其他集群的交叉链接。因此，我们使用聚类之间的交叉链接的预期数量(第 4 点中的分母)作为上述品质度量中的归一化因子，并作为一种启发式方法来引导我们朝向具有大的标准函数值的聚类的方向。**

# **履行**

**PyPi 提供了一个健壮的库来用 python 实现 rock 算法。对于 R 爱好者来说，一个很好的实现和解释可以在[这里](https://www.kaggle.com/vijjikiran/clustering-of-categorical-data)找到。**

# **结论**

**我们有许多其他的武器来处理用于聚类的分类数据，例如 K-modes、MROCK (Modified ROCK)等。，与我们从岩石中得到的团簇相比，这可能会给我们更好的同质团簇。然后是前面讨论过的数据准备技术，如编码、分桶等。，在某些情况下也是救命恩人。要点是技术/算法的选择很大程度上取决于手头的数据。我们必须通过使用外部度量来评估聚类方法的性能，例如调整的 Rand 指数、Fowlkes-Mallows 分数、基于互信息的分数、同质性、完整性和 V-measure 等。、或诸如轮廓系数、Calinski-Harabasz 指数、Davies-Bouldin 指数等内在量度。，以决定最佳方法。这就是为什么它被称为*数据科学*，因为它需要领域专业知识、经验和实验来获得最合适的解决方案。**

***如果不感谢****sudi PTO Guha*******Rajeev Rastogi****和***T21【Kyuseok Shim】Sir***开发出这种惊人的聚类技术——****ROCK****，本文就不完整。****

**我将期待你的评论和建议。
*感谢阅读！注意安全！***