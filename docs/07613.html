<html>
<head>
<title>Make Python Run Faster: A Machine Learning Perspective</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让Python运行得更快:机器学习的视角</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/make-python-run-faster-c73137598bae?source=collection_archive---------5-----------------------#2021-09-24">https://medium.com/geekculture/make-python-run-faster-c73137598bae?source=collection_archive---------5-----------------------#2021-09-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="a184" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">加速代码的7个原则</h2></div><p id="23f6" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Python有一个很好的机器学习生态系统，但深度学习是计算密集型的，<a class="ae jt" href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/python3-gcc.html" rel="noopener ugc nofollow" target="_blank"> Python很慢</a>。在这篇文章中，我将讨论帮助我的代码运行更快的不同方法，更具体地说是在物理模拟和角色动画的强化学习中。然而，大多数技巧适用于所有计算密集型程序。</p><p id="0fb7" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，这里有7种方法可以让Python代码运行得更快:</p><ol class=""><li id="5cab" class="ju jv hi iz b ja jb jd je jg jw jk jx jo jy js jz ka kb kc bi translated"><a class="ae jt" href="#4fdc" rel="noopener ugc nofollow">让你的机器跑得更快</a></li><li id="502b" class="ju jv hi iz b ja kd jd ke jg kf jk kg jo kh js jz ka kb kc bi translated"><a class="ae jt" href="#5860" rel="noopener ugc nofollow">尝试不同的Python版本和发行版</a></li><li id="7567" class="ju jv hi iz b ja kd jd ke jg kf jk kg jo kh js jz ka kb kc bi translated"><a class="ae jt" href="#9235" rel="noopener ugc nofollow">剖析和优化</a></li><li id="20f3" class="ju jv hi iz b ja kd jd ke jg kf jk kg jo kh js jz ka kb kc bi translated"><a class="ae jt" href="#d27e" rel="noopener ugc nofollow">注意类型转换</a></li><li id="ac95" class="ju jv hi iz b ja kd jd ke jg kf jk kg jo kh js jz ka kb kc bi translated"><a class="ae jt" href="#173e" rel="noopener ugc nofollow">对内存分配要有策略</a></li><li id="dd31" class="ju jv hi iz b ja kd jd ke jg kf jk kg jo kh js jz ka kb kc bi translated">写If语句时要巧妙<a class="ae jt" href="#0c9a" rel="noopener ugc nofollow"/></li><li id="9ce7" class="ju jv hi iz b ja kd jd ke jg kf jk kg jo kh js jz ka kb kc bi translated"><a class="ae jt" href="#83f9" rel="noopener ugc nofollow">使用包装时要小心</a></li></ol><p id="e194" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">关于我——我是不列颠哥伦比亚大学的博士生。我的研究使用深度学习和强化学习来解决角色动画问题。例如，看看这个<a class="ae jt" href="https://youtu.be/XQ0EKfunVT4?t=90" rel="noopener ugc nofollow" target="_blank">不断行走的机器人</a>和<a class="ae jt" href="https://belinghy.github.io/projects/MVAE/#demo" rel="noopener ugc nofollow" target="_blank">交互式基于网络的角色控制器</a>。我今天分享的让Python变得更快的例子是基于NumPy和PyTorch的，所以一些关于它们的经验会有所帮助。</p><h1 id="4fdc" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">1让你的机器跑得更快</h1><p id="10c6" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg lc ji jj jk ld jm jn jo le jq jr js hb bi translated">只有两种方法可以让任何程序运行得更快:编写更高效的代码或者让你的机器运行得更快。</p><p id="3645" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在花几个小时优化代码之前，花几秒钟检查您的机器是否尽可能高效地运行是值得的。这听起来很明显，但这正是为什么它如此容易被忽视，甚至被谷歌上的大多数首页结果所忽视。</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lf"><img src="../Images/d39c52c869a8ca86e9b9697f0e2cee0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GdDefWXRs1r07az4.png"/></div></div></figure><p id="4974" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">默认情况下，电脑不会以最大容量运行。以最大能力运行会浪费能源，对日常任务(如查看电子邮件)几乎没有明显的好处。所以默认的功率设置通常是按需或平衡的。这允许CPU在必要时使用更多的功率，例如在打开繁重的应用程序时，同时在机器空闲时节省能量。</p><p id="3fc7" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">操作系统智能地决定何时CPU可以汲取更多的能量。但是当我们追求最佳性能时，最好由我们自己来做决定。在性能模式下运行CPU给我的代码库带来了10-25%的差异，因为大多数物理模拟都是受CPU限制的。我使用以下命令在Linux上设置CPU性能模式。</p><pre class="lg lh li lj fd lr ls lt lu aw lv bi"><span id="bc89" class="lw kj hi ls b fi lx ly l lz ma">sudo apt install cpufrequtils</span><span id="4b27" class="lw kj hi ls b fi mb ly l lz ma"># Check current governor<br/>cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor</span><span id="bfa0" class="lw kj hi ls b fi mb ly l lz ma"># See governor options: conservative, ondemand, powersave, performance <br/>cpufreq-info</span><span id="f55e" class="lw kj hi ls b fi mb ly l lz ma"># Turn on `performance` mode for all cores<br/># $(($(nproc)-1)) returns the number of cores minus 1<br/>sudo bash -c 'for i in $(seq 0 $(($(nproc)-1))); do cpufreq-set -c $i -g performance; done'</span><span id="1f0c" class="lw kj hi ls b fi mb ly l lz ma"># Revert back to `ondemand` mode for all cores <br/>sudo bash -c 'for i in $(seq 0 $(($(nproc)-1))); do cpufreq-set -c $i -g ondemand; done'</span></pre><p id="9e8e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你运行的是Windows，最好还是换成Linux。上一次我在两种操作系统上比较运行实验时，Linux稍微快一些。如果情况有变，一定要让我知道；我很乐意换成现在最快的。</p><h1 id="5860" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">2尝试不同的Python版本和发行版</h1><p id="6cfc" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg lc ji jj jk ld jm jn jo le jq jr js hb bi translated">Python和其他软件一样，仍在随着时间的推移不断改进。Python的每个版本都有不同的优化；例如，这里是Python 3.10 的<a class="ae jt" href="https://docs.python.org/3.10/whatsnew/3.10.html#optimizations" rel="noopener ugc nofollow" target="_blank">发行说明。</a></p><p id="f580" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">较新的Python版本不一定比旧版本快。尝试所有版本，看看哪个版本最适合您的代码库。幸运的是，像<a class="ae jt" href="https://docs.conda.io/en/latest/miniconda.html" rel="noopener ugc nofollow" target="_blank"> miniconda </a>和<a class="ae jt" href="https://github.com/pyenv/pyenv" rel="noopener ugc nofollow" target="_blank"> pyenv </a>这样的工具使得管理不同的Python版本变得容易。</p><p id="e151" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">不要停留在尝试不同的Python版本，也要尝试不同的Python发行版。我发现来自<a class="ae jt" href="https://conda-forge.org/docs/" rel="noopener ugc nofollow" target="_blank"> conda-forge </a>的Python(下面的设置步骤)比其他任何东西都要稍微快一点。我尝试过使用pyenv、<a class="ae jt" href="https://github.com/pyston/pyston" rel="noopener ugc nofollow" target="_blank"> Pyston </a>和<a class="ae jt" href="https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/distribution-for-python.html" rel="noopener ugc nofollow" target="_blank">英特尔Python发行版</a>进行编译。我没有试过<a class="ae jt" href="https://github.com/facebookincubator/cinder" rel="noopener ugc nofollow" target="_blank"> Cinder </a>或者Python 3.10+。</p><pre class="lg lh li lj fd lr ls lt lu aw lv bi"><span id="d7c3" class="lw kj hi ls b fi lx ly l lz ma">conda config --add channels conda-forge <br/>conda config --set channel_priority strict <br/>conda create -n 3.9.5 python=3.9.5 -c conda-forge</span></pre><p id="d922" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果您一次运行12个小时的强化学习实验，那么在寻找最佳Python版本和发行版上的时间投资是值得的。以5%的速度提升，每天可以节省一个多小时。</p><h1 id="9235" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">3剖析和优化</h1><p id="c550" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg lc ji jj jk ld jm jn jo le jq jr js hb bi translated">从Google的首页结果中加速Python代码的大多数技巧都是值得的——尽可能遵循它们。最重要的是，<a class="ae jt" href="https://en.wikipedia.org/wiki/Profiling_(computer_programming)" rel="noopener ugc nofollow" target="_blank">剖析你的代码</a>，找到瓶颈，然后优化。</p><p id="611f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于剖析，有许多工具，如<a class="ae jt" href="https://github.com/benfred/py-spy" rel="noopener ugc nofollow" target="_blank"> py-spy </a>和<a class="ae jt" href="https://github.com/plasma-umass/scalene" rel="noopener ugc nofollow" target="_blank"> scalene </a>。我个人不记得输入标志，所以我倾向于使用内置的分析器。</p><pre class="lg lh li lj fd lr ls lt lu aw lv bi"><span id="88ad" class="lw kj hi ls b fi lx ly l lz ma">pip install snakeviz <br/>python -m cProfile -o temp.dat _command_<br/>snakeviz temp.dat</span></pre><p id="85d0" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是结果汇总的样子。在本例中，<code class="du mc md me ls b">test.py</code>第6行的列表理解花费了14.5秒，总运行时间为17.8秒。很容易一眼就看出哪部分代码执行时间最长，因此如果可能的话应该进行优化。</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mf"><img src="../Images/2bcf4095dc2e50bbc798ef96f99ee946.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DKE1z7Y8L_fgebYc.png"/></div></div></figure><p id="f28e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">找到瓶颈后，如何改进代码通常就很明显了。一个谷歌搜索就有很多资源，这里就不一一赘述了。对我来说最有帮助的技巧是:使用内置函数，更喜欢列表理解而不是循环，使用numpy向量化代码，numpy对于较小的数组来说会更慢，查看<a class="ae jt" href="https://numba.pydata.org/" rel="noopener ugc nofollow" target="_blank"> numba </a>和<a class="ae jt" href="https://github.com/pydata/bottleneck" rel="noopener ugc nofollow" target="_blank">瓶颈</a>。</p><p id="c288" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">大多数强化学习代码都遵循类似的格式，如下所示:</p><pre class="lg lh li lj fd lr ls lt lu aw lv bi"><span id="2654" class="lw kj hi ls b fi lx ly l lz ma">for _ in range(epochs):<br/>  for _ in range(steps_per_epoch):<br/>    run_simulation_step()<br/>    store_training_data()<br/>  for _ in range(training_epochs):<br/>    calculate_loss()<br/>    update_model()</span></pre><p id="b400" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通常，模拟是瓶颈，因为它在CPU上运行(例外:<a class="ae jt" href="https://developer.nvidia.com/isaac-gym" rel="noopener ugc nofollow" target="_blank"> Isaac Gym </a>和<a class="ae jt" href="https://github.com/google/brax" rel="noopener ugc nofollow" target="_blank"> Brax </a>)，而其他一切都可以在GPU上并行化。就前景而言，基于物理学的3D角色动画中的典型实验运行在数百万甚至数十亿个模拟步骤的数量级上。对于训练图像或语言模型，计算量是相当的，甚至更大。</p><p id="0d0b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这种程度上，即使是最微不足道的改进也会对代码执行时间产生很大影响。正如特斯拉的人工智能主管<a class="ae jt" href="https://karpathy.ai/" rel="noopener ugc nofollow" target="_blank">最近发现的那样，一个简单的</a><a class="ae jt" href="https://twitter.com/karpathy/status/1430316576016793600" rel="noopener ugc nofollow" target="_blank">单行变更</a>用<code class="du mc md me ls b">np.sqrt</code>替换<code class="du mc md me ls b">math.sqrt</code>将数据加载速度提高了10%。</p><figure class="lg lh li lj fd lk er es paragraph-image"><div class="er es mg"><img src="../Images/fdce3653bf9bd680e78fd0821e654b51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/0*qC12lI3taEx4xADh.png"/></div></figure><p id="e21e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">可惜Python里像这样的招数太多了。在这里一一列举不会很有成效，也不值得死记硬背。编写更快代码的最通用策略是进行分析和优化。其余部分描述了一些可以压缩更多性能的常见地方。</p><h1 id="d27e" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">4注意类型转换</h1><p id="071f" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg lc ji jj jk ld jm jn jo le jq jr js hb bi translated">像<code class="du mc md me ls b">numpy</code>和<code class="du mc md me ls b">torch</code>这样的Python包使用起来非常方便，以至于我们有时在使用它们的时候都不会考虑底层开销。我们使用numpy函数的频率有多高，仅仅是因为我们懒得检查底层对象是浮点、列表还是numpy数组？</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mh"><img src="../Images/c382cebd9e37f95184575a27561986d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FH0TVDkPFRb6aqmh.png"/></div></div></figure><p id="9e43" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了使这些包更方便，它必须检查数据类型，或者将对象转换成它能理解的东西。这需要时间，在大型应用程序中，特别是在机器学习中，纳秒会很快增加。在本例中，手动将常量从float转换为numpy数组使操作速度提高了30%。最快的实现使用内置的幂运算符。当然，当需要复数时，实现的行为会有所不同。</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mi"><img src="../Images/3c8b32fa377b05155c93ceff2b807174.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jwtJC3O8R2dmNJLk.png"/></div></div></figure><p id="5d4b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是另一个例子。在机器学习中，通常编写使用一个数组来掩盖另一个数组的代码，例如图像分割。在同一个操作中组合不同的数据类型通常会有损失，这一点很容易被忽略。</p><p id="2031" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">注意类型转换也迫使我们考虑底层数据对象的类型。在我们的大脑中这样做减少了需要用代码完成的工作。最终，执行更少的代码比执行更多的代码更快。</p><h1 id="173e" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">5对内存分配要有策略</h1><p id="a59d" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg lc ji jj jk ld jm jn jo le jq jr js hb bi translated">除了Visual Basic，我在大学第一年学的第一门语言是C。在课堂上了解了<code class="du mc md me ls b">malloc</code>和<code class="du mc md me ls b">free</code>之后，我首先了解到的一件事情是，分配内存比基本的算术运算要慢得多。Python没有<code class="du mc md me ls b">malloc</code>函数，但是糟糕的内存管理仍然会降低我们代码的速度。</p><p id="fa00" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在花了很多时间分析和优化我的RL模拟环境之后，我最终发现<code class="du mc md me ls b">np.array</code>在我的代码中花费了最多的时间。在那一刻，我意识到每个<code class="du mc md me ls b">np.array</code>都有一个底层的<code class="du mc md me ls b">malloc</code>用于分配必要的内存来存储数组。每当我把一个列表转换成一个数组时，通常是出于懒惰，我都忘记了我在c语言中学到的最重要的一课。</p><p id="f469" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我的大多数项目中，我使用PyBullet来模拟角色运动。它是用C++编写的物理引擎之上的Python绑定。默认情况下，PyBullet API以Python元组的形式返回对象，例如，机器人关节角度、角色根位置等。然后，我将把这些元组转换成Python中的numpy数组，用于进一步的计算，比如计算两点之间的距离。</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mj"><img src="../Images/fcf608b010bbaefe2a856cac214e19a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ykSvpcooeiPQCycR.png"/></div></div></figure><p id="6e38" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">尽管创建numpy数组的速度很快，但几纳秒的时间会累积起来，成为总时间的重要部分。通常最好在开始时分配一段代码需要的所有内存。在强化学习中，这转化为提前分配重放缓冲区，并直接修改环境中的缓冲区数据，而不是每次都创建新的元组。同样，PyTorch中的就地操作应该优先于异地操作。</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mk"><img src="../Images/4947c8030d545ebfcb2170c09203375e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*k-CJDAEG-knfZy7B.png"/></div></div></figure><p id="bbbb" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">关于内存分配还有一点要注意:CPU和GPU内存要分开处理。CPU内存和GPU内存之间传输数据需要时间，即<code class="du mc md me ls b">torch.randn(10).to(device)</code>。对于繁重的计算任务和<a class="ae jt" href="https://en.wikipedia.org/wiki/Embarrassingly_parallel" rel="noopener ugc nofollow" target="_blank">令人尴尬的可并行化</a>问题，利用GPU加速可能是值得的。但是如果实现需要在CPU和GPU之间来回传输数据，那么GPU的任何加速都很容易被内存传输时间抵消。</p><h1 id="0c9a" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">6使用If语句时要聪明</h1><p id="442b" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg lc ji jj jk ld jm jn jo le jq jr js hb bi translated">还记得我之前说过执行更少的代码比执行更多的代码更快吗？嗯，并不总是这样——有时候代码越多越快。</p><p id="8699" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面的例子比较了两个<code class="du mc md me ls b">clip_grad_norm</code>实现。它非常受欢迎，你可能已经在许多开源机器学习项目中看到过它。第一个实现(使用if语句)稍微修改了<a class="ae jt" href="https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html" rel="noopener ugc nofollow" target="_blank"> PyTorch的源代码</a>，只保留了必要的行进行剪辑。第二个实现用箝位操作代替if语句。</p><p id="9e4c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在numpy中矢量化代码时，箝位技术很常见。简而言之，第二个实现将乘法因子固定为1，然后总是执行循环。另一方面，第一个实现在执行循环之前检查乘法因子是否小于1。if语句实现执行的代码更少，所以理论上应该更快？</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es ml"><img src="../Images/2833f5fc2d54afed4b51c56b1b3b1c1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pAbDfomaNUoyG33N.png"/></div></div></figure><p id="db34" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了确保比较公平，我每次都初始化相同的模型。尽管执行了更多的代码，第二个实现还是快了15%。如果您不相信，这里有一个简单的设置，直接比较使用If和clamp的两种实现之间的差异。</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mm"><img src="../Images/e2c69864351a912823c2616b9027bc60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aL3HJz-KvGqrFdhu.png"/></div></div></figure><p id="00b4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">if语句会损害性能的原因是因为<a class="ae jt" href="https://en.wikipedia.org/wiki/Instruction_pipelining" rel="noopener ugc nofollow" target="_blank">指令流水线</a>。If语句和其他<a class="ae jt" href="https://en.wikipedia.org/wiki/Branch_(computer_science)" rel="noopener ugc nofollow" target="_blank">分支指令</a>很慢，因为处理器不知道下一步要执行什么，直到if条件被评估——这被称为<a class="ae jt" href="https://en.wikipedia.org/wiki/Hazard_(computer_architecture)" rel="noopener ugc nofollow" target="_blank">分支危险</a>。通常，这不是一个问题，因为<a class="ae jt" href="https://en.wikipedia.org/wiki/Branch_predictor" rel="noopener ugc nofollow" target="_blank">分支预测器</a>可以高精度地提前预测结果。但是在我们的第二个例子中，if条件的随机性使得分支预测器无效。没有放之四海而皆准的解决方案。两种方法都试试，看看哪种更快。</p><h1 id="83f9" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">7使用包装时要小心</h1><p id="c92c" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg lc ji jj jk ld jm jn jo le jq jr js hb bi translated">Python生态系统非常适合快速原型开发，因为它拥有庞大的用户群，而且许多包都是现成的。对于机器学习，其他人已经花时间编写了快速的神经网络实现，这些实现可能比我们自己的实现快几个数量级，例如<a class="ae jt" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>、<a class="ae jt" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>和<a class="ae jt" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank">抱抱脸</a>。</p><p id="ef46" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是现成的代码并不总是比我们自己的实现更快。首先，拥有大量用户的软件包需要对用户友好，并保持向后兼容性。在性能和支持一般用例之间可能会有一个折衷。第二，开源软件得到了其用户的支持，这些用户可能与你我没有太大的不同。对于个人来说，在任何时候找到最优的实现都要花费太多的时间，尤其是当他们在空闲时间做出贡献的时候。</p><p id="68da" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一个特别的例子是PyTorch创建小批量的工具:BatchSampler和SubsetRandomSampler。我发现自己创建小批量的实现比使用提供的实用程序快10倍，至少在我的实验中是这样。</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mn"><img src="../Images/e44011c6642f39bd1686f6602485774e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hKTMosJCMdde1Gh_.png"/></div></div></figure><p id="2ca8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">尽管这两种实现需要键入的字符数大致相同，但自定义采样器速度更快，而且从主观上来说更容易理解。我确信有一些我没有考虑到的边缘情况，但是自从在我的项目中使用我自己的实现以来，我没有遇到任何问题。对于我自己的研究项目，我更喜欢<em class="mo">快速但具体的</em>代码，而不是<em class="mo">缓慢但通用的</em>代码。</p><h1 id="e3cf" class="ki kj hi bd kk kl km kn ko kp kq kr ks io kt ip ku ir kv is kw iu kx iv ky kz bi translated">摘要</h1><p id="739f" class="pw-post-body-paragraph ix iy hi iz b ja la ij jc jd lb im jf jg lc ji jj jk ld jm jn jo le jq jr js hb bi translated">我希望这篇文章向您展示了如何编写更快的Python代码，而不仅仅是用循环替换列表理解。</p><p id="f50f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我想听听你要说什么。这篇文章中的哪个技巧对你来说是新的？每个程序员都应该知道的另一个窍门是什么？在下面评论分享你的想法。</p></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><p id="32ce" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="mo">要了解有关数据科学的更多信息，并与数据科学温哥华的DataCan &amp; Woman保持联系，请访问</em> <a class="ae jt" href="https://datacan.network/" rel="noopener ugc nofollow" target="_blank"> <em class="mo">查看我们的网站</em> </a> <em class="mo">。</em></p></div></div>    
</body>
</html>