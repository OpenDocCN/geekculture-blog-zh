<html>
<head>
<title>Where Backpropagation in Neural Networks Comes From (pt. 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络中的反向传播来自哪里(pt。1)</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/where-backpropagation-in-neural-networks-comes-from-pt-1-fc00c16f66a2?source=collection_archive---------50-----------------------#2021-05-27">https://medium.com/geekculture/where-backpropagation-in-neural-networks-comes-from-pt-1-fc00c16f66a2?source=collection_archive---------50-----------------------#2021-05-27</a></blockquote><div><div class="ds hc hd he hf hg"/><div class="hh hi hj hk hl"><figure class="hn ho ez fb hp hq er es paragraph-image"><div role="button" tabindex="0" class="hr hs di ht bf hu"><div class="er es hm"><img src="../Images/26149b1b15f9aaea77d2b47229002984.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m1fni2CZzjI_dkWWt9fi4A.png"/></div></div></figure><div class=""/><blockquote class="iw ix iy"><p id="6477" class="iz ja jb jc b jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx hh bi translated">这是一篇技术文章。我建议你在阅读之前至少了解2+2，以及一些微积分知识🙂。然而，它非常直观，所以无论你的知识水平如何，请尽情阅读吧！请记住，本文的更多部分(这是第1部分)将很快推出！</p></blockquote></div></div>    
</body>
</html>