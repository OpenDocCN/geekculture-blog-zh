<html>
<head>
<title>Understanding the basics of Neural Networks (for beginners)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解神经网络的基础(适用于初学者)</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/understanding-the-basics-of-neural-networks-for-beginners-9c26630d08?source=collection_archive---------12-----------------------#2021-07-21">https://medium.com/geekculture/understanding-the-basics-of-neural-networks-for-beginners-9c26630d08?source=collection_archive---------12-----------------------#2021-07-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="57f2" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">让我们来了解一下神经网络背后的魔力:隐藏层、激活函数、前馈和反向传播！</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/3faa9b9b106bcde57f025d6a3b2e1690.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LPV-fAlubpzam4bIrWubig.jpeg"/></div></div></figure><p id="73cd" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">任何在人工智能驱动的数据分析领域工作的人都应该知道神经网络，因为它是令人兴奋的深度学习领域的基石。虽然人工神经网络(ANN)的想法自20世纪40年代就已经存在(<em class="kf">沃伦麦卡洛克和沃尔特皮茨创建了第一个神经网络计算模型</em> ) <strong class="jl hj">，</strong>)，但最近数据可用性和计算能力的激增使神经网络及其变体重新成为人们关注的焦点<strong class="jl hj">。</strong></p><p id="c6a2" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">有许多与神经网络相关的<a class="ae kg" href="https://www.healthcareitnews.com/news/top-10-ai-and-machine-learning-stories-2020" rel="noopener ugc nofollow" target="_blank">成功故事</a>，这些模型观察到的高精度对于有抱负的数据科学家来说是令人兴奋的消息。<em class="kf">但我也看到许多人在使用最新最复杂的深度学习模型的竞赛中陷入困境，而不知道它们是如何工作的</em>。这种方法的问题是，他们不能理解或解释模型的输出，这限制了他们在默认版本失败时有效调整模型的能力。</p><p id="e19b" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这促使我写了一系列关于神经网络如何工作、关键参数是什么以及如何有效训练它们的博客。我将在另一个博客系列中添加详细的python代码(使用Keras和Pytorch库)来帮助读者实现这些方法。</p><p id="6a7c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们将从理解神经网络如何工作开始。最好的开始方式是用动物大脑中的生物神经网络进行类比。这就是为什么神经网络中的每个单独的组件被称为神经元，它们之间的链接被称为连接(<em class="kf">见下面的</em>图1)。这些模型通过考虑输入变量和<a class="ae kg" href="https://www.datarobot.com/wiki/target/" rel="noopener ugc nofollow" target="_blank">目标变量</a>之间的关系来“学习”执行任务(如<a class="ae kg" href="https://en.wikipedia.org/wiki/Regression_analysis" rel="noopener ugc nofollow" target="_blank">回归</a>或<a class="ae kg" href="https://en.wikipedia.org/wiki/Statistical_classification" rel="noopener ugc nofollow" target="_blank">分类</a>，而不指定任何预定义的规则。神经网络的工作涉及三个关键概念:</p><ol class=""><li id="d975" class="kh ki hi jl b jm jn jp jq js kj jw kk ka kl ke km kn ko kp bi translated"><em class="kf">图层(输入、隐藏和输出)</em></li><li id="6e3b" class="kh ki hi jl b jm kq jp kr js ks jw kt ka ku ke km kn ko kp bi translated"><em class="kf">前馈</em></li><li id="bf8f" class="kh ki hi jl b jm kq jp kr js ks jw kt ka ku ke km kn ko kp bi translated"><em class="kf">反向传播</em></li></ol><h2 id="8187" class="kv kw hi bd kx ky kz la lb lc ld le lf js lg lh li jw lj lk ll ka lm ln lo lp bi translated">层(输入、隐藏和输出)</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lq"><img src="../Images/b01e72482fa5f38b4fd6631368e69459.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5oKlWLN2d2NcxekFr55wTQ.png"/></div></div><figcaption class="lr ls et er es lt lu bd b be z dx">Image 1: Neural Network Structure</figcaption></figure><p id="a26d" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">神经网络中有三种类型的层:</p><ol class=""><li id="6a02" class="kh ki hi jl b jm jn jp jq js kj jw kk ka kl ke km kn ko kp bi translated"><strong class="jl hj">输入层</strong>:接收神经网络的输入数据。它不对输入值进行任何计算，而只是将值传递给下一层。在图1的网络中，我们有4个输入值:x1、x2、x3和x4。</li><li id="4b5e" class="kh ki hi jl b jm kq jp kr js ks jw kt ka ku ke km kn ko kp bi translated"><strong class="jl hj">隐藏层</strong>:这些是输入层和输出层之间的中间层，所有的魔法都在这里发生！这一步我们需要知道几个技术术语:<br/> <strong class="jl hj"> a .权重:</strong> <em class="kf">每个神经元都与一个权重相关联，这个权重代表了单元之间连接的强度。接近零的权重意味着改变神经元的输入不会改变输出，而负权重意味着增加输入会减少输出。<br/> </em> <strong class="jl hj"> b .激活函数:</strong> <em class="kf">隐层和输出层中的每个神经元都将前一层的输出作为输入，对权重和输入的和积应用函数。这种功能称为激活功能。我们在选择这些激活函数时需要非常小心(关于如何做的更多细节可以在这个</em> <a class="ae kg" href="https://indraneeldb1993ds.medium.com/activation-functions-and-loss-functions-for-neural-networks-how-to-pick-the-right-one-542e1dd523e0" rel="noopener"> <em class="kf">博客</em></a><em class="kf">)<br/></em><strong class="jl hj">c .深度网络:</strong> <em class="kf">如果神经网络至少有两个隐藏层，那么它被称为深度神经网络<br/> </em> <strong class="jl hj"> d .密集层:</strong> <em class="kf">这些层中的每个神经元接收来自其前一层的所有神经元的输入</em></li></ol><p id="3884" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们试着更好地理解这些层，因为大部分计算都发生在这里。在图1的网络中，我们有2个深度为6的隐藏层(即每层有6个神经元)。关注第一个隐藏层，我们可以观察到它的所有神经元都将获得输入层中所有4个神经元的输入。我们如何检查这个？只需检查从输入层的每个神经元到第一个隐藏层的每个神经元的连接数。<br/>然后，我们可以得出结论，在第一个隐藏层中，将有4个与每个神经元相关联的权重(如果存在偏差项，那么它将是5)。假设第一隐藏层中的第一个神经元的权重是w1、w2、w3和w4，与该神经元相关联的激活函数将看起来像:</p><p id="1ec3" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"><em class="kf">F((w1 * x1)+(w2 * x2)+(w3 * x3)+(w4 * x4))=输出</em> </strong></p><p id="227b" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">类似于第一个隐藏层中的第一个神经元，该层中的其他神经元将具有自己的权重和激活函数。第一层的输出成为第二隐藏层中神经元的输入。我们可以观察到所有的隐藏层都很密集<em class="kf">。</em>因此<em class="kf">，</em>第二隐层中的每个神经元将有6个权重。最后，第二层的输出成为输出层的输入。</p><p id="69d2" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> 3。输出层</strong>:使用最终隐藏层的输出作为输入，生成最终输出。在图1的网络中，最后的隐藏层从它的6个神经元产生6个输出。因此，将有6个权重与输出层中的每个神经元相关联。重要的是要记住，我们必须根据任务(回归与分类)在输出层中选择适当数量的神经元和适当的激活函数。在我们的例子中，我们用三个类进行多类分类。因此，我们可以使用3个神经元和一个softmax激活函数。</p><p id="26e5" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">如果熟悉矩阵运算，所有这些数学都可以用矩阵符号<a class="ae kg" href="https://ml-cheatsheet.readthedocs.io/en/latest/forwardpropagation.html" rel="noopener ugc nofollow" target="_blank">简洁地表示出来。为神经网络选择正确的架构可以使其性能完全不同，我们将在这篇</a><a class="ae kg" href="https://indraneeldb1993ds.medium.com/activation-functions-and-loss-functions-for-neural-networks-how-to-pick-the-right-one-542e1dd523e0" rel="noopener">博客</a>中对此进行详细讨论。</p><h2 id="093c" class="kv kw hi bd kx ky kz la lb lc ld le lf js lg lh li jw lj lk ll ka lm ln lo lp bi translated">正向输送</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lv"><img src="../Images/c537dc9584d68920c5c462aec92df824.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*gMJz6v4nQNXXxbDgYuynGg.gif"/></div></div><figcaption class="lr ls et er es lt lu bd b be z dx"><strong class="bd kx">Image 2: Feed Forward Neural Network for Classification</strong> (<em class="lw">Courtesy: </em><a class="ae kg" href="https://community.alteryx.com/t5/Data-Science/It-s-a-No-Brainer-An-Introduction-to-Neural-Networks/ba-p/300479" rel="noopener ugc nofollow" target="_blank"><em class="lw">Alteryx.com</em></a><em class="lw">)</em></figcaption></figure><p id="1489" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">前向传播是基于给定输入获得神经网络输出的过程。它实际上是指上一节中定义的过程，输出称为预测值。给定来自输入层的输入，第一个隐藏层中的每个神经元计算变换<em class="kf"> z = W*x + b </em> (W是权重矩阵，x是输入矩阵，b是偏置向量)，然后对变换应用激活函数。如图2所示，该过程对后续图层重复进行，最终输出图层生成预测。然后，可以将预测值与实际目标变量进行比较，以了解预测的好坏。实际值和预测值之间的差异称为误差，然后我们可以定义一个损失函数来计算这个误差。基于手头的任务，有各种各样的损失函数，我们将在下一篇<a class="ae kg" href="https://indraneeldb1993ds.medium.com/activation-functions-and-loss-functions-for-neural-networks-how-to-pick-the-right-one-542e1dd523e0" rel="noopener">博客</a>中讨论不同场景下的最优损失函数。然后，神经网络试图通过使用反向传播(我们接下来讨论)最小化损失函数来找到最佳权重。</p><h2 id="ae55" class="kv kw hi bd kx ky kz la lb lc ld le lf js lg lh li jw lj lk ll ka lm ln lo lp bi translated">反向传播</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/0da52b80dbac39abcc1931a276854407.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*09kq2L23D9XM_9Xtr8gc8Q.png"/></div></div><figcaption class="lr ls et er es lt lu bd b be z dx">Image 3: Finding the minimum of loss function</figcaption></figure><p id="a4f4" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">如前所述，我们通过前馈得到一个输出值，即<em class="kf">预测值</em>。我们通过使用计算预测值和实际值之差的损失函数来计算预测值的好坏。然后，我们尝试使用优化器(如梯度下降)来确定与所有神经元相关的权重值，使损失函数最小化(见图3)。这个过程被称为反向传播。有多种优化器可以用来执行回溯，我们将在我未来的博客中讨论流行的优化器的优缺点。模型构建器可以决定运行多少次训练迭代(称为历元),在每次迭代中，反向传播过程会根据选择的优化器不断更新权重。</p><p id="7f15" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">因此，反向传播算法允许信息从输出层反向通过网络，以便计算权重的最佳变化。它具有以下步骤:</p><ol class=""><li id="6656" class="kh ki hi jl b jm jn jp jq js kj jw kk ka kl ke km kn ko kp bi translated">使用前馈机制计算预测值</li><li id="98e3" class="kh ki hi jl b jm kq jp kr js ks jw kt ka ku ke km kn ko kp bi translated">使用损失函数计算误差</li><li id="e850" class="kh ki hi jl b jm kq jp kr js ks jw kt ka ku ke km kn ko kp bi translated">根据选择的优化器，确定权重更新的方向和幅度，以最小化损失函数(通常这一步包括计算导数)</li><li id="760d" class="kh ki hi jl b jm kq jp kr js ks jw kt ka ku ke km kn ko kp bi translated">将优化器的输出乘以一个分数(称为学习率),因为我们不希望权重快速变化，这可能会阻止我们找到损失函数的最小值</li><li id="d866" class="kh ki hi jl b jm kq jp kr js ks jw kt ka ku ke km kn ko kp bi translated">通过将步骤4的输出添加到原始权重来调整权重</li><li id="c2c5" class="kh ki hi jl b jm kq jp kr js ks jw kt ka ku ke km kn ko kp bi translated">对于模型开发人员提到的时期数，重复步骤1–5</li></ol><h1 id="6191" class="ly kw hi bd kx lz ma mb lb mc md me lf io mf ip li ir mg is ll iu mh iv lo mi bi translated">结论</h1><p id="aa57" class="pw-post-body-paragraph jj jk hi jl b jm mj ij jo jp mk im jr js ml ju jv jw mm jy jz ka mn kc kd ke hb bi translated">这个博客的目的是帮助开始探索深度学习的读者理解神经网络是如何工作的。我们了解到以下情况:</p><ol class=""><li id="7894" class="kh ki hi jl b jm jn jp jq js kj jw kk ka kl ke km kn ko kp bi translated">神经网络中有哪些不同的层，它们是如何工作的？</li><li id="3c68" class="kh ki hi jl b jm kq jp kr js ks jw kt ka ku ke km kn ko kp bi translated">什么是激活函数、权重、密集层和深度网络？</li><li id="6186" class="kh ki hi jl b jm kq jp kr js ks jw kt ka ku ke km kn ko kp bi translated">什么是前馈，它是如何工作的？</li><li id="0a0b" class="kh ki hi jl b jm kq jp kr js ks jw kt ka ku ke km kn ko kp bi translated">反向传播包括哪些步骤？我们为什么需要它？</li></ol><p id="e344" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">下一步是了解开发人员在选择激活和损失函数等关键组件时有哪些选项，以及如何选择正确的选项。请关注这个<a class="ae kg" href="https://indraneeldb1993ds.medium.com/activation-functions-and-loss-functions-for-neural-networks-how-to-pick-the-right-one-542e1dd523e0" rel="noopener">博客</a>，在接下来的部分中了解更多！</p><p id="6e19" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">你对这个博客有什么问题或建议吗？请随时留言。</p><h1 id="0f07" class="ly kw hi bd kx lz ma mb lb mc md me lf io mf ip li ir mg is ll iu mh iv lo mi bi translated">感谢您的阅读！</h1><p id="bc95" class="pw-post-body-paragraph jj jk hi jl b jm mj ij jo jp mk im jr js ml ju jv jw mm jy jz ka mn kc kd ke hb bi translated">如果你和我一样，对人工智能、数据科学或经济学充满热情，请随时添加/关注我的<a class="ae kg" href="http://www.linkedin.com/in/indraneel-dutta-baruah-ds" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>、<a class="ae kg" href="https://github.com/IDB-FOR-DATASCIENCE" rel="noopener ugc nofollow" target="_blank"> Github </a>和<a class="ae kg" rel="noopener" href="/@indraneeldb1993ds"> Medium </a>。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mo"><img src="../Images/22ea13fb386871c4902f61702ffc3b10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PAXHmzXxwcAi1Ck02aUNHw.png"/></div></div></figure><h1 id="50c9" class="ly kw hi bd kx lz ma mb lb mc md me lf io mf ip li ir mg is ll iu mh iv lo mi bi translated">参考</h1><ol class=""><li id="7c4a" class="kh ki hi jl b jm mj jp mk js mp jw mq ka mr ke km kn ko kp bi translated">A.K. Jain、毛建昌和K. M. Mohiuddin，“人工神经网络:教程”，载于<em class="kf">计算机</em>，第29卷，第3期，第31-44页，1996年3月，doi: 10.1109/2.485891。</li><li id="4ce8" class="kh ki hi jl b jm kq jp kr js ks jw kt ka ku ke km kn ko kp bi translated">神经网络的基础。美国:不扩散条约，1994年。网络。</li></ol></div></div>    
</body>
</html>