<html>
<head>
<title>The overpowered open-cv cheat sheet for AI and M 📷</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AI和M的强力公开简历小抄📷</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/the-overpowered-open-cv-cheat-sheet-c1825bd02bf6?source=collection_archive---------7-----------------------#2022-05-01">https://medium.com/geekculture/the-overpowered-open-cv-cheat-sheet-c1825bd02bf6?source=collection_archive---------7-----------------------#2022-05-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="2376" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">从零到精通</h2></div><p id="ef3b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">图像处理和计算机视觉的世界是启动机器学习和人工智能项目的最佳时机。通过这篇文章，我将提到各种图像处理技术和计算机视觉技术，它们将帮助您轻松完成基于视觉的机器学习和人工智能项目。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es jt"><img src="../Images/e27a8249ae768a65aeb2d406dc195f3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GOA8EQMEg1rjum6y"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">Photo by <a class="ae kj" href="https://unsplash.com/@paman0744?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Aman Pal</a> on <a class="ae kj" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="94d4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我告诉你更多关于这个小抄的事情。本笔记本将包含所有重要和有效的图像处理方法，从基础到高级。您可以将此页设为书签，以获得快速见解和代码片段。我创建这个备忘单的目的是将所有重要的图像处理和操作方法集中在一个来源，这将使即使是新手也能理解流程和实现。</p><p id="4389" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">贯穿本文，我们将有代码片段，输出和对程序块的理解。我还将提供一个python笔记本的链接，您可以在那里运行我们将在本文中讨论的所有内容</p><p id="38cf" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了运行代码片段，我将使用python 3.8和open CV，open CV是python中的一个计算机视觉库，它将帮助我们执行图像处理和操作技术。如果你对这些东西都不熟悉，我会推荐你去搜索anaconda，Jupiter notebook，或者如果你使用Google Colaboratory，你也需要安装你的Google Drive。</p><p id="ba8d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在动手之前，我们需要熟悉三个重要的术语。计算机视觉，图像处理和图像操作。</p><p id="3476" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们用简单的术语来定义计算机视觉，计算机视觉是一种人工智能技术，其中计算机可以解释、理解并从图像或视频中提取知识。也就是说它能帮助电脑看清。图像处理可以简化为对图像进行增强或提取有用信息的方法或操作。所谓的图像特征。图像处理是指改变数字图像的属性以达到预期的效果。在我们进行的过程中，我将提供所有三个术语的示例。</p><blockquote class="kk kl km"><p id="612d" class="ix iy kn iz b ja jb ij jc jd je im jf ko jh ji jj kp jl jm jn kq jp jq jr js hb bi translated">警告，如果你像我一样使用MacBook M1，我在退出预览版时遇到了一些问题，这可能是一个测试版操作系统，但你仍然可以使用笔记本预览版。</p></blockquote><p id="8051" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先用python安装open CV包，可以在anaconda提示符下使用下面的命令，也可以通过笔记本安装</p><p id="a6bf" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是这篇文章很长，很多人可能时间紧迫，所以我先链接了笔记本链接</p><p id="68b3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae kj" href="https://github.com/siddheshshivdikar/open-cv-cheatbook" rel="noopener ugc nofollow" target="_blank">https://github.com/siddheshshivdikar/open-cv-cheatbook</a></p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="f524" class="kw kx hi ks b fi ky kz l la lb">!pip install opencv-python<br/>!pip install matplotlib<br/>!pip install numpy</span></pre><p id="267a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">除此之外，还包括你最喜欢的图片，你会觉得很有趣(三年前，我选择了我最喜欢的歌手❤️的图片💁)</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/b74851b4fe09f26e350ff43fb6ef9d74.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*hhD7i853nFeTsoM6K0FH3Q.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Gonna use the same image throughout 😋</figcaption></figure><p id="69d1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们将包导入笔记本中</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="cdf7" class="kw kx hi ks b fi ky kz l la lb">import sys<br/>import os<br/>import cv2<br/>import numpy as np<br/>from matplotlib import pyplot as plt</span></pre><p id="6af9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们从打开和显示我们笔记本中的一张图片开始。我在同一个目录中创建了一个名为“图片”的文件夹</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="e10d" class="kw kx hi ks b fi ky kz l la lb">input = cv2.imread("./images/image_name.jpg")<br/>plt.axis("off")<br/>plt.imshow(input) #replace this with later for full screen image<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/a2171de8bbf96d847c5916c85bf0e4e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*LKmLKOigkYoOf3Tug43CDA.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Wait whaaa ! 😕</figcaption></figure><h2 id="fadd" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">我以为RGB是我的灵魂伴侣😩那为什么是BGR？😵‍💫</h2><p id="e22e" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">需要记住的重要一点是，默认情况下opencv使用BGR作为颜色格式，而不是RGB，所以当你试图在Matplotlib中预览图像时，它可能看起来很奇怪。如果你问为什么？那我来给你解答一下。像公制和英制一样，BGR色彩空间在色彩制造商和软件提供商中很受欢迎，这使得open CV的早期开发者选择它作为他们的格式。你最终会习惯的…</p><p id="a149" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里是你如何转换它只是取代上面的线，一切都会看起来正确！</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="4b21" class="kw kx hi ks b fi ky kz l la lb"><br/>plt.imshow(cv2.cvtColor(input, cv2.COLOR_BGR2RGB))</span></pre><h2 id="46bf" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">简单但最重要的✨灰度</h2><p id="6e12" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">尽管将彩色图像转换为灰度图像会导致信息丢失，但它在特征提取方面会更有用，比如在人脸识别任务中检测特征，此外还会提高性能指标。所以灰度是没有任何颜色的从黑到白的单色阴影范围。我将在下面提到这两种转换格式</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="ae89" class="kw kx hi ks b fi ky kz l la lb">#plt.imshow(cv2.cvtColor(input, cv2.COLOR_BGR2GRAY)) # BGR TO GRAY</span><span id="a464" class="kw kx hi ks b fi mb kz l la lb">g_input = cv2.imread("./images/image_name.jpg", 0) # 0 converts into GS </span><span id="2c46" class="kw kx hi ks b fi mb kz l la lb">plt.title("Grayscale")plt.axis("off")<br/>plt.imshow(cv2.cvtColor(g_input, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/3ea97b9befb3d072a2e18f0d18387fc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*0CN-tyQ7v6E69L49zy5q-A.png"/></div></figure><h2 id="e730" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">让我们看看更大的图片🤭</h2><p id="5389" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">我们甚至可以在笔记本电脑外的窗口中显示从输出中获得的图像。这可能是一个令人困惑的过程，因为它不像看起来那么简单。首先，您必须使用cv2.imshow()，然后是cv2.waitKey()，它在您指定的延迟后等待一个键。当那个键被按下时，程序恢复。现在我们将使用cv2.destroyAllWindows()来关闭窗口。试一试</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="b232" class="kw kx hi ks b fi ky kz l la lb">#For windows <br/>cv2.imshow('Chrissy Grey', g_input)<br/>cv2.waitKey()<br/>cv2.destroyAllWindows()</span><span id="9252" class="kw kx hi ks b fi mb kz l la lb">#If it dosen't run on Mac then<br/>cv2.imshow('Chrissy Grey', g_input)<br/>cv2.waitKey(1)<br/>cv2.destroyAllWindows('frames')</span></pre><h2 id="63b6" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">色调饱和度值；三颗宝石💎</h2><p id="a83c" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">HSV颜色空间由3个矩阵组成，“色调”、“饱和度”和“值”。在OpenCV中，“色调”、“饱和度”和“值”的取值范围分别是0–179、0–255和0–255。“色调”表示颜色，“饱和度”表示相应颜色与白色混合的量，“值”表示相应颜色与黑色混合的量。</p><blockquote class="kk kl km"><p id="09c4" class="ix iy kn iz b ja jb ij jc jd je im jf ko jh ji jj kp jl jm jn kq jp jq jr js hb bi translated">一个聪明的人说它比rgb格式更适合物体检测和跟踪</p></blockquote><p id="ef83" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">想知道为什么吗？这是因为HSV是最适合于<strong class="iz hj">基于颜色的图像分割</strong> a的颜色空间，因为物体的R、G、B分量与击中物体所捕获的光量相关，使得物体辨别困难。在HSV中，我们可以分离亮度。顺便说一句，你知道我们也可以提取单个的成分，比如H，S和V吗？也会证明这一点</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="55dc" class="kw kx hi ks b fi ky kz l la lb">plt.title("Converted to HSV")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(h_input, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>plt.title("Hue Sepration")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(h_input[:,:,0], cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>plt.title("Saturation Sepration")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(h_input[:,:,1], cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>plt.title("Value Sepration")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(h_input[:,:,2], cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/57924d2d91a2887825996525da99d659.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*Z2u2OF0erjt05nDNc0WubA.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">This is HSV conversion of our image.</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/67a8f3e805e7c7c733176daefaab6f49.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*_5Q1Y_6Kc4EkEAakzhRaag.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Do you find any Background elements ?</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/9a21e3da49abd69f50a774a871dcf0bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*zLojYHK7H5NVuIINFUIAOQ.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Better edges and facial features like boundaries ?</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/10b9cca28a5fa37a278bbb3b4bb10250.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*IeNgskj03oBDwMjoq89SqA.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Better Luminosity ?</figcaption></figure><p id="716e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个结果是不是很迷人，我们甚至还没有开始任何复杂的方法。为了证明这一点，让我们把R，G，B分量也分开；我在上面插入了三张图片，因为我必须通过分离不同的通道向你展示不同的特征，让我们通过连接我们将要分离的不同颜色的通道图片来节省一些空间。请注意，您必须按照BGR的顺序将其分开。</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="d305" class="kw kx hi ks b fi ky kz l la lb">B, G, R = cv2.split(input) # used to split into respective channels</span><span id="6733" class="kw kx hi ks b fi mb kz l la lb">#cv2.imshow('Red', R)<br/>#cv2.imshow('Green', G)<br/>#cv2.imshow('Blue', B)<br/>#plt.axis("off")<br/>#plt.imshow(cv2.cvtColor(R, cv2.COLOR_BGR2RGB))<br/>#plt.show()<br/>#plt.axis("off")<br/>#plt.imshow(cv2.cvtColor(G, cv2.COLOR_BGR2RGB))<br/>#plt.show()<br/>#plt.axis("off")<br/>#plt.imshow(cv2.cvtColor(B, cv2.COLOR_BGR2RGB))<br/>#plt.show()</span><span id="76c3" class="kw kx hi ks b fi mb kz l la lb">concat = cv2.hconcat([R,G,B]) <br/># or np.hstack([img,img]) use np.vstack and cv2.vconcat([img,img]) for vertical <br/>plt.title("Red Green and Blue Channels")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(concat, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="3a50" class="kw kx hi ks b fi mb kz l la lb">#cv2.waitKey()<br/>#cv2.destroyAllWindows()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es lc"><img src="../Images/ce747a74bf247f948f4dcb060777e262.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*lQot6SmLvUDXjxmBd5OeVg.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">Saw the difference ?</figcaption></figure><p id="6506" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">同样，如果你合并通道，你会得到原来的图像，试试看。</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="b765" class="kw kx hi ks b fi ky kz l la lb">merged = cv2.merge([B,G,R])</span></pre><h2 id="e088" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">我希望天空看起来更蓝🏙</h2><p id="0eed" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">现在，许多图像处理算法使天空看起来更美丽、更蓝，我们可以尝试通过放大通道的简单方式来模拟它，显然它必须是蓝色的。从长远来看，这些简单的事情会帮助我们</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="87c3" class="kw kx hi ks b fi ky kz l la lb">amplify = cv2.merge([B+50,G,R])<br/>#cv2.imshow('Amplify', amplify)<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(amplify, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>#cv2.waitKey()<br/>#cv2.destroyAllWindows()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/ae51075de4e56d77896e8a4ca651cd7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*x-IIaoCgZ8HOFumdpPXMfQ.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Way better than before ✨</figcaption></figure><p id="e79d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">同样，我们也可以分离通道组件和❤️💚💙为什么你会问？可以简单到只提取红色形状或使用彩色遮罩进行图像分割</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="c476" class="kw kx hi ks b fi ky kz l la lb">zeros = np.zeros(input.shape[:2], dtype = 'uint8')<br/># cv2.imshow("Red",cv2.merge([zeros,zeros,R]))<br/># cv2.imshow("Green",cv2.merge([zeros,G,zeros]))<br/># cv2.imshow("Blue",cv2.merge([B,zeros,zeros]))<br/># cv2.waitKey()<br/># cv2.destroyAllWindows()<br/>plt.title("Red Channel")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(cv2.merge([zeros,zeros,R]), cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>plt.title("Blue Channel")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(cv2.merge([zeros,G,zeros]), cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>plt.title("Green Channel")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(cv2.merge([B,zeros,zeros]), cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/1d36231db7471f405e3cc88afea6c691.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*oFeZ0A99C3Wom39RTj8Y4Q.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/49459b7ae6580073fcdbdcac474d9b69.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*3W6D5u7InJo-VxhB3mwD4g.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/42604e3686feed199b60b58a57693a72.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*k9BgNYAodi9x6AenHGRD-A.png"/></div></figure><h2 id="be3c" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">让我告诉你直方图被低估了😔</h2><p id="5ea8" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">直方图主要向您显示图像中有多少<strong class="iz hj">阴影</strong>、<strong class="iz hj">中间色调</strong>和<strong class="iz hj">高光</strong>及其位置，因为数据集图像操作直方图也会对您的理解产生影响。</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="bb3e" class="kw kx hi ks b fi ky kz l la lb">histogram = cv2.calcHist([input],[0], None,[256],[0,256])<br/>plt.hist(input.ravel(), 256,[0,256])<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mc"><img src="../Images/71b72ee9df987fb3140c95010ba6c132.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*UNy_8K7Fy0YH7ZaGYz7HLA.png"/></div></figure><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="0155" class="kw kx hi ks b fi ky kz l la lb">#lets look at colors through histogram as well<br/>color = ('b','g','r')<br/>for i, col in enumerate(color):<br/>    histogram = cv2.calcHist([input], [i], None, [256], [0, 256])<br/>    plt.plot(histogram, color =  col)<br/>    plt.xlim([0,256])<br/>plt.show</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es md"><img src="../Images/b176d625e8e5e1cdc0db57355e819589.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*R8TO45lNolbnn7eutTsL8w.png"/></div></figure><h2 id="d608" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">让我们从空白开始😶</h2><p id="2574" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">我们都知道什么是边界框，什么是人脸识别中的多边形，什么是车道检测中的每一条车道，现在我们要实现基础，这样下次你需要突出显示它们时，你就知道该怎么做了。让我们从空白画布开始。</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="1216" class="kw kx hi ks b fi ky kz l la lb"># mac users change the following destroy window function if you are directly jumping on this</span><span id="975a" class="kw kx hi ks b fi mb kz l la lb">image =  np.zeros((720,720,3), np.uint8)<br/>gimage =  np.zeros((720,720), np.uint8)</span><span id="9632" class="kw kx hi ks b fi mb kz l la lb">cv2.imshow("BGR",image)<br/>cv2.imshow("Grey Scale",gimage)</span><span id="2bba" class="kw kx hi ks b fi mb kz l la lb">cv2.waitKey(0)<br/>cv2.destroyAllWindows()</span></pre><p id="0a56" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在生成的图像上画一条简单的线，我已经在评论中非常直接地解释了参数，没有双关的意思😂</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="705b" class="kw kx hi ks b fi ky kz l la lb">image =  np.zeros((720,720,3), np.uint8)<br/>cv2.line(image, (0,0),(500,720), (157,229,16), 5)<br/>cv2.line(image, (720,720),(500,0), (157,229,16), 5)<br/>#here (0,0) is the origin <br/>#(500,50) is the the end<br/>#(157,229,16) is the BGR value of the line<br/>#5 is the thickness in pixels<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>#cv2.imshow("line",image)<br/>#cv2.waitKey(0)<br/>#cv2.destroyAllWindows()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es me"><img src="../Images/464913187a0a9570b6b77a1f40cfd091.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*lw_HB64VKeVQNQCQpIYA0Q.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Line over an image</figcaption></figure><p id="66cd" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">画矩形遵循与上面相同的惯例，这里有填充和未填充的变化。</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="b45a" class="kw kx hi ks b fi ky kz l la lb">image =  np.zeros((720,720,3), np.uint8)<br/>cv2.rectangle(image, (100,100), (300,200), (157,229,16), 5)<br/>#use -1 to fill images<br/>cv2.rectangle(image, (500,500), (600,600), (157,229,16), -1)<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>#cv2.imshow("rectangle",image)<br/>#cv2.waitKey()<br/>#cv2.destroyAllWindows()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es me"><img src="../Images/426ef9ae90c228181aadd3dbc65dac6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*6Zc3ZKlAaQ3N7bYwD-eWew.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Rectangle over an image</figcaption></figure><p id="b57d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Ummm圈子？</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="73bb" class="kw kx hi ks b fi ky kz l la lb">image =  np.zeros((720,720,3), np.uint8)<br/>cv2.circle(image, (350,350), 100, (157,229,16), 5)<br/># (350,350) coordinate<br/># 100 is the radius <br/># (157,229,16) is the color<br/># 5 is the thickness of the circle<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>#cv2.imshow("circle",image)<br/>#cv2.waitKey(0)<br/>#cv2.destroyAllWindows()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es me"><img src="../Images/f6fffa8bbfad95bf4ec42ef57b655241.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*CP44XxSrlJSJQLXL2A2dyw.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Circle over an image</figcaption></figure><p id="ee62" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在图像上绘制多边形*在边界框中的矩形上使用此选项*</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="e5a1" class="kw kx hi ks b fi ky kz l la lb">image =  np.zeros((720,720,3), np.uint8)<br/>pts = np.array([[10,50],[300,75],[100,200],[400,500],[10,500]], np.int32)<br/>#straight away feed the cords<br/>pts = pts.reshape((-1,1,2))<br/>cv2.polylines(image, [pts], True, (157,229,16), 3)<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>#cv2.imshow("polygon",image)<br/>#cv2.waitKey(0)<br/>#cv2.destroyAllWindows()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es me"><img src="../Images/4e952e2fb3048ab14731ee935699b5bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*UyVdMWYtf76zjZ6hzJy4UA.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Drawing a polygon over an image</figcaption></figure><p id="b1f9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">图片上的文字*我的猫在写文字的时候在我的键盘上打滚，她真笨*🐱</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="7589" class="kw kx hi ks b fi ky kz l la lb">image =  np.zeros((720,720,3), np.uint8)<br/>cv2.putText(image, 'Guddu is love', (80,300), cv2.FONT_HERSHEY_COMPLEX, 2, (100,170,0), 3)<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>#cv2.imshow('siddo', image)<br/>#cv2.waitKey(0)<br/>#cv2.destroyAllWindows()<br/>#(80,300) is bottom left start point</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es me"><img src="../Images/d1c9fd0c9f3f788bf06eb3af886c901d.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*QJczkzN3sgeg6eyYFyEI9Q.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Writing text on an image</figcaption></figure><blockquote class="kk kl km"><p id="20f2" class="ix iy kn iz b ja jb ij jc jd je im jf ko jh ji jj kp jl jm jn kq jp jq jr js hb bi translated">我的意思是我们已经学到了这么多，我们可以制作自己的照片编辑应用程序😛</p></blockquote><p id="889b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，如果你想制作一个照片编辑应用程序，你需要裁剪、旋转、缩放和调整大小，或者如果你是一只考拉🐨我们将坚持在图像预处理中使用它们…</p><p id="f702" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们快点🤫图像翻译。</p><blockquote class="kk kl km"><p id="fc29" class="ix iy kn iz b ja jb ij jc jd je im jf ko jh ji jj kp jl jm jn kq jp jq jr js hb bi translated">图片沿x轴和y轴的移动称为平移。我们可以使用平移来上下左右移动图像，以及上述方式的任意组合。—羽毛笔机器人为了好玩而转述的</p></blockquote><p id="2a1e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我用注释让你们更好地理解它，它有点数学化</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="93d8" class="kw kx hi ks b fi ky kz l la lb"># Types of image transformations affine transformation and non affine transformation<br/>#transformation matrix<br/># T = | 1 0 Tx|<br/>#     | 0 1 Ty|<br/>height, width =  input.shape[:2]<br/>s_height, s_width = height/3, width/3<br/>#making transformation matrix using numpy<br/>T = np.float32([[1, 0, s_width],[0, 1, s_height]])<br/>#use Wrap affine function which is built into  cv<br/>Translation = cv2.warpAffine(input, T,(width, height))<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(Translation, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/0d1e400a47283de2365688dcbe1eda9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*CGoSl6tZSuDqhxdc8xeI-A.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Translated image</figcaption></figure><blockquote class="kk kl km"><p id="ddd8" class="ix iy kn iz b ja jb ij jc jd je im jf ko jh ji jj kp jl jm jn kq jp jq jr js hb bi translated">PS一口气学完会很累，你可以休息一下！🥺</p></blockquote><p id="f64d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用旋转矩阵旋转图像🙂 → 🙃</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="4d2e" class="kw kx hi ks b fi ky kz l la lb"># T = |  cos0 -sin0|<br/>#    | sin0 cos0|<br/># 0 = is angle of rotation<br/>#cv2.getRotationMatrix2D(rotation_center_x, rotation_center_y, angle_of_rotation, Scale)<br/>#this will result in cropped image try scaling it<br/>height, width =  input.shape[:2]<br/>rotation_matrix = cv2.getRotationMatrix2D((width/2, height/2), 45, .55)</span><span id="5962" class="kw kx hi ks b fi mb kz l la lb">r_image = cv2.warpAffine(input, rotation_matrix, (width,height))</span><span id="bd61" class="kw kx hi ks b fi mb kz l la lb">plt.axis("off")<br/>plt.imshow(cv2.cvtColor(r_image, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/b7c462870864f72fbdcce76f4c7e057a.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*R59aUFhwzOfjYKn21naJNw.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Rotated image</figcaption></figure><p id="c2db" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以用转置来旋转，这很容易</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="1190" class="kw kx hi ks b fi ky kz l la lb">#transpose only rotates img 90 at a time<br/>r_img =  cv2.transpose(input)<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(r_img, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mf"><img src="../Images/edefb025bb1ca2ed841bb785d333df62.png" data-original-src="https://miro.medium.com/v2/resize:fit:272/format:webp/1*77wVwfxUfrDnhAr0ki_uDg.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">I bet I didn't rotate this manually you can check the code 💁‍♂️</figcaption></figure><p id="d400" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">调整图像大小:如果你试图在笔记本上显示调整后的图像，恭喜你！用窗户代替好吗？open cv为我们提供了一些调整大小的技巧，你可以使用最适合你的方法。我将在代码单元中解释它们的用法。</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="7feb" class="kw kx hi ks b fi ky kz l la lb">#interpolation(concept of image resizing): construction/genration new pixels while expanding the image<br/>#types<br/>#cv2.INTER_AREA : good for shrinking down or sampling<br/>#cv2.INTER_NEAREST : Fastest<br/>#cv2.INTER_LINEAR : good for zooming or up sampling<br/>#cv2.INTER_CUBIC : Better<br/>#cv2.INTER_LANCZOS4 : Best<br/>#uses cv2.resize function</span><span id="d2b2" class="kw kx hi ks b fi mb kz l la lb">shrink_img = cv2.resize(input, None, fx=0.75, fy=0.75)<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(shrink_img, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>cv2.imshow("shrink",shrink_img)<br/>cv2.waitKey(0)</span><span id="0145" class="kw kx hi ks b fi mb kz l la lb">up_img = cv2.resize(input, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(up_img, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>cv2.imshow("up",up_img)<br/>cv2.waitKey(0)</span><span id="7ae3" class="kw kx hi ks b fi mb kz l la lb">dsize_img = cv2.resize(input, (800,450), interpolation = cv2.INTER_AREA)<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(dsize_img, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>cv2.imshow("defined size",dsize_img)<br/>cv2.waitKey(0)</span><span id="2a41" class="kw kx hi ks b fi mb kz l la lb">cv2.destroyAllWindows()<br/>#you cant distinguish their sizes in matplot so see them in window or use shape function</span></pre><blockquote class="kk kl km"><p id="670e" class="ix iy kn iz b ja jb ij jc jd je im jf ko jh ji jj kp jl jm jn kq jp jq jr js hb bi translated">你想看什么？调整过大小的图片？真的吗？</p></blockquote><p id="2e40" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">此外，当调整图像大小时，它们会降低质量，所以你可能也想看看这个。</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="0395" class="kw kx hi ks b fi ky kz l la lb">#resizing images tends to loose quality<br/>#mac users please change the window functions</span><span id="f535" class="kw kx hi ks b fi mb kz l la lb">small_img=cv2.pyrDown(input)<br/>cv2.imshow("smalled",small_img)<br/>cv2.waitKey(0)</span><span id="07b6" class="kw kx hi ks b fi mb kz l la lb">large_img=cv2.pyrUp(small_img)<br/>cv2.imshow("Larged",large_img)<br/>cv2.waitKey(0)</span><span id="7afb" class="kw kx hi ks b fi mb kz l la lb">cv2.destroyAllWindows()</span></pre><h2 id="6752" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">裁剪不想要的人呜呜不是那个意思🌚</h2><p id="bb1d" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">当我制作这个cheatsheet Open Cv的时候，它没有直接裁剪功能，所以它有点棘手，因为我们只需要得到中心点并保存帧，但是嘿，可能有更好的选择，我发现这个很有趣</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="263e" class="kw kx hi ks b fi ky kz l la lb">#using numpy as cv dosent have direct cropping function<br/>height, width =  input.shape[:2]<br/>#25 and 75 gives the center point<br/>#start points<br/>s_r, s_c = int(height * .25), int(width * .25)<br/>#end points<br/>e_r, e_c = int(height * .75), int(width * .75)</span><span id="8872" class="kw kx hi ks b fi mb kz l la lb">crop = input[s_r:e_r , s_c:e_c]</span><span id="0784" class="kw kx hi ks b fi mb kz l la lb">plt.axis("off")<br/>plt.imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/01c2faaf2074806868377cb017ac35da.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*ms2YZZNe9-MtOukAleuwig.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Cropped image</figcaption></figure><blockquote class="kk kl km"><p id="5a87" class="ix iy kn iz b ja jb ij jc jd je im jf ko jh ji jj kp jl jm jn kq jp jq jr js hb bi translated">你还在photoshop火车上吗？*啾* *啾*🚄</p></blockquote><h2 id="b5c0" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">曝光或so解释为亮度，但不…曝光对高光色调起作用😬</h2><p id="f8cb" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">您可能需要使图像变亮或变暗，以使其适合您的数据准备清单，您可以通过以下方式实现这一点…</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="4dbb" class="kw kx hi ks b fi ky kz l la lb">M =np.ones(input.shape, dtype = "uint8") *50<br/>addexp = cv2.add(input, M)<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(addexp, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="7db0" class="kw kx hi ks b fi mb kz l la lb">subexp = cv2.subtract(input, M)<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(subexp, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/0deba4297ba7f65ecd556837cc510299.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*N_0YXPS-H2bKSP8osfFp7Q.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Increasing the exposure</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/d2db7444816ef6333191e5bf4a04d132.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*SL2RtrfNol4DXxhD2K6B-A.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Decreasing the exposure</figcaption></figure><blockquote class="kk kl km"><p id="05ec" class="ix iy kn iz b ja jb ij jc jd je im jf ko jh ji jj kp jl jm jn kq jp jq jr js hb bi translated">想象过photoshop图层合并是如何工作的吗？比如选择、删除和合并选定的区域？你和我一样激动吗！那就上车吧🤯</p></blockquote><p id="f071" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们现在创建两个形状，可能与我们之前创建的不同。</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="1012" class="kw kx hi ks b fi ky kz l la lb">#lets create two shapes like before but in grey scale<br/>sheet_square =  np.zeros((300,300), np.uint8)<br/>cv2.rectangle(sheet_square, (50, 50), (250, 250), 255, -2 )<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(sheet_square, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>sheet_semic =  np.zeros((300,300), np.uint8)<br/>cv2.ellipse(sheet_semic, (145, 145), (145, 145), 30, 0, 180, 255, -1 )<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(sheet_semic, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es me"><img src="../Images/9e7f8ae68acb3071a087c9418f6629ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*42-lKJxmLSXCE7Ej0g0hTw.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Lets call this Friend A</figcaption></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es me"><img src="../Images/7637b8bc1daeeb3d26b3634693ff3375.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*TFIweIKXbhtjdBTSm5C0bA.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx">Lets call this Arima San</figcaption></figure><p id="82f5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">还记得逻辑门*位运算*吗？我们将使用相同的人谁是新的，只是结合了图像；或者只是将它们重叠在一起；EXOR只是更像union一样使用公共区域；不仅仅是从另一个图形中减去图形，只剩下公共区域。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es me"><img src="../Images/03f4a0196bd5fd8c0145d782a6ad4cb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*Khmm4npSolKUOh_soik_qA.png"/></div></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es me"><img src="../Images/91f2a07bfde257b4d127c3f13507a5e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*6Oh_0LDtw57X6WX84iKufA.png"/></div></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es me"><img src="../Images/0aaee23dd5c33b5352a2faab57655ab4.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*7QW_Z8NpjgNaWdBl3baUbA.png"/></div></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es me"><img src="../Images/8a10585b22af8b9a803858c6d758c10b.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*gKPFG6h6Fpe_AuS74s16Ug.png"/></div></div></figure><h2 id="f848" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">模糊:可能有助于提高边缘检测性能</h2><p id="c797" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">许多类型的瑕疵都会进入图像:模糊、对比度差、噪声、JPEG压缩等等。其中，模糊可以使边缘变得柔和，这些边缘由于标记的粗糙表面而经常包含不规则性。让我们从使用归一化矩阵开始。</p><p id="1a83" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你可以把内核想象成一个3x3的遮罩，它覆盖每个像素并应用所需的变换</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="6c16" class="kw kx hi ks b fi ky kz l la lb">plt.title("Orignal")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(input, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="5488" class="kw kx hi ks b fi mb kz l la lb"># using kernal 3 x 3  normalizing it by dividing by 9<br/>kernel_3 =  np.ones((3,3), np.float32) / 9</span><span id="efbd" class="kw kx hi ks b fi mb kz l la lb"># using kernal 7 x 7  normalizing it by dividing by 49<br/>kernel_7 =  np.ones((7,7), np.float32) / 49</span><span id="7420" class="kw kx hi ks b fi mb kz l la lb">blured_3 =  cv2.filter2D(input, -1, kernel_3)<br/>plt.title("Blur using 3 x 3")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(blured_3, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="e922" class="kw kx hi ks b fi mb kz l la lb">blured_7 =  cv2.filter2D(input, -1, kernel_7)<br/>plt.title("Blur using 7 x 7")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(blured_7, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/704b2d8ac308d915ebb57fc748272568.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*iRCrhK4ic7aEBa1LIb17mQ.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/3e01efa42598dcca106d82ecad834196.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*cZJrPm16M03waRZfQYJSUw.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/d554d6dbf48648976942a617ef9d98c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*1Vum7vZ9RPB_GO-nzSBYZQ.png"/></div></figure><p id="7b73" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">open-cv内置的模糊和卷积功能非常棒，所以你应该很擅长它们。下面我将跳过显示它们，但是一定要运行并实现它们！</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="a559" class="kw kx hi ks b fi ky kz l la lb">#view using cv2.imshow to see the difference</span><span id="390a" class="kw kx hi ks b fi mb kz l la lb">plt.title("Orignal")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(input, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="68d5" class="kw kx hi ks b fi mb kz l la lb">box = cv2.blur(input, (3,3))<br/>plt.title("Box Blur")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(box, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="d3bf" class="kw kx hi ks b fi mb kz l la lb">gaussian = cv2.GaussianBlur(input, (7,7), 0)<br/>plt.title("Gaussian Blur")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(gaussian, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="8b28" class="kw kx hi ks b fi mb kz l la lb">#uses median values of pixels <br/>median = cv2.medianBlur(input, 5)<br/>plt.title("Median Blur")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(median, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="2789" class="kw kx hi ks b fi mb kz l la lb">#bilateral is used to remove noise and keep the edges sharp</span><span id="6368" class="kw kx hi ks b fi mb kz l la lb">bilateral = cv2.bilateralFilter(input, 9, 75, 75)<br/>plt.title("Bilatral Blur")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(bilateral, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><h2 id="d50b" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">图像去噪☁️</h2><p id="ae15" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">是的，模糊图像有效，但不是每次都有效。你可能会问为什么模糊图像也会模糊边缘，这将进一步影响，是的，你猜对了我们图像中的有用功能。cv2不漂亮吗？我们内置了所有东西，这里有一个例子。</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="aaa2" class="kw kx hi ks b fi ky kz l la lb">noise_img = cv2.imread("./images/Noise.jpg")<br/>#cv2.imshow('Noise', noise_img)<br/>#cv2.waitKey()<br/>plt.title("noise")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(noise_img, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>den = cv2.fastNlMeansDenoisingColored(noise_img, None, 6, 6, 7, 21)<br/>#parameter after None are filter strength use value in range (5-10)<br/>#next is hForColorComponents use same value as h<br/>#cv2.imshow('Denoised', den)<br/>#cv2.waitKey()<br/>#cv2.destroyAllWindows()<br/>plt.title("Denoise")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(den, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es me"><img src="../Images/43e6a68a957cc7e32595af3535247e2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*9fTbW-UZNPG_CVjDzFEB1g.png"/></div></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es me"><img src="../Images/4cc89ac3bc8e95b8d64053affda1fc78.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*srsmYEeeHqEQWcIW6B6nsA.png"/></div></div></figure><h2 id="e214" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">同样，我们可以锐化模糊的图像🃏</h2><p id="5c57" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">我们将使用内核来锐化图像，但是的，可能有其他令人敬畏的选项可以用来实现您想要的输出。在这一点上，我们应该研究更多关于内核作为图像过滤器的信息，以便我们可以掌握尽可能多的知识…</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="aa26" class="kw kx hi ks b fi ky kz l la lb">kernal_s = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])<br/>sharpened = cv2.filter2D(input, -1, kernal_s)<br/>plt.title("sharpned")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(sharpened, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/11d2699d13b4d4ca8d9ece3827edfd79.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*ipza5KcAOOiupa_P0PYIoQ.png"/></div></figure><h2 id="ccc0" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">阈值:回到人工智能和ML 🛤的轨道上</h2><p id="6928" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">就应用而言，图像分割无疑是最好的，你可以说它有助于分离图像中的背景和主体，但在你开始之前，阈值处理只对灰度图像有效。让我们来看看几种不同的类型。使用正确的阈值类型将为你创造奇迹，✨</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="f724" class="kw kx hi ks b fi ky kz l la lb">#converting it into binary form<br/>#cv2.threshold(input, Threshold value, max value, threshold type)<br/>#Threshold types<br/>#cv2.THRESH_BINARY - common<br/>#cv2.THRESH_BINARY_INV - common<br/>#cv2.THRESH_TRUNC<br/>#cv2.THRESH_TOZERO<br/>#cv2.THRESH_TOZERO_INV<br/>#Threshold only works on greyscale image</span><span id="d85c" class="kw kx hi ks b fi mb kz l la lb">ret, threshb = cv2.threshold(g_input, 127, 255, cv2.THRESH_BINARY)<br/>plt.title("Thresh binary")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(threshb, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="56e5" class="kw kx hi ks b fi mb kz l la lb">ret, threshbi = cv2.threshold(g_input, 127, 255, cv2.THRESH_BINARY_INV)<br/>plt.title("Thresh binary inverse")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(threshbi, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="eafd" class="kw kx hi ks b fi mb kz l la lb">ret, thresht = cv2.threshold(g_input, 127, 255, cv2.THRESH_TRUNC)<br/>plt.title("Thresh trunc")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(thresht, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="3f60" class="kw kx hi ks b fi mb kz l la lb">ret, threshz = cv2.threshold(g_input, 127, 255, cv2.THRESH_TOZERO)<br/>plt.title("Thresh zero")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(threshz, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="dd13" class="kw kx hi ks b fi mb kz l la lb">ret, threshzi = cv2.threshold(g_input, 127, 255, cv2.THRESH_TOZERO_INV)<br/>plt.title("Thresh zero Inverse")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(threshzi, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/2df09a1fa764c0ff635debbdb4def5e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*XlARSbLnRRCIeYgF2-812w.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/4ae9c2139a0105d82df736421266072f.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*W_sdWRS5HQobvuHTMIfuXQ.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/b5a79fd4e06ada30cd67654e57a97a1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*GBbcI_IGAQ-ltJI1H5vBGg.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/07cad81dab1abc6fdfe0a4c95650bb6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*QUGMxcBrF50ExtJstYyPeQ.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/25cf3df44cc56d2112f9843b76d85e26.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*KHhPl2nAfa_v8MZ1RfLM6Q.png"/></div></figure><blockquote class="kk kl km"><p id="aedf" class="ix iy kn iz b ja jb ij jc jd je im jf ko jh ji jj kp jl jm jn kq jp jq jr js hb bi translated">想过摄像机是如何工作的吗？让我看看👀</p></blockquote><p id="343c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我刚刚取出一页，现在我要指向它并对它进行拍摄，即使它在框架之外，因为我们希望将其裁剪和倾斜成一个直的图像。好的，但是我要借助网站找到坐标，以获得角点坐标，但是你也可以编码</p><p id="8820" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们开始吧…</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mg"><img src="../Images/80005e6e0cc60cddcc44d0393ff62cbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*qyv07sUaoHbFnlk8-RwtGw.png"/></div></figure><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="b063" class="kw kx hi ks b fi ky kz l la lb">#1 163 65<br/>#2 427 58<br/>#3 127 402<br/>#4 480 393<br/>#the boundary of page is contours<br/>#<a class="ae kj" href="https://www.image-map.net/" rel="noopener ugc nofollow" target="_blank">https://www.image-map.net/</a><br/>#non affine transform 4 points<br/># affine transform 3 points<br/>w_img = cv2.imread("./images/Warp.jpg")</span><span id="3c5b" class="kw kx hi ks b fi mb kz l la lb">#the coordinate of the object <br/>p_a = np.float32(([274,110], [713,96], [216,616], [802,655]))</span><span id="64e3" class="kw kx hi ks b fi mb kz l la lb">#coordinates of desired output<br/>p_b = np.float32(([0,0], [420,0], [0,594], [420,594]))</span><span id="b78b" class="kw kx hi ks b fi mb kz l la lb">#make cv2 perspective matrix<br/>M = cv2.getPerspectiveTransform(p_a, p_b)</span><span id="8926" class="kw kx hi ks b fi mb kz l la lb">warped = cv2.warpPerspective(w_img, M, (420,594))</span><span id="20ad" class="kw kx hi ks b fi mb kz l la lb">plt.title("Orignal")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(w_img, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="25b0" class="kw kx hi ks b fi mb kz l la lb">plt.title("warped")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(warped, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><p id="d86c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">带着这份美丽离开🤗</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mh"><img src="../Images/fff2a031595c58cf2f3697399de64f4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:336/format:webp/1*JTO7HBVNiH4wsx3BMtpcbQ.png"/></div></div></figure><p id="45d4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">嗯，好吧，但是文本呢？</p><p id="0e01" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们使用阈值，但等待！我们必须指定阈值的值，对吗？并且图像条件对于每个场景可能不相同，如果我们有阈值来自动适应我们的文本呢🤔</p><h2 id="124b" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">救援⛑的自适应阈值化</h2><p id="2f9e" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">考虑到我们捕获的带有手写文本的图像，我们可能需要识别它或至少改进它以使其可读，我们可以利用自适应阈值。我将鼓励您尝试简单的阈值处理来自己观察差异。自适应阈值处理评估像素的小邻居，然后为每个邻居选择最佳阈值T。这种策略允许我们处理像素强度变化很大的情况，并且T的理想值对于图像的不同区域是不同的。</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="0c3e" class="kw kx hi ks b fi ky kz l la lb">#Threshold is important for scanning text from materials here we can use adaptive threshold<br/>#remember to change window destroy function mac users<br/>#otsus thresholding is important for text recognition<br/>text_img = cv2.imread("./images/Chrissy_text.jpg", 0)</span><span id="0aaf" class="kw kx hi ks b fi mb kz l la lb">#for adaptive thresholding<br/>ret, thresha = cv2.threshold(text_img, 127, 255, cv2.THRESH_BINARY)<br/>#for removing noise<br/>text_img = cv2.GaussianBlur(text_img, (3,3), 0)</span><span id="4539" class="kw kx hi ks b fi mb kz l la lb">#adaptive thresholding<br/>#cv2.adaptiveThresholding(image, max Value, adaptive type, threshold type, block size, constant that is substracted from mean)<br/>#block size need to be odd number constant is optimally to be 5<br/>thresh = cv2.adaptiveThreshold(text_img, 225, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 5)<br/>plt.title("Adaptive threshold")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(thresh, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>cv2.imshow('Adaptive Threshold', thresh)<br/>cv2.waitKey()<br/>cv2.destroyAllWindows()</span><span id="ad6d" class="kw kx hi ks b fi mb kz l la lb">#adaptive <br/>_,thresh_one= cv2.threshold(text_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)<br/>plt.title("OTSU Adaptive threshold")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(thresh, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>cv2.imshow('OTSUS Adaptive Threshold', thresh_one)<br/>cv2.waitKey()<br/>cv2.destroyAllWindows()</span><span id="34eb" class="kw kx hi ks b fi mb kz l la lb">#adaptive thresholding with bluring<br/>blur =  cv2.GaussianBlur(text_img, (5,5), 0)<br/>_,thresh_two= cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)<br/>plt.title("OTSU Adaptive threshold blur")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(thresh, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>cv2.imshow('OTSUS Adaptive Threshold blur', thresh_two)<br/>cv2.waitKey()<br/>cv2.destroyAllWindows()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mi"><img src="../Images/697a72222c4888939f41f4920d718bf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:288/format:webp/1*jN_UnHYUoBJfGaJqPwHapg.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mj"><img src="../Images/6d74405e862a043015cd4413bcd5af01.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*7n_HOZNVSkrFQFMG8D0-pQ.png"/></div></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mk"><img src="../Images/cd1e24e855168ef368c743ede28b42cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/format:webp/1*OyIGie1nV6L3iZl21B81Kg.png"/></div></div></figure><blockquote class="kk kl km"><p id="436e" class="ix iy kn iz b ja jb ij jc jd je im jf ko jh ji jj kp jl jm jn kq jp jq jr js hb bi translated">相信我，这些图像在全屏下看起来完全可读，试一试吧</p></blockquote><h2 id="1483" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">是钢笔🖊还是铅笔✏️ …</h2><p id="de5f" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">如果我们中有人在做笔记，他们可能会用钢笔或铅笔，所以字体的粗细，不敢相信我把它叫做，在这两种情况下可能是不同的，但在最佳情况下，我们可以通过膨胀和腐蚀来达到一个合理的形式。简单地说，膨胀是从边界开始的，侵蚀是从边界开始的。示例图像和代码块将帮助您更好地进行说明</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/74845ffc6be5958b75d5fa6a8f58be4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*WQr1ttTkmjlbTHpY_sc9_g.png"/></div></figure><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="6616" class="kw kx hi ks b fi ky kz l la lb">#Dilation add pixels to boundaries of the object in an image **make white bigger<br/>#Erosion remove pixels from the boundaries **make black bigger<br/>#Opening erosion followed by dilation<br/>#closing dilation followed by erosion<br/>t_img = cv2.imread("./images/siddo.png", 0)<br/>plt.title("Orignal")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(t_img, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="d745" class="kw kx hi ks b fi mb kz l la lb">#kernal<br/>kernel = np.ones((5,5), np.uint8)</span><span id="bfe9" class="kw kx hi ks b fi mb kz l la lb">#erosion<br/>erosion = cv2.erode(t_img, kernel, iterations = 1)<br/>plt.title("Erosion")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(erosion, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="b96b" class="kw kx hi ks b fi mb kz l la lb">#dilation<br/>dilation = cv2.dilate(t_img, kernel, iterations = 1)<br/>plt.title("Dilation")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(dilation, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="b51d" class="kw kx hi ks b fi mb kz l la lb">#opening <br/>opening = cv2.morphologyEx(t_img, cv2.MORPH_OPEN, kernel)<br/>plt.title("Opening")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(opening, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="973b" class="kw kx hi ks b fi mb kz l la lb">#closing is da best<br/>closing = cv2.morphologyEx(t_img, cv2.MORPH_CLOSE, kernel)<br/>plt.title("Closing")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(closing, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/09f2b30b241fa29d28968deeef8f4eb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*L8ylG_Ht2zuT-EZ_rhm_eA.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/473e2877ebe425365437a96aab6a9f70.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*NfYjYpMABJb5akAzqDBvlQ.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/858dc4431471a01dfb14187d9a17f7e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*hDkbt7fVfjf1cCNasOaTxg.png"/></div></figure><h2 id="e4c4" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">婴儿步骤:让我们开始一点轮廓和分割我们的初始图像</h2><p id="92c5" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">正如我们所知，在对图像进行任何分割之前，我们最好的办法是将其转换为二进制，然后添加一点模糊以减少图像中的最小噪声。我们将使用findContours来检测图像的边界。我已经在代码块中解释了所需的信息🐥</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="7675" class="kw kx hi ks b fi ky kz l la lb">g_input = cv2.imread("./images/Chrissy.jpg", 0)<br/>blur =  cv2.GaussianBlur(g_input, (3,3), 0)<br/>edged = cv2.Canny(blur, 100, 150)<br/>contours, heirarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)<br/>print("Number of contours found = " + str(len(contours)))<br/>#cv2.CHAIN_APPROX_NONE : gives all the points<br/>#cv2.CHAIN_APPROX_SIMPLE : gives end points<br/>#mode<br/>#cv2.RETR_LIST : retrieves all contours<br/>#cv2.RETR_EXTERNAL : retrieves external or outer contours only<br/>#cv2.RETR_CCOMP : retrieves all in 2-level hierarchy<br/>#cv2.RETR_TREE : retrieves all in full hierarchy<br/>display = cv2.drawContours(input, contours, -1, (0,0,255), 2)<br/>plt.title("Contours")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(display, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>cv2.imshow('Contours', input)<br/>cv2.waitKey(0)<br/>cv2.destroyAllWindows()</span><span id="b5ed" class="kw kx hi ks b fi mb kz l la lb">#print(contours)<br/>#Number of contours found = 236</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/c7a2fcb0bc5d3dc31c52ccc2212cbffd.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*J7N47AhDur67LkkENalFiQ.png"/></div></figure><p id="77bd" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们甚至可以根据轮廓的区域对其进行排序，逻辑几乎相同，但我们将学习通过笔记本将输出图像保存在我们的工作目录中</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="263d" class="kw kx hi ks b fi ky kz l la lb">shape_img = cv2.imread("./images/shapes.jpg")<br/>plt.title("Shape before")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(shape_img, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>#cv2.imshow('Contours', shape_img)<br/>#cv2.waitKey(0)<br/>#cv2.destroyAllWindows()</span><span id="2642" class="kw kx hi ks b fi mb kz l la lb">blank_image = np.zeros((shape_img.shape[0], shape_img.shape[1], 3))<br/>shape_g = cv2.imread("./images/shapes.jpg", 0)</span><span id="74ee" class="kw kx hi ks b fi mb kz l la lb">edged = cv2.Canny(shape_g, 70, 100)</span><span id="ea4b" class="kw kx hi ks b fi mb kz l la lb">contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)<br/>print("Number of contours found = ", len(contours))</span><span id="7782" class="kw kx hi ks b fi mb kz l la lb">def areas(contours):<br/>    areas = []<br/>    for i in contours:<br/>        #calculates the pixel area<br/>        v = cv2.contourArea(i)<br/>        areas.append(area)<br/>    return areas<br/>    <br/>sort = sorted(contours, key=cv2.contourArea, reverse=True)</span><span id="1d9f" class="kw kx hi ks b fi mb kz l la lb">for j in sort:<br/>    cv2.drawContours(shape_img, [j], -1, (255,0,0), 3)<br/>    cv2.waitKey(0)<br/>    cv2.imshow("contours with greater to lower area ", shape_img)</span><span id="cee4" class="kw kx hi ks b fi mb kz l la lb">cv2.waitKey(0)<br/>cv2.destroyAllWindows()</span><span id="7402" class="kw kx hi ks b fi mb kz l la lb">for (i,k) in enumerate(sort):<br/>    (x, y, w, h) = cv2.boundingRect(k)<br/>    cropped = shape_img[y:y+h, x:x+w]<br/>    name = "out_" + str(i + 1) + ".jpg"<br/>    print(name)<br/>    cv2.imwrite(name, cropped)</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es ml"><img src="../Images/248c071cdeacba8787c1790d80afeaab.png" data-original-src="https://miro.medium.com/v2/resize:fit:606/format:webp/1*Be1Oc3Ued_d8JVdIG-e-Ww.png"/></div></figure><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="59d5" class="kw kx hi ks b fi ky kz l la lb">Number of contours found =  6<br/>out_1.jpg<br/>out_2.jpg<br/>out_3.jpg<br/>out_4.jpg<br/>out_5.jpg<br/>out_6.jpg</span></pre><p id="607f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们甚至可以将形状与一堆形状进行匹配，找出所有情况下的相似形状。让我告诉你一个用例，我必须区分任何其他端口，如HDMI、USB A， USB C和lightning，给定它们的插头从前面看的图像，我们知道它们每个都有不同的形状，现在我们可以对形状进行阈值处理和匹配，以找到哪个端口，形状匹配是如何工作的，找到一些定义该形状的特征，我们将在接下来的示例中进行研究，该示例将清楚地向您展示它提取的特征，但我们可以根据原始图像调整端口的大小，并比较 港口形状下的区域也可以工作，你应该试着把这个作为一个练习，挑战自己😎</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="3f97" class="kw kx hi ks b fi ky kz l la lb">src = cv2.imread("./images/src.png", 0)<br/>envv = cv2.imread("./images/env.png")<br/>env = cv2.imread("./images/env.png", 0)</span><span id="680e" class="kw kx hi ks b fi mb kz l la lb">ret, thresha = cv2.threshold(src, 127, 255, 0)<br/>ret, threshb = cv2.threshold(env, 127, 255, 0)</span><span id="c3e5" class="kw kx hi ks b fi mb kz l la lb">contours, hierarchy = cv2.findContours(thresha, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)</span><span id="773d" class="kw kx hi ks b fi mb kz l la lb">sorted_contours = sorted(contours, key=cv2.contourArea, reverse = True)</span><span id="8115" class="kw kx hi ks b fi mb kz l la lb">template_contour = contours[0]</span><span id="49ea" class="kw kx hi ks b fi mb kz l la lb">contours, hierarchy = cv2.findContours(threshb, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)</span><span id="1f45" class="kw kx hi ks b fi mb kz l la lb">for c in contours:<br/>    match = cv2.matchShapes(template_contour, c, 1, 0.0)<br/>    print(match)<br/>    if match &lt; 0.15:<br/>        closest_contour = c<br/>        break<br/>    else:<br/>        closest_contour = []<br/>cv2.drawContours(envv, closest_contour, -1, (0,255,0), 4)</span><span id="05af" class="kw kx hi ks b fi mb kz l la lb">plt.title("Source")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(src, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="26dd" class="kw kx hi ks b fi mb kz l la lb">plt.title("Enviornment")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(env, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="5385" class="kw kx hi ks b fi mb kz l la lb">plt.title("Match found")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(envv, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mm"><img src="../Images/c212a56a9891c86f95ef557e33c29488.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*nG_jP66DGCebmGG69rFdKA.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/d8d0a56a4d473cd97804d15fb2fbbc89.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*RKGAoEfEAgr9T06Y6gYGVg.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lc"><img src="../Images/0aef4464ce65d77a5d04e5f0ff3487d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*2V0o4VGgbvn1kWodb56ZoA.png"/></div></figure><p id="fc37" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们知道匹配形状，但让我们回到旧的记忆，我想找到口袋妖怪从废话吨口袋妖怪只是为了测试像素匹配的工作原理是它只是匹配像素到像素通过窗口扫描整个图像从左到右，然后下降</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="af17" class="kw kx hi ks b fi ky kz l la lb">#not even ideal :D<br/>pokemon = cv2.imread("./images/Pokemon.jpg")<br/>gray = cv2.cvtColor(pokemon, cv2.COLOR_BGR2GRAY)<br/>pikachu = cv2.imread("./images/Pikachu.jpg",0)</span><span id="1a2d" class="kw kx hi ks b fi mb kz l la lb">result = cv2.matchTemplate(gray, pikachu, cv2.TM_CCOEFF)<br/>min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)</span><span id="5a37" class="kw kx hi ks b fi mb kz l la lb">#marking<br/>top_l = max_loc<br/>bottom_r = (top_l[0]+50, top_l[1]+50)<br/>cv2.rectangle(pokemon, top_l, bottom_r, (255,0,0), 5)</span><span id="6ff5" class="kw kx hi ks b fi mb kz l la lb">plt.title("Pika")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(pikachu, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="9fec" class="kw kx hi ks b fi mb kz l la lb">plt.title("Pokemons")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(gray, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="7ccb" class="kw kx hi ks b fi mb kz l la lb">plt.title("Match found")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(pokemon, cv2.COLOR_BGR2RGB))<br/>plt.show()</span><span id="11bb" class="kw kx hi ks b fi mb kz l la lb">cv2.imshow('Matchfound', pokemon)<br/>cv2.waitKey()<br/>cv2.destroyAllWindows()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mn"><img src="../Images/d1aa8c68c13df76047294c1ca70eefdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:494/format:webp/1*D1P4CMT6gqsO07OdxEXDSg.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mo"><img src="../Images/1087bfe6d7da13075476755bd6bb108c.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*LZ0lFn2qIt9L4C9nel-dRA.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mo"><img src="../Images/431fedc760cca10515cd01a65d22992a.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*TqGc10XxgIv7R-LCprs0ug.png"/></div></figure><h2 id="6ab7" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">要跟踪的轮廓和特征:只剩一个…😵‍💫</h2><blockquote class="kk kl km"><p id="1052" class="ix iy kn iz b ja jb ij jc jd je im jf ko jh ji jj kp jl jm jn kq jp jq jr js hb bi translated">我爱上了你的形状~打开CV到每个交叉的角落，同时选择好的特征😂</p></blockquote><p id="1a1f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当分割图像时，如果你不需要一个完美的边界，我的朋友会节省大量的性能和提高速度，甚至会分离图像上的不同集群，就像考虑世界地图上的大陆一样🗺或者甚至检测手✋让使用凸包轮廓</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="7136" class="kw kx hi ks b fi ky kz l la lb">pup = cv2.imread("./images/pup.png")<br/>og = pup.copy()<br/>gg = pup.copy()<br/>gray = cv2.imread("./images/pup.png", 0)<br/>plt.title("Orignal ")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(pup, cv2.COLOR_BGR2RGB))<br/>plt.show()<br/>ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)<br/>contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)<br/>#bounding rectangle<br/>for c in contours:<br/>    x,y,w,h = cv2.boundingRect(c)<br/>    cv2.rectangle(og, (x,x), (x+w,y+h),(0,0,255),2)<br/>    cv2.imshow('Bounding rect', og)<br/>cv2.waitKey(0)<br/>#itreating through each contour<br/>for c in contours:<br/>    accuracy = 0.01 * cv2.arcLength(c,True)<br/>    approx = cv2.approxPolyDP(c, accuracy, True)<br/>    a = cv2.drawContours(pup, [approx], 0, (0,255,0), 2)<br/>    cv2.imshow('Approx poly DP', a)<br/>    <br/>cv2.waitKey(0)<br/>cv2.destroyAllWindows()</span><span id="f501" class="kw kx hi ks b fi mb kz l la lb">plt.title("contours")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(a, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mg"><img src="../Images/c09a2922b93fcce0dbc97927d45604d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*8W5W82oEE_uKFdb7sG0clQ.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mg"><img src="../Images/e78a7bcd40320f5c0fd1e7c5e3e743b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*c9_LL_Uvai5Q73MT18V98Q.png"/></div></figure><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="0a5f" class="kw kx hi ks b fi ky kz l la lb">ret, thresh = cv2.threshold(gray, 176,255,0)<br/>contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)<br/>n = len(contours) - 1<br/>contours = sorted(contours, key=cv2.contourArea, reverse = False)[:n]<br/>for c in contours:<br/>    hull =  cv2.convexHull(c)<br/>    b = cv2.drawContours(gg, [hull], 0, (255,0,0), 2)<br/>    cv2.imshow('conves Hull', b)</span><span id="c9ed" class="kw kx hi ks b fi mb kz l la lb">cv2.waitKey(0)<br/>cv2.destroyAllWindows()</span><span id="fda2" class="kw kx hi ks b fi mb kz l la lb">plt.title("convex hull")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(b, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><p id="706e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">跟踪具有harris角点的特征和要跟踪的良好特征。</p><blockquote class="kk kl km"><p id="50b9" class="ix iy kn iz b ja jb ij jc jd je im jf ko jh ji jj kp jl jm jn kq jp jq jr js hb bi translated">角落是一个很棒的功能！<strong class="iz hj">每个角落都有变化</strong>。所以，导数在各个方向上变化。所以二阶导数也是各个方向变化的！—有人</p></blockquote><p id="eec9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">简而言之，它决定了使用模糊时哪个滑动窗口(也称为核心窗口)在🥱的任何方向上移动时变化最大</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="4cc8" class="kw kx hi ks b fi ky kz l la lb">#image features<br/>img = cv2.imread("./images/pup.png")<br/>gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><span id="3309" class="kw kx hi ks b fi mb kz l la lb">#Harris corners require array datatype to be float<br/>gray = np.float32(gray)</span><span id="912d" class="kw kx hi ks b fi mb kz l la lb">harris_corners = cv2.cornerHarris(gray, 3, 3, 0.05)</span><span id="9e71" class="kw kx hi ks b fi mb kz l la lb">kernel = np.ones((7,7),np.uint8)</span><span id="2db5" class="kw kx hi ks b fi mb kz l la lb">corners=cv2.dilate(harris_corners, kernel, iterations = 2)</span><span id="76a5" class="kw kx hi ks b fi mb kz l la lb">img[corners &gt; 0.025 *  corners.max()] = [255, 127, 127]</span><span id="a253" class="kw kx hi ks b fi mb kz l la lb">plt.title("Corners")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mg"><img src="../Images/173092b073992cf062218ad15fbb6e0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*SJ_dIrWxs45X7nWtCZTgLw.png"/></div></figure><h2 id="aaa6" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">好的跟踪特征:我喜欢公开简历的命名连接</h2><p id="650d" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">看看好的跟踪功能是如何吸引眼球的👀眼睛从不说谎，所以用好的特征来跟踪就好了😂</p><pre class="ju jv jw jx fd kr ks kt ku aw kv bi"><span id="dd41" class="kw kx hi ks b fi ky kz l la lb">img = cv2.imread("./images/pup.png")<br/>gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><span id="fbce" class="kw kx hi ks b fi mb kz l la lb">corners = cv2.goodFeaturesToTrack(gray, 50, 0.01, 55)</span><span id="b500" class="kw kx hi ks b fi mb kz l la lb">for corners in corners:<br/>    x , y = corners[0]<br/>    x = int(x)<br/>    y = int(y)<br/>    cv2.rectangle(img, (x-10,y-10), (x+10,y+10), (0,255,0), 2)<br/>    <br/>plt.title("Corners")<br/>plt.axis("off")<br/>plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mg"><img src="../Images/ec8d1915afe735939702b9cdba01df45.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*8lvb2E50QEmcG_SZkNm8JQ.png"/></div></figure><h2 id="c666" class="kw kx hi bd ld le lf lg lh li lj lk ll jg lm ln lo jk lp lq lr jo ls lt lu lv bi translated">世界是美丽的，只是不要忘记拥抱它的美丽！✨</h2><p id="fe2c" class="pw-post-body-paragraph ix iy hi iz b ja lw ij jc jd lx im jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">你为学习所做的努力将永远带你去你想去的地方和人。我感到有动力与每一个想学习或开始学习的人分享我获得的知识，这是一个很大的进步，如果你已经完全了解了，你可以评论一下小抄的用处。我会继续在cheatsheet中添加一些东西，我已经准备好了很多，只需要发送给你们。快乐编码，用心生活。你可以在我的社交网站上关注我，我希望这能帮助和激励人们离开❤️</p></div></div>    
</body>
</html>