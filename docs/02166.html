<html>
<head>
<title>Obesity Classification and Data Analysis via Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于机器学习的肥胖分类和数据分析</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/obesity-classification-and-data-analysis-via-machine-learning-6635682f0f87?source=collection_archive---------6-----------------------#2021-05-06">https://medium.com/geekculture/obesity-classification-and-data-analysis-via-machine-learning-6635682f0f87?source=collection_archive---------6-----------------------#2021-05-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="9a6a" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="18d8" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我选择进一步分析我用于最终项目的<a class="ae kb" href="https://stacyy.medium.com/itp-449-exploratory-data-analysis-project-obesity-levels-based-on-eating-habits-and-physical-82fa10775c2e" rel="noopener"> <strong class="jf hj"> EDA </strong> </a>的<a class="ae kb" href="https://drive.google.com/file/d/1dqIVJkvy_8-DclFL_F4H8Izw9vGABlnV/view?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="jf hj">数据集</strong> </a>。该数据集记录了墨西哥、秘鲁和哥伦比亚人的肥胖水平，以及他们的饮食习惯和身体状况。由于该项目要求我们建立一个机器学习模型，我有兴趣建立一个关于一个人是否肥胖的准确模型——这是一个两类问题——以及找到与训练该模型最相关的特征。</p><p id="f7dd" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我使用的数据集有2111个年龄在14到61岁的个体的数据和17个属性。这些属性中有许多都有缩写，所以我在下面简要描述了它们:</p><ul class=""><li id="6848" class="kh ki hi jf b jg kc jk kd jo kj js kk jw kl ka km kn ko kp bi translated"><strong class="jf hj">性别</strong> : 1=女性，2 =男性</li><li id="e368" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj">年龄</strong>:数字</li><li id="d55e" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj">高度</strong>:数字，单位为米</li><li id="bc32" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj">重量</strong>:数字，单位为千克</li><li id="e483" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj">家族史</strong>(肥胖家族史):1 =是，2 =否</li><li id="fcb4" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj"> FCHCF </strong>(经常食用高热量食物):1=是，2=否</li><li id="3bcb" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">FCV (吃蔬菜的频率:1 =从不，2 =有时，3 =总是</li><li id="b072" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj"> NMM </strong>(主餐数量):每天1、2、3、4餐</li><li id="9bbb" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj"> CFBM </strong>(两餐之间的食物消耗量):1 =否，2 =有时，3 =经常，4 =总是</li><li id="3f6a" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj">烟雾</strong> : 1=是，2=否</li><li id="9e29" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj"> CW </strong>(耗水量):1 =小于1升，2 = 1–2升，3 =大于2升</li><li id="c09c" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj"> CCM </strong>(卡路里消耗监测):1=是，2 =否</li><li id="05bc" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj"> PAF </strong>(每周身体活动频率):0 =无，1 = 1至2天，2= 2至4天，3 = 4至5天</li><li id="87f1" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj">啧啧</strong>(一天使用科技设备的时间):0 = 0–2小时，1 = 3–5小时，2 = 5小时以上</li><li id="fcd1" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj"> CA </strong>(饮酒量):1=从不，2 =有时，3 =经常，4 =总是</li><li id="99d7" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj">交通</strong> : 1 =汽车，2 =摩托车，3 =自行车，4 =公共交通，5=步行</li><li id="e03b" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><strong class="jf hj">肥胖(目标变量)</strong> : 2 =不肥胖，4 =肥胖</li></ul></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="5e1f" class="if ig hi bd ih ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc bi translated">数据准备</h1><ol class=""><li id="de6b" class="kh ki hi jf b jg jh jk jl jo lh js li jw lj ka lk kn ko kp bi translated"><strong class="jf hj">导入库</strong></li></ol><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><p id="02f6" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">首先，我导入了理解和训练数据所需的库。之后，我使用google.colab导入CSV文件，然后使用pandas将数据加载到一个数据框中。前五个数据点通过。头部功能。</p><p id="ff9a" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj"> 2。检查形状和值</strong></p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><p id="0fdc" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">的。形状函数准确返回(2111，17)，热图确认没有丢失值。</p><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ls"><img src="../Images/8c7ec2cf30eae6043cde131c3a419169.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R3xRXqnEskHzkwW88HZ3hw.png"/></div></div></figure><p id="9c70" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj"> 3。相关性</strong></p><p id="b692" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">接下来，我打了电话。corr得到一个相关矩阵，因为这将帮助我确定是否有任何变量我应该放弃，因为它们与目标变量，肥胖，太相关了。我将矩阵转化为热图，因为它使我能够有效地识别高度相关或不相关的变量。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lz"><img src="../Images/9508c45428677a048f13fc5c3a205a71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5LF9jyLFGk6tQFNHcDXNvw.png"/></div></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ma"><img src="../Images/6a8302164d421f7e8cc0d8ad1f6b232d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zWnwOkygtNU5DYlRaMBFig.png"/></div></div></figure><p id="0719" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">热图告诉我，一个变量，体重变量，与肥胖高度相关(0.79)。这是有道理的，因为体重是决定一个人的身体质量指数和一个人是否肥胖的一个不可或缺的因素。</p><p id="189f" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj"> 4。丢弃变量</strong></p><p id="d564" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">知道体重与肥胖高度相关，我需要去掉这个变量，以确保我的模型可以从其他变量中学习。当我用权重特征运行我的模型时，我的集合模型在没有任何调整的情况下都具有98.74%至99.16%的准确度，甚至我的逻辑回归模型也具有97.68%的准确度。放下它会降低它们的精确度，让我可以分析更多的其他特征。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><p id="e2b9" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj"> 5。数据集概述</strong></p><p id="f832" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">为了检查变量是否被删除，以及我的数据集的整体准确性和组成，我调用了下面的四个函数来给我一个快速概述。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mb"><img src="../Images/d1baab4948cd057eea867ede4affea5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yZfUCpmLAo4zN30JStgwSw.png"/></div></div></figure><p id="49ac" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj"> 6。目标变量分布</strong></p><p id="67a9" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">最后，我创建了一个countplot来获取目标变量的分布，这样我就可以看到它是否平衡，以便通知训练集和测试集。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es mc"><img src="../Images/934337538233bee83a19e62d34ef4633.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*U9Cqk5RAUui5EvkpwjDSiA.png"/></div><figcaption class="md me et er es mf mg bd b be z dx">2 = not obese, 4= obese</figcaption></figure><p id="7d40" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">这个数据集相当平衡，因为肥胖的例子和不肥胖的例子几乎一样多。这里的目标变量显然是二元分类的情况，这将通知我们未来的模型选择。</p><p id="0efd" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">进一步的数据探索，请参考我的<a class="ae kb" href="https://stacyy.medium.com/itp-449-exploratory-data-analysis-project-obesity-levels-based-on-eating-habits-and-physical-82fa10775c2e" rel="noopener"> <strong class="jf hj"> EDA文章。</strong>T13】</a></p></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="6101" class="if ig hi bd ih ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc bi translated">预建模</h1><ol class=""><li id="ecf5" class="kh ki hi jf b jg jh jk jl jo lh js li jw lj ka lk kn ko kp bi translated"><strong class="jf hj">预处理</strong></li></ol><p id="52f3" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">在分割数据之前，应先对其进行规范化，因为数据集要素的范围并不相同。这可能会有问题，因为一个功能的微小变化可能不会影响到另一个功能，因此范围被规范化为0–1的统一范围。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mh"><img src="../Images/d0f445b9c3e42730744e0f1aa9bab8e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y8544ItXWSlMFQsgTazXCA.png"/></div></div></figure><p id="27c0" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj"> 2。分割测试和训练数据</strong></p><p id="1a2b" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">数据集被划分为训练集(70%)和测试集(30%)，并打印出各自的形状，以确保在构建模型之前数据被正确分割。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es mi"><img src="../Images/61b06982725aee85cdff09b0c9e41e71.png" data-original-src="https://miro.medium.com/v2/resize:fit:304/format:webp/1*OXvHIq4vB0romx2ZKwFiHQ.png"/></div></figure><p id="067d" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">这些数字表明训练集有1477个数据点，而测试集有634个数据点。</p><p id="f6b8" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj"> 3。基线分类精度</strong></p><p id="1efc" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">计算基线分类精度很有帮助，因为这是最简单的预测。这给了我们一个很好的起点，当我们以获得更好的分数为目标创建更精确的模型时，要记住这一点。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mj"><img src="../Images/275bcfaea6265b9a271cfbf65255e3da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ZgctSoPQaQmydIhhKH7AuQ.png"/></div></div></figure><p id="0ca5" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们得到了54.57%的低基线精度，因此我们的后续模型应该具有比这更高的精度。</p></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="d250" class="if ig hi bd ih ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc bi translated">模型</h1><p id="b1c1" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我选择了以下六个模型，因为它们可以很好地处理二元分类问题，比如这篇文章所讨论的肥胖问题。</p><p id="3fda" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">模型#1:逻辑回归&amp;超参数微调</strong></p><p id="699a" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我将训练的第一个模型是逻辑回归模型，因为它是一种预测分类变量概率的分类算法。除了random_state之外，我还使用默认参数实例化了它，因为我希望每次分割都是相同的。然后用数据拟合模型，并进行预测和评估。之后，通过标准的10重交叉验证对模型进行交叉验证，其中数据被分成10个子集，每个子集依次作为验证数据集搁置，以确定拟合度。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es mk"><img src="../Images/cc4ec61d315f186b39858c12c457c849.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*5aJTkOre3_qBdK4_HpHEBw.png"/></div></figure><p id="354a" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">在这里，我们可以看到，逻辑回归模型在77.91%的时间内是准确的，这远远低于当体重特征仍然存在时模型得到的97.68%。71.01%的交叉验证分数明显低于模型的准确性。这表明我们的模型可能过度拟合，或者与当前数据和随机噪声过于接近，而不是变量之间的实际关系。由于差异几乎是8%，我们应该微调模型的超参数，看看当我们使用GridSearchCV时会发生什么。GridSearchCV被视为更准确的方法之一，因为它的迭代次数很多，因为它贯穿了超参数值的每个组合。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ml"><img src="../Images/7bddc2140ec0267f8c60a09c90bbc196.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ZXtjgYy1PR5paRpg3L8wQ.png"/></div></div></figure><p id="7051" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">现在GridSearchCV已经给了我们最好的超参数用于C，penalty和solver，我们应该使用它们并重新评估精度。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es mm"><img src="../Images/dc14369db761809fbd0380f143272196.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*rP3iTjquktabcTXtuqIctg.png"/></div></figure><p id="388e" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">在使用建议的超参数后，我们的交叉验证分数72%更接近GridSearchCV的75.72%输出，这意味着我们的模型得到了改进，不像以前那样过度拟合。然而，我很好奇另一种流行的调整超参数的方法RandomizedSearchCV会怎么样，因为它采用了一种不同的方法，通过创建超参数值的网格并在训练时选择随机组合。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mn"><img src="../Images/5c76066f608d32fa5a10fc233a7816cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Weyge4nNDExigChhKRgL6g.png"/></div></div></figure><p id="1acc" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我将RandomizedSearchCV的关键超参数重新插入到逻辑回归中，以观察其性能。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es mo"><img src="../Images/a2a34be61a1289fb818654f52ea2f3de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*ZdYL8bDbE6gjIN7xewaMyg.png"/></div></figure><p id="7c32" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">虽然与初始逻辑回归模型准确性及其交叉验证分数相比，RandomizedSearchCV的超参数仍然改善了交叉验证和RandomizedSearchCV分数之间的差异，但它并没有像GridSearchCV那样将差异最小化。因此，我们将使用GridSearchCV的超参数来看看逻辑回归的主要特征。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mp"><img src="../Images/f3e4f4f584489445130bc2bf1f524160.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CB1BVq7BYWoB0_gEHg_BPA.png"/></div></div></figure><p id="f362" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">这张图表向我们展示了预测肥胖的不同特征的相对重要性。我们可以看到，这个模型的三个最重要的特征是CFBM(两餐之间的食物消耗量)、年龄和家族史。从表面上看，这些变量似乎对肥胖有更大的影响，但我们将继续探索更多的模型，并获得更好的共识。</p><p id="89fc" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们还可以在逻辑回归模型上快速创建分类报告。“精确度”类别指的是准确预测的百分比,“召回”类别详细说明了找到的肯定案例的百分比，F1分数是正确的肯定预测的百分比。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mq"><img src="../Images/5eb9c856629e09ed4c3a23572ec33218.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6rTf_4vFAiWiIH0BWUfJqA.png"/></div></div></figure><p id="ab68" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">接下来，我将使用各种集成方法，这些方法是将多个模型结合起来得到最终预测的预测模型。</p><p id="1efd" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">模型#2:装袋</strong></p><p id="31c0" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">Bagging也称为bootstrap aggregation，是一种平均集成方法，用于决策树并聚合多个模型的预测。n_estimators是BaggingClassifier和其他类似模型的参数，它会对模型的准确性产生很大影响，并且很难确定要使用的最佳n _ estimators。因此，我们可以使用n估计量的增加值和它们的测试精度的图表来帮助我们选择具有最高可能精度的n估计量。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es mr"><img src="../Images/f02c1943e539a4d2880d3cfd30cc0457.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*LDgxXXsLh2iL2Fc6xWfR7g.png"/></div></figure><p id="86ee" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">这张图告诉我们，当n_estimator约为79时，精确度最高，因此我们将使用它来构建bagging模型。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es ms"><img src="../Images/52af424b3e1f33bc35b6ab991fd0a37a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*gDygzFWFmBqXroFSA87tMA.png"/></div></figure><p id="dabb" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">bagging模型为我们提供了93.06%的准确性和92.14%的交叉验证分数，这是我们从逻辑回归模型中获得的巨大改进，可能是因为它是几个模型的产物，这些模型分别进行了训练和平均。这两个分数之间的差异也非常小，表明模型拟合得更好，不需要像我们在逻辑回归模型中那样微调超参数。<em class="mt">交叉验证和准确度分数之间有微小差异(&lt; 1%)的所有后续模型将不会被微调</em>。</p><p id="0759" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">打印分类报告只是为了确认准确性:</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mu"><img src="../Images/9749ff2503d476d034e42cdec55ed71a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PKFrGsLDcEE4wLO8b5_PnQ.png"/></div></div></figure><p id="14c7" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">该报告告诉我们，与逻辑回归模型的分类报告相比，该模型对于类别0和类别1中的对象都具有更高的准确性。</p><p id="b001" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">模式三:随机森林</strong></p><p id="8c8f" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">接下来，我将构建一个随机森林模型，这是另一种平均方法，并创建一个去相关决策树的集合。</p><p id="4d02" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我创建了另一个关于n估计量及其测试精度的图表，让我知道在我的随机森林模型中应该使用什么样的n估计量。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es mv"><img src="../Images/17324754f5c9da4fd1d1030a2de2fa69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*qXo4jUi0f31vdROJaNzxIQ.png"/></div></figure><p id="30ea" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">该图表明，大约为132的n估计值将有助于我们实现高精度。然而，准确性的大小仍然取决于我指定或不指定的其他参数。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es mw"><img src="../Images/b4316c189b43a88823efa6434deea171.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*1fgIetN5Qme_Oh7_ErvbLA.png"/></div></figure><p id="80f7" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">max_features是分割结点时要考虑的随机要素子集的大小。虽然将其设置为“auto”使我获得了94.95%的高准确度和93.85%的交叉验证，但我选择将其设置为6，以获得类似的94.79%的准确度和更高的94.04%的交叉验证分数。正如我们所看到的，随机森林模型是迄今为止性能最好的模型，具有很高的准确性和交叉验证分数，交叉验证分数非常接近准确性，表明过度拟合程度低得多。</p><p id="921a" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我还对随机森林模型中最有影响力的特性感到好奇，所以我创建了一个简单的条形图来直观显示这一点。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mx"><img src="../Images/c2009dcf4b18e004d70b0092329f51d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ehx9Oiajnd_kkpgaqvzDNw.png"/></div></div></figure><p id="adb6" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">这向我表明，年龄、家族史和身高是通过随机森林模型预测肥胖最有用的特征，而吸烟和卡路里消耗监测等其他特征仅仅是噪声。我还可以通过下面的代码快速提取前三个特性及其特性重要性值:</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es my"><img src="../Images/b9457c52ff99d2db787fa8ec99e66e99.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*ChBIUFOE-F_0nxZHDUFHNA.png"/></div></figure><p id="3773" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">袋外(OOB)样本是被排除在引导样本之外的样本，可以用作测试样本，因为它们没有在培训中使用，因此可以防止泄漏。由于oob_score提供了一个更好的模型，具有更低的方差，并且没有过度拟合，因此它有助于验证该模型。在下面的代码中，我比较了OOB准确度分数和随机森林模型的准确度。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es mz"><img src="../Images/057be41ecf2089b3994d97ff21bc656b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*Yt2vZgtJtIrNOg91AdL1Vg.png"/></div></figure><p id="3d14" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">在这里，我们可以看到，OOB分数非常接近我们以前计算的测试精度，证实了我们的模型是高性能的。</p><p id="b813" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">型号#4: AdaBoost </strong></p><p id="a734" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">接下来，我们将看看另一种不同的系综方法，增强方法。这与bagging方法不同，因为这些方法可以减少总体方差，而boosting模型通过顺序训练弱学习者来降低总体偏差。</p><p id="fe21" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我选择建立一个AdaBoost模型，它将几个弱学习器组合成一个强学习器，并为每个错误分类的观察值改变权重。我从另一个n_estimator图开始:</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es na"><img src="../Images/70839a2be73d61326eecdbe3b8871a5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*7P71N-tryuZDdHlE2GmJ8Q.png"/></div></figure><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es nb"><img src="../Images/468dcb827d102801cfc6033cca629303.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*xKe0PB17fBynRTsrgCi8XQ.png"/></div></figure><p id="40e0" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我用AdaBoost模型指定了更多的参数，比如max_depth为7，learning_rate为0.5，以进一步提高准确性和交叉验证分数。我测试了这些参数的各种实例，并根据它们的精度输出来选择它们。该模型为我们提供了很高的准确性和交叉验证分数，两者之间的差异可以忽略不计。</p><p id="8a80" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我很想看看AdaBoost模型的特征变量与随机森林模型相比如何，所以我将它们绘制在下面。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es nc"><img src="../Images/63750520dcd7d4f2bc9caed2d280db8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VYEiExJqfcJmUNtlgx27LQ.png"/></div></div></figure><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es nd"><img src="../Images/52748072018c351fa0b7aca490d478ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*BOTL6RlR2yLEfOirbf73jw.png"/></div></figure><p id="8346" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">对于最重要和最不重要的变量，特征重要性输出是相似的，因为身高和年龄都出现在两个模型的前三个特征中，吸烟和卡路里消耗监测仍然是最不重要的。然而，在AdaBoost模型的前三个特征中，家族史被替换为身体活动频率。</p><p id="c771" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">模型#5:梯度推进树</strong></p><p id="33fc" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">梯度增强树是另一种增强模型。然而，当AdaBoost根据其预测精度对观测值进行重新加权时，梯度增强树试图将新的预测值拟合到来自先前预测值的残差中。</p><p id="9d52" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">和以前一样，我首先可视化了n _估计量的性能。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es ne"><img src="../Images/bef4431e7c3fce00f2d99017adfed00d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*4N5RlZhxPwPKeBaPDngQUw.png"/></div></figure><p id="b931" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">这里的峰值好像是170左右。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es mw"><img src="../Images/91e12371ef3105341695f43ae6db4a65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*ZCn794cvDuwIKfj_0ZjMdw.png"/></div></figure><p id="2a78" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">梯度提升在这里也表现得相当好，交叉验证和准确度得分之间的差异也很小。</p><p id="92e4" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我对梯度增强树模型的特征重要性分数与AdaBoost模型的特征重要性分数进行了比较，因此我绘制了特征重要性图和下面的前三个特征。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es nf"><img src="../Images/50dd87992c7bf24d9b573fd244e38e61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*waZ7KGEmTQBmsuVZ0QGxNw.png"/></div></div></figure><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es ng"><img src="../Images/7a990007d97d80d350ee204298f3bfc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*PqhLVEgwnxssDC8cV-3vAw.png"/></div></figure><p id="1ab8" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">梯度增强树和AdaBoost模型共享年龄作为三大特征之一，但是梯度增强树模型也受到家族史和主餐数量的影响。吸烟和卡路里消耗监测再次排名靠后。</p><p id="8a4d" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">模型#6:投票分类器</strong></p><p id="4543" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">最后，我们将使用投票分类器模型，该模型通过选定模型的集合进行训练，并平衡单个分类器的弱点。有两种投票方式:硬投票和软投票。我们将使用软投票，因为它提供了更多的概率信息，而不是类别标签。它包括平均每个类别的概率，并选择平均值最高的类别作为最终预测。我选择在集合中包含四个最高性能的模型:随机森林、Bagging、AdaBoost和梯度增强。</p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es nh"><img src="../Images/c2de75230e56abffb610c92c8ffa60c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*f7WTTxQzmjbxkNHS-dYs7w.png"/></div></figure><p id="b18d" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">正如预期的那样，投票分类器模型在所有模型中返回了最高的准确性和交叉验证分数，尽管它并没有比AdaBoost模型好太多。这可能是因为软投票考虑了实际概率，考虑了每个分类器的不确定性，并给予高度自信的投票更多的权重。投票分类器模型是最有前途的一个，因为它的高准确性、交叉验证和准确性得分之间的小差异、它的较低方差以及它的最终预测来自贡献模型的多数投票的事实，这些贡献模型已经都是高性能的。</p></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="0ae0" class="if ig hi bd ih ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc bi translated">结论</h1><p id="f2de" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">通过聚合不同的模型和调整各种参数，如n估计量、最大深度和学习率，从54.57%的基线准确度到95.27%的投票集成准确度有了显著的提高。虽然精确度很高，但该模型基本上没有过度拟合，因为每种集成方法的交叉验证分数与模型精确度的差异都小于1%。</p><p id="eeea" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">特征重要性计算表明，年龄、家族史和身高对上述模型的影响最大。对上述模型中的一个有很大影响的其他因素是饭前食物的消耗、身体活动频率和主餐的数量。没有全面影响的因素是吸烟、卡路里消耗监测、性别和交通。鉴于该模型的高准确性，任何出于自身健康原因或其他用途而对影响肥胖的因素感兴趣的人都可以参考上述突出特征。</p></div></div>    
</body>
</html>