<html>
<head>
<title>Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/linear-regression-939262ea5b83?source=collection_archive---------26-----------------------#2021-04-06">https://medium.com/geekculture/linear-regression-939262ea5b83?source=collection_archive---------26-----------------------#2021-04-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="217d" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated"><strong class="ak">什么是回归？</strong></h2></div><p id="8403" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">回归是我们根据自变量预测某个因变量的值，它具有连续性。</p><p id="15dd" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们举一个例子，假设我们想预测一家公司的股价，我们知道许多因素影响股价。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es jt"><img src="../Images/76b2d5268049f15aa4185a60758910fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d6i3QROVb8R76ZJstOvpjA.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">source -mymoneysage</figcaption></figure><p id="0cff" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们希望找到一个函数，在这些因素和股价之间建立联系。</p><h2 id="365b" class="kj kk hi bd kl km kn ko kp kq kr ks kt jg ku kv kw jk kx ky kz jo la lb lc ld bi translated"><strong class="ak">线性回归</strong></h2><p id="9ee0" class="pw-post-body-paragraph ix iy hi iz b ja le ij jc jd lf im jf jg lg ji jj jk lh jm jn jo li jq jr js hb bi translated">说到机器学习中最简单化的模型，首先想到的就是线性回归。虽然与今天的现代算法相比，线性回归可能显得有些苍白，但它仍然是一种非常有用和广泛使用的统计学习方法。</p><p id="a880" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">数学上的线性回归看起来像</strong></p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lj"><img src="../Images/cb665dd42bdb88023019e24235e6d815.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/0*2qTQ_jhd_2r4yjhw"/></div></figure><p id="969d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">其中:</strong></p><ul class=""><li id="8df0" class="lk ll hi iz b ja jb jd je jg lm jk ln jo lo js lp lq lr ls bi translated">y是我们的目标变量(因变量)</li><li id="e395" class="lk ll hi iz b ja lt jd lu jg lv jk lw jo lx js lp lq lr ls bi translated"><em class="ly"> β值称为</em>模型系数。这些值是在模型训练期间学习的。</li><li id="5e5f" class="lk ll hi iz b ja lt jd lu jg lv jk lw jo lx js lp lq lr ls bi translated"><em class="ly"> β0 </em>是截距</li><li id="1fc5" class="lk ll hi iz b ja lt jd lu jg lv jk lw jo lx js lp lq lr ls bi translated"><em class="ly"> β1，βn </em>分别是<em class="ly"> X1，Xn特征的系数。</em></li></ul><h2 id="73ef" class="kj kk hi bd kl km kn ko kp kq kr ks kt jg ku kv kw jk kx ky kz jo la lb lc ld bi translated"><strong class="ak">损失函数:</strong></h2><p id="b086" class="pw-post-body-paragraph ix iy hi iz b ja le ij jc jd lf im jf jg lg ji jj jk lh jm jn jo li jq jr js hb bi translated">当我们建立我们的模型时，我们主要关注最小化我们的估计预测的误差。这就是我们所认为的建立模型的规则。成本函数是测量误差平方和的函数。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es lz"><img src="../Images/7e95d3e3d5fb0eb14132194fad225823.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/0*PjukdPTPJS9MKXOr"/></div></figure><h2 id="cb56" class="kj kk hi bd kl km kn ko kp kq kr ks kt jg ku kv kw jk kx ky kz jo la lb lc ld bi translated"><strong class="ak">模型训练:</strong></h2><p id="6477" class="pw-post-body-paragraph ix iy hi iz b ja le ij jc jd lf im jf jg lg ji jj jk lh jm jn jo li jq jr js hb bi translated">模型训练是通过选择模型参数来定义特征和目标变量之间关系的过程。模型参数是函数常数，即<em class="ly"> β0，β1，β2…βn等。</em></p><p id="c961" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们如何计算这些参数？</p><p id="6962" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">高中的时候，我们学过，如何在微积分中计算一个函数的最优值。这里，我们想找出损失函数的最佳值，对于函数的最佳值，我们感兴趣的是找出函数参数。对于这个任务，有一个数学算法叫做<strong class="iz hj">梯度下降</strong>，我现在不打算详细介绍，但这里有一个它的概要:</p><ul class=""><li id="0ced" class="lk ll hi iz b ja jb jd je jg lm jk ln jo lo js lp lq lr ls bi translated">从一些系数/参数值开始，例如<em class="ly"> β0 </em> =0，<em class="ly"> β1 </em> =0</li><li id="38e7" class="lk ll hi iz b ja lt jd lu jg lv jk lw jo lx js lp lq lr ls bi translated">不断改变<em class="ly"> B0 </em>和<em class="ly"> B1 </em>以减少J( <em class="ly"> B0，B1 </em>)，直到我们有希望达到最小值。</li></ul><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es ma"><img src="../Images/ee117c72a6e544d1b026caef2440e5e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Eoi0PxhbByMZdXyNx-juWA.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx">representative image of how we reach global minima starting from a random point by using <strong class="bd kl">gradient descent</strong></figcaption></figure><h2 id="1763" class="kj kk hi bd kl km kn ko kp kq kr ks kt jg ku kv kw jk kx ky kz jo la lb lc ld bi translated"><strong class="ak">线性回归的假设- </strong></h2><ul class=""><li id="9b5b" class="lk ll hi iz b ja le jd lf jg mb jk mc jo md js lp lq lr ls bi translated">因变量和自变量之间应该存在线性关系。</li><li id="1d59" class="lk ll hi iz b ja lt jd lu jg lv jk lw jo lx js lp lq lr ls bi translated">平均残差应该为零或接近零，这确保拟合的线是我们的<strong class="iz hj"><em class="ly"/></strong>线<strong class="iz hj">。</strong></li><li id="5f8f" class="lk ll hi iz b ja lt jd lu jg lv jk lw jo lx js lp lq lr ls bi translated">在我们的回归线周围应该有<strong class="iz hj"> <em class="ly">同方差或等方差</em> </strong>。异方差正好与同方差相反，表示数据点在回归线上的不均匀分布。</li></ul><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es me"><img src="../Images/c82ea31294e398f05f5f35610df15b8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*K6JdRHaDlkmCT_o5.png"/></div></div></figure><ul class=""><li id="4c8f" class="lk ll hi iz b ja jb jd je jg lm jk ln jo lo js lp lq lr ls bi translated">回归模型中不应有<strong class="iz hj">多重共线性</strong>。这意味着没有两个独立变量是相关的。简单地说，一个独立变量不应该从其他独立变量中预测出来。<strong class="iz hj"> <em class="ly"> VIF </em> </strong>是检测回归模型中是否存在多重共线性的常用工具。它测量估计回归系数的方差(或标准误差)因共线性而增大的程度。</li></ul><p id="b0ff" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">VIF可以通过下面的公式计算:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mf"><img src="../Images/668f6341d6080321ceda61f81c852270.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*R8aR5XpqPD0S4UQ5.png"/></div></figure><p id="88e8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中<strong class="iz hj"> Ri2 </strong>代表剩余变量中回归第I个自变量的未调整决定系数。VIF的倒数被称为<strong class="iz hj">公差</strong>。VIF或容差都可用于检测多重共线性，具体取决于个人偏好。</p><h2 id="38e4" class="kj kk hi bd kl km kn ko kp kq kr ks kt jg ku kv kw jk kx ky kz jo la lb lc ld bi translated"><strong class="ak">模型评估矩阵:</strong></h2><p id="bb40" class="pw-post-body-paragraph ix iy hi iz b ja le ij jc jd lf im jf jg lg ji jj jk lh jm jn jo li jq jr js hb bi translated">1.<strong class="iz hj">均方误差(MSE): </strong>均方误差是拟合优度的绝对度量。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mg"><img src="../Images/992d16f4220e2ad1e54dee952f9ad079.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/0*CXWdvgutXhBVsUpK.png"/></div></figure><p id="75ef" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">均方差公式</p><p id="dd78" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">MSE是通过预测误差的平方和(实际输出减去预测输出)然后除以数据点数来计算的。它给你一个绝对的数字，告诉你你的预测结果与实际数字有多大的偏差。您无法从一个单一的结果中解读许多见解，但它给了您一个真实的数字来与其他模型结果进行比较，并帮助您选择最佳的回归模型。</p><p id="3eda" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> 2。</strong><strong class="iz hj">【RMSE】均方根误差</strong>是MSE的平方根。它比MSE更常用，因为首先有时MSE值可能太大而不容易比较。第二，MSE是通过误差的平方计算的，因此平方根使它回到预测误差的相同水平，并使它更容易解释。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mh"><img src="../Images/ebf5f1b08558a58aef451a3c88ccdfe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/0*caR9XQDIpzzSlSZW"/></div></figure><p id="c83a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> 3。平均绝对误差(MAE): </strong></p><p id="180a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">平均绝对误差(MAE)类似于均方误差(MSE)。然而，MAE取的不是MSE中误差的平方和，而是误差绝对值的和。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mi"><img src="../Images/050a4d9d0dd448ae6fe5a20df59bd2ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:120/0*5CckhO_sGjeTFRX4"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mj"><img src="../Images/36bc8be0c0eadeddb1cf6bc0dd26ea44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/0*gEuusDkU2KZsTym4.png"/></div></figure><p id="9093" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">平均绝对误差公式</p><p id="fda9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">与均方误差或RMSE相比，平均误差是误差项总和的更直接表示。<strong class="iz hj"> MSE通过平方对大的预测误差给予较大的惩罚，而MAE对所有误差一视同仁</strong>。</p><p id="89de" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> 4。</strong> <strong class="iz hj"> R方/调整后的R方:</strong></p><p id="baa8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">r平方衡量模型可以解释因变量的多少可变性。它是相关系数(R)的平方，这就是它被称为R平方的原因。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mi"><img src="../Images/2776cedbbd89c3797ab27500ca10d692.png" data-original-src="https://miro.medium.com/v2/resize:fit:120/0*T55f1MiQVnBD4rAJ"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mk"><img src="../Images/c050e66cd4baacaaccfb4d01de9c4b0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-qPpyGU2Cxe1vrp4.png"/></div></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es ml"><img src="../Images/6a3837392908b24a2b722037fd955b06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*6y4VKykwZlkkMOXqCZTK1g.png"/></div></figure><p id="cbe8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">r平方公式</p><p id="ca79" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通过预测误差的平方和除以用平均值代替计算预测的平方和来计算r平方。r平方值在0到1之间，较大的值表示预测值和实际值之间的拟合较好。</p><p id="73e4" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">r平方是确定模型拟合因变量的好方法。然而，它没有考虑过拟合问题。如果您的回归模型有许多独立变量，由于模型太复杂，它可能非常适合定型数据，但对于测试数据来说表现很差。这就是引入调整后的R平方的原因，因为它将惩罚添加到模型中的额外独立变量，并调整度量以防止过度拟合问题。</p><p id="5d61" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">范围:</strong></p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mm"><img src="../Images/bc44174a1f992f1e3edb3ce73d6721f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:184/0*dO6LziPh8bG-Z_6J"/></div></figure><p id="6768" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它通常取(0，1)之间的值。</p><p id="c044" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> <em class="ly">解释R : </em> </strong>如果R值为0.8，则意味着目标变量的80%方差可以从自变量的方差中预测出来。</p><p id="3b45" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> 5。调整后的R : </strong></p><p id="e214" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它与R得分非常相似，但是调整后的R不会遇到这样的问题，即得分随着特征(独立变量)的增加而提高，这与R正好相反。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mn"><img src="../Images/de66fd098c4ab4e768b6760a8fd6ed8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*nv5Yx2Fi2tw66ZnRBGy2NQ.png"/></div></figure><p id="1d2d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中:</p><p id="bfcb" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">n =观察次数</p><p id="ff02" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">k =独立变量的数量</p></div></div>    
</body>
</html>