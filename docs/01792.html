<html>
<head>
<title>Concept of Machine Learning | Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的概念|回归</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/linear-regression-465946664994?source=collection_archive---------25-----------------------#2021-04-23">https://medium.com/geekculture/linear-regression-465946664994?source=collection_archive---------25-----------------------#2021-04-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="3659" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">在本文中，我们将讨论简单的线性回归</h2></div><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="jc jd l"/></div><figcaption class="je jf et er es jg jh bd b be z dx">Concept of Machine Learning | Introduction to Machine Learning</figcaption></figure><h2 id="fa0b" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">什么是回归？</h2><p id="1dc1" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko jt kp kq kr jx ks kt ku kb kv kw kx ky hb bi translated">一种用于估计因变量和自变量之间关系的统计监督学习技术。</p><h2 id="0676" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">因变量和自变量:</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es kz"><img src="../Images/46fad9630757d2e170b94ec53769b6e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*jzzjdlN3pSeWC6rLcfcTkQ.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx">Example</figcaption></figure><p id="debb" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko jt le kq kr jx lf kt ku kb lg kw kx ky hb bi translated">这里y是因变量，X₁,X₂,X₃ ……，Xn是独立变量。因变量也叫结果变量、反应变量，自变量也叫预测变量、解释变量。</p><h2 id="a851" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">线性回归:</h2><p id="c6ae" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko jt kp kq kr jx ks kt ku kb kv kw kx ky hb bi translated">线性回归是一种统计监督学习技术，通过与一个或多个自变量形成线性关系来预测因变量。</p><h2 id="ae96" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">线性回归的类型:</h2><ol class=""><li id="2425" class="lh li hi ki b kj kk km kn jt lj jx lk kb ll ky lm ln lo lp bi translated">简单线性回归</li><li id="c3f5" class="lh li hi ki b kj lq km lr jt ls jx lt kb lu ky lm ln lo lp bi translated">多元线性回归</li></ol><h2 id="fa59" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">1.简单线性回归</h2><p id="2044" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko jt kp kq kr jx ks kt ku kb kv kw kx ky hb bi translated">简单线性回归找出两个连续变量之间的线性关系，一个自变量，一个因变量。这两个变量之间的关系是一个直线方程。</p><p id="4d9c" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko jt le kq kr jx lf kt ku kb lg kw kx ky hb bi translated">例如，我们正在查找最近出售的房屋的b/w面积与其价格的关系:-</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lv"><img src="../Images/d7f0d8c3054903400564ecc7c17fd755.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*kwFt5CFabyBu8bUVH9GPjA.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx">Datasets of Houses sold recently</figcaption></figure><p id="34cc" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko jt le kq kr jx lf kt ku kb lg kw kx ky hb bi translated">在这个例子中，我们采用了一个小的房屋数据集，但在机器学习模型中，它们是大量的房屋。</p><p id="c43c" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko jt le kq kr jx lf kt ku kb lg kw kx ky hb bi translated">现在，如果我们要预测一栋300平方英尺的房子的价格。ft，那怎么算？为此，我们必须找到房屋的b/w面积和价格之间的关系，通过这个关系，我们可以找到面积为300平方米的房屋的价格。制成</p><p id="0ad9" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko jt le kq kr jx lf kt ku kb lg kw kx ky hb bi translated">这就是回归的概念。</p><p id="c9d3" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko jt le kq kr jx lf kt ku kb lg kw kx ky hb bi translated">如果我们画出这些点，我们就找不到一条穿过所有点的直线。现在我们必须找到一条更接近所有点的线。因此，我们正在绘制许多线条。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lw"><img src="../Images/21c5c219ce9209c3a59917fd810089e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*7Xewes72eEwyoNPbYhacow.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx">Sq. Feet of House vs. Price</figcaption></figure><p id="b46b" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko jt le kq kr jx lf kt ku kb lg kw kx ky hb bi translated">那么，哪条线最好？😢</p><p id="1d86" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko jt le kq kr jx lf kt ku kb lg kw kx ky hb bi translated">为了找到最佳线，我们必须最小化残差平方和(RSS)。现在什么是RSS？😧</p><h2 id="902c" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">普通最小二乘法或残差平方和(RSS):</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lx"><img src="../Images/eb1aa32657dcbfdeb72fa154c65b1c41.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*A6K2cken1OcV6urfZHATHQ.png"/></div></figure><p id="df3c" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko jt le kq kr jx lf kt ku kb lg kw kx ky hb bi translated">假设B₀ + B₁x是最佳拟合线。那么B₀,B₁的价值是什么呢？</p><p id="1918" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko jt le kq kr jx lf kt ku kb lg kw kx ky hb bi translated">为此，我们必须计算RSS最小值。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lx"><img src="../Images/10843cab27f4237c3f5d5413fdf18f11.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*HgGQxk41OO4q2M6BB_qw9Q.png"/></div></figure><p id="9828" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko jt le kq kr jx lf kt ku kb lg kw kx ky hb bi translated">RSS = ∑Wᵢ</p><p id="3757" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko jt le kq kr jx lf kt ku kb lg kw kx ky hb bi translated">对于不同的圣线，即不同的B₀,B₁值，RSS是不同的。其中对于B₀和B₁来说，RSS是最小最适合的行。</p><h2 id="a8a1" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">但是怎么找到这条线呢？😨</h2><p id="f06a" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko jt kp kq kr jx ks kt ku kb kv kw kx ky hb bi translated">它可以通过求解超定方程组或梯度下降来找到。但这是一个简单的方法，对简单的线性回归有用。即</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ly"><img src="../Images/d7190af2498569d18fe204a780531192.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*PiynfTDzrNQB_5kuWW_uqw.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx">value of B0 and B1</figcaption></figure><p id="6711" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko jt le kq kr jx lf kt ku kb lg kw kx ky hb bi translated">对于这条B0和B1最好的线，我们将得到。该方法仅适用于简单线性回归，即单一特征。对于多重特征我们必须使用其他方法，稍后讨论。</p><h2 id="d4e5" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">为什么我们要取RSS的最小值呢？</h2><p id="e256" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko jt kp kq kr jx ks kt ku kb kv kw kx ky hb bi translated">仔细注意，<strong class="ki hj"> RSS无非是机器学习模型</strong>的错误。所以，如果我们把B₀,B₁作为最小RSS，我们会得到一个更好的结果，然后这里的误差是最低的。</p><h2 id="e19e" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">为什么我们不拿下∑|Wᵢ|？</h2><p id="1117" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko jt kp kq kr jx ks kt ku kb kv kw kx ky hb bi translated">因为，y=|x|在x=0处不可微</p><h2 id="399a" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">全文系列:</h2><div class="lz ma ez fb mb mc"><a href="https://ujjwalkar.netlify.app/post/concept-of-machine-learning-tutorial-series/" rel="noopener  ugc nofollow" target="_blank"><div class="md ab dw"><div class="me ab mf cl cj mg"><h2 class="bd hj fi z dy mh ea eb mi ed ef hh bi translated">机器学习的概念文章系列| Ujjwal Kar</h2><div class="mj l"><h3 class="bd b fi z dy mh ea eb mi ed ef dx translated">回归入门|使用梯度下降的简单线性回归优化…</h3></div><div class="mk l"><p class="bd b fp z dy mh ea eb mi ed ef dx translated">ujjwalkar.netlify.app</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq la mc"/></div></div></a></div></div></div>    
</body>
</html>