<html>
<head>
<title>Real time sync from on-premise to AWS data lake</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从内部到AWS数据湖的实时同步</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/real-time-sync-from-on-premise-to-aws-data-lake-2e8d834c45dd?source=collection_archive---------8-----------------------#2021-10-08">https://medium.com/geekculture/real-time-sync-from-on-premise-to-aws-data-lake-2e8d834c45dd?source=collection_archive---------8-----------------------#2021-10-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="faaf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">混合分析和运营使用，MS SQL server，debezium，MSK，kafka connect，mongodb，实时同步</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/077a128da99d56f29a18c40c2aaeb3cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GZdsobitv2MT5Y59VV1SSQ.jpeg"/></div></div></figure><h1 id="6f0d" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">建筑选择的动机</h1><ul class=""><li id="434f" class="ko kp hi ih b ii kq im kr iq ks iu kt iy ku jc kv kw kx ky bi translated">亚马逊MSK，全面管理方面，易于设置和配置，在vpc内部部署</li><li id="9207" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">卡夫卡，已被证明，广泛的生态系统包括连接器</li><li id="7411" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">Debezium，所有主要数据库技术的真正CDC</li><li id="87c2" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">mongoDB，部署在EC2上以提高性能，并拥有所有可用的数据类型</li></ul><h1 id="5024" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">语境</h1><p id="cb69" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">业务关键型应用程序会生成大量数据，但是像许多这样的应用程序一样，它们对自己的数据库有点自私，尤其是在如何进行CRUD操作方面。通常情况下，绝对没有办法确定哪些记录被插入、更新或删除了。因此，如果您想要复制数据，您或多或少会被迫进行完全转储。</p><p id="7f8c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种方法对于反映昨天数据的数据系统是有效的。但是当我们谈到大容量时也达到了极限。识别新插入、更新和删除的记录的一种<strong class="ih hj">干净和结构化的</strong>方法是使用变更数据捕获，CDC。</p><p id="8da4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该解决方案部署在分析和<strong class="ih hj">运营使用</strong>的环境中。考虑到这一点，我们会立即认为对象存储和AWS s3是Kafka的成果——如果我们希望拥有单个记录经历的更新的完整历史，这将是有效的。</p><p id="b849" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的目标是在云中有一个视图，反映本地应用程序的当前状态，有一秒钟的延迟，这没有特定记录的所有更新历史。比如说，卡夫卡的结局需要按表键<strong class="ih hj">上插</strong>。</p><p id="8d88" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了用对象存储处理upserts，我们还可以使用Apache胡迪或Delta lake并实现一个lakehouse。湖屋的概念当然是有效的，我打赌未来将朝着这个方向发展。但是现在，这将使情况变得复杂，需要额外的技能，这符合我们当前的要求“实时复制数据的当前状态并做到万无一失”。</p><h1 id="c47c" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">变更数据捕获</h1><p id="cf10" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">为了保证我们不会在主数据库上引入任何额外的负载，数据库技术提供了将其主数据库同步到辅助(读取)副本的能力，这是一种非常<strong class="ih hj">非侵入性的</strong>方式。<br/>CDC从副本启动。这样做，我们真的不会触及操作数据库。我们在副本数据库上为范围内的表激活CDC，并为每个表创建一个新的组合字段，它是表的主键<code class="du lh li lj lk b">pk_</code>的串联。mongoDB kafka connect sink config和mongoDB将使用这个<code class="du lh li lj lk b">pk_</code>来标识需要插入或更新哪个记录。</p><p id="e14f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">CDC是由数据库技术提供的，每个数据库在如何实现CDC方面都有自己的特点和风格。Debezium为主要数据库处理这个问题:MySQL、MongoDB、PostgreSQL、Oracle、SQL server、DB2、Cassandra和Vitess。</p><h1 id="6aaa" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">阿帕奇卡夫卡</h1><p id="9301" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">Apache Kafka是一个社区分布式事件流平台，能够处理大量数据。<br/>Kafka最初被设想为一个消息队列，它基于分布式提交日志的抽象。自2011年由LinkedIn创建并开源以来，Kafka已经从消息队列迅速发展成为一个成熟的事件流媒体平台。</p><h1 id="7fc2" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">卡夫卡连接</h1><p id="dd6d" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">Kafka connect是Kafka提供的4个API之一，connect API特别适合于保持源数据库与…</p><p id="3ce1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">connect <a class="ae ll" href="https://www.confluent.io/product/connectors/" rel="noopener ugc nofollow" target="_blank">组合</a>由许多类型的连接器组成，使得用Apache Kafka推/拉数据变得非常容易。源连接器，从源获取数据并将其推送到Kafka接收器连接器从Kafka获取数据，并将其推送到接收器。</p><ul class=""><li id="f884" class="ko kp hi ih b ii ij im in iq lm iu ln iy lo jc kv kw kx ky bi translated">源连接器可以是:sftp、jdbc、debezium CDC、Splunk、Redis、<a class="ae ll" href="https://github.com/SAP/kafka-connect-sap" rel="noopener ugc nofollow" target="_blank"> SAP </a>(总是在做之前检查术语)、…</li><li id="2c3c" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">接收器连接器可以是:Salesforce、sftp、http、…</li></ul><p id="6c00" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">连接器分为:开源、社区、商业、高级和融合验证合作伙伴。</p><p id="f2a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当连接器独立运行或成组运行时，我们通过connect <a class="ae ll" href="https://docs.confluent.io/platform/current/connect/references/restapi.html" rel="noopener ugc nofollow" target="_blank"> REST接口</a>传递配置。<br/>每个connect config都有一点偏离他的具体细节，这是我们要讨论的源或接收器的功能。</p><h1 id="6cb9" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">MS SQL源连接器的示例:</h1><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="d000" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将此配置发布到Kafka connect将开始同步，快照过程中有8个步骤。<code class="du lh li lj lk b">demo.dbo.ORDERS</code>的日志如下图所示。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="lp lq l"/></div></figure><h1 id="3d9c" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">mongodb接收器连接器的示例</h1><p id="2302" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">mongodb连接器支持多种<a class="ae ll" href="https://docs.mongodb.com/kafka-connector/current/kafka-sink-postprocessors/#custom-write-model-strategy" rel="noopener ugc nofollow" target="_blank">写模型策略</a>，它们将定义如何将记录写入mongodb。我们选择使用<strong class="ih hj">插入和修改的时间戳</strong></p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="1d90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，我们还配置了一个转换动作:<code class="du lh li lj lk b">ExtractNewRecordState</code>类型的<code class="du lh li lj lk b">unwrap</code>，它只有CDC的后像。</p><p id="141a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在mongodb中有一个单一级别的数据结构，这与我们在Microsoft SQL数据库中有两个额外的时间戳:<code class="du lh li lj lk b">_insertedTS: ISODate("2021-10-01T09:38:14.659Z")</code>和<code class="du lh li lj lk b">_modifiedTS: ISODate("2021-10-01T10:38:14.659Z")</code>完全对应。</p><p id="ef98" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Kafka connect无疑是Kafka生态系统中的一项资产，AWS也通过<a class="ae ll" href="https://aws.amazon.com/blogs/aws/introducing-amazon-msk-connect-stream-data-to-and-from-your-apache-kafka-clusters-using-managed-connectors/" rel="noopener ugc nofollow" target="_blank">托管连接产品</a>扩展了其MSK产品。<br/>这当然有利于运行Kafka connect的所有操作方面。</p><h1 id="11ce" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">MongoDB</h1><p id="9118" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">当您选择AWS作为云提供商时，第一个教训可能是为什么不使用doucmnetDB？mongoDB的完全托管版本。<br/> DocumentDB是首选，但很快我们就遇到了这两个缺点:</p><ul class=""><li id="abc2" class="ko kp hi ih b ii ij im in iq lm iu ln iy lo jc kv kw kx ky bi translated">缺少mongodb decimal数据类型，这种数据类型在我们的源数据库中随处可见。是的，你可以在connect中做一个<a class="ae ll" href="https://docs.confluent.io/platform/current/connect/transforms/cast.html#cast" rel="noopener ugc nofollow" target="_blank"> SMT </a>并转换成另一种数据类型，知道之后所有的消费者都需要重新转换每个字段</li><li id="d453" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">性能方面，与EC2上的mongoDB(每秒- 8000次插入)相比，Kafka connect对documentdb的接收速度要慢得多(每秒- 50次插入)</li></ul><p id="28c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">目前，我们在docker下的EC2上运行mongoDB，并将做操作所需的事情或转移到mongodb atlas的<a class="ae ll" href="https://www.mongodb.com/cloud/atlas/" rel="noopener ugc nofollow" target="_blank">产品。</a></p><h1 id="aaaa" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">得到你的操场</h1><p id="f2d3" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">可以在<a class="ae ll" href="https://youtu.be/g5Kb53irYrI" rel="noopener ugc nofollow" target="_blank">这里</a>找到该案例的完整演示记录。<br/>GitHub<a class="ae ll" href="https://github.com/thierryturpin/msk-connect" rel="noopener ugc nofollow" target="_blank">上的回购</a>。</p><p id="40ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你想知道更多关于这个话题的信息，请联系我们！</p><p id="0b11" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">玩得开心，蒂埃里</p><h1 id="7f82" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">参考</h1><ul class=""><li id="7369" class="ko kp hi ih b ii kq im kr iq ks iu kt iy ku jc kv kw kx ky bi translated">拥有关于卡夫卡和卡夫卡连接的顶级素材的rmoff的随机漫谈</li><li id="e97d" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated"><a class="ae ll" href="https://databricks.com/blog/2020/01/30/what-is-a-data-lakehouse.html" rel="noopener ugc nofollow" target="_blank">湖边小屋建筑</a></li><li id="c15e" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated"><a class="ae ll" href="https://debezium.io/" rel="noopener ugc nofollow" target="_blank"> debezium </a></li></ul></div></div>    
</body>
</html>