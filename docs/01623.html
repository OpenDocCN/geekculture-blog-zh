<html>
<head>
<title>Creating Realistic Deepfakes With DeepFaceLab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用DeepFaceLab创建真实的深度赝品</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/realistic-deepfakes-with-deepfacelab-530e90bd29f2?source=collection_archive---------0-----------------------#2021-04-18">https://medium.com/geekculture/realistic-deepfakes-with-deepfacelab-530e90bd29f2?source=collection_archive---------0-----------------------#2021-04-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="3d9c" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">开放源代码中最流行的深度伪造工具介绍</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/66830d5bbd181ed14e745e4a566c6a9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uwp_enSns16QtaXNiUjtXQ.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Source: Deepfakery</figcaption></figure><p id="19dc" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在过去的几年里，机器学习领域令人兴奋的进步已经给了我们使用一种称为<strong class="jp hj">深度伪造</strong>的技术来执行真实感视频操作的可怕能力。</p><p id="52d0" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">负责这项技术的底层技术可以在<strong class="jp hj">生成对抗网络(GAN) </strong>、<strong class="jp hj"> </strong>中找到，这是由Ian Goodfellow和他的同事在2014年开创的一类新的机器学习框架。在这种方法中，两个神经网络(生成器和鉴别器)在极大极小游戏中相互竞争，以产生能够生成具有与训练集相同属性的新数据的模型。更多信息请见他们的白皮书<a class="ae kj" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="93d9" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">出于好的和坏的原因，Deepfakes受到了媒体的极大关注。这项技术的含义可能是可怕的。在一个充斥着假新闻和骗局的世界里，让自己熟悉“假”和“合成”媒体的样子变得更加重要。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es kk"><img src="../Images/0ab3074b9615d61331783773dd2d93d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MizWFfK2K1ehRSXdQoVb2g.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">DeepFaceLab samples. Can you recognize these celebs? Source: iperov</figcaption></figure><p id="2171" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">GitHub上有超过13，000颗星，<strong class="jp hj"> DeepFaceLab </strong>已经成为消费者和专业deepfake创作的流行解决方案。即使您拥有有限的硬件和技术知识，我也会向您展示从有限的训练数据中生成高质量的deepfakes是多么容易。</p><p id="c438" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">具体来说，我们将分三个阶段把托尼·斯塔克的脸印在埃隆·马斯克的脸上:</p><ul class=""><li id="6dd3" class="kl km hi jp b jq jr jt ju jw kn ka ko ke kp ki kq kr ks kt bi translated"><strong class="jp hj">提取阶段</strong> <em class="ku"> — </em>准备和清理数据集</li><li id="9735" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki kq kr ks kt bi translated"><strong class="jp hj">培训阶段</strong> —我们培训我们的模型</li><li id="5890" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki kq kr ks kt bi translated"><strong class="jp hj">转换阶段</strong>——我们使用我们的模型创建一个遮罩</li></ul><p id="f055" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">要下载并熟悉该工具，您可以在此处找到回购<a class="ae kj" href="https://github.com/iperov/DeepFaceLab" rel="noopener ugc nofollow" target="_blank">，在此处</a>找到白皮书<a class="ae kj" href="https://arxiv.org/abs/2005.05535" rel="noopener ugc nofollow" target="_blank">。请注意，目前仅支持Windows和Linux操作系统。</a></p></div><div class="ab cl la lb gp lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hb hc hd he hf"><h1 id="bd50" class="lh li hi bd lj lk ll lm ln lo lp lq lr io ls ip lt ir lu is lv iu lw iv lx ly bi translated">第一阶段:提取</h1><p id="64fc" class="pw-post-body-paragraph jn jo hi jp b jq lz ij js jt ma im jv jw mb jy jz ka mc kc kd ke md kg kh ki hb bi translated">下载DeepFaceLab后，您将生活在两个不同的目录中:</p><ul class=""><li id="8a63" class="kl km hi jp b jq jr jt ju jw kn ka ko ke kp ki kq kr ks kt bi translated"><strong class="jp hj">项目</strong>目录(名为DeepFaceLab_NVIDIA)</li><li id="dcdf" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki kq kr ks kt bi translated"><strong class="jp hj">工作区</strong>目录(主项目目录的子目录)</li></ul><p id="8470" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">项目目录保存我们的脚本文件，我们将使用这些文件来执行操作(提取、训练)，而我们的工作区目录将保存以下内容:</p><ul class=""><li id="aa60" class="kl km hi jp b jq jr jt ju jw kn ka ko ke kp ki kq kr ks kt bi translated"><strong class="jp hj">源数据</strong> —面向我们要嵌入的主题</li><li id="70b9" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki kq kr ks kt bi translated"><strong class="jp hj">目标数据</strong> —我们想要覆盖的主体的面部</li><li id="d436" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki kq kr ks kt bi translated"><strong class="jp hj">型号</strong>——我们将要训练的GAN动力发动机</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es me"><img src="../Images/fe1eb6701488ea725cb39d888a8d44fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g3-quf4uLjw9LUBsRllOpA.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Source and destination videos in the workspace directory. Source: <a class="ae kj" href="https://www.youtube.com/c/Deepfakery/about" rel="noopener ugc nofollow" target="_blank">Deepfakery</a></figcaption></figure><ol class=""><li id="9dee" class="kl km hi jp b jq jr jt ju jw kn ka ko ke kp ki mf kr ks kt bi translated">首先将您的<code class="du mg mh mi mj b">data_dst.mp4</code>和<code class="du mg mh mi mj b">data_src.mp4</code>视频文件添加到您的工作区。</li><li id="a306" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki mf kr ks kt bi translated">导航回DeepFaceLab_NVIDIA目录。</li><li id="c0a4" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki mf kr ks kt bi translated">运行<code class="du mg mh mi mj b">2) extract images from video data_src.bat</code>从你的源视频中提取训练人脸。</li><li id="0c36" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki mf kr ks kt bi translated">运行<code class="du mg mh mi mj b">3) extract images from video data_dst FULL FPS.bat</code>从目标视频中提取训练人脸。</li><li id="25b0" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki mf kr ks kt bi translated">导航到<code class="du mg mh mi mj b">data_dst</code>和<code class="du mg mh mi mj b">data_src</code>文件夹，通过移除错位和扭曲的面来清理提取的面。</li><li id="8592" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki mf kr ks kt bi translated">(可选)运行<code class="du mg mh mi mj b">4.2) data_dst sort.bat</code>和<code class="du mg mh mi mj b">5.2) data_dst sort.bat</code>以便在清理过程中更容易进行面部对比。</li></ol><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mk"><img src="../Images/f0a986da96b69b941b6e514bd2e036c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TIwWm1mYgdJPm8WYHaRscQ.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Aligned extracted faces from the source and destination videos. Source: <a class="ae kj" href="https://www.youtube.com/c/Deepfakery/about" rel="noopener ugc nofollow" target="_blank">Deepfakery</a></figcaption></figure><p id="8e41" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">💡<strong class="jp hj">此阶段的有用提示</strong>:</p><ul class=""><li id="5f6c" class="kl km hi jp b jq jr jt ju jw kn ka ko ke kp ki kq kr ks kt bi translated">挑选正确的源和目的地培训视频是这一过程中最重要的一步。视频质量、面部对齐和照明都是影响成品质量的因素。</li><li id="d7da" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki kq kr ks kt bi translated">你可以在YouTube上从名人访谈和电影剪辑等来源找到高质量的剪辑。</li><li id="c3ee" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki kq kr ks kt bi translated">不要过分使用你的源数据。我发现最佳点是大约2000张不同角度和表情的脸(或一个2-3分钟的剪辑)，最理想的是与你的目标剪辑相匹配。</li></ul><h1 id="2e90" class="lh li hi bd lj lk ml lm ln lo mm lq lr io mn ip lt ir mo is lv iu mp iv lx ly bi translated">第二阶段:培训</h1><p id="ed3b" class="pw-post-body-paragraph jn jo hi jp b jq lz ij js jt ma im jv jw mb jy jz ka mc kc kd ke md kg kh ki hb bi translated">对于这个基本的deepfake，我们将使用<strong class="jp hj"> Quick96 </strong>模型，因为它对低端GPU有更好的支持，并且通常对初学者更友好。</p><ol class=""><li id="fa0e" class="kl km hi jp b jq jr jt ju jw kn ka ko ke kp ki mf kr ks kt bi translated">从项目目录中，运行<code class="du mg mh mi mj b">6) train Quick96.bat</code></li><li id="2df5" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki mf kr ks kt bi translated">出现提示时选择您的GPU(也支持仅使用CPU)</li></ol><p id="d813" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">训练开始后，您将在命令行窗口中看到这些数字。它们是什么意思？</p><pre class="iy iz ja jb fd mq mj mr ms aw mt bi"><span id="c4de" class="mu li hi mj b fi mv mw l mx my">Starting. Press "Enter" to stop training and save model.<br/>[12:33:13][#000219][0764ms][0.9550][0.9910]</span></pre><p id="9944" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">从左到右，各列代表以下内容。</p><ol class=""><li id="e071" class="kl km hi jp b jq jr jt ju jw kn ka ko ke kp ki mf kr ks kt bi translated">当前当地时间</li><li id="3317" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki mf kr ks kt bi translated">当前迭代</li><li id="6f88" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki mf kr ks kt bi translated">迭代时间</li><li id="9f52" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki mf kr ks kt bi translated">SRC损失值</li><li id="03b1" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki mf kr ks kt bi translated">DST损失值</li></ol><p id="c1a1" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们的目标是使src和dst损失值尽可能低。</p><p id="2e84" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">排队点<em class="ku">洛基</em>训练蒙太奇音乐！让我们继续训练吧💪</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mz"><img src="../Images/496f7a8d9eb982d026b7a57350a4512a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8rGIMY7IA-m76ERZZ7s1mg.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Sample faces after 219 iterations</figcaption></figure><p id="68aa" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">就像我小时候第一次尝试吹萨克斯管一样，第一批迭代看起来相当可怜。随着时间和训练，幽灵般的斑点将开始成形，看起来有点像我们的对象。从左到右，图像列代表我们的模型输出的以下数据:</p><ol class=""><li id="572a" class="kl km hi jp b jq jr jt ju jw kn ka ko ke kp ki mf kr ks kt bi translated">SRC面部样本</li><li id="c4a1" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki mf kr ks kt bi translated">从该样本生成的SRC面</li><li id="f416" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki mf kr ks kt bi translated">DST面部样本</li><li id="25ce" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki mf kr ks kt bi translated">从该样本生成的钻杆测试面</li><li id="d9b2" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki mf kr ks kt bi translated">生成的SRC面模拟DST面样本</li></ol><p id="f50c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">正如你所看到的，最后一个专栏是我们最感兴趣的，它会给我们一个很好的信号，告诉我们deepfake看起来有多真实。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es na"><img src="../Images/f33d6d7bb8a3abe9fa0c9cd993f5b2f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bZCMEwtcw-wV_d73kFuR-Q.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Over 160,000 iterations</figcaption></figure><p id="425e" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">经过160，000次迭代后，你真的可以开始看到我们生成的人脸达到了一种可怕的逼真程度。有了这个，就该把所有的东西放在一起了！</p><p id="6cda" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">💡<strong class="jp hj">此阶段的有用提示:</strong></p><ul class=""><li id="4e31" class="kl km hi jp b jq jr jt ju jw kn ka ko ke kp ki kq kr ks kt bi translated">在这个阶段，耐心是关键。我建议您至少等到80，000次迭代才能获得最佳结果。根据您的硬件，您可能需要运行这个通宵或周末。或者，你可以通过观看你的模型火车本身来做现代版的<em class="ku">看着油漆变干</em>。</li><li id="d78e" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki kq kr ks kt bi translated">在更高级的模型上，要注意你使用的图像分辨率，因为这将增加训练的复杂性，甚至可能超出你的GPU的处理能力。通过使用6 GB VRAM的GTX 1060，我能够推动我的GPU在我的模型中处理高达192的分辨率。超过这个数量的任何东西都会导致我的模型在安装时崩溃。</li><li id="d9db" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki kq kr ks kt bi translated">DeepFaceLab还支持<a class="ae kj" href="https://en.wikipedia.org/wiki/Transfer_learning" rel="noopener ugc nofollow" target="_blank">迁移学习</a>，可以使用预先训练好的模型来大大提高训练的初始速度。您可以在DeepFaceLab社区论坛中找到其中的许多内容。</li></ul><h1 id="67cd" class="lh li hi bd lj lk ml lm ln lo mm lq lr io mn ip lt ir mo is lv iu mp iv lx ly bi translated">第三阶段:转换</h1><p id="4b34" class="pw-post-body-paragraph jn jo hi jp b jq lz ij js jt ma im jv jw mb jy jz ka mc kc kd ke md kg kh ki hb bi translated">随着我们的模型完全训练，我们现在可以将我们生成的人脸与目标视频合并。</p><p id="cc27" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">从项目目录中，运行<code class="du mg mh mi mj b">7) merge Quick96.bat</code>调出交互式合并。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nb"><img src="../Images/ef30e62a7e91487882f480b44bb9946e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QG9NoBo3qwb7NrGR3PXxlQ.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">DeepFaceLab merger tool interface</figcaption></figure><p id="5709" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">好吧，这里发生了很多事。我们来分解一下。</p><p id="d571" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们需要一帧一帧地进行，并使用以下技术对生成的面具进行任何调整。</p><ul class=""><li id="6f44" class="kl km hi jp b jq jr jt ju jw kn ka ko ke kp ki kq kr ks kt bi translated">习惯按下<strong class="jp hj">键</strong>在界面和图像框之间来回移动。</li><li id="a9ba" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki kq kr ks kt bi translated">使用<strong class="jp hj">模糊蒙版</strong> (E和D)和<strong class="jp hj">腐蚀蒙版</strong> (W和S)将生成的脸与主体的脸型相匹配。对于基本的Quick96型号，我们对下颌线识别的支持有限，因此这一步非常重要。</li><li id="e153" class="kl km hi jp b jq kv jt kw jw kx ka ky ke kz ki kq kr ks kt bi translated">一旦您准备好继续前进，您可以使用句点键移动到下一帧或使用<strong class="jp hj"> Shift +。</strong>处理所有剩余帧。</li></ul><p id="6728" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这是一个相当初级的工具，但是当一个训练有素的模型处理大部分繁重的工作时，你会惊讶它能带你走多远。</p><p id="7b8a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">之后，运行<code class="du mg mh mi mj b">8) merged to mp4 lossless.bat</code>来运行一个小的FFmpeg脚本，它将构建你的合并视频，并将其渲染为<strong class="jp hj">result.mp4</strong>。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nc"><img src="../Images/f30af5fc48da80783287f1b55a274ce2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LWA_HEQVJy7QeSUYHBNtUg.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Tada! You’ve just played God with video manipulation. 🎉</figcaption></figure></div><div class="ab cl la lb gp lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hb hc hd he hf"><h1 id="e9f1" class="lh li hi bd lj lk ll lm ln lo lp lq lr io ls ip lt ir lu is lv iu lw iv lx ly bi translated">接下来去哪里？</h1><p id="0b11" class="pw-post-body-paragraph jn jo hi jp b jq lz ij js jt ma im jv jw mb jy jz ka mc kc kd ke md kg kh ki hb bi translated">在你的第一次深度造假得到满足后，你会很快获得创作更多荒谬作品的欲望。托尼·斯塔克/埃隆·马斯克的例子有点像DeepFaceLab工具的“Hello World ”,你很快就会发现Quick96模型和你四年前的Nvidia GPU不适合更高级的情况。</p><p id="7e22" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在我的下一篇文章中，我将向您展示我们如何使用<strong class="jp hj"> SAEHD模型</strong>来创建更高级的生成面具，以及我们如何使用<strong class="jp hj"> GoogleCollab </strong>笔记本将培训开销卸载到云。敬请期待！🤖</p></div></div>    
</body>
</html>