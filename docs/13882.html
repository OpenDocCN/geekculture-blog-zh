<html>
<head>
<title>DataOps: Using LakeFS for Data Version Control</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DataOps:使用LakeFS进行数据版本控制</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/dataops-using-lakefs-for-data-version-control-6ef5ddd65ebe?source=collection_archive---------6-----------------------#2022-08-03">https://medium.com/geekculture/dataops-using-lakefs-for-data-version-control-6ef5ddd65ebe?source=collection_archive---------6-----------------------#2022-08-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="381a" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">如果Git是用于代码版本控制，那么我们可以使用LakeFS进行数据版本控制吗？</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/9dda48b454f65a7b827e5d908f8c422f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IEscngPU8_iliweQ"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://unsplash.com/@sakethgaruda" rel="noopener ugc nofollow" target="_blank">Saketh Garuda</a> on <a class="ae jn" href="https://unsplash.com/photos/oAcozr3ru3E" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="7631" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">Git是代码版本控制领域的游戏改变者，每个开发人员都同意这一点。多个开发人员能够轻松地在项目上工作，每个团队成员都能够在项目的不同部分工作，直到发布完整的产品。在Git的帮助下，开发人员能够开发新特性，并将新特性无缝地引入生产环境。这正是LakeFS带给数据世界的解决方案。</p><p id="a3e3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">问题是我们能否拥有一个系统来监控和跟踪投入生产的数据的变化？在团队成员错误地引入扰乱生产环境的脏数据之前，我们能否回滚到以前工作正常的数据？答案是肯定的，我们可以。我们需要推出坏数据并回滚到更干净的数据，在LakeFS的帮助下，我们可以通过一个命令轻松实现这一点。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kk"><img src="../Images/f929ca067dcad11aa0b4eb52b1a04da5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/0*r8vVhan21YrVIf1O"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">Photo by <a class="ae jn" href="https://github.com/treeverse/lakeFS" rel="noopener ugc nofollow" target="_blank">LakeFS</a></figcaption></figure><h1 id="fdfd" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">LakeFS帮助解决什么问题？</h1><p id="baaa" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">这些是我们作为数据工程师每天遇到的一些问题，这些是LakeFS帮助解决的一些问题。LakeFS解决的一些问题包括从数据错误中无缝恢复、数据重新处理和回填、生产问题的故障排除、交叉收集一致性以及建立数据质量。</p><p id="3e50" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">例如，如果您的Spark代码如下所示:</p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="08f3" class="ln km hi lj b fi lo lp l lq lr">df <strong class="lj hj">=</strong> spark.read.parquet(“s3a://my-bucket/collections/foo/”)</span></pre><p id="e2c7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然后您可以插入您的应用程序，使用下面的命令直接从LakeFS分支读取:</p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="4727" class="ln km hi lj b fi lo lp l lq lr">df <strong class="lj hj">=</strong> spark.read.parquet(“s3a://my-repo/main-branch/collections/foo/”)</span></pre><p id="b520" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这允许您在将数据投入生产之前测试和验证开发中的数据。我知道在这一点上，一切看起来仍然可疑，但不要担心，你会知道这是如何运作的。</p><p id="fdcd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在这篇博文中，我们将建立LakeFS:一个与AWS S3存储桶通信并跟踪数据变化的数据版本控制系统。这种方法可以适用于Azure blob存储或Google云存储，而不是使用AWS S3存储桶，但重点将是AWS S3存储桶。如果你热衷于学习如何设置这个，那就跟我来。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ls"><img src="../Images/61cf54bff2726f19d2007c0ef1768391.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QhHyTScRy6aFla-c5blVtw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">LakeFS for Delta Lake version control (Image by author)</figcaption></figure><p id="bf9f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这篇文章中使用的数据是由<a class="ae jn" href="https://www.kaggle.com/datasets/bravehart101/sample-supermarket-dataset" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>提供的开源样本超市数据集。在本帖中，我们将创建一个AWS S3桶并将我们的数据上传到S3桶，在LakeFS可以与我们的S3桶通信之前设计一个专用的AWS IAM角色。我们还将为我们的bucket创建一个AWS bucket策略，在本地安装和配置AWS CLI，然后使用Docker Compose文件设置LakeFS。</p><p id="01ef" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们还将在本地安装和配置LakeFS CLI (lakectl ),并且我们将使用LakeFS CLI从终端创建一个数据存储库。下面是最有趣的部分，我们将使用lakectl向主分支上传新数据。然后，我们将创建一个新的分支，并使用lakectl命令上传缺少列的数据，以模拟如何使用LakeFS处理生产中的中断，最后我们将回滚到具有完整列的先前数据。</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><p id="0a4b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们开门见山，不要浪费太多时间，在当地建立LakeFS。您也可以在云上设置它，并在您公司的环境中添加不同的贡献者。出于本文的目的，您将需要一个AWS帐户，并且需要创建一个AWS S3桶。你也可以使用MinIO来代替S3桶，它的API与AWS S3桶兼容，但是我们将使用AWS S3桶来存储我的对象。这样，你就可以走了。</p><h1 id="01a5" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak"> #1创建一个AWS S3存储桶，并将您的数据上传到S3存储桶</strong></h1><p id="8205" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">从AWS控制台，导航到AWS S3铲斗控制台，点击<strong class="jq hj">创建铲斗，</strong>，然后输入您的铲斗名称，其他选项为默认。下载数据集并将文件上传到bucket中。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/1dd5c38add893a9c92982cdbdc9b69a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tIAjf3jLUG50AOL6"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">AWS S3 bucket creation icon (Image by author)</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/808a040216c4bc0bf57762deaad4a4b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Pa8Hcn-XFSFtFsZ9"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Image showing data uploaded to the S3 bucket (Image by author)</figcaption></figure><h1 id="57fe" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak"> #2为您的存储桶创建一个专用的AWS IAM角色</strong></h1><p id="9534" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">导航到AWS IAM角色控制台，并为您的存储段创建IAM角色和策略。您可能希望为您的AWS资源提供严格的规则，在这种情况下，请非常认真地对待这一点，您不希望暴露基础架构安全方面的漏洞。在我们的例子中，IAM策略如下所示:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mb mc l"/></div></figure><h1 id="1e9b" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak"> #3为您的S3时段创建AWS时段策略</strong></h1><p id="50ab" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">在我们能够在AWS控制台上创建IAM角色策略之后，现在是我们创建bucket策略的时候了。存储桶策略如下所示:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mb mc l"/></div></figure><h1 id="490d" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak"> #4在本地获取并配置AWS CLI</strong></h1><p id="aaa0" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">为了从LakeFS环境中与AWS S3存储桶进行通信，我们必须设置AWS CLI并充分配置CLI，这样我们就能够执行不同的操作，如从AWS S3存储桶向我们的存储库注入数据，从LakeFS CLI连接并创建S3存储桶等。为了实现这一点，我们将执行以下操作:</p><ul class=""><li id="8547" class="md me hi jq b jr js ju jv jx mf kb mg kf mh kj mi mj mk ml bi translated"><strong class="jq hj">获取AWS CLI包，并在您的终端中使用以下命令进行安装:</strong></li></ul><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="c181" class="ln km hi lj b fi lo lp l lq lr"><strong class="lj hj"># Get the AWS CLI package<br/></strong>curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"</span><span id="ce0e" class="ln km hi lj b fi mm lp l lq lr"><strong class="lj hj"># Unzip the file<br/></strong>unzip awscliv2.zip</span><span id="b44f" class="ln km hi lj b fi mm lp l lq lr"><strong class="lj hj"># Install the AWS CLI package and move the installation to the bin folder<br/></strong>./aws/install -i /usr/local/aws-cli -b /usr/local/bin</span><span id="453f" class="ln km hi lj b fi mm lp l lq lr"><strong class="lj hj"># Check the version of AWS installed to confirm that the CLI is installed<br/></strong>aws --version</span></pre><p id="2b09" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果你做了正确的事情，那么你会看到如下的截图:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mn"><img src="../Images/10d7f6a5b02f4e1f0f5ef6f728a915f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*ET2dNRJtsznqrqmPeZ670A.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx"><strong class="bd kn">AWS CLI version confirmation (Image by author)</strong></figcaption></figure><ul class=""><li id="ce70" class="md me hi jq b jr js ju jv jx mf kb mg kf mh kj mi mj mk ml bi translated"><strong class="jq hj">配置AWS CLI </strong></li></ul><p id="df83" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">由于我们看到AWS CLI已成功安装，我们将配置CLI。我们将需要AWS IAM用户凭证，我们只需要我们的访问密钥，秘密访问密钥，默认区域是<strong class="jq hj"> us-east-1 </strong>，默认输出格式是<strong class="jq hj"> json </strong>。</p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="43f0" class="ln km hi lj b fi lo lp l lq lr">aws configure<br/><strong class="lj hj"># Result will look like the below</strong><br/># AWS Access Key ID [None]: AKIATExample<br/># AWS Secret Access Key [None]: HSIIYDJKejkjsiExample<br/># Default region name [None]: us-east-1<br/># Default output format [None]: json</span></pre><p id="d488" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">为了确认我们的配置工作正常，让我们列出我们客户中的所有AWS S3产品。下面还提供了结果截图:</p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="b7d2" class="ln km hi lj b fi lo lp l lq lr">aws s3 ls</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mo"><img src="../Images/28979491e0745d5cb978fa782138e018.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*JLlRGyqW-QiPcittuemn7w.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">List of S3 buckets in the AWS account (Image by author)</figcaption></figure><h1 id="72bd" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak"> #5使用Docker合成文件设置LakeFS</strong></h1><p id="d5d8" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">随着AWS CLI的启动，我们将继续使用Docker容器设置LakeFS和Postgres数据库。Postgres数据库用于存储和检索LakeFS操作的元数据。以下是实现这一目标的步骤。你可以直接从LakeFS GitHub仓库中获取，这里有<a class="ae jn" href="https://github.com/treeverse/lakeFS" rel="noopener ugc nofollow" target="_blank">的</a>。你也可以从官方的LakeFS Docker <a class="ae jn" href="https://hub.docker.com/r/treeverse/lakefs" rel="noopener ugc nofollow" target="_blank"> hub </a>获取你的LakeFS图片。但是不要担心，我已经在我的GitHub库中包含了这个Docker Compose文件的副本，可以克隆这个库并自由使用它:</p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="cfe3" class="ln km hi lj b fi lo lp l lq lr">git clone <a class="ae jn" href="https://github.com/yTek01/data-versioning-using-lakefs.git" rel="noopener ugc nofollow" target="_blank">https://github.com/yTek01/data-versioning-using-lakefs.git</a></span></pre><p id="e6b4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">启动Docker容器:</strong></p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="398e" class="ln km hi lj b fi lo lp l lq lr">docker-compose -f docker-compose.LakeFS.yaml up -d</span></pre><p id="a7e0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">非常重要的是，当你读到这篇博文的时候，Docker图片可能已经有了一个重要的更新，一定要更新它。容器启动并运行后，从浏览器转到<a class="ae jn" href="http://localhost:8000/" rel="noopener ugc nofollow" target="_blank"> http://localhost:8000 </a>，如果一切正常，您将看到类似下面的截图:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mp"><img src="../Images/026f7945bd4eee517858a75a9caecfba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*srTejuhJXkcx5FiULHjPDQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">LakeFS initialization page (Image by author)</figcaption></figure><p id="1ffc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">输入您的管理员信息并进入下一页。在下一页，您将看到访问LakeFS UI控制台所需的凭证。现在确保下载lakectl.yaml文件。这将是您最后一次看到凭据，因此请确保下载它们。它包含在初始化页面上显示的凭据。输入您在上一页下载的访问密钥ID和秘密访问密钥，并使用凭据登录。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/fabec64b49c96aeb28926bc23649c3d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*cmRPgq5e6erdbSWMMJWPxQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">LakeFS UI login page (Image by author)</figcaption></figure><p id="b989" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">您应该会看到存储库窗口，如下图所示:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mr"><img src="../Images/63cb6069c74914f44e2e9d57d0fc6aa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6sDBsG6d94VdKn1bk0KCPw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">LakeFS Repository (Image by author)</figcaption></figure><h1 id="c736" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak"> #6在本地获取并配置LakeFS CLI(lake CTL)</strong></h1><p id="02d0" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">LakeFS启动并运行后，我们将按照以下步骤设置LakeFS CLI。LakeFS CLI (lakectl)是LakeFS的一个方面，它允许我们从命令行界面管理LakeFS资源。</p><p id="e826" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">使用以下命令进行设置:</strong></p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="a401" class="ln km hi lj b fi lo lp l lq lr"><strong class="lj hj"># Get the LakeFS CLI set up file with the command below:</strong><br/>wget   <a class="ae jn" href="https://github.com/treeverse/lakeFS/releases/download/v0.68.0/lakeFS_0.68.0_Linux_x86_64.tar.gz" rel="noopener ugc nofollow" target="_blank">https://github.com/treeverse/lakeFS/releases/download/v0.68.0/lakeFS_0.68.0_Linux_x86_64.tar.gz</a></span><span id="a4ef" class="ln km hi lj b fi mm lp l lq lr"><strong class="lj hj">#</strong> <strong class="lj hj">Extract the lakectl file using the command below:<br/></strong>tar -xf lakeFS_0.68.0_Linux_x86_64.tar.gz</span><span id="b3cc" class="ln km hi lj b fi mm lp l lq lr"><strong class="lj hj">Move the extracted file to the bin location so that we can use lakectl from anywhere in our instance:<br/></strong>mv lakectl /usr/local/bin</span></pre><p id="6e2b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">配置LakeFS CLI进行通信，以便我们可以与AWS S3和LakeFS实例进行通信。您的访问密钥Id和秘密访问密钥是从LakeFS UI下载的，而不是AWS用户IAM凭证。对于本地部署，您的服务器端点URL是<a class="ae jn" href="http://127.0.0.1:8000" rel="noopener ugc nofollow" target="_blank"> http://127.0.0.1:8000 </a>。</p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="4afa" class="ln km hi lj b fi lo lp l lq lr">lakectl config</span><span id="65c9" class="ln km hi lj b fi mm lp l lq lr"><strong class="lj hj"># My result looks like this.</strong><br/># Config file /root/.lakectl.yaml will be used<br/># ✔ Access key ID: AKIAJVYVYBRAExample█<br/># ✔ Secret access key: ****************************************█<br/># Server endpoint URL: http://127.0.0.1:8000</span></pre><h1 id="4ec4" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak"> #7使用LakeFS CLI (lakectl)创建一个存储库</strong></h1><p id="2e61" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">现在，我们可以开始从UI或CLI创建我们的存储库。确保您的LakeFS容器可以与AWS S3通信。如果您在UI和LakeFS CLI上看到与“<strong class="jq hj">未能创建存储库:未能访问存储库</strong>”相关的错误，那么应该知道AWS凭证有问题。LakeFS无权访问您的AWS凭据。如果您试图从CLI与LakeFS通信，请确保您拥有正确的权限，否则您将会得到<strong class="jq hj"/><strong class="jq hj">“错误认证请求”</strong>。</p><p id="fb40" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">我们将使用LakeFS CLI创建一个LakeFS存储库，命令如下:</strong></p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="9d48" class="ln km hi lj b fi lo lp l lq lr">lakectl repo create lakefs://stagingtable s3://lakefsstoragea -d main</span></pre><h1 id="5e3c" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak"> #8使用lakectl命令将数据摄取到主分支</strong></h1><p id="5fd0" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">我们可以决定通过不同的选项将数据接收到我们的LakeFS环境中，我们可以上传(将本地文件上传到指定的URI)，我们可以决定使用接收方法(将对象从外部源加载到LakeFS分支，而不实际复制它们)。在我们的例子中，我们将使用下面的命令将上传到S3存储桶的数据接收到主分支中:</p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="e174" class="ln km hi lj b fi lo lp l lq lr">lakectl ingest --from s3://lakefs.data.versioning/Sample_Superstore.xlsx --to lakefs://stagingtable/main/store/Sample_Superstore.xlsx</span></pre><p id="0f9e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">结果显示在下面截图中的终端上。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ms"><img src="../Images/c549b3e3cbb00a0af3eae9caff1eac55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nOerRuNLnP_rT2LY"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Response of the ingestion method (Image by author)</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mt"><img src="../Images/2a0f99c54c5ef65833bb97154cc13753.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ovMRYiddGJYGQsdE_chj3Q.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">List of LakeFS commits to the main branch (Image by author)</figcaption></figure><h1 id="2c44" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak"> #9使用LakeFS CLI创建一个新分支并上传缺少列的数据</strong></h1><p id="9c32" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">此时，我们将创建一个新的分支，并将不完整的数据上传到该分支中，我们将有意识地这样做，看看我们如何在生产中处理这种类型的暴行，并回滚我们工作数据的先前版本。过程如下。</p><p id="d98e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">创建一个新的分支来存放不完整的数据，以展示暴行:</strong></p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="ab53" class="ln km hi lj b fi lo lp l lq lr">lakectl branch create lakefs://stagingtable/removed-a-column-from-data --source lakefs://stagingtable/main</span></pre><p id="368d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">#执行命令后的终端响应如下所示:</p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="014d" class="ln km hi lj b fi lo lp l lq lr">Source ref: lakefs://stagingtable/main<br/>created branch ‘removed-a-column-from-data’ 451e738f1cf290df0cc52eb339c0c4a7788fb59e8dff3ecdf7ef640fdff74f11</span></pre><p id="e3da" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">下面的屏幕截图显示了LakeFS UI中现在可用的分支列表。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mu"><img src="../Images/afaf4bd5e2e71bfbf5de901a68d604eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*Jyi3uPgSbkm01nzpqdV7JQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx">List of branches in the stagingtable repository (Image by author)</figcaption></figure><p id="a605" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">将数据上传到名为‘removed-a-column-from-data’的新分支:</strong></p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="9682" class="ln km hi lj b fi lo lp l lq lr">lakectl fs upload -s Sample_Superstore.xlsx lakefs://stagingtable/removed-a-column-from-data/store/Sample_Superstore.xlsx</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/216e21fa947d55ccba66b50e51b8cfef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AOI_pygfLTCiGsW2"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">List of commits (Image by author)</figcaption></figure><p id="0889" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">合并新分行和主分行</p><p id="e9d2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">上面，我们的新数据在特征分支中，我们将分支合并到主分支中。以下命令有助于我们实现这一目标:</p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="1e1c" class="ln km hi lj b fi lo lp l lq lr">lakectl merge lakefs://stagingtable/removed-a-column-from-data<strong class="lj hj"><em class="mv"> </em></strong>lakefs://stagingtable/main</span></pre><p id="9f76" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">合并两个分支后的数据结果如下所示:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/d7c717fe352141b3331dfdb1ffedc768.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QfoltnjvVRMyKpJ_"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Superstore data without the State column (Image by author)</figcaption></figure><h1 id="ee98" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak"> #10使用已完成的列</strong>回滚到之前的数据</h1><p id="8b41" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">对于存储库中不需要的数据，我们必须回滚已经导致的更改。在我们的例子中，一个非常重要的列丢失了，State列必须包含在我们的示例超市数据中。我们将把最后一次合并操作中所做的所有更改恢复到最近一次提交时的状态，即没有错误。以下命令有助于我们实现这一目标:</p><pre class="iy iz ja jb fd li lj lk ll aw lm bi"><span id="9a65" class="ln km hi lj b fi lo lp l lq lr">lakectl branch revert lakefs://stagingtable/main &lt;commit_id&gt; --yes</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/9e7ea568163ddbeca924573e6b890dbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_F1O_G2X8ay-LEzO"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Table with State column after rolling back to the initial commit (Image by author)</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/49f0d4c4e80fc145f17e15497a372a85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eHHdjnNVLxhcXkqx"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx">Commit page showing the reverting operation (Image by author)</figcaption></figure><h1 id="bcdd" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated"><strong class="ak">结论</strong></h1><p id="0431" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">在这篇文章中，我们已经展示了在LakeFS的帮助下管理我们的数据操作是多么容易。LakeFS帮助我们在一个非常接近Git代码版本管理的过程中管理我们的数据。有趣的是，LakeFS为您提供了一个S3兼容性API，允许我们在数据管道中直接使用LakeFS功能分支链接，以在我们将数据工作负载转移到生产中之前确认一切正常。事实上，您可以自动化数据质量验证，并抽象掉手工工作。</p></div><div class="ab cl lt lu gp lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="hb hc hd he hf"><p id="d9e7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">推荐阅读</strong></p><p id="d221" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">[1] <a class="ae jn" href="https://docs.lakefs.io/" rel="noopener ugc nofollow" target="_blank">什么是LakeFS — LakeFS </a></p><p id="e64c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">[2] <a class="ae jn" href="https://github.com/treeverse/lakeFS" rel="noopener ugc nofollow" target="_blank"> LakeFS Github页面— Treeverse </a></p><p id="2b79" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">[3] <a class="ae jn" href="https://towardsdatascience.com/data-versioning-all-you-need-to-know-7077aa5ed6d1" rel="noopener" target="_blank">数据版本化:您需要知道的一切— Bex T. </a></p><p id="37f9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">感谢您的阅读。我很乐意回答任何问题，并听取任何意见。</p></div></div>    
</body>
</html>