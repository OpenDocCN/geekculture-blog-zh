<html>
<head>
<title>Deep Convolutional Generative Adversarial Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度卷积生成对抗网络</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/deep-convolutional-generative-adversarial-networks-a6a0b0da3253?source=collection_archive---------25-----------------------#2021-04-11">https://medium.com/geekculture/deep-convolutional-generative-adversarial-networks-a6a0b0da3253?source=collection_archive---------25-----------------------#2021-04-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="792d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在2014年，<a class="ae jd" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank"> Goodfellow等人</a>提出了生成对抗网络(GAN ),它可以生成与图像数据集中的图像相似的图像，而不需要训练标签。从那以后，研究界开始接受GANs，并且不断有关于GANs的新论文发表。我将向您展示GAN的基本结构，以及如何构建GAN来生成<a class="ae jd" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST数字</a>。随附的Colab笔记本在<a class="ae jd" href="https://colab.research.google.com/drive/1xniGgjynsrceFKEVSlt_FPXDHqkQQAGR?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>有售。</p><p id="f089" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GAN由一个生成器网络(G)和一个鉴别器网络(D)组成，每个网络都是一个具有潜在卷积层的神经网络。鉴别器接收一幅图像，并试图辨别该图像是真的还是假的，而生成器接收高斯噪声并输出一幅图像，试图欺骗鉴别器，使其相信假图像是真的。甘的设置就像一盘棋，每个玩家都试图让他的对手失败。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/2f52016df243b9d68358aa26a223d966.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5xgDIcxsHfjHT62WBBO3Xw.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx">image from <a class="ae jd" href="https://arxiv.org/pdf/1701.00160.pdf" rel="noopener ugc nofollow" target="_blank">Goodfellow’s NIPS 2016 Tutorial</a></figcaption></figure><p id="2487" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练的每次迭代包括两个步骤。首先，鉴别器被给予来自未标记的训练数据集的一批真实数据和由生成器生成的另一批虚假数据，并且鉴别器使用梯度下降来更新其参数，以最大化其正确区分虚假和真实图像的能力，就像在图像分类的情况下一样。第二，生成器接受高斯噪声，输出一批假图像。鉴别器接收一批假图像，并输出它对这些图像是真实图像的置信度。然后，发生器使用梯度下降来更新其参数，以最大化鉴别器的置信度，即当这些图像是假的时，它们是真实的。在每一步中，只有GAN的一部分(鉴别器或发生器)更新其参数。</p><p id="6b51" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随着训练的进行，鉴别器在区分真实和虚假图像方面变得更好，而生成器必须产生更真实的图像才能骗过鉴别器。在训练结束时，我们的希望是生成器将产生与真实图像无法区分的假图像。</p><p id="4243" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将通过一个真实的例子来尝试生成MNIST数字。我们将使用PyTorch和NumPy来完成这个任务。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ju"><img src="../Images/65c364cc7ddd0d60e79a6d44cf4e1c32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*xPXuEx_cwMQGDHc8QFpyKw.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx">real MNIST images</figcaption></figure><p id="e143" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们首先用公式表示发生器和鉴别器的损耗函数。</p><p id="0461" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">鉴别器输出[0，1]范围内的数字。对于真实图像，它希望输出接近1的数字，而对于虚假图像，它希望输出接近0的数字，因此一个好的损失函数应该是(D(真实图像)-1) + D(G(高斯噪声))。</p><p id="61bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生成器希望鉴别器为它生成的假图像输出接近1的数字，因此一个好的损失函数应该是(D(G(gaussian_noise))-1)。</p><p id="ce24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是论文<a class="ae jd" href="https://arxiv.org/abs/1611.04076" rel="noopener ugc nofollow" target="_blank">这里</a>使用的损失函数，他们声称最小二乘损失比原始的二元交叉熵损失提高了GANs的稳定性。python代码如下所示。因为我们是在一批图像上训练，而不是一张，所以我们另外取损失的平均值。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="jv jw l"/></div><figcaption class="jq jr et er es js jt bd b be z dx">discriminator loss and generator loss</figcaption></figure><p id="b8d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们指定鉴别器网络。它由两个卷积层、一个最大池层和两个线性层组成。它使用LeakyReLU而不是通常的ReLU。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="jv jw l"/></div><figcaption class="jq jr et er es js jt bd b be z dx">discriminator network</figcaption></figure><p id="5614" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是本文使用的发电机网络<a class="ae jd" href="https://arxiv.org/abs/1606.03657" rel="noopener ugc nofollow" target="_blank">这里</a>。它接收维数为96的高斯噪声。它由2个线性层和2个卷积转置层组成。步长为2的卷积转置层具有将图像上采样2倍的效果。在跨距2的两个卷积转置层之后，7×7图像将变成28×28图像，这是MNIST图像的大小。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="jv jw l"/></div><figcaption class="jq jr et er es js jt bd b be z dx">generator network</figcaption></figure><p id="4a42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将省略实际的训练循环。如果你有兴趣，可以在这里看看我创作的<a class="ae jd" href="https://colab.research.google.com/drive/1xniGgjynsrceFKEVSlt_FPXDHqkQQAGR?usp=sharing" rel="noopener ugc nofollow" target="_blank">的Colab笔记本。</a></p><p id="d819" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过运行Colab笔记本，我们可以得到看起来相当不错的假图像。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jx"><img src="../Images/3f5231316a3f8f53bbcef2b4dca4228e.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*MmqrSWIxg-uQ8uHtcTRY0A.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx">fake images generated</figcaption></figure><p id="2f57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">就是这样！现在你知道如何使用GANs生成图像了。GANs的内容比我在这里介绍的要多得多。甘动物园列出了很多关于甘的论文。还有其他生成图像的方法，如<a class="ae jd" href="https://arxiv.org/abs/1312.6114" rel="noopener ugc nofollow" target="_blank">变型自动编码器</a>和<a class="ae jd" rel="noopener" href="/swlh/why-i-stopped-using-gan-eccv2020-d2b20dcfe1d">标准化流程</a>。</p></div></div>    
</body>
</html>