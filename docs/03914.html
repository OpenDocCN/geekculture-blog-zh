<html>
<head>
<title>A Deep Learning Experiment for Quarantine Home Gyms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于隔离家庭健身房的深度学习实验</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/a-deep-learning-experiment-for-quarantine-home-gyms-216ab1d28c1e?source=collection_archive---------24-----------------------#2021-06-17">https://medium.com/geekculture/a-deep-learning-experiment-for-quarantine-home-gyms-216ab1d28c1e?source=collection_archive---------24-----------------------#2021-06-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="ce23" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">与<a class="ix iy ge" href="https://medium.com/u/b84cd651e185?source=post_page-----216ab1d28c1e--------------------------------" rel="noopener" target="_blank"> Ojasvi Yadav </a>合著</h2></div><figure class="ja jb jc jd fd je er es paragraph-image"><div role="button" tabindex="0" class="jf jg di jh bf ji"><div class="er es iz"><img src="../Images/439763911c60241c4bec952229a63680.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oA4eldRhrZrk_qVh.jpeg"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx">Image Credits — <a class="ae jp" href="https://www.castlehillfitness.com/group-programs/online-classes" rel="noopener ugc nofollow" target="_blank">https://www.castlehillfitness.com/group-programs/online-classes</a></figcaption></figure><blockquote class="jq jr js"><p id="2e96" class="jt ju jv jw b jx jy ij jz ka kb im kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">在2020年，大量的人口不得不被限制在他们家的四面墙内。隔离打开了以前没有想到的问题，不能去健身房就是其中之一。46%的印度人受到全国封锁的影响，因为健身房、公园和健身中心的可达性有限。因此，许多健身圈转移到在线视频会议平台，在家工作<strong class="jw hj">变得突出。</strong></p></blockquote><p id="b6fa" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">随着这些班级的规模每天呈指数级增长，培训师很难关注每个单独注册的学生。尤其是当一些锻炼涉及大量重复时，训练者很难保持计数并适当地评估注册的学生。它呼吁开发工具，以满足此类和类似场景的分析和实时性能跟踪。在这篇博客中，我们讨论了一个这样的用例——<strong class="jw hj">在深度学习的帮助下计算俯卧撑的重复次数。</strong></p><p id="ecf7" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">由于深度学习可以帮助缓解和自动化许多计算机视觉问题，因此为管道找到正确的架构是我们必须解决的第一个问题。现在，通常使用先进的计算机视觉技术来解决这些问题，如<a class="ae jp" href="https://towardsdatascience.com/human-pose-estimation-simplified-6cfd88542ab3" rel="noopener" target="_blank">人体姿态估计</a>、<a class="ae jp" href="https://en.wikipedia.org/wiki/Optical_flow#:~:text=Optical%20flow%20or%20optic%20flow,brightness%20pattern%20in%20an%20image." rel="noopener ugc nofollow" target="_blank">光流</a>等。通过使用诸如<a class="ae jp" href="https://www.tensorflow.org/lite/examples/pose_estimation/overview" rel="noopener ugc nofollow" target="_blank"> Tensorflow的姿势估计</a>库之类的库来进行关节的姿势估计是有用的，但是由于它需要高计算能力，所以在基于移动的部署中使用它可能是不合理的。但是因为我们希望这个实验非常用户友好、简单和灵活，所以我们选择使用传统的分类管道。该算法应该能够将俯卧撑视频的帧分类到不同的俯卧撑阶段，如图1所示，可以将其附加到事件列表中(…向下- &gt;向上- &gt;向下…)，因此充当计数器。</p><p id="8abf" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated"><strong class="jw hj">更新</strong>——这个博客不是一个跟进/代码跟进的博客，尽管它看起来可能是这样。查看本博客的结论，以便在继续讨论之前检查我们的学习成果。</p><figure class="ja jb jc jd fd je er es paragraph-image"><div role="button" tabindex="0" class="jf jg di jh bf ji"><div class="er es kt"><img src="../Images/ecd68ac423ba3bcc687d68dff075002b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*05Wv4W5v78ybIVGFWScOMA.jpeg"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx">Fig 1. A simple illustration depicting the classification of frames into notable events.</figcaption></figure><h1 id="cf5d" class="ku kv hi bd kw kx ky kz la lb lc ld le io lf ip lg ir lh is li iu lj iv lk ll bi translated">1 —选择模型和框架</h1><p id="0869" class="pw-post-body-paragraph jt ju hi jw b jx lm ij jz ka ln im kc kq lo kf kg kr lp kj kk ks lq kn ko kp hb bi translated">对于这种特殊情况，对象检测算法必须足够快速、精确和轻便，甚至可以部署在手持设备上。根据Jonathan Hui的全面比较，快速部署模型领域的流行算法包括Fast-CNN、YOLO、SSD和MobileNet。与此同时，大多数被比较的模型都是Tensorflow 2的<a class="ae jp" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md" rel="noopener ugc nofollow" target="_blank">检测模型Zoo </a>的一部分，所以我们继续使用Tensorflow 2作为框架。仔细比较了COCO数据集上许多模型的性能指标，以及它们的易于部署性和灵活性，我们选择了SSD-MobileNet V2。该网的研究论文可以在这里阅读<a class="ae jp" href="https://arxiv.org/pdf/1801.04381.pdf" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="206e" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">使用该模型的特别优点包括即使在移动设备上也能快速准确地预测，并且可以方便地与Tensorflow一起用于迁移学习应用。<a class="ae jp" href="https://machinelearningmastery.com/transfer-learning-for-deep-learning/#:~:text=Transfer%20learning%20is%20a%20machine,model%20on%20a%20second%20task.&amp;text=Common%20examples%20of%20transfer%20learning,your%20own%20predictive%20modeling%20problems." rel="noopener ugc nofollow" target="_blank">迁移学习</a>是一种创新的方法，通过使用预训练模型(通常在大型数据集上训练，如<a class="ae jp" href="https://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>)和重新训练最后的“n”(可配置参数)层进行微调，来减少训练时间。这使得NN初始层中的基本特征识别器准确地工作，同时影响最终层的权重以迎合我们特定的数据集。使用迁移学习的另一个优点是，它有助于用更少的图像获得想要的结果。在我们的案例中，我们也决定遵循TensorFlow提供的迁移学习教程，如这个<a class="ae jp" href="https://www.tensorflow.org/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank">链接</a>所示。</p><h1 id="4cb5" class="ku kv hi bd kw kx ky kz la lb lc ld le io lf ip lg ir lh is li iu lj iv lk ll bi translated">2 —获取和设置迁移学习所需的数据</h1><p id="26f4" class="pw-post-body-paragraph jt ju hi jw b jx lm ij jz ka ln im kc kq lo kf kg kr lp kj kk ks lq kn ko kp hb bi translated">在迁移学习开始之前，我们必须找到一个数据集来满足我们对俯卧撑阶段进行分类的需要。我们没有去寻找外部资源，而是录下了自己做俯卧撑的过程。视频是从我们的手机摄像头拍摄的非常简单的记录，帧是使用非常基本的Python-OpenCV脚本提取的，如图所示。</p><figure class="ja jb jc jd fd je"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="6ed7" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">在查看提取的帧时，我们得出结论，最好将帧分成三个事件，down、else和up，如图2所示。标签完全是通过目测来决定的。</p><figure class="ja jb jc jd fd je er es paragraph-image"><div role="button" tabindex="0" class="jf jg di jh bf ji"><div class="er es kt"><img src="../Images/a7bbf9ea340287e7e23811c93e86caa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v-bPXVO1bT7YNVwZAyJF_Q.jpeg"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx">Fig 2. Sample Images were taken from the video stream and labeled into the three respective categories purely based on visual examination.</figcaption></figure><p id="f033" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">在我们提取数据之后，我们手动地(随意探索注释数据的方法<a class="ae jp" href="https://evergreen.team/articles/image-annotation.html" rel="noopener ugc nofollow" target="_blank">这里是</a>)将数据分离到它们各自的标签中，并将它们放入如下所示的三个类别中。这些文件夹存储在另一个文件夹中，即“标签帧”</p><figure class="ja jb jc jd fd je er es paragraph-image"><div role="button" tabindex="0" class="jf jg di jh bf ji"><div class="er es lt"><img src="../Images/e24f2feb7d4b13d91e3121cbbaab3758.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YxE8369-VenZTYcaZKNTew.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx">Fig 3. Labeled Folder structure for all the extracted frames from the pushup’s video, to ease out the CNN Training Process.</figcaption></figure><p id="d5a1" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">保持数据原样是一种非常低效的构建项目或机器学习应用程序的方式，尤其是当您在Google Colab/Kaggle等云机器上工作时。因此，我们决定使用<a class="ae jp" href="https://docs.python.org/3/library/pickle.html" rel="noopener ugc nofollow" target="_blank"> Pickle </a>来序列化数据集。序列化或“pickle”数据可以帮助您将python对象转换为字符流，字符流可以通过pickle反序列化，对于共享对象非常有用。多亏了<a class="ae jp" href="https://pythonprogramming.net/" rel="noopener ugc nofollow" target="_blank">sendex</a>，我们能够使用下面的方法将数据集打包成一个序列化的对象。在序列化的同时，我们决定将图像的尺寸调整为100 * 100，以使我们的图像与教程保持一致。</p><figure class="ja jb jc jd fd je"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="46f3" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">在这个过程完成之后，如图4所示，在随机重排之后，有必要以预定的比率将数据集分成训练、验证和测试数据集。它是使用Sklearn的<a class="ae jp" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank"> train_test_split </a>函数(执行了两次)实现的，并进一步序列化如下图以供进一步使用。</p><figure class="ja jb jc jd fd je er es paragraph-image"><div role="button" tabindex="0" class="jf jg di jh bf ji"><div class="er es lu"><img src="../Images/36d2eef8e5bf75d1a8c9d784c8d040f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nVTiUlK9EQ3aAVTe.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx">Fig. 4 — A visualization showcasing how the entire dataset has to be split to train a model with less bias and variance. Image Source — <a class="ae jp" href="https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7" rel="noopener" target="_blank">https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7</a></figcaption></figure><figure class="ja jb jc jd fd je"><div class="bz dy l di"><div class="lr ls l"/></div></figure><h1 id="687d" class="ku kv hi bd kw kx ky kz la lb lc ld le io lf ip lg ir lh is li iu lj iv lk ll bi translated">3 —数据预处理</h1><p id="6045" class="pw-post-body-paragraph jt ju hi jw b jx lm ij jz ka ln im kc kq lo kf kg kr lp kj kk ks lq kn ko kp hb bi translated">在将数据序列化为单独的变量后，它被单独读取并被整形。数据集的形状是根据必须训练的神经网络的形状决定的，如教程中所示。</p><figure class="ja jb jc jd fd je"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="b72c" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">必须完成另一个预处理步骤，即<a class="ae jp" href="https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">一键编码</a>。需要对标签进行一次热编码，其中标签本质上不是有序的。在这里，标签的性质是绝对的(up、down和else是彼此独立的)。因此，我们需要一种方法来确保算法在对给定数据进行训练之前知道这种差异。下面你可以看到我们是如何在开始迁移学习之前对标签进行一次性编码的。</p><figure class="ja jb jc jd fd je"><div class="bz dy l di"><div class="lr ls l"/></div></figure><h1 id="22ea" class="ku kv hi bd kw kx ky kz la lb lc ld le io lf ip lg ir lh is li iu lj iv lk ll bi translated">4 —执行迁移学习</h1><p id="3769" class="pw-post-body-paragraph jt ju hi jw b jx lm ij jz ka ln im kc kq lo kf kg kr lp kj kk ks lq kn ko kp hb bi translated">首先，加载预先训练好的MobileNet-V2(已经在ImageNet数据库上进行了训练),并如下所示创建数据批次。与此同时，参数base _ model.trainable = False用于定义在迁移学习期间不应训练MobileNet模型。</p><figure class="ja jb jc jd fd je"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="7499" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">然后，创建非冻结层，并编译和验证模型。</p><figure class="ja jb jc jd fd je"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="3eb6" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">输出应该是这样的</p><pre class="ja jb jc jd fd lv lw lx ly aw lz bi"><span id="d420" class="ma kv hi lw b fi mb mc l md me">20/20 [==============================] - 5s 229ms/step - loss: 2.2518 - categorical_accuracy: 0.2546</span><span id="9a8f" class="ma kv hi lw b fi mf mc l md me">initial loss: 2.25<br/>initial accuracy: 0.25</span></pre><p id="684e" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">最后，它被训练…(请记住，我们选择在训练时保存每个时期的模型权重，因为这是一种良好的做法，以便在梯度爆炸的情况下选择最佳模型)。</p><figure class="ja jb jc jd fd je"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="6b6d" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">输出太长而不能在本实验的范围内共享，然而，可以在图5中查看训练和验证准确度与训练时期的关系图。</p><figure class="ja jb jc jd fd je er es paragraph-image"><div role="button" tabindex="0" class="jf jg di jh bf ji"><div class="er es mg"><img src="../Images/35e269c1d4b748c30aa55e3769320aff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KWAZKW-rf7-Fgo179yScOQ.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx">Fig. 5 Training and Validation Accuracy after Transfer Learning has been done</figcaption></figure><p id="cca3" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">我们在数据集上实现的验证数据集的总体分类准确度约为0.89。</p><h1 id="2ca6" class="ku kv hi bd kw kx ky kz la lb lc ld le io lf ip lg ir lh is li iu lj iv lk ll bi translated">5-保存和测试模型</h1><p id="6c02" class="pw-post-body-paragraph jt ju hi jw b jx lm ij jz ka ln im kc kq lo kf kg kr lp kj kk ks lq kn ko kp hb bi translated">加载保存的模型，并使用下面的代码在测试数据集上评估该模型</p><figure class="ja jb jc jd fd je"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="d171" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">输出是…</p><pre class="ja jb jc jd fd lv lw lx ly aw lz bi"><span id="8ffa" class="ma kv hi lw b fi mb mc l md me">20/20 - 0s - loss: 0.2301 - categorical_accuracy: 0.9076<br/>Restored model, accuracy: 90.76%</span></pre><p id="abcf" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">在测试数据集上实现了良好的准确性(因为它与我们的验证准确性相当)，这表明模型具有更小的偏差和方差。</p><h1 id="5d24" class="ku kv hi bd kw kx ky kz la lb lc ld le io lf ip lg ir lh is li iu lj iv lk ll bi translated">5-网络摄像头上的实时测试</h1><p id="9022" class="pw-post-body-paragraph jt ju hi jw b jx lm ij jz ka ln im kc kq lo kf kg kr lp kj kk ks lq kn ko kp hb bi translated">为了结束我们的实验，我们开始创建一个小脚本，它将直接从我们的笔记本电脑的网络摄像头接收视频，然后计算俯卧撑的总数。首先，我们保存了我们在之前的帖子中创建的检查点，然后我们加载它，以便直接从相机预测帧，如下所示。该代码从摄像机获取一个输入帧，通过CNN运行它，预测动作，并将其存储在一个列表中。当我们退出循环时，在后处理过程中，将按照特定顺序扫描整个事件列表([2(向上)，1(否则)，0(向下)])。找到这种模式后，计数器会更新，并打印在最后，表示俯卧撑的总数。</p><figure class="ja jb jc jd fd je"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="62d3" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">在运行这个脚本时，我们注意到，通过执行俯卧撑，脚本有时能够识别帧，但不是太准确，但我们以前没有预见到的许多其他问题出现了，它们将在下一节中讨论。</p><h1 id="59f4" class="ku kv hi bd kw kx ky kz la lb lc ld le io lf ip lg ir lh is li iu lj iv lk ll bi translated">结论</h1><p id="9142" class="pw-post-body-paragraph jt ju hi jw b jx lm ij jz ka ln im kc kq lo kf kg kr lp kj kk ks lq kn ko kp hb bi translated">尽管有一个非常快速和易于理解的原型，它的工作(有时😆)，网络摄像头上的现场测试为我们提供了一个了解项目中仍然存在的谬误的学习机会。</p><p id="ad93" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">1-分类算法确实擅长快速解决问题，但是，不同的衣服，不同的背景，以及俯卧撑表演场所的不同设置，会很快破坏标准模型。在接下来的文章中，我们将进一步用其他模型对此进行实验，如<a class="ae jp" href="https://www.jeremyjordan.me/semantic-segmentation/" rel="noopener ugc nofollow" target="_blank"><strong class="jw hj"/></a>或<strong class="jw hj">光流</strong>，以便将动作从整体框架中分离出来。</p><p id="f426" class="pw-post-body-paragraph jt ju hi jw b jx jy ij jz ka kb im kc kq ke kf kg kr ki kj kk ks km kn ko kp hb bi translated">2-在这种情况下，计数算法没有完全优化，以适应在解决计数问题时可能存在的各种边缘情况。例如，俯卧撑的速度可能快或慢，这取决于人，因此需要更鲁棒的模式识别算法，例如<a class="ae jp" href="https://towardsdatascience.com/pattern-search-with-the-knuth-morris-pratt-kmp-algorithm-8562407dba5b" rel="noopener" target="_blank"> <strong class="jw hj"> Knuth Morris Pratt搜索算法</strong> </a> <strong class="jw hj">。</strong></p></div></div>    
</body>
</html>