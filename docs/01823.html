<html>
<head>
<title>Concept of Machine Learning | Polynomial Regression | Errors: Noise, Bias, and Variance | Splitting Data Into Training and Test Set</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的概念|多项式回归|误差:噪声、偏差和方差|将数据分成训练集和测试集</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/concept-of-machine-learning-polynomial-regression-errors-noise-bias-and-variance-splitting-222193e2331f?source=collection_archive---------9-----------------------#2021-04-25">https://medium.com/geekculture/concept-of-machine-learning-polynomial-regression-errors-noise-bias-and-variance-splitting-222193e2331f?source=collection_archive---------9-----------------------#2021-04-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c84e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上一篇文章中，我写了线性回归、用这样的系数优化误差、梯度下降法、超定方程组等。在这篇文章中，我写的是关于多项式回归和标题中写的其他东西。</p><p id="380f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个线性回归的图像</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/88ad07301969baaf36b0babc90128055.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8xWf4UwUHIbelROodBEsTg.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx"><strong class="bd jt">Linear Regression</strong></figcaption></figure><h2 id="a85b" class="ju jv hi bd jt jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">什么是多项式回归？</h2><p id="f933" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">多项式回归是一种回归形式，其中自变量和因变量之间的关系是x的nᵗʰ次多项式函数</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/1573c8c133504d76e84926abfa6ae603.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tSbXARoNDrjpqlOHtwVudg.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx"><strong class="bd jt">Polynomial Regression</strong></figcaption></figure><p id="5b8b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随着n的增加，结果将更加精确。更准确的结果是</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/7739309cad8cc26bcc116612a50873b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*chau7VF993tKAl6q9wYmyw.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Polynomial Regression</figcaption></figure><p id="aa24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是，K平方英尺的价格。英尺的房子比“L”平方小得多。英尺，所以这不是一个最佳预测。</p><h2 id="5a85" class="ju jv hi bd jt jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">那么什么是最合适的呢😕？</h2><p id="9e81" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">为了找到最佳拟合模型，我们必须将数据集分成训练和测试数据。</p><h2 id="a035" class="ju jv hi bd jt jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">训练和测试分割</h2><p id="b090" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">我们必须移除一些测试设备中的房子，剩下的是训练设备。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/b2f350ad40a4696e4b484dec30d12696.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yMUOIPSHy1LUDgGFXnvdEg.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Train Data &amp; Test Data Split</figcaption></figure><p id="5391" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练错误:训练数据集RSS。</p><p id="b7f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">测试错误:测试数据集的RSS。</p><h2 id="918e" class="ju jv hi bd jt jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">机器学习中的错误类型</h2><ol class=""><li id="d738" class="kt ku hi ih b ii ko im kp iq kv iu kw iy kx jc ky kz la lb bi translated">噪音</li><li id="bee1" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">偏见</li><li id="c697" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">差异</li></ol><h2 id="ddf5" class="ju jv hi bd jt jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">噪音</h2><ul class=""><li id="6ca6" class="kt ku hi ih b ii ko im kp iq kv iu kw iy kx jc lh kz la lb bi translated">不可约误差。</li><li id="2c86" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc lh kz la lb bi translated">收集数据时出错。</li></ul><h2 id="71f0" class="ju jv hi bd jt jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">偏见</h2><ul class=""><li id="9166" class="kt ku hi ih b ii ko im kp iq kv iu kw iy kx jc lh kz la lb bi translated">偏差与训练集的误差有关。</li><li id="674b" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc lh kz la lb bi translated">如果训练集的误差(RSS)很高，则称为高偏差，如果很低，则称为低偏差。</li></ul><p id="7e25" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果训练集误差高，则数据欠拟合。</p><h2 id="56fe" class="ju jv hi bd jt jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">差异</h2><ul class=""><li id="0fac" class="kt ku hi ih b ii ko im kp iq kv iu kw iy kx jc lh kz la lb bi translated">方差与测试集的误差(RSS)有关(与训练集误差相比，测试集误差有多大)</li><li id="1926" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc lh kz la lb bi translated">如果测试集误差比训练集误差高得多，那么我们可以说我们有很高的方差。</li></ul><p id="ea2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">获得0.5%的训练集误差和10%的测试集误差意味着我们的模型不能很好地概括，这意味着我们的模型也是过度拟合的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/5f57cc4824e9527443ce0d54693ddd3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*55kBY-guAiOmlN7G6ySbGA.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Bias, Variance, Over-fitting, Under-fitting in One Picture</figcaption></figure><h2 id="5da6" class="ju jv hi bd jt jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">偏差-方差权衡</h2><blockquote class="li lj lk"><p id="cbbf" class="if ig ll ih b ii ij ik il im in io ip lm ir is it ln iv iw ix lo iz ja jb jc hb bi translated">减少偏差会增加方差&amp;减少方差会增加偏差。因此，我们的目标是在偏差和方差之间找到正确的平衡。这被称为偏差-方差权衡</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lp"><img src="../Images/f68e7a21e3f0588466f860384ea676a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*OjdC1DZ9f4VdsEQX_kXgyw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx"><strong class="bd jt">Bias Variance tradeoff</strong></figcaption></figure><p id="cc16" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从图中可以看出，随着多项式次数的增加，训练误差减小，但是在某个值(多项式次数= p)之后，测试误差增加。因此，最佳曲线是p次多项式。</p><h2 id="77e5" class="ju jv hi bd jt jw jx jy jz ka kb kc kd iq ke kf kg iu kh ki kj iy kk kl km kn bi translated">全文系列:</h2><div class="lq lr ez fb ls lt"><a href="https://ujjwalkar.netlify.app/post/concept-of-machine-learning-tutorial-series/" rel="noopener  ugc nofollow" target="_blank"><div class="lu ab dw"><div class="lv ab lw cl cj lx"><h2 class="bd hj fi z dy ly ea eb lz ed ef hh bi translated">机器学习的概念文章系列| Ujjwal Kar</h2><div class="ma l"><h3 class="bd b fi z dy ly ea eb lz ed ef dx translated">回归入门|使用梯度下降的简单线性回归优化…</h3></div><div class="mb l"><p class="bd b fp z dy ly ea eb lz ed ef dx translated">ujjwalkar.netlify.app</p></div></div><div class="mc l"><div class="md l me mf mg mc mh jn lt"/></div></div></a></div></div></div>    
</body>
</html>