<html>
<head>
<title>Sparkify: Using PySpark to Predict Customer Churn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Sparkify:使用PySpark预测客户流失</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/sparkify-using-pyspark-to-predict-customer-churn-10060cff9d71?source=collection_archive---------24-----------------------#2021-05-02">https://medium.com/geekculture/sparkify-using-pyspark-to-predict-customer-churn-10060cff9d71?source=collection_archive---------24-----------------------#2021-05-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/29dc923cd3f261934754da87d21eb8a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*PgFlLeRU3TNhIq7jU2u0PQ.jpeg"/></div></figure><h1 id="dfb7" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated"><strong class="ak">简介</strong></h1><p id="bbbd" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">在这个故事中，我将展示一项数据科学研究，该研究基于一家名为<em class="ki"> Sparkify </em>(就像<a class="ae kj" href="https://www.spotify.com/br/premium/?utm_source=br-pt_brand_contextual-desktop_text&amp;utm_medium=paidsearch&amp;utm_campaign=alwayson_latam_br_premiumbusiness_core_brand+contextual-desktop+text+exact+br-pt+google&amp;gclid=CjwKCAjw7J6EBhBDEiwA5UUM2lnJCIHXJXj2WF7vHlTtfuPrnFMmTZSCZzAz2lkktDmSA7vdZlXRGRoC9OQQAvD_BwE&amp;gclsrc=aw.ds" rel="noopener ugc nofollow" target="_blank">T5】Spotify</a>)的虚构企业，旨在通过模拟音乐流媒体现实世界数据的数据集来预测客户流失。当客户决定取消或降级某个计划的订购时，就会发生客户流失。这个项目是我个人选择的Udacity的Nanodegree <a class="ae kj" href="https://www.udacity.com/course/data-scientist-nanodegree--nd025" rel="noopener ugc nofollow" target="_blank">数据科学家</a>的顶点项目。</p><h1 id="fd97" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated"><strong class="ak">项目目标</strong></h1><p id="3c26" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">这个项目的主要目标是创建一个机器学习模型来预测在给定时间哪个客户将(可能)流失。如果机器学习模型能够高度可靠地预测哪个客户可能会流失，那么应用于数百万客户的相同模型应该能够通过联系这些客户并向他们提供折扣来为(虚构的)<em class="ki"> Sparkify </em>节省数百万美元，从而潜在地避免预测的流失发生。探索性数据分析、特征工程和机器学习建模将派上用场，在PySpark中找到解决这个问题的好方法。当在测试数据中验证机器学习模型时，所选择的度量将是<a class="ae kj" href="https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1" rel="noopener" target="_blank"> f1分数</a>，因为它是精确度和召回率的加权度量。</p><h1 id="a4ed" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated"><strong class="ak">了解数据</strong></h1><p id="903f" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">为了在<em class="ki"> Udacity </em>集群中运行该数据集，提供了一个由<em class="ki"> 286500 </em>行和<em class="ki"> 18 </em>列组成的迷你版本。数据集显示没有重复，但是有许多<em class="ki"> NaN的</em>在其中，它们被适当地处理，正如这里将显示的。完整代码可以在下面的GitHub资源库<a class="ae kj" href="https://github.com/vzeizer/Uda_Capstone_Sparkify" rel="noopener ugc nofollow" target="_blank"> <strong class="jm hj"> <em class="ki">这里</em> </strong> </a>下载。</p><p id="f91a" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">让我们首先打印Dataframe的模式(可用的小型数据集):</p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="5798" class="ky in hi ku b fi kz la l lb lc">|-- artist: string (nullable = true)<br/> |-- auth: string (nullable = true)<br/> |-- firstName: string (nullable = true)<br/> |-- gender: string (nullable = true)<br/> |-- itemInSession: long (nullable = true)<br/> |-- lastName: string (nullable = true)<br/> |-- length: double (nullable = true)<br/> |-- level: string (nullable = true)<br/> |-- location: string (nullable = true)<br/> |-- method: string (nullable = true)<br/> |-- page: string (nullable = true)<br/> |-- registration: long (nullable = true)<br/> |-- sessionId: long (nullable = true)<br/> |-- song: string (nullable = true)<br/> |-- status: long (nullable = true)<br/> |-- ts: long (nullable = true)<br/> |-- userAgent: string (nullable = true)<br/> |-- userId: string (nullable = true)</span></pre><p id="b0e5" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">数据框架的列是不言自明的，对本项目最重要的列将在下面详细研究。值得强调的是，由于Dataframe包含时间(<em class="ki">‘ts’</em>)作为其列之一，因此它由一个<a class="ae kj" href="https://towardsdatascience.com/time-series-analysis-in-python-an-introduction-70d5a5b1d52a" rel="noopener" target="_blank"> <em class="ki">时间序列</em> </a>组成。</p><p id="9312" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">在搜索数据集中的空值和<em class="ki">NaN的</em>时，我们发现</p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="3aa8" class="ky in hi ku b fi kz la l lb lc">+------+----+---------+------+-------------+--------+------+-----+--------+------+----+------------+---------+-----+------+---+---------+------+<br/>|artist|auth|firstName|gender|itemInSession|lastName|length|level|location|method|page|registration|sessionId| song|status| ts|userAgent|userId|<br/>+------+----+---------+------+-------------+--------+------+-----+--------+------+----+------------+---------+-----+------+---+---------+------+<br/>| 58392|   0|     8346|  8346|            0|    8346| 58392|    0|    8346|     0|   0|        8346|        0|58392|     0|  0|     8346|     0|<br/>+------+----+---------+------+-------------+--------+------+-----+--------+------+----+------------+---------+-----+------+---+---------+------+</span></pre><p id="7ad1" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">考虑到数据的整体大小，这是相当多的缺失数据。因此，删除丢失的数据不是一个好主意。因此，我们通过在分类列的<em class="ki"> NaN的</em>中插入<em class="ki"> "missing_val" </em>，并将相应列的平均值放在数字列中来解决这个问题。清理后的数据集不再有<em class="ki">南的</em>。</p><p id="d241" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">下一步是创建<strong class="jm hj">流失</strong>列，可以通过考虑页面列来计算，并考虑当我们有“提交降级”或“降级”或“取消确认”或“取消”时，流失已经发生。这导致了数据集中不平衡的列“变动”。</p><p id="dfb9" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">现在，我们准备进入我们故事的下一个阶段，即探索性数据分析，这将在<a class="ae kj" rel="noopener" href="/swlh/the-mastery-of-pandas-i-50156db42125"> Pandas </a>中完成！</p><h1 id="b6a1" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">探索性数据分析</h1><p id="901f" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">在下面显示的<em class="ki">探索性数据分析</em>中，我将调查有过不愉快经历的客户，从这些数据中获得见解。</p><ol class=""><li id="5963" class="ld le hi jm b jn kk jr kl jv lf jz lg kd lh kh li lj lk ll bi translated">流失<em class="ki">失衡</em>:</li></ol><p id="7462" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">图1显示了数据集中无顾客(零)和有顾客(一)的总数:</p><pre class="kp kq kr ks fd kt ku kv kw aw kx bi"><span id="3593" class="ky in hi ku b fi kz la l lb lc">0    284278<br/>1      2222</span></pre><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/3ec30db714f32d5e31c28724b9cd13c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*VAh3Zy-54lb2N_z1cBuYvw.jpeg"/></div><figcaption class="ln lo et er es lp lq bd b be z dx"><strong class="bd io">Figure 1.</strong> it is shown the imbalance of the churn values, zero's represent customers which did not churn and the one's represent customers who churned.</figcaption></figure><p id="b712" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">流失不平衡显示在上面的直方图中，可以看出这是一个非常不平衡的数据集。从某种程度上来说，这应该会使预测变得更加困难。</p><p id="9521" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">2.搅动<em class="ki">长度</em>:</p><p id="283c" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">下面的直方图(图2)显示了翻唱客户的歌曲长度。有趣的是，它们都有相同的长度！！这与客户的艺术家和歌曲在原始给定的迷你数据集中全部是南的事实有关。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/84b2881bc12f63deec78493a86a07445.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*RUw8An0FtTKbrWhF2ym0Og.jpeg"/></div><figcaption class="ln lo et er es lp lq bd b be z dx"><strong class="bd io">Figure 2.</strong> It shows a histogram of the length of the song for customers who churned.</figcaption></figure><p id="4639" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">3.按<em class="ki">性别</em>分类的客户流失:</p><p id="2adb" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">下面的图3显示了顾客的性别直方图。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/58ef279f4b8750deef530d344989d158.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*IQWN0FCSb3-5lKERdeZwzQ.jpeg"/></div><figcaption class="ln lo et er es lp lq bd b be z dx"><strong class="bd io">Figure 3.</strong> This figure shows a histogram for each gender for customers who churned.</figcaption></figure><p id="7465" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">可以看出，更多的女性比男性翻腾。Sparkify宣布对女性的<em class="ki">折扣</em>似乎是合适的，以减少这种明显的“女性流失”。</p><p id="745f" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">4.通过<em class="ki">位置</em>搅动:</p><p id="51cc" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">下图4显示了按<em class="ki">位置</em>划分的搅拌总数。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es lr"><img src="../Images/f12e809aa00a07d6db140fcf255516d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*InBC1RaDZjhFfjwI5h6kyg.jpeg"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx"><strong class="bd io">Figure 4.</strong> It shows the top 10 locations where churn took place.</figcaption></figure><p id="71dd" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">从该图可以看出，洛杉矶、纽约和波士顿的客户流失率最高。因此，为Sparkify的计划提供折扣是适当的，以便最大限度地减少这些地方的客户流失(最好是在图中所示的前10个地方应用此折扣)。</p><p id="ae27" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">5.用户代理:</p><p id="6dc4" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">下面的图5显示了用户代理的客户流失总数。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es lr"><img src="../Images/145ba47c26c145af69030a89d556351a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3IISS83UfI1ZHLDiTsKnIg.jpeg"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx"><strong class="bd io">Figure 5.</strong> This figure shows the total number of customers who churned by userAgent.</figcaption></figure><p id="b69b" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">如前所述，我们可以研究前10名用户代理，尽量减少客户流失。</p><p id="df85" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">6.搅动<em class="ki">项目插入</em>:</p><p id="c9ee" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">下图(图6)显示了<em class="ki"> itemInSession </em>的客户流失总数。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/39f06aec51da449f93deda82cd62f4b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*oVOQlw_OijMG3_1YO5ktoQ.jpeg"/></div><figcaption class="ln lo et er es lp lq bd b be z dx"><strong class="bd io">Figure 6.</strong> It shows the top 20 itemInSession from which customer churn takes place.</figcaption></figure><p id="bbcb" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">从上图中可以看出，与前面提到的功能相同的讨论也成立，为了尽量减少客户流失，应该对这20个最重要的项目进行研究。</p><p id="8f61" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated"><em class="ki"> 7。时态探索性数据分析</em></p><p id="29ea" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">现在，该数据集的时态分析开始了。</p><p id="7035" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">图7显示了给定时间段内每天的客户流失总数。</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/3d86c8e0ae2418d3624aeb7ade3b591f.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*sYFmDoG7u16fn3cAaz7V6w.jpeg"/></div><figcaption class="ln lo et er es lp lq bd b be z dx"><strong class="bd io">Figure 7.</strong> It shows total churns by day.</figcaption></figure><p id="92ac" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">这个时间序列很有趣，它有一个几乎明确定义的模式，总搅动次数几乎周期性地达到最大值和最小值。</p><h1 id="a449" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">特征工程</h1><p id="af22" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">在本次会议中，我将总结通过管道创建机器学习模型的特征工程流程。</p><p id="b25c" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">我们发现对预测无用的列(它们被删除):</p><p id="5006" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated"><em class="ki"> to_drop_cols=['艺术家'，'验证'，'名字'，'姓氏'，'页面'，'注册'，'会话Id '，'歌曲'，'小时'] </em></p><p id="7002" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">因为<em class="ki">【艺术家】</em>【歌曲】<em class="ki">【名字】</em><em class="ki">【姓氏】【注册】【会话Id】【小时】</em>(定义为时间的函数)不携带关于顾客的重要信息。</p><p id="6a53" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">列<em class="ki"> ['gender '，' level '，' method'] </em>是通过使用StringIndexer和OneHotEncoder进行功能设计的，而列<em class="ki"> ['location '，' userAgent'] </em>只是通过StringIndexer进行功能设计的，因为它们包含了太多的分类值。从这些工程特征中产生了一个矢量汇编器。</p><h1 id="482c" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">机器学习模型</h1><p id="44b5" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">为了避免这个<a class="ae kj" href="https://towardsdatascience.com/how-data-leakage-affects-machine-learning-models-in-practice-f448be6080d0" rel="noopener" target="_blank">时间</a> <a class="ae kj" href="https://mlopshowto.com/data-leakage-part-i-think-you-have-a-great-machine-learning-model-think-again-ad44921fbf34" rel="noopener ugc nofollow" target="_blank">系列</a>的<em class="ki">数据泄露</em>，首先将微型数据集按时间顺序排序，分割成<strong class="jm hj">训练</strong> (80%)和<strong class="jm hj">测试</strong>(剩余20%)数据帧。测试了几个机器学习模型以及参数调整，以便找到最合适的模型。</p><p id="6892" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">我们已经在所有的机器学习模型中设置了合理数量的交叉验证折叠，等于4。如前所述，我们的最大化指标(越接近1.0越好)被选为f1分数。对于一些模型，参数网格被详尽地评估以改进结果，而对于一些更方便的模型，我们直接且容易地得到好的模型，而不需要详尽的网格搜索，但是计算成本更高。</p><p id="9da1" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">总之，我们测试了以下模型:</p><ol class=""><li id="6047" class="ld le hi jm b jn kk jr kl jv lf jz lg kd lh kh li lj lk ll bi translated"><em class="ki"> Logistic回归</em> (LR):正则化参数等于0.05和0.15，弹性网参数等于0.25和0.75，最大迭代次数等于5和10；最佳参数为:regParam: 0.05，elasticNetParam: 0.25，maxIter:5；</li><li id="0a44" class="ld le hi jm b jn lw jr lx jv ly jz lz kd ma kh li lj lk ll bi translated"><em class="ki">线性回归</em> (LReg):正则化参数从0.0到0.8，弹性网参数从0.0到0.75；最佳参数为:regParam: 0.0，elasticNetParam:0.0；</li><li id="3281" class="ld le hi jm b jn lw jr lx jv ly jz lz kd ma kh li lj lk ll bi translated"><em class="ki">随机森林</em> (RF):树木数量从50到100，最大深度从10到20；最佳参数为:numTrees: 50，max depth:15；</li><li id="1244" class="ld le hi jm b jn lw jr lx jv ly jz lz kd ma kh li lj lk ll bi translated"><a class="ae kj" href="https://spark.apache.org/docs/latest/ml-classification-regression.html#one-vs-rest-classifier-aka-one-vs-all" rel="noopener ugc nofollow" target="_blank"> <em class="ki"> OneVsRest分类器</em> (OVR) </a>是用于执行多类分类的机器学习简化的示例，给出了可以有效执行二分类的基础分类器:正则化参数从0.05变化到0.15；值为0.25和0.75的弹性网络参数；最大迭代次数等于5或10；</li><li id="c85f" class="ld le hi jm b jn lw jr lx jv ly jz lz kd ma kh li lj lk ll bi translated"><em class="ki">支持向量机</em> (SVM):用从0.05到0.4变化的正则化参数运行；最佳参数regParam等于0.1；</li><li id="2c72" class="ld le hi jm b jn lw jr lx jv ly jz lz kd ma kh li lj lk ll bi translated"><em class="ki">梯度提升树分类器</em> (GBT):使用默认参数运行。当然，最好的参数是默认的。</li></ol><p id="1f38" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">下表总结了我们对每个型号测试数据的最佳发现:</p><p id="8285" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated"><strong class="jm hj">f1车型-得分</strong></p><p id="1c26" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">0.98829</p><p id="a5be" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">LReg 0.00000</p><p id="6c6d" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">射频0.98829</p><p id="3007" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">OVR  0.98829</p><p id="aafa" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">SVM 0.98829</p><p id="b791" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated"><em class="ki"> GBT </em> 0.98799</p><p id="6a8e" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">随机森林被选为最适合这个问题的机器学习模型。可以选择在测试数据上具有类似f1分数的其他模型，但是我们选择了随机森林，因为它在决策树上的特性和相对较快的训练速度。图8显示了从该分类器中获得的前10个最重要的特征:</p><figure class="kp kq kr ks fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es lr"><img src="../Images/2af455ce03ab6dc9fb6372efd1886ca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Py5HCpE8HLMC9K16FaGBfw.jpeg"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx"><strong class="bd io">Figure 8.</strong> It shows the top 10 feature importances for the random forest classifier.</figcaption></figure><p id="cb6a" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">最重要的特性是指列有'<em class="ki"> userAgent </em>'、'<em class="ki"> itemInSession </em>'和<em class="ki"> 'ts' </em>(时间)。</p><h1 id="e83b" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">模型评估和验证</h1><p id="1969" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">最佳模型，随机森林，在训练数据(0.98796)和测试数据(0.98829)上呈现出相当好的结果，最佳树数量等于50，最大深度等于15。更多的树或更大的最大深度不会使算法执行得更好。这些值对于随机森林分类器来说非常好，并且训练相对更快。进行了K=2或K=3的交叉验证，发现了类似的结果。此外，如前所述，该模型的前3个特征对于负责客户流失非常有意义。此外，正如将在下面的<em class="ki">调整</em>部分中讨论的，随机森林适用于大型数据集。</p><h1 id="c354" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">正当理由；辩解</h1><p id="e74a" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">随机森林是我目前的选择，作为这个问题的最佳机器学习模型，因为它容易理解，因为它的本质是决策树和相对较快的训练速度。尽管比决策树更复杂，随机森林在测试数据中不容易出现<a class="ae kj" href="https://www.datacamp.com/community/tutorials/random-forests-classifier-python#advantages" rel="noopener ugc nofollow" target="_blank">过度拟合</a>。此外，Random Forest对于海量数据的强大功能和<a class="ae kj" href="https://link.springer.com/chapter/10.1007/978-3-642-30217-6_12" rel="noopener ugc nofollow" target="_blank">可伸缩性</a>使其适合在集群中运行，如<a class="ae kj" href="https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&amp;all-free-tier.sort-order=asc&amp;awsf.Free%20Tier%20Types=*all&amp;awsf.Free%20Tier%20Categories=categories%23compute&amp;trk=ps_a134p000006gXvEAAU&amp;trkCampaign=acq_paid_search_brand&amp;sc_channel=PS&amp;sc_campaign=acquisition_BR&amp;sc_publisher=Google&amp;sc_category=Cloud%20Computing&amp;sc_country=BR&amp;sc_geo=LATAM&amp;sc_outcome=acq&amp;sc_detail=amazon%20cloud&amp;sc_content=Cloud%20Hosting_e&amp;sc_matchtype=e&amp;sc_segment=490489331981&amp;sc_medium=ACQ-P|PS-GO|Brand|Desktop|SU|Cloud%20Computing|Solution|BR|EN|Text&amp;s_kwcid=AL!4422!3!490489331981!e!!g!!amazon%20cloud&amp;ef_id=CjwKCAjwm7mEBhBsEiwA_of-TPX4tzrRPT8UKvcMYMHMrPDp-h5Mnave-vI5_BuDa3NdRxyYAhKHChoCnR0QAvD_BwE:G:s&amp;s_kwcid=AL!4422!3!490489331981!e!!g!!amazon%20cloud" rel="noopener ugc nofollow" target="_blank"><em class="ki">Amazon Web Services</em></a>或<a class="ae kj" href="https://cloud.ibm.com/login" rel="noopener ugc nofollow" target="_blank"> <em class="ki"> IBM Cloud </em> </a>。</p><h1 id="9213" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">讨论</h1><p id="10c5" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">我们已经成功地在测试数据上训练了几个模型，达到了非常好的f1分数。这可能是由于数据较小。运行完整的12 GB数据集应该是一种更好的方法，可以获得f1分数的真实值。然而，我们的模型没有过度拟合，从这些分析中可以得出许多有趣的结论，正如这里所示。线性回归，最简单的模型，在训练和预测中惨败，其他模型也达到了类似的结果。</p><h1 id="5313" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">结论</h1><p id="642c" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">总之，我们通过PySpark和Pandas详细研究了一个数据集，它模仿了一个名为Sparkify的真实音乐流媒体服务。</p><p id="b89b" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">我们的<strong class="jm hj"> EDA结果</strong>已经指出，一小部分客户流失，而且女性比男性流失更多。调查了位置、项目插入、用户代理，通过正确处理这些特征，可以最大限度地减少客户流失。</p><p id="3707" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated"><strong class="jm hj">当前机器学习模型结果</strong>已经表明，人们可以认为随机森林是最适合这个问题的。这种模式在测试数据上有很高的f1分数，因此当应用于数百万用户时，它可能会为Sparkify节省数百万美元的资金，从而尽量减少客户流失。该模型最具预测性的列是'<em class="ki"> userAgent </em>'、<em class="ki"> itemInSession </em>'和<em class="ki"> 'ts' </em> (time)。这非常有趣，因为前两个特征在<em class="ki">探索性数据分析</em>部分进行了探索，它们在客户流失中扮演着重要角色。因此，开发这些功能非常重要，值得(虚拟)企业<em class="ki"> Sparkify </em>的强烈关注。</p><h1 id="13fa" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">进一步的改进</h1><p id="b71c" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">作为对<em class="ki">探索性数据分析的进一步改进，</em>可以对<em class="ki">时间序列进行更深入的数据分析。</em>例如，我们致力于按分钟分析客户流失总数，就像这里展示的几天一样。</p><p id="51aa" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated"><em class="ki">特征工程</em>可以以不同的方式完成(基于Kaggle的<a class="ae kj" href="https://www.kaggle.com/dhirajrai87/feature-engineering-with-pyspark/notebook" rel="noopener ugc nofollow" target="_blank">笔记本</a>):</p><ol class=""><li id="a861" class="ld le hi jm b jn kk jr kl jv lf jz lg kd lh kh li lj lk ll bi translated">使用<strong class="jm hj">缩放和归一化</strong> : StandardScaler和MinMaxScaler，以及许多其他工具。</li><li id="ac9c" class="ld le hi jm b jn lw jr lx jv ly jz lz kd ma kh li lj lk ll bi translated"><strong class="jm hj">分桶</strong>用于将连续变量转换为分类变量。之后，我们可以通过StringIndexer和OneHotEncoder来解决这个问题。</li><li id="b8ad" class="ld le hi jm b jn lw jr lx jv ly jz lz kd ma kh li lj lk ll bi translated">使用<strong class="jm hj"> PCA </strong>使用特征的维度。</li><li id="2a0f" class="ld le hi jm b jn lw jr lx jv ly jz lz kd ma kh li lj lk ll bi translated">而且，<strong class="jm hj">特征选择</strong>由卡方选择器完成。</li><li id="d6d5" class="ld le hi jm b jn lw jr lx jv ly jz lz kd ma kh li lj lk ll bi translated">测试模型像<a class="ae kj" href="https://spark.apache.org/docs/latest/ml-classification-regression.html#multilayer-perceptron-classifier" rel="noopener ugc nofollow" target="_blank"> <strong class="jm hj"> <em class="ki">多层感知器</em> </strong> </a> <strong class="jm hj"> <em class="ki">，xgboost和catboost </em> </strong>分类器也可以测试。然而，为了训练xgboost和catboost，你必须使用<a class="ae kj" href="https://databricks.com/blog/2020/11/16/how-to-train-xgboost-with-spark.html" rel="noopener ugc nofollow" target="_blank"> <em class="ki"> PySpark包装器</em> </a>。</li><li id="7fc8" class="ld le hi jm b jn lw jr lx jv ly jz lz kd ma kh li lj lk ll bi translated"><a class="ae kj" href="https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python" rel="noopener ugc nofollow" target="_blank"> <em class="ki">堆叠</em> </a>:一旦对几个模型进行监督学习，可以使用堆叠，以便从其他预测中获得更好的模型。堆叠使用几个基本分类器的预测作为第一级(基础)，然后在第二级使用另一个模型来预测早期第一级预测的输出。</li></ol><p id="8995" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">我希望这是对你有深刻见解的阅读:)</p><p id="4a17" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">随时加我在<a class="ae kj" href="https://www.linkedin.com/in/vagner-zeizer-carvalho-paes-31494b43/" rel="noopener ugc nofollow" target="_blank"><strong class="jm hj"><em class="ki">LinkedIn</em></strong></a>。</p><p id="17cb" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">欢迎建设性的批评。</p><p id="a975" class="pw-post-body-paragraph jk jl hi jm b jn kk jp jq jr kl jt ju jv km jx jy jz kn kb kc kd ko kf kg kh hb bi translated">如果你喜欢它，请给它一些掌声。</p></div></div>    
</body>
</html>