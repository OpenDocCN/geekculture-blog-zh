<html>
<head>
<title>A step by step demo on Kubernetes cluster creation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kubernetes集群创建的逐步演示</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/a-step-by-step-demo-on-kubernetes-cluster-creation-f183823c0411?source=collection_archive---------6-----------------------#2021-08-03">https://medium.com/geekculture/a-step-by-step-demo-on-kubernetes-cluster-creation-f183823c0411?source=collection_archive---------6-----------------------#2021-08-03</a></blockquote><div><div class="dt gx gy gz ha hb"/><div class="hc hd he hf hg"><div class=""/><blockquote class="ig ih ii"><p id="b07d" class="ij ik il im b in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh hc bi translated">“不要担心我们无法控制的事情，让我们把注意力转移到我们能够创造的事情上。”</p></blockquote><figure class="jj jk jl jm fe jn es et paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="es et ji"><img src="../Images/7634064923e8d9158c45ae7693bc6d66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*38g6fLfPzpwOGgPhAGBCng.jpeg"/></div></div><figcaption class="ju jv eu es et jw jx bd b be z dy">Photo Credit: <a class="ae jy" href="https://unsplash.com/@anniespratt" rel="noopener ugc nofollow" target="_blank">Annie Spratt</a> | <a class="ae jy" href="https://unsplash.com/photos/QckxruozjRg" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/QckxruozjRg</a></figcaption></figure><h1 id="57ea" class="jz ka hj bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">介绍</h1><p id="7dbe" class="pw-post-body-paragraph ij ik hj im b in kx ip iq ir ky it iu kz la ix iy lb lc jb jc ld le jf jg jh hc bi translated">在这个演示中，我将分享我使用kubeadm工具创建kubernetes集群的经验。将使用lxc机器容器来设置集群。将启动一个主节点和3个工作节点，形成一个kubernetes集群。让我们一步一步来，然后自动化整个过程。</p><h2 id="7735" class="lf ka hj bd kb lg lh li kf lj lk ll kj kz lm ln kn lb lo lp kr ld lq lr kv ls bi translated">我的实验室设置</h2><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="146e" class="lf ka hj lu b fj ly lz l ma mb">user1@k8s_cluster_demo_lab:~/lab/asish$uname -a<br/>Linux lab 5.4.0-77-generic #86~18.04.1-Ubuntu SMP Fri Jun 18 01:23:22 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux</span><span id="43fe" class="lf ka hj lu b fj mc lz l ma mb">user1@k8s_cluster_demo_lab:~/lab/asish$lsb_release -dr<br/>Description:    Ubuntu 18.04.5 LTS<br/>Release:        18.04</span></pre><h2 id="331a" class="lf ka hj bd kb lg lh li kf lj lk ll kj kz lm ln kn lb lo lp kr ld lq lr kv ls bi translated">关于LXC</h2><p id="128f" class="pw-post-body-paragraph ij ik hj im b in kx ip iq ir ky it iu kz la ix iy lb lc jb jc ld le jf jg jh hc bi translated">LinuX容器(LXC)通常被认为是介于chroot和完全成熟的虚拟机之间的东西。它还可以在虚拟机和容器运行时托管的应用程序容器之间进行比较。要深入了解与常规应用程序容器的比较，请参考本文—<a class="ae jy" href="https://asishmm.medium.com/lxc-vs-docker-container-5699db209391" rel="noopener">https://asishmm . medium . com/lxc-vs-docker-container-5699 db 209391</a></p><p id="61b6" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">实验室中使用的主机是采用x86_64架构的Ubuntu服务器(18.04)。</p><p id="2644" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">确认您的机器上安装了lxc。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="b6bf" class="lf ka hj lu b fj ly lz l ma mb">user1@k8s_cluster_demo_lab:~/lab/asish$dpkg -l | grep lxd<br/>ii  lxd                                        3.0.3-0ubuntu1~18.04.1                           amd64        Container hypervisor based on LXC - daemon<br/>ii  lxd-client                                 3.0.3-0ubuntu1~18.04.1                           amd64        Container hypervisor based on LXC - client</span></pre><p id="e719" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">如果没有安装lxc，按照<a class="ae jy" href="https://linuxcontainers.org/lxc/getting-started/" rel="noopener ugc nofollow" target="_blank"> LXC入门</a></p><h1 id="d047" class="jz ka hj bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">高层次的步骤</h1><p id="45a5" class="pw-post-body-paragraph ij ik hj im b in kx ip iq ir ky it iu kz la ix iy lb lc jb jc ld le jf jg jh hc bi translated">下面是使用lxc设置K8s集群的步骤。</p><ol class=""><li id="191e" class="md me hj im b in io ir is kz mf lb mg ld mh jh mi mj mk ml bi translated">准备好主节点和工作节点的lxc设置。</li><li id="fb29" class="md me hj im b in mm ir mn kz mo lb mp ld mq jh mi mj mk ml bi translated">使用docker安装容器运行时。</li><li id="20f2" class="md me hj im b in mm ir mn kz mo lb mp ld mq jh mi mj mk ml bi translated">安装kubeadm并初始化主服务器。</li><li id="37ba" class="md me hj im b in mm ir mn kz mo lb mp ld mq jh mi mj mk ml bi translated">应安装Pod网络解决方案。</li><li id="0886" class="md me hj im b in mm ir mn kz mo lb mp ld mq jh mi mj mk ml bi translated">运行join命令，让工作节点加入主节点。</li></ol><h1 id="f315" class="jz ka hj bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">第一步</h1><p id="a71c" class="pw-post-body-paragraph ij ik hj im b in kx ip iq ir ky it iu kz la ix iy lb lc jb jc ld le jf jg jh hc bi translated">启动lxd容器并初始化它。将用户添加到lxd组，以便在没有sudo的情况下执行lxc操作。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="3fa5" class="lf ka hj lu b fj ly lz l ma mb">user1@k8s_cluster_demo_lab:~$<strong class="lu hk">sudo systemctl start lxd</strong><br/>[sudo] password for user1:<br/>user1@k8s_cluster_demo_lab:~$<strong class="lu hk">sudo usermod -a -G lxd user1</strong><br/>user1@k8s_cluster_demo_lab:~$<strong class="lu hk">getent group lxd</strong><br/>lxd:x:130:user1<br/>user1@k8s_cluster_demo_lab:~$<strong class="lu hk">lxc version</strong><br/>Client version: 3.0.3<br/>Server version: 3.0.3</span></pre><p id="ae7b" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">初始化LXD。选择默认选项。对于存储后端，我选择“dir ”,而不是默认的“bitrfs”</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="e2c2" class="lf ka hj lu b fj ly lz l ma mb">user1@k8s_cluster_demo_lab:~$<strong class="lu hk">lxd init</strong><br/>Would you like to use LXD clustering? (yes/no) [default=no]:<br/>Do you want to configure a new storage pool? (yes/no) [default=yes]:<br/>Name of the new storage pool [default=default]:<br/>Name of the storage backend to use (btrfs, dir, lvm) [default=btrfs]: dir<br/>Would you like to connect to a MAAS server? (yes/no) [default=no]:<br/>Would you like to create a new local network bridge? (yes/no) [default=yes]:<br/>What should the new bridge be called? [default=lxdbr0]:<br/>What IPv4 address should be used? (CIDR subnet notation, “auto” or “none”) [default=auto]:<br/>What IPv6 address should be used? (CIDR subnet notation, “auto” or “none”) [default=auto]:<br/>Would you like LXD to be available over the network? (yes/no) [default=no]:<br/>Would you like stale cached images to be updated automatically? (yes/no) [default=yes]<br/>Would you like a YAML "lxd init" preseed to be printed? (yes/no) [default=no]:</span></pre><p id="2cc0" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">Lxd带有默认配置文件。概要文件是创建实例时使用的特定于实例的配置。让我们为我们为K8s集群创建的机器容器创建一个定制概要文件。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="4683" class="lf ka hj lu b fj ly lz l ma mb">user1@k8s_cluster_demo_lab:~$<strong class="lu hk">lxc profile copy default k8s</strong><br/>user1@k8s_cluster_demo_lab:~$<strong class="lu hk">lxc profile ls</strong><br/>+---------+---------+<br/>|  NAME   | USED BY |<br/>+---------+---------+<br/>| default | 0       |<br/>+---------+---------+<br/>| k8s     | 0       |<br/>+---------+---------+</span></pre><p id="a61d" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">我将使用下面的自定义配置文件，并将其应用到k8s配置文件。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="dcac" class="lf ka hj lu b fj ly lz l ma mb">user1@k8s_cluster_demo_lab:~/lab/asish$<strong class="lu hk">cat k8s-profile-config</strong><br/>config:<br/>  limits.cpu: "2"<br/>  limits.memory: 2GB<br/>  limits.memory.swap: "false"<br/>  linux.kernel_modules: ip_tables,ip6_tables,nf_nat,overlay,br_netfilter<br/>  raw.lxc: "lxc.apparmor.profile=unconfined\nlxc.cap.drop= \nlxc.cgroup.devices.allow=a\nlxc.mount.auto=proc:rw<br/>    sys:rw"<br/><strong class="lu hk">  security.nesting: "true"<br/>  security.privileged: "true"</strong><br/>description: Kubernetes LXD profile<br/>devices:<br/>  eth0:<br/>    name: eth0<br/>    nictype: bridged<br/>    parent: lxdbr0<br/>    type: nic<br/>  root:<br/>    path: /<br/>    pool: default<br/>    type: disk<br/>name: k8s<br/>used_by: []</span></pre><p id="40cb" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">要考虑的最重要的部分是“安全.嵌套”和“安全.提供”。应该为机器容器启用这两个选项，以便在其中运行容器。</p><p id="b635" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">我觉得用vim作为默认编辑器是合适的，编辑k8s配置文件如下。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="0fbe" class="lf ka hj lu b fj ly lz l ma mb">user1@k8s_cluster_demo_lab:~/lab/asish$<strong class="lu hk">export EDITOR=vim</strong><br/>user1@k8s_cluster_demo_lab:~/lab/asish$<strong class="lu hk">lxc profile edit k8s</strong></span></pre><p id="260e" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">将概要文件的内容粘贴到编辑视图中。</p><p id="fb43" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">让我们在这个演示中使用Ubuntu作为主节点和工作节点的lxc机器映像。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="ac6a" class="lf ka hj lu b fj ly lz l ma mb">user1@k8s_cluster_demo_lab:~/lab/asish$<strong class="lu hk">lxc launch </strong>images:ubuntu/18.04 kmaster1 --profile k8s<br/>Creating kmaster1<br/>Starting kmaster1</span></pre><p id="9a3f" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">我们可以类似地创建3个工作节点。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="f29b" class="lf ka hj lu b fj ly lz l ma mb">user1@k8s_cluster_demo_lab:~/lab/asish$<strong class="lu hk">for i in {1..3} ; do lxc launch images:ubuntu/18.04 kworker${i} --profile k8s ; done</strong><br/>Creating kworker1<br/>Starting kworker1<br/>Creating kworker2<br/>Starting kworker2<br/>Creating kworker3<br/>Starting kworker3</span></pre><p id="33c1" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">确保lxc容器已打开。</p><figure class="jj jk jl jm fe jn es et paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><div class="es et mr"><img src="../Images/5c8ed93987923ac38b3d4f8601fa91ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qKJbKtxEAMocHOYmpPCJ0g.png"/></div></div></figure><p id="ae5e" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">现在我们实验室准备安装k8s集群，有一个master—“kmaster 1”和3个workers。</p><h1 id="7ccd" class="jz ka hj bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">第二步</h1><p id="a1b6" class="pw-post-body-paragraph ij ik hj im b in kx ip iq ir ky it iu kz la ix iy lb lc jb jc ld le jf jg jh hc bi translated">在主服务器上安装caontainer运行时。让我们使用docker作为容器运行时。</p><p id="1763" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">https://docs.docker.com/engine/install/ubuntu/<a class="ae jy" href="https://docs.docker.com/engine/install/ubuntu/" rel="noopener ugc nofollow" target="_blank"/></p><p id="76a1" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">让我们在主容器中登录。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="8eeb" class="lf ka hj lu b fj ly lz l ma mb">user1@k8s_cluster_demo_lab:~/lab/asish$<strong class="lu hk">lxc exec kmaster1 bash</strong><br/>root@kmaster1:~#</span></pre><p id="55e4" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">[注意:我们将在kmaster1容器中执行以下步骤。]</p><p id="b529" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">如果安装了旧版本的docker，请将其删除。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="8b5b" class="lf ka hj lu b fj ly lz l ma mb"><strong class="lu hk">sudo apt-get remove docker docker-engine docker.io containerd runc</strong></span></pre><p id="b4b0" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">安装基本软件包</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="ddbe" class="lf ka hj lu b fj ly lz l ma mb"><strong class="lu hk">apt-get update<br/>sudo apt-get install \<br/>     apt-transport-https \<br/>     ca-certificates \<br/>     curl \<br/>     gnupg \<br/>     lsb-release -y</strong></span></pre><p id="2c52" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">下载docker gpg密钥并添加docker repo</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="b4eb" class="lf ka hj lu b fj ly lz l ma mb">root@kmaster1:~# <strong class="lu hk">curl -fsSL </strong><a class="ae jy" href="https://download.docker.com/linux/ubuntu/gpg" rel="noopener ugc nofollow" target="_blank"><strong class="lu hk">https://download.docker.com/linux/ubuntu/gpg</strong></a><strong class="lu hk"> | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg  &gt;/dev/null</strong><br/>root@kmaster1:~#<br/>root@kmaster1:~# <strong class="lu hk">echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] </strong><a class="ae jy" href="https://download.docker.com/linux/ubuntu" rel="noopener ugc nofollow" target="_blank"><strong class="lu hk">https://download.docker.com/linux/ubuntu</strong></a><strong class="lu hk"> \<br/>   $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null</strong></span></pre><p id="b48b" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">现在安装docker-ce</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="5f0d" class="lf ka hj lu b fj ly lz l ma mb"><strong class="lu hk">sudo apt-get update<br/>sudo apt-get install docker-ce docker-ce-cli -y</strong></span></pre><p id="ef09" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">配置Docker守护进程使用systemd来管理容器的cgroups。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="e748" class="lf ka hj lu b fj ly lz l ma mb">root@kmaster1:~# <strong class="lu hk">sudo mkdir /etc/docker</strong></span><span id="6033" class="lf ka hj lu b fj mc lz l ma mb">root@kmaster1:~# <strong class="lu hk">cat &lt;&lt;EOF | sudo tee /etc/docker/daemon.json<br/>{<br/>  "exec-opts": ["native.cgroupdriver=systemd"],<br/>  "log-driver": "json-file",<br/>  "log-opts": {<br/>    "max-size": "100m"<br/>  },<br/>  "storage-driver": "overlay2"<br/>}<br/>EOF</strong></span></pre><p id="57a7" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">重启docker并在重启时启用；</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="f890" class="lf ka hj lu b fj ly lz l ma mb">root@kmaster1:~# <strong class="lu hk">systemctl enable docker</strong></span><span id="4013" class="lf ka hj lu b fj mc lz l ma mb">root@kmaster1:~# <strong class="lu hk">systemctl daemon-reload</strong></span><span id="2d80" class="lf ka hj lu b fj mc lz l ma mb">root@kmaster1:~# <strong class="lu hk">systemctl restart docker</strong></span></pre><h1 id="de1d" class="jz ka hj bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">第三步</h1><p id="8ddc" class="pw-post-body-paragraph ij ik hj im b in kx ip iq ir ky it iu kz la ix iy lb lc jb jc ld le jf jg jh hc bi translated">让我们安装kubeadm、kubectl和kubelet。检查br_netfilter模块是否已加载。如果没有加载该模块，请使用modeprobe显式加载。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="9346" class="lf ka hj lu b fj ly lz l ma mb">root@kmaster1:~# <strong class="lu hk">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf<br/>br_netfilter<br/>EOF</strong></span></pre><p id="fc58" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">要使iptables正确地看到桥接的流量，请确保在sysctl配置中将net.bridge-nf-call-iptables设置为1</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="aef9" class="lf ka hj lu b fj ly lz l ma mb">root@kmaster1:~# <strong class="lu hk">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf<br/>net.bridge.bridge-nf-call-ip6tables = 1<br/>net.bridge.bridge-nf-call-iptables = 1<br/>EOF</strong></span></pre><p id="8c2d" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">验证一下；</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="156f" class="lf ka hj lu b fj ly lz l ma mb">root@kmaster1:~# <strong class="lu hk">sysctl --system</strong><br/>* Applying /etc/sysctl.d/10-console-messages.conf ...<br/>kernel.printk = 4 4 1 7<br/>* Applying /etc/sysctl.d/10-ipv6-privacy.conf ...<br/>net.ipv6.conf.all.use_tempaddr = 2<br/>net.ipv6.conf.default.use_tempaddr = 2<br/>* Applying /etc/sysctl.d/10-kernel-hardening.conf ...<br/>kernel.kptr_restrict = 1<br/>* Applying /etc/sysctl.d/10-link-restrictions.conf ...<br/>fs.protected_hardlinks = 1<br/>fs.protected_symlinks = 1<br/>* Applying /etc/sysctl.d/10-magic-sysrq.conf ...<br/>kernel.sysrq = 176<br/>* Applying /etc/sysctl.d/10-network-security.conf ...<br/>net.ipv4.conf.default.rp_filter = 1<br/>net.ipv4.conf.all.rp_filter = 1<br/>net.ipv4.tcp_syncookies = 1<br/>* Applying /etc/sysctl.d/10-ptrace.conf ...<br/>kernel.yama.ptrace_scope = 1<br/>* Applying /etc/sysctl.d/10-zeropage.conf ...<br/>vm.mmap_min_addr = 65536<br/>* Applying /usr/lib/sysctl.d/50-default.conf ...<br/>net.ipv4.conf.all.promote_secondaries = 1<br/>* Applying /etc/sysctl.d/99-sysctl.conf ...<br/>* Applying /etc/sysctl.d/k8s.conf ...<br/><strong class="lu hk">net.bridge.bridge-nf-call-ip6tables = 1<br/>net.bridge.bridge-nf-call-iptables = 1</strong><br/>* Applying /etc/sysctl.conf ...</span></pre><p id="b019" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">现在是时候安装kubeadm、kubelet和kubectl了。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="0e1f" class="lf ka hj lu b fj ly lz l ma mb"><strong class="lu hk">sudo apt-get update</strong></span><span id="db97" class="lf ka hj lu b fj mc lz l ma mb"><strong class="lu hk">sudo apt-get install -y apt-transport-https ca-certificates curl</strong></span><span id="3a85" class="lf ka hj lu b fj mc lz l ma mb"><strong class="lu hk">sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg </strong><a class="ae jy" href="https://packages.cloud.google.com/apt/doc/apt-key.gpg" rel="noopener ugc nofollow" target="_blank"><strong class="lu hk">https://packages.cloud.google.com/apt/doc/apt-key.gpg</strong></a><strong class="lu hk"> &gt; /dev/null</strong></span><span id="c8be" class="lf ka hj lu b fj mc lz l ma mb"><strong class="lu hk">echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] </strong><a class="ae jy" href="https://apt.kubernetes.io/" rel="noopener ugc nofollow" target="_blank"><strong class="lu hk">https://apt.kubernetes.io/</strong></a><strong class="lu hk"> kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list</strong></span><span id="b11f" class="lf ka hj lu b fj mc lz l ma mb"><strong class="lu hk">sudo apt-get update</strong></span><span id="6c71" class="lf ka hj lu b fj mc lz l ma mb"><strong class="lu hk">sudo apt-get install -y kubelet kubeadm kubectl</strong></span></pre><p id="fe06" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">完成上述步骤后，添加一个kubelet extra标志来禁用交换失败，然后重新启动kubelet</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="293a" class="lf ka hj lu b fj ly lz l ma mb"><strong class="lu hk">echo 'KUBELET_EXTRA_ARGS="--fail-swap-on=false"' &gt; /etc/default/kubelet</strong></span><span id="ee7e" class="lf ka hj lu b fj mc lz l ma mb"><strong class="lu hk">systemctl restart kubelet</strong></span></pre><p id="dd27" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">现在，有一个我们必须做的小黑客在LXC启用K8s v1.15+。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="58d1" class="lf ka hj lu b fj ly lz l ma mb"><strong class="lu hk">apt install -qq -y net-tools<br/>mknod /dev/kmsg c 1 11<br/>echo 'mknod /dev/kmsg c 1 11' &gt;&gt; /etc/rc.local<br/>chmod +x /etc/rc.local</strong></span></pre><p id="9645" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">允许kubeadm提取所需的图像</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="f5dd" class="lf ka hj lu b fj ly lz l ma mb"><strong class="lu hk">kubeadm config images pull &gt;/dev/null 2&gt;&amp;1</strong></span></pre><p id="37a1" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">使用kubeadm初始化集群</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="3ae0" class="lf ka hj lu b fj ly lz l ma mb"><strong class="lu hk">kubeadm init --pod-network-cidr=10.244.0.0/16 --ignore-preflight-errors=all</strong></span></pre><p id="fe09" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">完成输出。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="bd98" class="lf ka hj lu b fj ly lz l ma mb">root@kmaster1:~# <strong class="lu hk">kubeadm init --pod-network-cidr=10.244.0.0/16 --ignore-preflight-errors=all</strong><br/>[init] Using Kubernetes version: v1.21.3<br/>[preflight] Running pre-flight checks<br/>        [WARNING Swap]: running with swap on is not supported. Please disable swap<br/>[preflight] The system verification failed. Printing the output from the verification:<br/>KERNEL_VERSION: 5.4.0-80-generic<br/>DOCKER_VERSION: 20.10.7<br/>DOCKER_GRAPH_DRIVER: overlay2<br/>OS: Linux<br/>CGROUPS_CPU: enabled<br/>CGROUPS_CPUACCT: enabled<br/>CGROUPS_CPUSET: enabled<br/>CGROUPS_DEVICES: enabled<br/>CGROUPS_FREEZER: enabled<br/>CGROUPS_MEMORY: enabled<br/>CGROUPS_PIDS: enabled<br/>CGROUPS_HUGETLB: enabled<br/>        [WARNING SystemVerification]: failed to parse kernel config: unable to load kernel module: "configs", output: "modprobe: FATAL: Module configs not found in directory /lib/modules/5.4.0-80-generic\n", err: exit status 1<br/>[preflight] Pulling images required for setting up a Kubernetes cluster<br/>[preflight] This might take a minute or two, depending on the speed of your internet connection<br/>[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'<br/>[certs] Using certificateDir folder "/etc/kubernetes/pki"<br/>[certs] Generating "ca" certificate and key<br/>[certs] Generating "apiserver" certificate and key<br/>[certs] apiserver serving cert is signed for DNS names [kmaster1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.38.156.125]<br/>[certs] Generating "apiserver-kubelet-client" certificate and key<br/>[certs] Generating "front-proxy-ca" certificate and key<br/>[certs] Generating "front-proxy-client" certificate and key<br/>[certs] Generating "etcd/ca" certificate and key<br/>[certs] Generating "etcd/server" certificate and key<br/>[certs] etcd/server serving cert is signed for DNS names [kmaster1 localhost] and IPs [10.38.156.125 127.0.0.1 ::1]<br/>[certs] Generating "etcd/peer" certificate and key<br/>[certs] etcd/peer serving cert is signed for DNS names [kmaster1 localhost] and IPs [10.38.156.125 127.0.0.1 ::1]<br/>[certs] Generating "etcd/healthcheck-client" certificate and key<br/>[certs] Generating "apiserver-etcd-client" certificate and key<br/>[certs] Generating "sa" key and public key<br/>[kubeconfig] Using kubeconfig folder "/etc/kubernetes"<br/>[kubeconfig] Writing "admin.conf" kubeconfig file<br/>[kubeconfig] Writing "kubelet.conf" kubeconfig file<br/>[kubeconfig] Writing "controller-manager.conf" kubeconfig file<br/>[kubeconfig] Writing "scheduler.conf" kubeconfig file<br/>[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"<br/>[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"<br/>[kubelet-start] Starting the kubelet<br/>[control-plane] Using manifest folder "/etc/kubernetes/manifests"<br/>[control-plane] Creating static Pod manifest for "kube-apiserver"<br/>[control-plane] Creating static Pod manifest for "kube-controller-manager"<br/>[control-plane] Creating static Pod manifest for "kube-scheduler"<br/>[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"<br/>[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s<br/>[apiclient] All control plane components are healthy after 28.003274 seconds<br/>[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace<br/>[kubelet] Creating a ConfigMap "kubelet-config-1.21" in namespace kube-system with the configuration for the kubelets in the cluster<br/>[upload-certs] Skipping phase. Please see --upload-certs<br/>[mark-control-plane] Marking the node kmaster1 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]<br/>[mark-control-plane] Marking the node kmaster1 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]<br/>[bootstrap-token] Using token: yg4xfz.heffiwkqvfyyxr5t<br/>[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles<br/>[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes<br/>[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials<br/>[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token<br/>[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster<br/>[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace<br/>[kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key<br/>[addons] Applied essential addon: CoreDNS<br/>[addons] Applied essential addon: kube-proxy</span><span id="0108" class="lf ka hj lu b fj mc lz l ma mb">Your Kubernetes control-plane has initialized successfully!</span><span id="1401" class="lf ka hj lu b fj mc lz l ma mb">To start using your cluster, you need to run the following as a regular user:</span><span id="5f74" class="lf ka hj lu b fj mc lz l ma mb">mkdir -p $HOME/.kube<br/>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config<br/>  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><span id="89a5" class="lf ka hj lu b fj mc lz l ma mb">Alternatively, if you are the root user, you can run:</span><span id="c3f6" class="lf ka hj lu b fj mc lz l ma mb">export KUBECONFIG=/etc/kubernetes/admin.conf</span><span id="7240" class="lf ka hj lu b fj mc lz l ma mb">You should now deploy a pod network to the cluster.<br/>Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:<br/>  <a class="ae jy" href="https://kubernetes.io/docs/concepts/cluster-administration/addons/" rel="noopener ugc nofollow" target="_blank">https://kubernetes.io/docs/concepts/cluster-administration/addons/</a></span><span id="cadc" class="lf ka hj lu b fj mc lz l ma mb">Then you can join any number of worker nodes by running the following on each as root:</span><span id="3a43" class="lf ka hj lu b fj mc lz l ma mb"><strong class="lu hk">kubeadm join 10.38.156.125:6443 --token yg4xfz.heffiwkqvfyyxr5t \<br/>        --discovery-token-ca-cert-hash sha256:1db2277f65f33cbf72a61f1ebfe9d506605f07f6cf7690b0089d9d3debcee812</strong></span></pre><p id="4f63" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">记下join命令，该命令包含工作者节点要加入的令牌散列。将kube配置复制到主目录中，并检查kubectl命令是否正常工作。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="ea9c" class="lf ka hj lu b fj ly lz l ma mb">root@kmaster1:~# <strong class="lu hk">mkdir ~/.kube</strong><br/>root@kmaster1:~# <strong class="lu hk">cp /etc/kubernetes/admin.conf ~/.kube/config</strong><br/>root@kmaster1:~# <strong class="lu hk">kubectl get nodes</strong><br/>NAME       STATUS     ROLES                  AGE   VERSION<br/>kmaster1   Ready   control-plane,master   10m   v1.21.3<br/>root@kmaster1:~# <strong class="lu hk">kubectl cluster-info</strong><br/>Kubernetes control plane is running at <a class="ae jy" href="https://10.38.156.125:6443" rel="noopener ugc nofollow" target="_blank">https://10.38.156.125:6443</a><br/>CoreDNS is running at <a class="ae jy" href="https://10.38.156.125:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy" rel="noopener ugc nofollow" target="_blank">https://10.38.156.125:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</a></span><span id="f866" class="lf ka hj lu b fj mc lz l ma mb">To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.</span></pre><h1 id="e05d" class="jz ka hj bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">第四步</h1><p id="1881" class="pw-post-body-paragraph ij ik hj im b in kx ip iq ir ky it iu kz la ix iy lb lc jb jc ld le jf jg jh hc bi translated">现在是时候为k8s安装法兰绒网络提供程序了</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="330f" class="lf ka hj lu b fj ly lz l ma mb">kubectl apply -f <a class="ae jy" href="https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</a> &gt; /dev/null 2&gt;&amp;1</span></pre><p id="772d" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">上述命令的输出</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="eb1a" class="lf ka hj lu b fj ly lz l ma mb">root@kmaster1:~# kubectl apply -f <a class="ae jy" href="https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</a><br/>Warning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+<br/>podsecuritypolicy.policy/psp.flannel.unprivileged created<br/>clusterrole.rbac.authorization.k8s.io/flannel created<br/>clusterrolebinding.rbac.authorization.k8s.io/flannel created<br/>serviceaccount/flannel created<br/>configmap/kube-flannel-cfg created<br/>daemonset.apps/kube-flannel-ds created</span></pre><h1 id="c456" class="jz ka hj bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">第五步</h1><p id="fac3" class="pw-post-body-paragraph ij ik hj im b in kx ip iq ir ky it iu kz la ix iy lb lc jb jc ld le jf jg jh hc bi translated">让引导工作节点并将其加入主节点。在上一步中，我们已经为要连接的工作节点复制了join命令。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="c010" class="lf ka hj lu b fj ly lz l ma mb"><strong class="lu hk">kubeadm join 10.38.156.125:6443 --token yg4xfz.heffiwkqvfyyxr5t \<br/>        --discovery-token-ca-cert-hash sha256:1db2277f65f33cbf72a61f1ebfe9d506605f07f6cf7690b0089d9d3debcee812</strong></span></pre><p id="b61d" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">按照与master相同的步骤设置docker和kubeadm、kubelet和kubectl安装。下面是步骤，你可以复制并运行它作为一个bash脚本。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="81e4" class="lf ka hj lu b fj ly lz l ma mb">sudo apt-get remove docker docker-engine docker.io containerd runc</span><span id="362c" class="lf ka hj lu b fj mc lz l ma mb">sudo apt-get update</span><span id="0e44" class="lf ka hj lu b fj mc lz l ma mb">sudo apt-get install \<br/>     apt-transport-https \<br/>     ca-certificates \<br/>     curl \<br/>     gnupg \<br/>     lsb-release -y</span><span id="8a15" class="lf ka hj lu b fj mc lz l ma mb">curl -fsSL <a class="ae jy" href="https://download.docker.com/linux/ubuntu/gpg" rel="noopener ugc nofollow" target="_blank">https://download.docker.com/linux/ubuntu/gpg</a> | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg  &gt;/dev/null</span><span id="f8bf" class="lf ka hj lu b fj mc lz l ma mb">echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] <a class="ae jy" href="https://download.docker.com/linux/ubuntu" rel="noopener ugc nofollow" target="_blank">https://download.docker.com/linux/ubuntu</a> \<br/>  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null</span><span id="fe25" class="lf ka hj lu b fj mc lz l ma mb">sudo apt-get update</span><span id="fbd2" class="lf ka hj lu b fj mc lz l ma mb">sudo apt-get install docker-ce docker-ce-cli containerd.io -y</span><span id="8ac1" class="lf ka hj lu b fj mc lz l ma mb">sudo mkdir /etc/docker</span><span id="8831" class="lf ka hj lu b fj mc lz l ma mb">cat &lt;&lt;EOF | sudo tee /etc/docker/daemon.json<br/>{<br/>  "exec-opts": ["native.cgroupdriver=systemd"],<br/>  "log-driver": "json-file",<br/>  "log-opts": {<br/>    "max-size": "100m"<br/>  },<br/>  "storage-driver": "overlay2"<br/>}<br/>EOF</span><span id="02e4" class="lf ka hj lu b fj mc lz l ma mb">systemctl enable docker</span><span id="e116" class="lf ka hj lu b fj mc lz l ma mb">systemctl daemon-reload</span><span id="4dcf" class="lf ka hj lu b fj mc lz l ma mb">systemctl restart docker</span><span id="4994" class="lf ka hj lu b fj mc lz l ma mb">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf<br/>br_netfilter<br/>EOF</span><span id="d8de" class="lf ka hj lu b fj mc lz l ma mb">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf<br/>net.bridge.bridge-nf-call-ip6tables = 1<br/>net.bridge.bridge-nf-call-iptables = 1<br/>EOF</span><span id="f7b7" class="lf ka hj lu b fj mc lz l ma mb">sudo sysctl --system</span><span id="05fa" class="lf ka hj lu b fj mc lz l ma mb">sudo apt-get update</span><span id="83fe" class="lf ka hj lu b fj mc lz l ma mb">sudo apt-get install -y apt-transport-https ca-certificates curl</span><span id="c739" class="lf ka hj lu b fj mc lz l ma mb">sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg <a class="ae jy" href="https://packages.cloud.google.com/apt/doc/apt-key.gpg" rel="noopener ugc nofollow" target="_blank">https://packages.cloud.google.com/apt/doc/apt-key.gpg</a> &gt; /dev/null</span><span id="926d" class="lf ka hj lu b fj mc lz l ma mb">echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] <a class="ae jy" href="https://apt.kubernetes.io/" rel="noopener ugc nofollow" target="_blank">https://apt.kubernetes.io/</a> kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list</span><span id="ace7" class="lf ka hj lu b fj mc lz l ma mb">sudo apt-get update</span><span id="3b7b" class="lf ka hj lu b fj mc lz l ma mb">sudo apt-get install -y kubelet kubeadm kubectl</span><span id="c7f4" class="lf ka hj lu b fj mc lz l ma mb">echo 'KUBELET_EXTRA_ARGS="--fail-swap-on=false"' &gt; /etc/default/kubelet</span><span id="79e4" class="lf ka hj lu b fj mc lz l ma mb">systemctl restart kubelet</span><span id="1651" class="lf ka hj lu b fj mc lz l ma mb">apt install -qq -y net-tools</span><span id="6072" class="lf ka hj lu b fj mc lz l ma mb">mknod /dev/kmsg c 1 11</span><span id="b903" class="lf ka hj lu b fj mc lz l ma mb">echo 'mknod /dev/kmsg c 1 11' &gt;&gt; /etc/rc.local</span><span id="5810" class="lf ka hj lu b fj mc lz l ma mb">chmod +x /etc/rc.local</span><span id="c323" class="lf ka hj lu b fj mc lz l ma mb"><strong class="lu hk">kubeadm join 10.38.156.125:6443 --token yg4xfz.heffiwkqvfyyxr5t \<br/>        --discovery-token-ca-cert-hash sha256:1db2277f65f33cbf72a61f1ebfe9d506605f07f6cf7690b0089d9d3debcee812</strong></span></pre><p id="ce1d" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">[注意:从主容器中适当地更改kubeadm join命令。]</p><p id="05c2" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">我将使用这些步骤作为bash脚本(bootstrap.sh ),并直接在worker节点上执行它们，如下所示。这是从主机上运行的。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="7818" class="lf ka hj lu b fj ly lz l ma mb"><strong class="lu hk"><em class="il">cat bootstrap.sh | lxc exec kworker1 bash</em></strong></span><span id="605d" class="lf ka hj lu b fj mc lz l ma mb"><strong class="lu hk"><em class="il">cat bootstrap.sh | lxc exec kworker2 bash</em></strong></span><span id="608a" class="lf ka hj lu b fj mc lz l ma mb"><strong class="lu hk"><em class="il">cat bootstrap.sh | lxc exec kworker3 bash</em></strong></span></pre><p id="09df" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">注意:</p><p id="559a" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">我在提出kubelet时遇到了下面的警告。(未找到时忽略)</p><p id="34dd" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated"><em class="il">【警告系统验证】:无法解析内核配置:无法加载内核模块:“配置”，输出:“modprobe: FATAL:在目录/lib/modules/5 . 4 . 0–77-generic \ n中找不到模块配置”，错误:退出状态1 </em></p><p id="f6ce" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">安装linux-image后，这种情况消失了</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="8a91" class="lf ka hj lu b fj ly lz l ma mb"><em class="il">apt-get install linux-image-$(uname -r)</em></span></pre><p id="d510" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">让我们验证集群，并在其中运行一个简单的nginx应用程序。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="a8ce" class="lf ka hj lu b fj ly lz l ma mb">root@kmaster1:~# <strong class="lu hk">kubectl get nodes</strong><br/>NAME       STATUS   ROLES                  AGE     VERSION<br/>kmaster1   Ready    control-plane,master   133m    v1.21.3<br/>kworker1   Ready    &lt;none&gt;                 27m     v1.21.3<br/>kworker2   Ready    &lt;none&gt;                 13m     v1.21.3<br/>kworker3   Ready    &lt;none&gt;                 6m17s   v1.21.3</span></pre><p id="6006" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">在这个集群中创建一个示例nginx应用和服务。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="4c8d" class="lf ka hj lu b fj ly lz l ma mb">root@kmaster1:~# <strong class="lu hk">kubectl create deploy --image=nginx nginx</strong><br/>deployment.apps/nginx created<br/><br/></span><span id="e49b" class="lf ka hj lu b fj mc lz l ma mb">root@kmaster1:~# <strong class="lu hk">kubectl expose deploy nginx --type=NodePort --name nginx --port 80</strong><br/>service/nginx exposed<br/>root@kmaster1:~# <strong class="lu hk">kubectl get svc</strong><br/>NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE<br/>kubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP        139m<br/>nginx        NodePort    10.111.136.18   &lt;none&gt;        80:31273/TCP   4s</span><span id="9c85" class="lf ka hj lu b fj mc lz l ma mb">root@kmaster1:~# <strong class="lu hk">ip a show dev eth0</strong><br/>15: eth0@if16: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000<br/>    link/ether 00:16:3e:11:2e:72 brd ff:ff:ff:ff:ff:ff link-netnsid 0<br/>    inet <strong class="lu hk">10.38.156.125</strong>/24 brd 10.38.156.255 scope global dynamic eth0<br/>       valid_lft 2583sec preferred_lft 2583sec<br/>    inet6 fd42:45a3:f671:9991:216:3eff:fe11:2e72/64 scope global dynamic mngtmpaddr noprefixroute<br/>       valid_lft 3190sec preferred_lft 3190sec<br/>    inet6 fe80::216:3eff:fe11:2e72/64 scope link<br/>       valid_lft forever preferred_lft forever</span><span id="8a02" class="lf ka hj lu b fj mc lz l ma mb"><br/>root@kmaster1:~# <strong class="lu hk">curl </strong><a class="ae jy" href="http://10.38.156.125:31273" rel="noopener ugc nofollow" target="_blank"><strong class="lu hk">http://10.38.156.125:31273</strong></a><br/>&lt;!DOCTYPE html&gt;<br/>&lt;html&gt;<br/>&lt;head&gt;<br/>&lt;title&gt;Welcome to nginx!&lt;/title&gt;<br/>&lt;style&gt;<br/>    body {<br/>        width: 35em;<br/>        margin: 0 auto;<br/>        font-family: Tahoma, Verdana, Arial, sans-serif;<br/>    }<br/>&lt;/style&gt;<br/>&lt;/head&gt;<br/>&lt;body&gt;<br/>&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;<br/>&lt;p&gt;If you see this page, the nginx web server is successfully installed and<br/>working. Further configuration is required.&lt;/p&gt;</span><span id="2a1f" class="lf ka hj lu b fj mc lz l ma mb">&lt;p&gt;For online documentation and support please refer to<br/>&lt;a href="<a class="ae jy" href="http://nginx.org/" rel="noopener ugc nofollow" target="_blank">http://nginx.org/</a>"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;<br/>Commercial support is available at<br/>&lt;a href="<a class="ae jy" href="http://nginx.com/" rel="noopener ugc nofollow" target="_blank">http://nginx.com/</a>"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;</span><span id="dec0" class="lf ka hj lu b fj mc lz l ma mb">&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;<br/>&lt;/body&gt;<br/>&lt;/html&gt;<br/>root@kmaster1:~#</span></pre><p id="0111" class="pw-post-body-paragraph ij ik hj im b in io ip iq ir is it iu kz iw ix iy lb ja jb jc ld je jf jg jh hc bi translated">通过验证主机名，我们可以调整bash脚本，使其具有执行master中包含的额外步骤的条件，如下所示。在这种情况下，在适当地创建时命名容器。</p><pre class="jj jk jl jm fe lt lu lv lw aw lx bi"><span id="2382" class="lf ka hj lu b fj ly lz l ma mb"><strong class="lu hk">if [[ $(hostname) =~ .*master.* ]]</strong><br/>then</span><span id="4522" class="lf ka hj lu b fj mc lz l ma mb">kubeadm config images pull &gt;/dev/null 2&gt;&amp;1</span><span id="1857" class="lf ka hj lu b fj mc lz l ma mb">kubeadm init --pod-network-cidr=10.244.0.0/16 --ignore-preflight-errors=all</span><span id="95e8" class="lf ka hj lu b fj mc lz l ma mb">mkdir /root/.kube<br/>  cp /etc/kubernetes/admin.conf /root/.kube/config</span><span id="9066" class="lf ka hj lu b fj mc lz l ma mb">kubectl apply -f <a class="ae jy" href="https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</a> &gt; /dev/null 2&gt;&amp;1</span><span id="679e" class="lf ka hj lu b fj mc lz l ma mb">joinCommand=$(kubeadm token create --print-join-command 2&gt;/dev/null)<br/>  echo "$joinCommand --ignore-preflight-errors=all"</span><span id="9611" class="lf ka hj lu b fj mc lz l ma mb">fi</span><span id="bebb" class="lf ka hj lu b fj mc lz l ma mb"><strong class="lu hk">if [[ $(hostname) =~ .*worker.* ]]</strong><br/>then<br/>  kubeadm join 10.38.156.125:6443 --token yg4xfz.heffiwkqvfyyxr5t \<br/>        --discovery-token-ca-cert-hash sha256:1db2277f65f33cbf72a61f1ebfe9d506605f07f6cf7690b0089d9d3debcee812 --ignore-preflight-errors=all</span></pre><h1 id="4fb7" class="jz ka hj bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">未来范围</h1><p id="d75c" class="pw-post-body-paragraph ij ik hj im b in kx ip iq ir ky it iu kz la ix iy lb lc jb jc ld le jf jg jh hc bi translated">我们可以在创建主节点和工作节点基础设施之后添加集群创建自动化。在演示中，我们使用kubeadm部署在LXC支持的基础设施上。但在真实的生产环境中，Terraform和Ansible等工具可以用来在物理机、虚拟机或云资源上构建基础设施。一旦基础设施建立起来，我们就可以通过ansible或其他一些自动化来触发集群创建自动化。目前在terraform中有Kubernetes提供者，他们可以为您完成集群创建任务，甚至在集群创建后部署应用程序pod。</p><h1 id="f033" class="jz ka hj bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">结论</h1><p id="56ab" class="pw-post-body-paragraph ij ik hj im b in kx ip iq ir ky it iu kz la ix iy lb lc jb jc ld le jf jg jh hc bi translated">我们逐步介绍了使用kubeadm工具构建kubernetes集群的过程。我们使用lxc来快速设置集群。最后，我们将这些步骤放在一个bash脚本中，该脚本可用于自动化该过程，并部署了一个样例nginx服务。感谢您的阅读，并希望本文能为您在设置kubernetes集群时增加一些价值。</p></div></div>    
</body>
</html>