<html>
<head>
<title>Implementing K-Means Clustering with K-Means++ Initialization in Python.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python中的K-Means++初始化实现K-Means聚类。</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/implementing-k-means-clustering-with-k-means-initialization-in-python-7ca5a859d63a?source=collection_archive---------1-----------------------#2021-04-09">https://medium.com/geekculture/implementing-k-means-clustering-with-k-means-initialization-in-python-7ca5a859d63a?source=collection_archive---------1-----------------------#2021-04-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e753b44a630317756dc5bf0305f96315.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SJbm600sb6dJZ-Z9qTTwYg.png"/></div></div></figure><p id="fcf6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> K-Means聚类</strong>是一种<em class="jo">无监督机器学习</em>算法。无监督意味着它不需要被观察数据的标签或类别。如果你对<strong class="is hj">监督算法</strong>感兴趣，那么你可以从这里开始<a class="ae jp" href="https://writersbyte.com/datascience/implementing-multi-variable-linear-regression-algorithm-in-python/" rel="noopener ugc nofollow" target="_blank">。</a></p><div class="jq jr ez fb js jt"><a href="https://writersbyte.com/datascience/implementing-multi-variable-linear-regression-algorithm-in-python/" rel="noopener  ugc nofollow" target="_blank"><div class="ju ab dw"><div class="jv ab jw cl cj jx"><h2 class="bd hj fi z dy jy ea eb jz ed ef hh bi translated">用Python实现“多元线性回归”算法。- WritersByte</h2><div class="ka l"><h3 class="bd b fi z dy jy ea eb jz ed ef dx translated">机器学习算法在过去十年中获得了巨大的普及。今天，这些算法被用于…</h3></div><div class="kb l"><p class="bd b fp z dy jy ea eb jz ed ef dx translated">writersbyte.com</p></div></div><div class="kc l"><div class="kd l ke kf kg kc kh io jt"/></div></div></a></div><p id="0106" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">K-means聚类是一种非常简单的算法，它在我们的整个数据集中创建相似数据点的组(聚类)。<strong class="is hj"> </strong>在<strong class="is hj"> <em class="jo">寻找零散数据中的隐藏模式时，这个算法被证明是一个非常方便的工具。</em>T13】</strong></p><div class="jq jr ez fb js jt"><a href="https://writersbyte.com" rel="noopener  ugc nofollow" target="_blank"><div class="ju ab dw"><div class="jv ab jw cl cj jx"><h2 class="bd hj fi z dy jy ea eb jz ed ef hh bi translated">▤作家字节</h2><div class="ka l"><h3 class="bd b fi z dy jy ea eb jz ed ef dx translated">思想，故事和想法。</h3></div><div class="kb l"><p class="bd b fp z dy jy ea eb jz ed ef dx translated">writersbyte.com</p></div></div><div class="kc l"><div class="ki l ke kf kg kc kh io jt"/></div></div></a></div><p id="e58a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">本教程中使用的全部代码可以在<a class="ae jp" href="https://github.com/Moosa-Ali/K-means-Implementation.git" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="e7ef" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">本教程将涵盖以下内容:</p><p id="44ea" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">k-means算法的简要概述。</strong></p><p id="b012" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">用随机初始化实现k-means。</strong></p><p id="b496" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">最优质心初始化的重要性概述。</strong></p><p id="7812" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">实现K-means++的</strong> <strong class="is hj">进行智能质心初始化。</strong></p><div class="jq jr ez fb js jt"><a href="https://writersbyte.com/datascience/ai-for-beginners-3/" rel="noopener  ugc nofollow" target="_blank"><div class="ju ab dw"><div class="jv ab jw cl cj jx"><h2 class="bd hj fi z dy jy ea eb jz ed ef hh bi translated">面向初学者的人工智能:计算机视觉和自然语言处理</h2><div class="ka l"><h3 class="bd b fi z dy jy ea eb jz ed ef dx translated">我们已经谈了很多关于人工智能的一般意义以及它对我们世界的影响。在以前的文章中，我们…</h3></div><div class="kb l"><p class="bd b fp z dy jy ea eb jz ed ef dx translated">writersbyte.com</p></div></div><div class="kc l"><div class="kj l ke kf kg kc kh io jt"/></div></div></a></div><p id="a7eb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在你前进之前，请考虑在科菲问题上支持我。点击下面的图片。</p><figure class="kl km kn ko fd ij er es paragraph-image"><a href="http://ko-fi.com/moosaali9906"><div class="er es kk"><img src="../Images/a9b75b9a2d9b6bf73b23151d0a95f04f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RAVsw7Mcvsh8aJL3LuG6bg.png"/></div></a></figure><p id="9880" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们开始吧:</p><h1 id="c200" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">1.理解算法:</h1><p id="49ec" class="pw-post-body-paragraph iq ir hi is b it ln iv iw ix lo iz ja jb lp jd je jf lq jh ji jj lr jl jm jn hb bi translated">假设我们有一些随机的数据，如下图所示。我们希望在数据中创建分组，这样看起来更有条理一些。但是，用肉眼来看，很难决定将哪些点关联在一起。K-means会帮我们做的。</p><figure class="kl km kn ko fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/17d4cb971c5c7e9cd793909ab1405e5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y1BE1HEVgolf3TDt2fB-KA.png"/></div></div><figcaption class="lt lu et er es lv lw bd b be z dx">image source :<a class="ae jp" href="http://sungsoo.github.com/images/scatter1.png" rel="noopener ugc nofollow" target="_blank">http://sungsoo.github.com/images/scatter1.png</a></figcaption></figure><p id="866b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">K-means算法的一个缺点是你需要从数据中指定你需要多少个聚类。如果您想要分离数据，但不确定应该有多少个类别是最佳的，这可能会是一个问题。</p><ul class=""><li id="c04d" class="lx ly hi is b it iu ix iy jb lz jf ma jj mb jn mc md me mf bi translated">像elbow方法这样的方法可以用来找到一个最佳的集群数量，但是在本文中没有讨论。* </li></ul><p id="7a4a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">K-means算法遵循以下步骤:</p><p id="1c5a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1.选择n个数据点作为初始质心。</p><p id="4c70" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.从步骤1中选择的每个质心点计算每个数据点的欧几里德距离。</p><p id="b491" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.通过将每个数据点分配到距离其最近的质心来形成数据聚类。</p><p id="6bda" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.取每个形成的集群的平均值。中点是我们新的质心。</p><p id="a8b0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="jo">重复步骤2到4，直到质心</em> </strong>不再变化。</p><p id="ea78" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其他算法的实现；</p><div class="jq jr ez fb js jt"><a href="https://writersbyte.com/datascience/implementing-multi-variable-linear-regression-algorithm-in-python/" rel="noopener  ugc nofollow" target="_blank"><div class="ju ab dw"><div class="jv ab jw cl cj jx"><h2 class="bd hj fi z dy jy ea eb jz ed ef hh bi translated">用Python实现“多元线性回归”算法。- WritersByte</h2><div class="ka l"><h3 class="bd b fi z dy jy ea eb jz ed ef dx translated">机器学习算法在过去十年中获得了巨大的普及。今天，这些算法被用于…</h3></div><div class="kb l"><p class="bd b fp z dy jy ea eb jz ed ef dx translated">writersbyte.com</p></div></div><div class="kc l"><div class="kd l ke kf kg kc kh io jt"/></div></div></a></div><h1 id="c927" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">2.履行</h1><p id="805a" class="pw-post-body-paragraph iq ir hi is b it ln iv iw ix lo iz ja jb lp jd je jf lq jh ji jj lr jl jm jn hb bi translated">足够的理论让我们开始编码。</p><p id="ca8d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我们将看看我们的数据集。出于本教程的目的，我们将使用人体身高体重指数的数据集。数据集是免费的，可以从<a class="ae jp" href="https://www.kaggle.com/yersever/500-person-gender-height-weight-bodymassindex" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><pre class="kl km kn ko fd mg mh mi mj aw mk bi"><span id="86d7" class="ml kq hi mh b fi mm mn l mo mp"><em class="jo">#loading up the libraries</em><br/><br/><strong class="mh hj">import</strong> <strong class="mh hj">pandas</strong> <strong class="mh hj">as</strong> <strong class="mh hj">pd</strong><br/><strong class="mh hj">import</strong> <strong class="mh hj">numpy</strong> <strong class="mh hj">as</strong> <strong class="mh hj">np</strong><br/><strong class="mh hj">import</strong> <strong class="mh hj">random</strong> <strong class="mh hj">as</strong> <strong class="mh hj">rd</strong><br/><strong class="mh hj">import</strong> <strong class="mh hj">matplotlib.pyplot</strong> <strong class="mh hj">as</strong> <strong class="mh hj">plt<br/></strong></span><span id="695b" class="ml kq hi mh b fi mq mn l mo mp"><em class="jo">#loading data</em><br/>data = pd.read_csv("500_Person_Gender_Height_Weight_Index.csv")</span></pre><figure class="kl km kn ko fd ij er es paragraph-image"><div class="er es mr"><img src="../Images/b0e556807d09081fe8376d19cd5878a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*-kcp9N6f4FelftUfP3z3KA.png"/></div><figcaption class="lt lu et er es lv lw bd b be z dx">Visualizing our data</figcaption></figure><p id="221d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从散点图中，我们可以看到数据具有相当随机的分布，没有清晰的聚类。看看我们的算法执行什么样的分组会很有趣。</p><p id="b1e1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们快速写下一个函数来得到随机点。</p><figure class="kl km kn ko fd ij"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="bdfb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们看看它是否有效。</p><figure class="kl km kn ko fd ij er es paragraph-image"><div class="er es mu"><img src="../Images/64af4eeee81b33e31f0472e7485baefa.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*XCCFzZD44LLTrJ0qTAVHGQ.png"/></div><figcaption class="lt lu et er es lv lw bd b be z dx">Random centroids initialized</figcaption></figure><p id="4963" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这些随机的质心…嗯…相当随机😵。</p><p id="19bd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们编写程序到达合适的质心并创建相应的集群。</p><figure class="kl km kn ko fd ij"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="9b98" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们运行这个例程来定位数据中的4个集群。</p><figure class="kl km kn ko fd ij"><div class="bz dy l di"><div class="ms mt l"/></div></figure><figure class="kl km kn ko fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/1db8af06945e5421ecd3b2a7076386a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*PLI2t5UX-mL0FV-StBPkKw.png"/></div><figcaption class="lt lu et er es lv lw bd b be z dx">Final Centroids found</figcaption></figure><p id="d83f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">全部完成！</p><p id="9bf7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们看看我们得到了什么。</p><figure class="kl km kn ko fd ij"><div class="bz dy l di"><div class="ms mt l"/></div></figure><figure class="kl km kn ko fd ij er es paragraph-image"><div class="er es mw"><img src="../Images/deee766b087f469b88c6d64122610636.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*mmMnThxsOzAEgKbHWXHoFA.png"/></div><figcaption class="lt lu et er es lv lw bd b be z dx">Red dot: Centroid, Remaining Points: Dataset</figcaption></figure><p id="55ef" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">看起来我们的分组都完成了，✌️.现在是时候看看初始化不同的质心是否会有所不同。</p><p id="589b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">先说K-means++初始化算法。</p><h1 id="4703" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">3.最佳质心初始化。</h1><p id="7d47" class="pw-post-body-paragraph iq ir hi is b it ln iv iw ix lo iz ja jb lp jd je jf lq jh ji jj lr jl jm jn hb bi translated">初始化形心时，最初选择的点相距较远是很重要的。如果这些点靠得太近，这些点很可能会在它们的局部区域中找到一个聚类，而实际的聚类将与另一个聚类混合。</p><p id="a253" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当随机初始化质心时，我们无法控制它们的初始位置。T9】</p><figure class="kl km kn ko fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mx"><img src="../Images/bf5c12abd1a9944f8af8f052b7a0eb4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HTo4ICJeRKq2wYYPpsjFBg.png"/></div></div><figcaption class="lt lu et er es lv lw bd b be z dx">Image Source: <a class="ae jp" href="https://media.geeksforgeeks.org/wp-content/uploads/20190812011808/Screenshot-2019-08-12-at-1.13.15-AM.png" rel="noopener ugc nofollow" target="_blank">https://media.geeksforgeeks.org/wp-content/uploads/20190812011808/Screenshot-2019-08-12-at-1.13.15-AM.png</a></figcaption></figure><figure class="kl km kn ko fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mx"><img src="../Images/20821e9efb2186bcc98fd53cd73119f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x6DYAq6Ssg-6hpNNV4unEQ.png"/></div></div><figcaption class="lt lu et er es lv lw bd b be z dx">Image Source: <a class="ae jp" href="https://media.geeksforgeeks.org/wp-content/uploads/20190812011831/Screenshot-2019-08-12-at-1.09.42-AM.png" rel="noopener ugc nofollow" target="_blank">https://media.geeksforgeeks.org/wp-content/uploads/20190812011831/Screenshot-2019-08-12-at-1.09.42-AM.png</a></figcaption></figure><p id="f91e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">K-means++是解决这个问题的一个聪明的方法。</p><p id="cbe5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">就像K-Means本身一样，K-Means++也是一个非常简单的算法。</p><p id="f5de" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1.随机选择第一个质心。</p><p id="aa09" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.计算质心和数据集中每隔一个数据点之间的欧几里德距离。最远的点将成为我们的下一个质心。</p><p id="d822" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.通过将每个点与其最近的质心相关联，围绕这些质心创建簇。</p><p id="b973" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.距离质心最远的点将是我们的下一个质心。</p><p id="70cf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.重复步骤3和4，直到找到n个质心。</p><h1 id="af75" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><strong class="ak"> 4。K-Means++的实现</strong></h1><p id="2ba2" class="pw-post-body-paragraph iq ir hi is b it ln iv iw ix lo iz ja jb lp jd je jf lq jh ji jj lr jl jm jn hb bi translated">让我们编码我们的算法。</p><figure class="kl km kn ko fd ij"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="37ea" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">写下算法后，让我们在上面构建的K-Means算法上测试它。</p><figure class="kl km kn ko fd ij"><div class="bz dy l di"><div class="ms mt l"/></div></figure><figure class="kl km kn ko fd ij er es paragraph-image"><div class="er es my"><img src="../Images/3ad49fd36e8c47f453f9ed61d590b5cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*viDfd_KLLQsfBYr6-oCc5A.png"/></div><figcaption class="lt lu et er es lv lw bd b be z dx">Clusters after applying k-means++</figcaption></figure><p id="125a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以看到这次我们发现了不同的集群。这显示了初始质心可以产生的差异。</p><h1 id="8763" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">5.<strong class="ak">结论</strong></h1><p id="0773" class="pw-post-body-paragraph iq ir hi is b it ln iv iw ix lo iz ja jb lp jd je jf lq jh ji jj lr jl jm jn hb bi translated">总之，K-Means是一个简单而强大的算法。它可用于在当前数据中创建聚类。这些分类有助于您更好地了解当前数据，并且分类可用于分析任何未来数据。如果你试图分析你的业务的客户基础，这可能是有帮助的。将客户分组可以帮助您为每个集群创建个性化的策略，当新客户加入时，他们可以很容易地与已经形成的集群相关联，可能性是无限的。</p><p id="06eb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">更多文章；</p><div class="jq jr ez fb js jt"><a href="https://writersbyte.com" rel="noopener  ugc nofollow" target="_blank"><div class="ju ab dw"><div class="jv ab jw cl cj jx"><h2 class="bd hj fi z dy jy ea eb jz ed ef hh bi translated">▤作家字节</h2><div class="ka l"><h3 class="bd b fi z dy jy ea eb jz ed ef dx translated">思想，故事和想法。</h3></div><div class="kb l"><p class="bd b fp z dy jy ea eb jz ed ef dx translated">writersbyte.com</p></div></div><div class="kc l"><div class="ki l ke kf kg kc kh io jt"/></div></div></a></div><p id="505d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果这对你有帮助，考虑支持我对科菲。点击下面的图片。</p><figure class="kl km kn ko fd ij er es paragraph-image"><a href="http://ko-fi.com/moosaali9906"><div class="er es kk"><img src="../Images/a9b75b9a2d9b6bf73b23151d0a95f04f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RAVsw7Mcvsh8aJL3LuG6bg.png"/></div></a></figure></div></div>    
</body>
</html>