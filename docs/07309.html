<html>
<head>
<title>From Domain Randomisation to Structurally-Aware Synthetic Data Generation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从领域随机化到结构感知合成数据生成</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/from-domain-randomisation-to-structurally-aware-synthetic-data-generation-c6078bf42def?source=collection_archive---------16-----------------------#2021-09-14">https://medium.com/geekculture/from-domain-randomisation-to-structurally-aware-synthetic-data-generation-c6078bf42def?source=collection_archive---------16-----------------------#2021-09-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="4f17" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">用虚拟合成数据提高模型的通用性:零售业产品识别的案例研究</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/21a6edc238269cd33e236b43c519bf29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_LRd8W7DfYQpP3Xi3ZC1lQ.png"/></div></div></figure></div><div class="ab cl jj jk gp jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="hb hc hd he hf"><p id="3da0" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi km translated">上个月在<a class="ae kv" href="https://www.youtube.com/watch?v=j0z4FweCy4M&amp;ab_channel=Tesla" rel="noopener ugc nofollow" target="_blank">特斯拉人工智能日</a>，世界再次被埃隆·马斯克的雄心勃勃的目标震惊了，他要创造一个<a class="ae kv" href="https://www.fastcompany.com/90673676/elon-musk-tesla-bot" rel="noopener ugc nofollow" target="_blank">人形特斯拉机器人</a>，旨在帮助我们人类完成无聊和重复的任务。你们中的一些人可能已经看到，就在半小时前，特斯拉的视觉团队介绍了他们的<a class="ae kv" href="https://youtu.be/j0z4FweCy4M?t=5291" rel="noopener ugc nofollow" target="_blank">自动标签</a> &amp; <a class="ae kv" href="https://youtu.be/j0z4FweCy4M?t=5715" rel="noopener ugc nofollow" target="_blank">模拟</a>管道，这是他们自动驾驶工作的核心，由数千名内部手动贴标机和3D艺术家提供支持。有了惊人的程序和自动化工具，他们仍然需要很多人参与。作为世界上最成功的公司之一，市值接近7000亿英镑的特斯拉是能够负担得起为视频片段添加标签和注释的人力的幸运儿之一。一旦他们获得了足够的数据，他们就可以自动标记和构建超现实世界的模拟。</p><p id="598b" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">然而残酷的现实是，大多数希望在业务流程中应用计算机视觉的公司往往受到数据访问的限制。此外，<strong class="js hj">注释和标记用于对象识别的数据集</strong>是成本最高、劳动强度最大、容易出错的任务之一。麻省理工学院的一项研究最近显示，ImageNet上标签的错误率令人震惊地达到了6 %, ImageNet是分类任务中最广泛用于基准测试最先进模型的数据集。</p><h1 id="e4d1" class="kw kx hi bd ky kz la lb lc ld le lf lg io lh ip li ir lj is lk iu ll iv lm ln bi translated">零售业中以数据为中心的人工智能和合成数据</h1><p id="98c5" class="pw-post-body-paragraph jq jr hi js b jt lo ij jv jw lp im jy jz lq kb kc kd lr kf kg kh ls kj kk kl hb bi translated">在Neurolabs，我们认为解决这些问题和开启计算机视觉下一个里程碑的关键是使用Blender、Unity或Unreal等3D图形引擎，用合成生成的数据训练模型。</p><p id="2783" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在最近推出的以数据为中心的人工智能范例中，目标不是创造更好的T2模型，而是通过改变T4数据来提高性能。即使有大量的数据，为计算机视觉任务开发这样的控制也不能仅仅通过获取真实数据来完成。我们必须考虑控制影响计算机视觉模型的所有参数，如相机、灯光、物体姿态、分辨率、遮挡或边缘情况。</p><p id="a7ce" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在本帖中，我们将重点关注合成数据给零售业的产品识别带来的影响。我们在这里选择的具体用例是实时货架监控，以提高超市中的货架可用性。具体来说，我们将了解:</p><ul class=""><li id="51ac" class="lt lu hi js b jt ju jw jx jz lv kd lw kh lx kl ly lz ma mb bi translated">比较在真实数据集上评估的各种形式的合成数据的性能，从域随机化(DR)到杂乱域随机化，最后是<strong class="js hj"> <em class="mc">结构感知合成场景</em> </strong>。</li><li id="b9d8" class="lt lu hi js b jt md jw me jz mf kd mg kh mh kl ly lz ma mb bi translated">在小数据域，即少于100幅图像和同一域 的微小<strong class="js hj"> <em class="mc">变化，即不同的长宽比、相机姿态、光照条件&amp;货架产品结构中综合合成数据的能力。</em></strong></li><li id="338e" class="lt lu hi js b jt md jw me jz mf kd mg kh mh kl ly lz ma mb bi translated">为什么<strong class="js hj"> <em class="mc">不可扩展</em> </strong>获取和增加更多真实数据的变化，花费&amp;时间权衡。</li></ul><h1 id="2ae6" class="kw kx hi bd ky kz la lb lc ld le lf lg io lh ip li ir lj is lk iu ll iv lm ln bi translated">真实数据集和合成数据技术</h1><p id="0541" class="pw-post-body-paragraph jq jr hi js b jt lo ij jv jw lp im jy jz lq kb kc kd lr kf kg kh ls kj kk kl hb bi translated">在这种特殊情况下，创建合成数据集和训练计算机视觉模型的请求来自一家早期创业公司<a class="ae kv" href="https://www.superobotics.com/" rel="noopener ugc nofollow" target="_blank"> SuperRobotics </a>，该公司正在为超市制造一种创新的自主智能机器人。他们想为70种西班牙超市产品演示产品检测机。目标是在合成数据上训练产品识别模型。</p><h1 id="ea60" class="kw kx hi bd ky kz la lb lc ld le lf lg io lh ip li ir lj is lk iu ll iv lm ln bi translated">真实数据</h1><p id="58cf" class="pw-post-body-paragraph jq jr hi js b jt lo ij jv jw lp im jy jz lq kb kc kd lr kf kg kh ls kj kk kl hb bi translated">SuperRobotics能够收集近500幅真实图像，这些图像经过仔细注释，准备用于物体检测。对象实例的总数接近10，000。拼接数据集的图像是使用图像拼接技术构建的，这是SuperRobotics的专业领域之一。</p><p id="a348" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">数据集<strong class="js hj"><em class="mc">“Cropped”</em></strong>包含381张裁剪货架的图像，平均每张图像有10-15件产品，分辨率(长宽比)固定为3280x2464 (1.33)，光线和摄像机位置也各不相同。</p><p id="b116" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">数据集<strong class="js hj"> <em class="mc">“真实拼接1”</em></strong>包含48幅全货架图像，分辨率(纵横比)为3280 x 5144 (0.63)</p><p id="1fde" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">数据集<strong class="js hj"> <em class="mc">“真实缝合2”</em></strong>包含55幅全货架的图像，与<strong class="js hj"> <em class="mc">“真实缝合1”</em></strong>相比，这些图像在相机、照明和货架上产品的定位方面略有不同，但分辨率相同。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mi"><img src="../Images/97e1480a6a8090a5ac792a45934507fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Cudw6q3g2eDrvOx88mNuQ.png"/></div></div><figcaption class="mj mk et er es ml mm bd b be z dx"><strong class="bd ky">Fig. 1. Cropped Real Dataset</strong></figcaption></figure><div class="iy iz ja jb fd ab cb"><figure class="mn jc mo mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/87232a0f371f2e3060cce9d59c697c42.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*iDhmt80udFqEYIg6D3HjKw.jpeg"/></div></figure><figure class="mn jc mt mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/3db584198867b9ce656b1e4ad610d983.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*sSuWWjxDMkqV_Ja1XkE_4g.png"/></div><figcaption class="mj mk et er es ml mm bd b be z dx mu di mv mw"><strong class="bd ky">Fig. 2. Real Stitched 1 (left) vs. Real Stitched 2 (right) | Neurolabs</strong></figcaption></figure></div></div><div class="ab cl jj jk gp jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="hb hc hd he hf"><h1 id="e0c1" class="kw kx hi bd ky kz mx lb lc ld my lf lg io mz ip li ir na is lk iu nb iv lm ln bi translated">综合数据</h1><p id="4cef" class="pw-post-body-paragraph jq jr hi js b jt lo ij jv jw lp im jy jz lq kb kc kd lr kf kg kh ls kj kk kl hb bi translated">从70个类别的3D数字资产开始，我们使用各种技术生成合成数据，例如普通域随机化(图3)和杂乱域随机化(图4)。在这个场景中，想法是通过随机化参数，如产品的姿势、背景、光线、相机以及HSV，来引入尽可能多的变化。这些技术已经在<a class="ae kv" href="https://ai.googleblog.com/2017/10/closing-simulation-to-reality-gap-for.html" rel="noopener ugc nofollow" target="_blank">研究</a>和<a class="ae kv" href="https://blog.unity.com/technology/boosting-computer-vision-performance-with-synthetic-data" rel="noopener ugc nofollow" target="_blank">实践</a>中成功使用，但是，正如我们将看到的，当处理结构化场景和大量类别时，这些技术还存在不足。这些不同的数据集每个都包含近250幅图像和原始70个类别的6000个平衡实例。</p><p id="52d4" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">第二合成数据集(在<strong class="js hj">表1中标记为<strong class="js hj"><em class="mc"/></strong>)</strong>包含200个结构感知场景的图像(图5)，其具有与真实数据相同的纵横比。使用货架的基本场景，通过随机化产品的属性和放置，以语义上有意义的方式放置产品，使得真实数据和合成数据之间的差异最小化。</p><p id="d480" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">第三个数据集是一个混合了<strong class="js hj"> <em class="mc">【合成】</em> </strong>和真实数据的一个小子集(20%)。</p><p id="1efd" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">最后，<strong class="js hj"> <em class="mc">【广义合成】</em> </strong>数据集具有1500个具有5种不同分辨率(纵横比)的图像，并用于测试对所有真实数据集的学习可移植性。</p><ul class=""><li id="d3ac" class="lt lu hi js b jt ju jw jx jz lv kd lw kh lx kl ly lz ma mb bi translated">2048 x 1152 (1.77英寸)</li><li id="28cc" class="lt lu hi js b jt md jw me jz mf kd mg kh mh kl ly lz ma mb bi translated">2256 x 1504 (1.5英寸)</li><li id="5ccb" class="lt lu hi js b jt md jw me jz mf kd mg kh mh kl ly lz ma mb bi translated">2260 x 2160 (1.04英寸)</li><li id="4e30" class="lt lu hi js b jt md jw me jz mf kd mg kh mh kl ly lz ma mb bi translated">4096 x 5120 (0.8)</li><li id="c6a6" class="lt lu hi js b jt md jw me jz mf kd mg kh mh kl ly lz ma mb bi translated">2520 x 4880 (0.51)</li></ul><p id="01e4" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">所有上述合成数据技术目前都可以作为Neurolabs平台的一部分，在该平台上可以轻松配置场景和生成参数。</p><div class="iy iz ja jb fd ab cb"><figure class="mn jc nc mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/6bf98661aaf061cf51d61d3a76d46af2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*lDjlJODMwgJPE6K8q-VL4Q.jpeg"/></div></figure><figure class="mn jc nc mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/9724edb9978328ee0137f900a4a5f312.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*VQ0jBxJqgeQcBG7TzoM5gA.jpeg"/></div><figcaption class="mj mk et er es ml mm bd b be z dx nd di ne mw"><strong class="bd ky">Fig. 3. Vanilla Domain Randomisation</strong></figcaption></figure></div><div class="ab cb"><figure class="mn jc nc mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/4674d3ac67562647e63e31a1e02abc04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*FYRsHND5zTXnqQ3U8FpOUA.jpeg"/></div></figure><figure class="mn jc nc mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/9aac75c4a084c204bcd8ec1f406e74ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*pLYZyP3wcc8vXodolHS7wA.jpeg"/></div><figcaption class="mj mk et er es ml mm bd b be z dx nd di ne mw"><strong class="bd ky">Fig. 4. (Left) Cluttered Domain Randomisation | Neurolabs &amp; Fig. 5. (Right) Structurally Aware Synthetic Scene | Neurolabs</strong></figcaption></figure></div></div><div class="ab cl jj jk gp jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="hb hc hd he hf"><h1 id="785c" class="kw kx hi bd ky kz mx lb lc ld my lf lg io mz ip li ir na is lk iu nb iv lm ln bi translated">实验</h1><p id="ea58" class="pw-post-body-paragraph jq jr hi js b jt lo ij jv jw lp im jy jz lq kb kc kd lr kf kg kh ls kj kk kl hb bi translated">对于所有实验，我们使用相同的对象检测模型、D3 EfficientDet和COCO预训练主干作为起点，网络的前两层被冻结。使用80/20 train/val组合进行训练，并根据验证损失提前停止。自始至终都使用标准优化器，没有使用超参数调整来提高模型的性能。在<strong class="js hj"> <em class="mc">表1 </em> </strong>中，您可以看到作为real2real和syn2real学习实验一部分的mAP评估结果。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="nf ng l"/></div><figcaption class="mj mk et er es ml mm bd b be z dx"><strong class="ak">Table 1. Evaluation Performance (%mAP)</strong></figcaption></figure><h1 id="78fc" class="kw kx hi bd ky kz la lb lc ld le lf lg io lh ip li ir lj is lk iu ll iv lm ln bi translated">用合成数据进行模型概括</h1><p id="5233" class="pw-post-body-paragraph jq jr hi js b jt lo ij jv jw lp im jy jz lq kb kc kd lr kf kg kh ls kj kk kl hb bi translated">在<strong class="js hj"> <em class="mc">表1 </em> </strong>中，我们展示了培训和评估的组合以及绩效图。有两个主要发现强烈暗示了综合数据的概括能力。</p><h1 id="7c58" class="kw kx hi bd ky kz la lb lc ld le lf lg io lh ip li ir lj is lk iu ll iv lm ln bi translated">DR2real与Syn2real与Mixed2real</h1><p id="8984" class="pw-post-body-paragraph jq jr hi js b jt lo ij jv jw lp im jy jz lq kb kc kd lr kf kg kh ls kj kk kl hb bi translated">相对容易构建并且只需要访问3D资产(不需要场景构建)的域随机化技术(图3、图4)在两个真实数据集上都达到了71%和72% mAP的性能。这些方法可用于启动计算机视觉模型，然后用更多真实数据对其进行微调。</p><p id="282e" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">结构感知合成数据是使用可组合的基本资产自动构建的，并且生成货架，以及在该货架上执行产品的智能放置，使得与真实数据的领域差距最小化。与灾难恢复相比，在真实域中评估的mAP增加了10–15%。</p><p id="a25b" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">最后，将合成数据集与来自第一真实数据集的20%真实数据(12幅图像)混合，将模型的性能提高到94%。再加上一些为推断寻找最佳IoU阈值的后处理步骤，这是将模型部署到生产环境中所必需的。</p><h1 id="1056" class="kw kx hi bd ky kz la lb lc ld le lf lg io lh ip li ir lj is lk iu ll iv lm ln bi translated">Syn2real与Real2real</h1><p id="a8b4" class="pw-post-body-paragraph jq jr hi js b jt lo ij jv jw lp im jy jz lq kb kc kd lr kf kg kh ls kj kk kl hb bi translated">当使用仅在真实数据上训练的模型进行测试时，即<strong class="js hj"> <em class="mc">【真实缝合1】</em></strong>，环境中非常小的变化使得测试集不同，即<strong class="js hj"> <em class="mc">【真实缝合2】</em></strong>，对整体性能有很大的影响。在图中有一个约20%的缺口，这表明在真实域的微小变化上概括较差。</p><p id="f5d5" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">正如我们所看到的，合成数据并非如此，它在这种低数据场景中带来了许多变化，并且能够在非常相似的真实域之间移动时进行归纳，两个真实数据集上的映射比例分别为85%和91%。控制参数，如相机，灯光，和产品的姿态是必不可少的概括，更重要的是，可以很容易地实现与合成数据。如果我们将12张真实照片与合成数据混合，我们可以在两个真实数据集上获得生产就绪的结果，即95%的地图。</p><p id="fb0d" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在一般化的方向上更进一步，我们观察到，当在更多样化的、具有不同纵横比的真实数据集上测试真实数据模型时，性能急剧下降，如表1中的两行所示。从大约90%到4%的mAP下降是真实数据结果中的巨大变化。</p><p id="ddb5" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我们通过生成具有5种不同纵横比的1500幅图像的<strong class="js hj"> <em class="mc">【广义合成】</em> </strong>数据集来规避这个问题。正如可以预料的那样，当提高泛化能力时，性能略有下降，但能够准确地检测大范围变化的产品，<em class="mc">在所有三个真实数据集上具有相似的性能</em>，分别为73%、74%和52%。</p><h1 id="bcb6" class="kw kx hi bd ky kz la lb lc ld le lf lg io lh ip li ir lj is lk iu ll iv lm ln bi translated">成本和时间的权衡</h1><p id="9b18" class="pw-post-body-paragraph jq jr hi js b jt lo ij jv jw lp im jy jz lq kb kc kd lr kf kg kh ls kj kk kl hb bi translated">收集真实数据并对其进行注释的整个过程分为3个步骤，用了近<strong class="js hj"> 1个月</strong>完成。首先采集“裁剪”数据集，然后采集“真实拼接1”和“真实拼接2”。10，000个包围盒的包围盒和类注释的总成本是700美元。</p><p id="43c3" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我们的一名计算机视觉工程师使用我们的数据生成平台，总共花了3个工作日来完成生成所有合成数据集和训练CV模型的整个过程。这是95%的成本效益。设置合成数据配置和场景花费了1天时间，而实际渲染过程和所有数据集的自动标记总共花费了3个小时才完成。额外的一天半时间用于培训和评估模型。</p><p id="c6b2" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">虽然这些数字充分说明了真实数据与合成数据之间的时间和成本权衡，但最有吸引力的论点可能是通过快速迭代来控制和改变数据的能力，以便轻松适应手头的特定用例。</p><h1 id="d218" class="kw kx hi bd ky kz la lb lc ld le lf lg io lh ip li ir lj is lk iu ll iv lm ln bi translated">结论</h1><p id="fa30" class="pw-post-body-paragraph jq jr hi js b jt lo ij jv jw lp im jy jz lq kb kc kd lr kf kg kh ls kj kk kl hb bi translated">我们展示了一个零售案例研究，其中虚拟合成数据为货架产品识别提供了一个可扩展的解决方案，解决了数据可用性和注释问题。创造变异和控制代参数增加了模型在小范围内的通用性。</p><p id="d54d" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">人工智能资深人士安德鲁·吴(Andrew NG)建议，需要转变心态，以更有意义的方式推进人工智能领域，并提出以数据为中心的人工智能心态是潜在的解决方案:“最近发表的一份<em class="mc">样本显示，99%的论文是以模型为中心的，只有1%是以数据为中心的”。</em>考虑到这一点，<strong class="js hj">还有什么比控制数据的创建方式更以数据为中心的方法呢？</strong></p><p id="155e" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">如果你对这篇文章中使用的任何合成数据感兴趣，请随意点击这里的<a class="ae kv" href="https://drive.google.com/drive/folders/1v3Qza9vO8wb5pJ3yW6stG6XdiYX6lwWI?usp=sharing" rel="noopener ugc nofollow" target="_blank"/>。请确保您<a class="ae kv" href="https://www.neurolabs.ai/free-trial" rel="noopener ugc nofollow" target="_blank">注册提前访问</a>我们将于下个月发布的综合数据平台。</p></div><div class="ab cl jj jk gp jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="hb hc hd he hf"><p id="0029" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><em class="mc">作者</em><a class="ae kv" href="https://www.linkedin.com/in/patric-fulop/" rel="noopener ugc nofollow" target="_blank"><em class="mc">Patric FULOP</em></a><em class="mc">，CTO at</em><a class="nh ni ge" href="https://medium.com/u/1888f854e2da?source=post_page-----c6078bf42def--------------------------------" rel="noopener" target="_blank"><em class="mc">neuro labs</em></a></p><p id="aa33" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><em class="mc">由于糟糕的库存管理成本，全球零售商每年损失高达6340亿美元，仅缺货一项就造成5%的销售损失。🤯</em></p><p id="45fc" class="pw-post-body-paragraph jq jr hi js b jt ju ij jv jw jx im jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><a class="ae kv" href="https://www.linkedin.com/company/neurolabs/" rel="noopener ugc nofollow" target="_blank"><em class="mc">neuro labs</em></a><em class="mc">使用计算机视觉和合成数据的强大组合，帮助结束缺货，改善客户体验，增加收入。🤖🛒 </em></p></div></div>    
</body>
</html>