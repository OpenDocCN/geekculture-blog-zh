<html>
<head>
<title>Logo Detector iOS App using CoreML and CreateML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用CoreML和CreateML的徽标检测器iOS应用程序</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/logo-detector-ios-app-using-coreml-and-createml-860b0377cd7d?source=collection_archive---------3-----------------------#2022-01-22">https://medium.com/geekculture/logo-detector-ios-app-using-coreml-and-createml-860b0377cd7d?source=collection_archive---------3-----------------------#2022-01-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="71b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你能从这个博客中期待什么？</p><ol class=""><li id="d307" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">什么是机器学习？</li><li id="c605" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">CoreML是什么？</li><li id="acc0" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">什么是愿景框架？</li><li id="dc27" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">什么是CreateML？</li><li id="31d8" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">如何用CreateML训练一个模型？</li><li id="e12c" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">构建一个样本图像(徽标)识别应用程序</li></ol><p id="e904" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从我最喜欢的关于机器学习的名言开始:</p><p id="97ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你折磨数据的时间足够长，它就会招供。</p><h1 id="3d62" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">什么是机器学习？</h1><p id="cd20" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated"><strong class="ih hj">机器学习</strong> ( <strong class="ih hj"> ML </strong>)是对计算机<a class="ae ku" href="https://en.wikipedia.org/wiki/Algorithm" rel="noopener ugc nofollow" target="_blank">算法</a>的研究，这些算法通过经验和数据的使用自动改进。</p><p id="5dbe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它被视为<a class="ae ku" href="https://en.wikipedia.org/wiki/Artificial_intelligence" rel="noopener ugc nofollow" target="_blank">人工智能</a>的一部分。</p><p id="ec3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些算法基于样本数据建立一个模型，称为“<a class="ae ku" href="https://en.wikipedia.org/wiki/Training_data" rel="noopener ugc nofollow" target="_blank">训练数据</a>”，以便在没有明确编程的情况下进行预测或决策。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es kv"><img src="../Images/601a09c092e17879eb13774f5933a435.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9oaYL_7sPQh3EKqH.jpg"/></div></div></figure><p id="0a89" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">比如苹果在<strong class="ih hj"> <em class="lh">拍照app中使用ML识别人脸</em> </strong>和<strong class="ih hj"> <em class="lh">键盘app预测下一个单词建议</em> </strong></p><h1 id="48f2" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">CoreML是什么？</h1><pre class="kw kx ky kz fd li lj lk ll aw lm bi"><span id="b2b5" class="ln js hi lj b fi lo lp l lq lr">import CoreML</span></pre><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ls"><img src="../Images/c31e30b1204424f60d43015ede3c4540.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vf7vV34v-mGf2ZZv.png"/></div></div></figure><p id="bd45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Apple提供的一个框架，用于将机器学习模型集成到您的应用程序中。</p><p id="daa4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Core ML自动生成一个Swift类，提供对ML模型的简单访问，当我们有一个模型数据集时，CoreML很容易在iOS中设置和使用</p><p id="7d21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">什么是模型？</strong></p><p id="aca5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Core ML将机器学习算法应用于一组训练数据，以创建一个<em class="lh">模型</em>。该模型用于根据新的输入数据进行预测。例如，您可以训练模型对照片进行分类，或者直接从照片的像素中检测照片中的特定对象。</p><h1 id="00b7" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">什么是愿景框架？</h1><pre class="kw kx ky kz fd li lj lk ll aw lm bi"><span id="a1e6" class="ln js hi lj b fi lo lp l lq lr">import Vision</span></pre><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es lt"><img src="../Images/e97e1657111050708de24eb970fc1ed7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/0*EPPTff8Bun8JBmv3.png"/></div></figure><p id="18f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ku" href="https://developer.apple.com/documentation/vision" rel="noopener ugc nofollow" target="_blank">视觉框架</a>与Core ML合作，将分类模型应用于图像，并对这些图像进行预处理，以使机器学习任务更容易、更可靠。</p><p id="abe1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">来自视觉框架的一些预先存在的API是面部和身体检测、动物检测、文本检测、条形码检测。</p><h1 id="3032" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">语音、自然语言和声音分析</h1><p id="cf13" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">我们知道Core ML支持视觉分析图像，就像它使用自然语言处理文本一样，</p><p id="1fe7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用此框架执行以下任务:</p><ul class=""><li id="9acc" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc lu jj jk jl bi translated"><em class="lh">语言识别</em>自动检测一段文字的语言。</li><li id="73b5" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc lu jj jk jl bi translated"><em class="lh">记号化</em>，将一段文本分解成语言单位或记号。</li><li id="e8a1" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc lu jj jk jl bi translated"><em class="lh">词性标注</em>，用词性标注单个单词。</li><li id="3569" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc lu jj jk jl bi translated"><em class="lh">词干化</em>，根据词形分析推断词干。</li><li id="541c" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc lu jj jk jl bi translated"><em class="lh">命名实体识别</em>，将标记识别为人名、地名或组织名。</li></ul><p id="9822" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ku" href="https://developer.apple.com/documentation/speech" rel="noopener ugc nofollow" target="_blank">语音</a>用于将音频转换为文本，以及<a class="ae ku" href="https://developer.apple.com/documentation/soundanalysis" rel="noopener ugc nofollow" target="_blank">声音分析</a>用于识别音频中的声音</p><p id="39b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用语音框架来识别录音或现场音频中的口语单词。键盘的听写支持使用语音识别将音频内容翻译成文本。</p><h1 id="a18b" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">什么是CreateML？</h1><p id="c296" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">CreateML是苹果公司(与Xcode捆绑的app)提供的一个工具，用来创建机器学习模型(<code class="du lv lw lx lj b">***.mlmodel)</code>在你的app中使用。其他语言的ML模型也可以通过CreateML app轻松转换成我们的<code class="du lv lw lx lj b">.mlmodel</code>。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ly"><img src="../Images/7bc10ca78edd781f1e3d303ef23e768b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S4hU-AdhAnv_PSkU.png"/></div></div></figure><h1 id="9b59" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">蜜蜂</h1><p id="a23f" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated"><code class="du lv lw lx lj b">VNCoreMLRequest</code> -使用核心ML模型处理图像的图像分析请求。</p><p id="b4a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du lv lw lx lj b">VNImageRequestHandler</code> -处理与单个图像相关的一个或多个图像分析请求的对象。</p><p id="e9af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du lv lw lx lj b">VNClassificationObservation</code> -由图像分析请求产生的分类信息。</p><p id="9574" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du lv lw lx lj b">VNObservatoinResults</code> -请求处理生成的VNObservation结果集合。</p><h1 id="f7ef" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">如何用CreateML训练一个模型？</h1><p id="b114" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">打开CreateML，方法是转到Xcode菜单，然后单击打开开发者工具→ CreateML。然后创建一个新项目。导航到左侧面板中的模型源部分。这是我们的模型，我们将训练、建造和使用它。(还有其他生成MLModel的方法，如playgrounds和terminal，也可以随意探索它们)</p><p id="67ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了创建模型，我们需要一个logo数据集，同样可以从<a class="ae ku" href="https://www.kaggle.com/volkandl/car-brand-logos" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>获得(Kaggle是Google LLC的子公司，是数据科学家和机器学习实践者的在线社区。)Kaggle有数千个由各种机器学习开发者上传的数据集。一旦你下载了数据集。打开CreateML窗口，点击模型源中的LogoDetector文件。该窗口有两个主要栏，1。数据和2。参数。让我们关注数据列，它包括:</p><ol class=""><li id="ba0d" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><strong class="ih hj">训练数据:</strong></li></ol><p id="92cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一步是为Create ML提供一些训练数据。打开下载的文件夹，将train文件夹拖放到此列中。</p><p id="2f3d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">额外提示:对于图像识别，尝试向图像添加增强功能，如模糊和噪声，这将提高准确性。增加迭代次数也会提高精度。但是这两种改变都会增加训练时间。</em></p><p id="3fbf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。验证数据:</strong></p><p id="06f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该验证数据用于检查其模型:它基于输入进行预测，然后检查该预测与来自数据的真实值相差多远。默认设置为自动-从训练数据中拆分</p><p id="694c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。测试数据:</strong></p><p id="a22a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">打开下载的文件夹，将测试文件夹拖放到此列中。我们将使用<em class="lh">训练数据</em>中的图像来训练我们的分类器，然后使用<em class="lh">测试数据</em>来确定其准确性。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lz"><img src="../Images/bb92add830ce5d86fdac58ee638d8966.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*0UMXzO4T6B_bIELFArEBQw.gif"/></div></div></figure><p id="0cb9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在单击左上角的run按钮开始训练我们的模型。流程完成后，我们将看到培训数据:</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es ma"><img src="../Images/c56cd9be414e9d1b3288a12ce4cb4338.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KAts2sJKitNhFOYh4Vb4Fw.png"/></div></div></figure><p id="fa1b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，它会使用我们提供的测试数据集自动启动评估(测试)流程:</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mb"><img src="../Images/8f8d39a86cb94f74b5ccfbf210889574.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d3sayT-P8akCv3jlnwidjw.png"/></div></div></figure><p id="e8f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们的MLModel已经准备好添加到项目中了，点击顶部中间的Output选项卡，点击⬇️ Get图标并保存它。</p><h1 id="0c0f" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">构建一个样本图像(徽标)识别应用程序</h1><p id="6ebb" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">在Xcode中创建一个新的iOS项目(storyboard one而不是SwiftUI)并拖放我们在上面创建的MLModel。现在的目标是建立一个应用程序，打开摄像头视图，扫描任何捕获的徽标(图像)，并用我们创建的mlmodel验证它，并在标签中显示结果。</p><p id="f245" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最终项目可以从<a class="ae ku" href="https://github.com/MuralidharanKathiresan/LogoDetector" rel="noopener ugc nofollow" target="_blank">这里</a>下载</p><ol class=""><li id="372e" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><a class="ae ku" href="https://stackoverflow.com/a/59332619/3701589" rel="noopener ugc nofollow" target="_blank">删除故事板文件</a>，<em class="lh">删除主界面，</em>从Info.plist中删除Main.storyboard。</li><li id="a930" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">在本教程中，我们将使用AVCaptureSession从相机中捕获图像，并使用CoreML的Vision框架对其进行处理，因此我们需要在info.plist中添加一个<a class="ae ku" href="https://developer.apple.com/documentation/bundleresources/information_property_list/nscamerausagedescription" rel="noopener ugc nofollow" target="_blank">相机权限</a>字符串。右键单击Info.plist →作为源代码打开，在&lt; dict &gt;中添加以下内容</li></ol><pre class="kw kx ky kz fd li lj lk ll aw lm bi"><span id="39a0" class="ln js hi lj b fi lo lp l lq lr"><strong class="lj hj">&lt;key&gt;</strong>NSCameraUsageDescription<strong class="lj hj">&lt;/key&gt;</strong></span><span id="bcfe" class="ln js hi lj b fi mc lp l lq lr"><strong class="lj hj">&lt;string&gt;</strong>Accessing your camera to take photo.<strong class="lj hj">&lt;/string&gt;</strong></span></pre><p id="14a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.现在让我们尝试在viewDidLoad中显示相机权限对话框，并尝试获得用户权限来开始捕捉图像:</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es md"><img src="../Images/d7285115d1e59d48ac4769c3042fee42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aN0oJl2QGC8kAZW1sQwHrw.png"/></div></div></figure><p id="5187" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.一旦许可被授予，我们需要创建一个<a class="ae ku" href="https://developer.apple.com/documentation/avfoundation/avcapturesession" rel="noopener ugc nofollow" target="_blank"> AVCaptureSession </a>。</p><p id="9922" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">什么是AVCaptureSession？</strong></p><p id="65ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要执行实时捕获，您需要实例化一个<code class="du lv lw lx lj b">AVCaptureSession</code>对象，并添加适当的输入和输出。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es me"><img src="../Images/69e94eb3c93fe99fca47e53d71488cab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k9hG5lMIhAuHE5Y48-vuqw.png"/></div></div></figure><p id="8434" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦AVCaptureSession被实例化，就需要为其添加适当的输入和输出。这里的输入是→设备的默认摄像机，摄像机的媒体类型是<code class="du lv lw lx lj b">video</code></p><pre class="kw kx ky kz fd li lj lk ll aw lm bi"><span id="ca67" class="ln js hi lj b fi lo lp l lq lr">AVCaptureDevice.default(for: AVMediaType.video) // MediaType<br/>AVCaptureDeviceInput(device: captureDevice)     // Input</span></pre><p id="596d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了接收这个会话的输出，我们可以在类级别创建一个属性，这样就可以在任何地方访问它</p><pre class="kw kx ky kz fd li lj lk ll aw lm bi"><span id="ef77" class="ln js hi lj b fi lo lp l lq lr"><strong class="lj hj">private</strong> <strong class="lj hj">let</strong> photoOutput = AVCapturePhotoOutput()</span></pre><p id="f035" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦配置了I/O设置。让我们在“AVCaptureVideoPreviewLayer”的帮助下将摄像机视图添加到视图控制器的视图中，最后，必须使用</p><pre class="kw kx ky kz fd li lj lk ll aw lm bi"><span id="fefa" class="ln js hi lj b fi lo lp l lq lr">captureSession.startRunning()</span></pre><p id="f4e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个调用启动了从输入到输出的数据流。现在我们已经配置了一个“AVCaptureSession ”,并将摄像机的视图添加到ViewController视图中。</p><p id="2428" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.既然会话已经准备好，我们就可以开始通过摄像机捕捉图像了</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mf"><img src="../Images/3265ca1b9b86334d6a7efd23a0a3808d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4J6_lhttiYMnqf8iFw60Ag.png"/></div></div></figure><p id="69ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们创建了一个“AVCapturePhotoSettings”对象，从而帮助我们在捕获照片之前自定义设置，这里，我们必须调用带有照片设置和委托的方法“capturePhoto()”。</p><p id="96b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">6.向ViewController确认“AVCapturePhotoCaptureDelegate ”,并添加其photoOutput()方法</p><pre class="kw kx ky kz fd li lj lk ll aw lm bi"><span id="4e9e" class="ln js hi lj b fi lo lp l lq lr"><strong class="lj hj">func</strong> photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?)</span></pre><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mg"><img src="../Images/072d8351036e3ed4db46c7d4e5698c89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kZ-awa40Z47p2QxLyln2qw.png"/></div></div></figure><p id="28f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个方法帮助我们从captureSession传递输出，它是一个imageData和来自它的一个适当的图像。</p><p id="0d0d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.现在，既然我们有了从设备捕获的图像，我们需要用MLModel处理它以获得结果:</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mh"><img src="../Images/77cea422d1cf072d8d57dd788732447c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8Nq-kNN8sNhOMHJvMXj_ng.png"/></div></div></figure><p id="6dee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们创建了一个类型为<code class="du lv lw lx lj b">VNCoreMLRequest</code>的“classificationRequest ”,它需要一个模型，当我们将从CreateML下载的MLModel移动到项目中时，Xcode会自动为我们创建一个<code class="du lv lw lx lj b">LogoDetector</code> swift类。此外，当在用模型处理之后接收到请求时，请求提供带有‘vnrequest’的completionHandler。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mi"><img src="../Images/ca20df5a5e946e8f8b8fa4f8590a01d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tcDPMYy4bNBZY-QsmAjj0Q.png"/></div></div></figure><p id="d14a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，最后一部分是在图像传入模型时处理来自模型的请求/结果。</p><p id="e31f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们接收一组分类作为结果的一部分，我们以最大的置信度过滤元素，</p><p id="c4f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">什么是自信？</strong></p><p id="311c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">置信度标准化为[0，1]，其中1最有把握</p><p id="fc80" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意:信心总是可以作为1 ☹️返回，如果信心不被支持或没有意义，那么就要小心玩弄它。</p><p id="f0e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦我们得到了徽标名称，我将在一秒钟内再次开始捕获会话。(可根据各种使用情况进行定制)</p><p id="05f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">8.每当我们从“AVCapturePhotoCaptureDelegate”的“photoOutput”方法接收到一个图像对象时，它必须被传递到“VNImageRequestHandler”中，以处理如下结果:</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es mj"><img src="../Images/7e661d1345e96dc6df9c7eb903d7653b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aF1aAmns8E8Vv5a4rA3hrA.png"/></div></div></figure><p id="6633" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">9.让我们运行我们的应用程序，看看它是如何工作的</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es mk"><img src="../Images/e8efe8b708cb5d9baa5528506c4009c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/1*EXSMbXoTnGJCr7ebI6HIyQ.gif"/></div></figure><h1 id="0231" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">需要记住以下几点:</h1><p id="693d" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated"><code class="du lv lw lx lj b">***.mlmodel</code>一旦应用程序安装完毕，就无法在用户设备内部进行动态更新，如果我们需要使用新型号，那么我们必须更换现有型号。</p><p id="27e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du lv lw lx lj b">***.mlmodel</code>可以与<a class="ae ku" href="https://developer.apple.com/library/archive/documentation/FileManagement/Conceptual/On_Demand_Resources_Guide/index.html" rel="noopener ugc nofollow" target="_blank">按需资源</a>一起使用，这样它就可以在空中更新任何人，</p><p id="256b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个扫描和识别过程中，用户的隐私得到高度保护，因为它发生在用户的设备内部，没有API，没有来自第三方的数据收集，</p><p id="3c34" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">处理结果的速度在iOS设备中是一流的，并且创建的ML模型的大小远远小于CreateML的其他替代方案</p><figure class="kw kx ky kz fd la"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="5d2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望文章对你有帮助。如果你喜欢这篇文章，请告诉我👏你可以在LinkedIn<a class="ae ku" href="https://www.linkedin.com/in/muralidharankathiresan/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/muralidharankathiresan/</a>上找到我</p></div></div>    
</body>
</html>