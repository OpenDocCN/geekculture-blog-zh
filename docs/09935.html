<html>
<head>
<title>Semantic Segmentation with SegFormer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用SegFormer进行语义分割</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/semantic-segmentation-with-segformer-2501543d2be4?source=collection_archive---------1-----------------------#2022-01-06">https://medium.com/geekculture/semantic-segmentation-with-segformer-2501543d2be4?source=collection_archive---------1-----------------------#2022-01-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/084289690ac99fbba2d19eee04c4609a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bp9f-dCSecuZIsa6GMcLjA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Model Prediction on Drone Dataset Image</figcaption></figure><h1 id="fb75" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">介绍</h1><p id="c716" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">图像分割是对图像中的每个像素进行分类的过程。这是一项计算机视觉任务，主要任务是检测图像中带有对象的区域。</p><p id="d8fd" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">今天我们将讨论使用<a class="ae kv" href="https://deepai.org/publication/segformer-simple-and-efficient-design-for-semantic-segmentation-with-transformers" rel="noopener ugc nofollow" target="_blank"> SegFormer </a>的语义分割。这是一个神经网络架构，其灵感来自于当今热门的建筑——变形金刚。如果没有任何印象的话，你一定是住在岩石下了！</p><p id="eb72" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">Segformer架构不像视觉转换器那样依赖于位置编码，因此提高了对不同分辨率图像的推断。Segformer领先于其他同类产品的另一点是其解码器的设计方式。与所有使用上采样或去卷积的分段架构不同，Segformer使用速度更快、效率更高的MLP解码器。我们将在接下来的章节中更详细地讨论这个架构。</p><h1 id="b94f" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">变形金刚(电影名)</h1><h2 id="3551" class="kw iv hi bd iw kx ky kz ja la lb lc je kd ld le ji kh lf lg jm kl lh li jq lj bi translated">这些变形金刚到底是什么？</h2><p id="042b" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">变形金刚最初是用来解决文本生成和翻译等问题的。Transformer是一种新颖的架构，使用编码器和解码器以及自关注机制将一个序列转换为另一个序列。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/a0cc021905e46e26330a9fa48539f579.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h-LZILODPXyvDHQzko00Bw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">Figure 1: From ‘Attention Is All You Need’ by Vaswani et al.</figcaption></figure><h1 id="c757" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">SegFormer建筑</h1><p id="0e24" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">该架构基于具有编码器-解码器头的变换器架构，其中编码器利用自关注。</p><p id="411f" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">编码器结构本质上是分级的，输出多尺度特征。它不需要位置编码，从而避免了当测试分辨率不同于训练时导致性能下降的位置码的<a class="ae kv" href="https://deepai.org/machine-learning-glossary-and-terms/interpolation" rel="noopener ugc nofollow" target="_blank">插值</a>。</p><p id="bd82" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">与其他复杂解码器不同，该架构采用简单的MLP解码器，该解码器聚合来自不同层的信息，从而将局部注意力和全局注意力相结合，以呈现强大的表示。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/867baae4b39964992da417d31d6c482b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Utu8S0Z9EQs-odAAHiM31g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Figure 2: SegFormer architecture</figcaption></figure><h1 id="508f" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">语义分割</h1><p id="c8f3" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">对于这篇博客，我们将使用SegFormer在<a class="ae kv" href="https://www.tugraz.at/index.php?id=22387" rel="noopener ugc nofollow" target="_blank">无人机数据集</a>上训练一个语义分割模型，该数据集可以从<a class="ae kv" href="https://www.kaggle.com/bulentsiyah/semantic-drone-dataset" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载。</p><h2 id="00c5" class="kw iv hi bd iw kx ky kz ja la lb lc je kd ld le ji kh lf lg jm kl lh li jq lj bi translated">数据集概述</h2><p id="a89e" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">语义无人机数据集侧重于对城市场景的语义理解，以提高自主无人机飞行和着陆程序的安全性。该图像描绘了在离地5至30米的高度从天底(鸟瞰)拍摄的20多座房屋。使用高分辨率相机获取6000x4000px (24Mpx)大小的图像。训练集包含400个公开可用的图像。</p><h2 id="361d" class="kw iv hi bd iw kx ky kz ja la lb lc je kd ld le ji kh lf lg jm kl lh li jq lj bi translated">数据扩充</h2><p id="558b" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">由于图像的大小为6000x4000px，这对于训练我们的模型来说太大了，我们将应用一个裁剪放大步骤，用滑动窗口机制来挑选2000x2000px的作物。这为我们提供了每幅图像6次裁剪，从而将数据集大小增加到2400幅图像。我们将使用2100幅图像进行训练，300幅图像进行验证。扩充的数据集可以从<a class="ae kv" href="https://drive.google.com/file/d/14uIrMaB9z0unQUG7f851QV0YG1EcNJyq/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">的Google Drive </a>下载。</p><h2 id="ef80" class="kw iv hi bd iw kx ky kz ja la lb lc je kd ld le ji kh lf lg jm kl lh li jq lj bi translated">培养</h2><p id="9670" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">在PyTorch中训练SegFormer模型就像训练任何其他模型一样简单。我们将遵循的步骤是:</p><ul class=""><li id="c4bc" class="lq lr hi ju b jv kq jz kr kd ls kh lt kl lu kp lv lw lx ly bi translated">用数据加载器加载数据。</li><li id="189c" class="lq lr hi ju b jv lz jz ma kd mb kh mc kl md kp lv lw lx ly bi translated">初始化超参数和优化器。</li><li id="c2cd" class="lq lr hi ju b jv lz jz ma kd mb kh mc kl md kp lv lw lx ly bi translated">编写训练循环</li></ul><p id="c62f" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">我们将使用HuggingFace的特征提取器，它直接从加载的蒙版中处理分割标签。</p><pre class="ll lm ln lo fd me mf mg mh aw mi bi"><span id="8dc0" class="kw iv hi mf b fi mj mk l ml mm">encoded_inputs = self.feature_extractor(augmented['image'], augmented['mask'], return_tensors="pt")</span></pre><p id="b743" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">我们有标签CSV，可用于在分割图像上绘制颜色。</p><pre class="ll lm ln lo fd me mf mg mh aw mi bi"><span id="bf54" class="kw iv hi mf b fi mj mk l ml mm">classes = pd.read_csv('class_dict_seg.csv')['name']</span><span id="08ab" class="kw iv hi mf b fi mn mk l ml mm">id2label = classes.to_dict()</span><span id="7096" class="kw iv hi mf b fi mn mk l ml mm">label2id = {v: k for k, v in id2label.items()}</span></pre><p id="cbb7" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">我们将使用HuggingFace的预训练SegFormer模型，并用我们自己的数据集对其进行微调。HuggingFace的<code class="du mo mp mq mf b">transformers</code>库使得使用预训练的模型通过自定义数据集进行微调变得非常容易。加载预先训练好的模型只有几行代码。</p><pre class="ll lm ln lo fd me mf mg mh aw mi bi"><span id="7982" class="kw iv hi mf b fi mj mk l ml mm">feature_extractor = SegformerFeatureExtractor(align=False, reduce_zero_label=False)</span><span id="17b1" class="kw iv hi mf b fi mn mk l ml mm">model = SegformerForSemanticSegmentation.from_pretrained(<br/>"nvidia/mit-b5", ignore_mismatched_sizes=True, num_labels=len(id2label), id2label=id2label, label2id=label2id, reshape_last_stage=True)</span></pre><p id="62b6" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">我们将使用训练SegFormer时使用的默认超参数来训练带有无人机数据集的模型。HuggingFace的<code class="du mo mp mq mf b">transformers</code>库为优化器<code class="du mo mp mq mf b">AdamW</code>提供了微小的变化，以处理预训练HuggingFace模型的训练。</p><pre class="ll lm ln lo fd me mf mg mh aw mi bi"><span id="c4b2" class="kw iv hi mf b fi mj mk l ml mm">optimizer = AdamW(model.parameters(), lr=0.00006)</span></pre><figure class="ll lm ln lo fd ij"><div class="bz dy l di"><div class="mr ms l"/></div></figure><p id="c1f6" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">在这里，我们准备训练模型。为了博客的缘故，我们只对它进行10个纪元的训练，因为在Colab上训练需要很长时间，并且用10个纪元就能给出不错的结果。</p><h2 id="c276" class="kw iv hi bd iw kx ky kz ja la lb lc je kd ld le ji kh lf lg jm kl lh li jq lj bi translated">推理</h2><p id="82d6" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">上面在无人机数据集上训练的模型被推送到HuggingFace模型中枢。</p><p id="10bb" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">让我们看看推理代码来测试我们的模型。</p><p id="acd0" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">获取调色板的颜色，我们将使用它在图像上绘制分类分割。</p><pre class="ll lm ln lo fd me mf mg mh aw mi bi"><span id="bd9b" class="kw iv hi mf b fi mj mk l ml mm">df = pd.read_csv('drone_dataset/class_dict_seg.csv')</span><span id="e352" class="kw iv hi mf b fi mn mk l ml mm">classes = df['name']</span><span id="6a6f" class="kw iv hi mf b fi mn mk l ml mm">palette = df[[' r', ' g', ' b']].values</span><span id="1a83" class="kw iv hi mf b fi mn mk l ml mm">id2label = classes.to_dict()</span><span id="1c1a" class="kw iv hi mf b fi mn mk l ml mm">label2id = {v: k for k, v in id2label.items()}</span></pre><p id="22a2" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">正如我们前面看到的，使用HuggingFace加载预训练模型非常容易。</p><p id="486c" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated"><strong class="ju hj">注意:</strong>我们将使用我们的预训练模型，而不是Nvidia的预训练模型。模型被推送到HuggingFace Model Hub中名为<code class="du mo mp mq mf b">deep-learning-analytics/segformer_semantic_segmentation</code>的存储库中。</p><pre class="ll lm ln lo fd me mf mg mh aw mi bi"><span id="c2cb" class="kw iv hi mf b fi mj mk l ml mm">feature_extractor = SegformerFeatureExtractor(align=False, reduce_zero_label=False)</span><span id="8486" class="kw iv hi mf b fi mn mk l ml mm">device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span><span id="24e2" class="kw iv hi mf b fi mn mk l ml mm">model = SegformerForSemanticSegmentation.from_pretrained("deep-learning-analytics/segformer_semantic_segmentation", ignore_mismatched_sizes=True,</span><span id="01f6" class="kw iv hi mf b fi mn mk l ml mm">num_labels=len(id2label), id2label=id2label, label2id=label2id,</span><span id="a348" class="kw iv hi mf b fi mn mk l ml mm">reshape_last_stage=True)</span><span id="18c0" class="kw iv hi mf b fi mn mk l ml mm">model = model.to(device)</span></pre><p id="04cd" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">我们需要做的唯一一件事就是让加载的图像通过我们之前谈到的<code class="du mo mp mq mf b">feature_extractor</code>,为模型推断做好准备。</p><pre class="ll lm ln lo fd me mf mg mh aw mi bi"><span id="4de5" class="kw iv hi mf b fi mj mk l ml mm"># prepare the image for the model (aligned resize)</span><span id="b67c" class="kw iv hi mf b fi mn mk l ml mm">feature_extractor_inference = SegformerFeatureExtractor(do_random_crop=False, do_pad=False)</span><span id="3301" class="kw iv hi mf b fi mn mk l ml mm">pixel_values = feature_extractor_inference(image, return_tensors="pt").pixel_values.to(device)</span><span id="adf7" class="kw iv hi mf b fi mn mk l ml mm">outputs = model(pixel_values=pixel_values)# logits are of shape (batch_size, num_labels, height/4, width/4)</span><span id="44c3" class="kw iv hi mf b fi mn mk l ml mm">logits = outputs.logits.cpu()</span></pre><h2 id="0e99" class="kw iv hi bd iw kx ky kz ja la lb lc je kd ld le ji kh lf lg jm kl lh li jq lj bi translated">结果</h2><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mt"><img src="../Images/02c41f76dddd357023891811ad370161.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PFyvrxP8EKOy8p_yhTmBqw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Model Prediction Examples on Drone Dataset Images</figcaption></figure><p id="43ad" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">仅此而已。我们做到了！拍拍你的背，你自己训练了一个变形金刚模型！</p><p id="6c5b" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">你可以在<a class="ae kv" href="https://colab.research.google.com/drive/1_t3KvF3qg4IJfEhTuftFI1GSlscapNgf?usp=sharing" rel="noopener ugc nofollow" target="_blank">谷歌实验室</a>或者<a class="ae kv" href="https://github.com/Praneet9/SegFormer_Segmentation" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到训练和推理的代码</p><p id="de10" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">您也可以使用部署在<a class="ae kv" href="https://huggingface.co/spaces/deep-learning-analytics/segformer_semantic_segmentation" rel="noopener ugc nofollow" target="_blank"> HuggingFace Spaces </a>上的模型，用您自己的数据来试用该模型。</p><h1 id="9a76" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">结论</h1><p id="691f" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">我们实现了一个基于Transformer的语义分割模型，它在多个任务中提供了最先进的结果。我们还看到了架构是如何考虑到问题的各个方面而设计的。分层设计有助于以多种尺度传播特征。MLP解码器有助于加速向前传递，从而显著提高模型的FPS。我们还尝试了拥抱脸，这使得训练和尝试基于变形金刚的模型变得非常容易。</p><p id="43c3" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">我希望你能从博客中吸取一些东西。请尝试一下colab笔记本，并在下面的评论中分享你的经验。</p><p id="3b6c" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">在<a class="ae kv" href="https://deeplearninganalytics.org/" rel="noopener ugc nofollow" target="_blank">深度学习分析</a>，我们非常热衷于使用机器学习来解决现实世界的问题。我们已经帮助许多企业部署了创新的基于人工智能的解决方案。如果您看到合作的机会，请通过我们的网站<a class="ae kv" href="https://deeplearninganalytics.org/contact-us/" rel="noopener ugc nofollow" target="_blank">这里</a>联系我们。</p><h2 id="53d4" class="kw iv hi bd iw kx ky kz ja la lb lc je kd ld le ji kh lf lg jm kl lh li jq lj bi translated">重要链接</h2><ul class=""><li id="c9d3" class="lq lr hi ju b jv jw jz ka kd mu kh mv kl mw kp lv lw lx ly bi translated"><a class="ae kv" href="https://colab.research.google.com/drive/1_t3KvF3qg4IJfEhTuftFI1GSlscapNgf?usp=sharing" rel="noopener ugc nofollow" target="_blank">谷歌Colab </a></li><li id="d32b" class="lq lr hi ju b jv lz jz ma kd mb kh mc kl md kp lv lw lx ly bi translated"><a class="ae kv" href="https://www.tugraz.at/index.php?id=22387" rel="noopener ugc nofollow" target="_blank">原始无人机数据集</a></li><li id="f737" class="lq lr hi ju b jv lz jz ma kd mb kh mc kl md kp lv lw lx ly bi translated"><a class="ae kv" href="https://drive.google.com/file/d/14uIrMaB9z0unQUG7f851QV0YG1EcNJyq/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">增强无人机数据集</a></li><li id="5e7b" class="lq lr hi ju b jv lz jz ma kd mb kh mc kl md kp lv lw lx ly bi translated"><a class="ae kv" href="https://github.com/Praneet9/SegFormer_Segmentation" rel="noopener ugc nofollow" target="_blank"> Github </a></li><li id="0b57" class="lq lr hi ju b jv lz jz ma kd mb kh mc kl md kp lv lw lx ly bi translated"><a class="ae kv" href="https://huggingface.co/deep-learning-analytics/segformer_semantic_segmentation" rel="noopener ugc nofollow" target="_blank">拥抱脸模型轮毂</a></li><li id="ca50" class="lq lr hi ju b jv lz jz ma kd mb kh mc kl md kp lv lw lx ly bi translated"><a class="ae kv" href="https://huggingface.co/spaces/deep-learning-analytics/segformer_semantic_segmentation" rel="noopener ugc nofollow" target="_blank">拥抱脸空间</a></li></ul><h1 id="c880" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">参考</h1><div class="mx my ez fb mz na"><a href="https://github.com/NVlabs/SegFormer" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hj fi z dy nf ea eb ng ed ef hh bi translated">GitHub-NV labs/seg former:seg former的官方PyTorch实现</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">图1:seg former-B0至SegFormer-B5的性能。SegFormer:简单有效的语义分割设计…</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">github.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no io na"/></div></div></a></div><div class="mx my ez fb mz na"><a href="https://arxiv.org/abs/2105.15203" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hj fi z dy nf ea eb ng ed ef hh bi translated">SegFormer:简单有效的变形语义分割设计</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">我们提出了SegFormer，一个简单、有效而强大的语义分割框架，它将变形器与语义分割相结合。</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">arxiv.org</p></div></div><div class="nj l"><div class="np l nl nm nn nj no io na"/></div></div></a></div><div class="mx my ez fb mz na"><a href="https://arxiv.org/abs/1706.03762" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hj fi z dy nf ea eb ng ed ef hh bi translated">你需要的只是关注</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">主导序列转导模型是基于复杂的递归或卷积神经网络在一个…</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">arxiv.org</p></div></div><div class="nj l"><div class="nq l nl nm nn nj no io na"/></div></div></a></div><div class="mx my ez fb mz na"><a href="https://huggingface.co/" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hj fi z dy nf ea eb ng ed ef hh bi translated">拥抱脸-人工智能社区建设未来。</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">我们正在通过开源和开放科学来推进和民主化人工智能的旅程。</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">huggingface.co</p></div></div><div class="nj l"><div class="nr l nl nm nn nj no io na"/></div></div></a></div><div class="mx my ez fb mz na"><a href="https://www.tugraz.at/index.php?id=22387" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hj fi z dy nf ea eb ng ed ef hh bi translated">ICG -德罗内达塞特</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">无人机数据集免费提供给学术和非学术实体用于非商业目的，例如…</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">www.tugraz.at</p></div></div><div class="nj l"><div class="ns l nl nm nn nj no io na"/></div></div></a></div></div></div>    
</body>
</html>