<html>
<head>
<title>Scrape Organic News from Brave Search with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python从勇敢搜索中抓取有机新闻</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/scrape-organic-news-from-brave-search-with-python-5eae4d8584d9?source=collection_archive---------27-----------------------#2021-10-27">https://medium.com/geekculture/scrape-organic-news-from-brave-search-with-python-5eae4d8584d9?source=collection_archive---------27-----------------------#2021-10-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/d61bf56ab1f5139e2aaadf18f8b00017.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tUNMACXEFAOBKhhD.jpg"/></div></div></figure><div class=""/><ul class=""><li id="8d3d" class="iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh bi translated"><a class="ae ji" href="#4d2d" rel="noopener ugc nofollow">简介</a></li><li id="353e" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><a class="ae ji" href="#0d8c" rel="noopener ugc nofollow">会刮什么</a></li><li id="d780" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><a class="ae ji" href="#e351" rel="noopener ugc nofollow">什么是勇敢的搜索</a></li><li id="36c5" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><a class="ae ji" href="#96a0" rel="noopener ugc nofollow">完整代码</a></li><li id="b5dd" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><a class="ae ji" href="#3c4f" rel="noopener ugc nofollow">准备</a></li><li id="edbb" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><a class="ae ji" href="#6bad" rel="noopener ugc nofollow">代码解释</a></li><li id="c1f8" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><a class="ae ji" href="#0c4d" rel="noopener ugc nofollow">刮掉有机新闻</a></li><li id="2c45" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><a class="ae ji" href="#3812" rel="noopener ugc nofollow">刮掉标签新闻</a></li><li id="56db" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><a class="ae ji" href="#1e28" rel="noopener ugc nofollow">链接</a></li></ul><h1 id="4d2d" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">介绍</h1><p id="b8c0" class="pw-post-body-paragraph km kn ht is b it ko kp kq iv kr ks kt ix ku kv kw iz kx ky kz jb la lb lc jd hb bi translated">目前，我们还没有一个支持从Brave Search中提取数据的API。</p><p id="0458" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">这篇博文向你展示了在我们发布合适的API的时候，你如何用下面提供的DIY解决方案来做这件事。</p><p id="221d" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">该解决方案可用于个人用途，因为它不包括我们为付费<a class="ae ji" href="https://serpapi.com/pricing" rel="noopener ugc nofollow" target="_blank">生产和以上计划</a>提供的<a class="ae ji" href="https://serpapi.com/#features" rel="noopener ugc nofollow" target="_blank">合法美国盾</a>，并且有其局限性，例如需要绕过验证码。</p><p id="1ac3" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">你可以查看我们的公共路线图来跟踪这个API的进展:<a class="ae ji" href="https://github.com/serpapi/public-roadmap/issues/323" rel="noopener ugc nofollow" target="_blank">【新API】勇敢搜索</a></p><h1 id="0d8c" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">会刮什么</h1><figure class="lh li lj lk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lg"><img src="../Images/b7d804a1b5a02cc620ec2321adc1eccd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*r6q8ydlIu3j1YE4y.png"/></div></div></figure><p id="d4c6" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">📌注意:有时候有机搜索结果可能没有新闻。这篇博文从有机结果和新闻标签中获取新闻。</p><h1 id="e351" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">什么是勇敢的搜索</h1><p id="2a61" class="pw-post-body-paragraph km kn ht is b it ko kp kq iv kr ks kt ix ku kv kw iz kx ky kz jb la lb lc jd hb bi translated">之前的勇者博文之前描述过<a class="ae ji" href="https://serpapi.com/blog/scrape-brave-search-organic-results-with-python/" rel="noopener ugc nofollow" target="_blank">什么是勇者搜索</a>。为了避免内容重复，这篇博文中没有提到这些信息。</p><h1 id="96a0" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">完整代码</h1><p id="69c8" class="pw-post-body-paragraph km kn ht is b it ko kp kq iv kr ks kt ix ku kv kw iz kx ky kz jb la lb lc jd hb bi translated">如果不需要解释，可以看看在线IDE 中的<a class="ae ji" href="https://replit.com/@chukhraiartur/blog-brave-search-organic-news#main.py" rel="noopener ugc nofollow" target="_blank">完整代码示例。</a></p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="b66e" class="lq jp ht lm b fi lr ls l lt lu">from bs4 import BeautifulSoup<br/>import requests, lxml, json</span><span id="c3dc" class="lq jp ht lm b fi lv ls l lt lu"># https://docs.python-requests.org/en/master/user/quickstart/#passing-parameters-in-urls<br/>params = {<br/>    'q': 'dune',            # query<br/>    'source': 'web',        # source<br/>    'tf': 'at'              # publish time (by default any time)<br/>}</span><span id="2c02" class="lq jp ht lm b fi lv ls l lt lu"># https://docs.python-requests.org/en/master/user/quickstart/#custom-headers<br/>headers = {<br/>    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'<br/>}<br/></span><span id="ab60" class="lq jp ht lm b fi lv ls l lt lu">def scrape_organic_news():<br/>    html = requests.get('https://search.brave.com/search', headers=headers, params=params)<br/>    soup = BeautifulSoup(html.text, 'lxml')</span><span id="a00b" class="lq jp ht lm b fi lv ls l lt lu">    brave_organic_news = []</span><span id="d870" class="lq jp ht lm b fi lv ls l lt lu">    for result in soup.select('#news-carousel .card'):<br/>        title = result.select_one('.title').get_text().strip()<br/>        link = result.get('href')<br/>        time_published = result.select_one('.card-footer__timestamp').get_text().strip()<br/>        source = result.select_one('.anchor').get_text().strip()<br/>        favicon = result.select_one('.favicon').get('src')<br/>        thumbnail = result.select_one('.img-bg').get('style').split(', ')[0].replace("background-image: url('", "").replace("')", "")</span><span id="9161" class="lq jp ht lm b fi lv ls l lt lu">        brave_organic_news.append({<br/>            'title': title,<br/>            'link': link,<br/>            'time_published': time_published,<br/>            'source': source,<br/>            'favicon': favicon,<br/>            'thumbnail': thumbnail<br/>        })</span><span id="6baf" class="lq jp ht lm b fi lv ls l lt lu">    print(json.dumps(brave_organic_news, indent=2, ensure_ascii=False))<br/></span><span id="33a4" class="lq jp ht lm b fi lv ls l lt lu">def scrape_tab_news():<br/>    del params['source']<br/>    html = requests.get('https://search.brave.com/news', headers=headers, params=params)<br/>    soup = BeautifulSoup(html.text, 'lxml')</span><span id="b481" class="lq jp ht lm b fi lv ls l lt lu">    brave_tab_news = []</span><span id="75ed" class="lq jp ht lm b fi lv ls l lt lu">    for result in soup.select('.snippet'):<br/>        title = result.select_one('.snippet-title').get_text()<br/>        link = result.select_one('.result-header').get('href')<br/>        snippet = result.select_one('.snippet-description').get_text().strip()<br/>        time_published = result.select_one('.ml-5+ .text-gray').get_text()<br/>        source = result.select_one('.netloc').get_text()<br/>        favicon = result.select_one('.favicon').get('src')<br/>        thumbnail = result.select_one('.thumb')<br/>        thumbnail = thumbnail.get('src') if thumbnail else None</span><span id="09bb" class="lq jp ht lm b fi lv ls l lt lu">        brave_tab_news.append({<br/>            'title': title,<br/>            'link': link,<br/>            'snippet': snippet,<br/>            'time_published': time_published,<br/>            'source': source,<br/>            'favicon': favicon,<br/>            'thumbnail': thumbnail<br/>        })</span><span id="e206" class="lq jp ht lm b fi lv ls l lt lu">    print(json.dumps(brave_tab_news, indent=2, ensure_ascii=False))<br/></span><span id="3fea" class="lq jp ht lm b fi lv ls l lt lu">if __name__ == "__main__":<br/>    # scrape_organic_news()<br/>    scrape_tab_news()</span></pre><h1 id="3c4f" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">准备</h1><p id="7c24" class="pw-post-body-paragraph km kn ht is b it ko kp kq iv kr ks kt ix ku kv kw iz kx ky kz jb la lb lc jd hb bi translated"><strong class="is hu">安装库</strong>:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="5039" class="lq jp ht lm b fi lr ls l lt lu">pip install requests lxml beautifulsoup4</span></pre><p id="6cfc" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated"><strong class="is hu">CSS选择器基础知识抓取</strong></p><p id="24f9" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">CSS选择器声明样式应用于标记的哪一部分，从而允许从匹配的标签和属性中提取数据。</p><p id="8df0" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">如果你还没有使用CSS选择器，我有一篇关于如何在抓取网页时使用CSS选择器的博文，它涵盖了什么是CSS选择器，利弊，以及为什么从抓取网页的角度来看它们很重要。</p><p id="5a6c" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated"><strong class="is hu">降低被阻挡的几率</strong></p><p id="ec6d" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">确保使用<a class="ae ji" href="https://docs.python-requests.org/en/master/user/quickstart/#custom-headers" rel="noopener ugc nofollow" target="_blank">请求头</a> <code class="du lw lx ly lm b"><a class="ae ji" href="https://developer.mozilla.org/en-US/docs/Glossary/User_agent" rel="noopener ugc nofollow" target="_blank">user-agent</a></code>作为“真正的”用户访问。因为默认的<code class="du lw lx ly lm b">requests</code> <code class="du lw lx ly lm b">user-agent</code>是<code class="du lw lx ly lm b"><a class="ae ji" href="https://github.com/psf/requests/blob/589c4547338b592b1fb77c65663d8aa6fbb7e38b/requests/utils.py#L808-L814" rel="noopener ugc nofollow" target="_blank">python-requests</a></code>，网站知道这很可能是一个发送请求的脚本。<a class="ae ji" href="https://www.whatismybrowser.com/detect/what-is-my-user-agent/" rel="noopener ugc nofollow" target="_blank">检查你的</a> <code class="du lw lx ly lm b"><a class="ae ji" href="https://www.whatismybrowser.com/detect/what-is-my-user-agent/" rel="noopener ugc nofollow" target="_blank">user-agent</a></code>。</p><p id="5beb" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">有一个<a class="ae ji" href="https://serpapi.com/blog/how-to-reduce-chance-of-being-blocked-while-web/" rel="noopener ugc nofollow" target="_blank">如何在抓取博客文章时减少被屏蔽的机会</a>可以让你熟悉基本的和更高级的方法。</p><h1 id="6bad" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">代码解释</h1><p id="1584" class="pw-post-body-paragraph km kn ht is b it ko kp kq iv kr ks kt ix ku kv kw iz kx ky kz jb la lb lc jd hb bi translated">导入库:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="cc51" class="lq jp ht lm b fi lr ls l lt lu">from bs4 import BeautifulSoup<br/>import requests, lxml, json</span></pre><ul class=""><li id="f9fc" class="iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh bi translated"><code class="du lw lx ly lm b"><a class="ae ji" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">BeautifulSoup</a></code>从网页中抓取信息。它位于HTML或XML解析器之上，为迭代、搜索和修改解析树提供了Pythonic习惯用法。</li><li id="a132" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><code class="du lw lx ly lm b"><a class="ae ji" href="https://requests.readthedocs.io/en/latest/user/quickstart/" rel="noopener ugc nofollow" target="_blank">requests</a></code>向网站发出请求。</li><li id="c800" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><code class="du lw lx ly lm b"><a class="ae ji" href="https://lxml.de/" rel="noopener ugc nofollow" target="_blank">lxml</a></code>快速处理XML/HTML文档。</li><li id="0f3b" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><code class="du lw lx ly lm b"><a class="ae ji" href="https://docs.python.org/3/library/json.html" rel="noopener ugc nofollow" target="_blank">json</a></code>将提取的数据转换成JSON对象。</li></ul><p id="6dd3" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">创建URL参数和请求标头:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="67f2" class="lq jp ht lm b fi lr ls l lt lu"># https://docs.python-requests.org/en/master/user/quickstart/#passing-parameters-in-urls<br/>params = {<br/>    'q': 'dune',            # query<br/>    'source': 'web',        # source<br/>    'tf': 'at'              # publish time (by default any time)<br/>}</span><span id="ada6" class="lq jp ht lm b fi lv ls l lt lu"># https://docs.python-requests.org/en/master/user/quickstart/#custom-headers<br/>headers = {<br/>    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'<br/>}</span></pre><ul class=""><li id="760e" class="iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh bi translated">向请求传递URL参数的一种更好的方式。</li><li id="77af" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><code class="du lw lx ly lm b"><a class="ae ji" href="https://developer.mozilla.org/en-US/docs/Glossary/User_agent" rel="noopener ugc nofollow" target="_blank">user-agent</a></code>作为来自浏览器的“真实”用户请求，将其传递给<a class="ae ji" href="https://docs.python-requests.org/en/master/user/quickstart/#custom-headers" rel="noopener ugc nofollow" target="_blank">请求头</a>。<a class="ae ji" href="https://github.com/psf/requests/blob/589c4547338b592b1fb77c65663d8aa6fbb7e38b/requests/utils.py#L808-L814" rel="noopener ugc nofollow" target="_blank">默认</a> <code class="du lw lx ly lm b"><a class="ae ji" href="https://github.com/psf/requests/blob/589c4547338b592b1fb77c65663d8aa6fbb7e38b/requests/utils.py#L808-L814" rel="noopener ugc nofollow" target="_blank">requests</a></code> <a class="ae ji" href="https://github.com/psf/requests/blob/589c4547338b592b1fb77c65663d8aa6fbb7e38b/requests/utils.py#L808-L814" rel="noopener ugc nofollow" target="_blank">用户代理是一个</a> <code class="du lw lx ly lm b"><a class="ae ji" href="https://github.com/psf/requests/blob/589c4547338b592b1fb77c65663d8aa6fbb7e38b/requests/utils.py#L808-L814" rel="noopener ugc nofollow" target="_blank">python-reqeusts</a></code>，因此网站可能会认为它是一个机器人或脚本，并阻止对网站的请求。<a class="ae ji" href="https://www.whatismybrowser.com/detect/what-is-my-user-agent" rel="noopener ugc nofollow" target="_blank">检查你的</a>是什么<code class="du lw lx ly lm b"><a class="ae ji" href="https://www.whatismybrowser.com/detect/what-is-my-user-agent" rel="noopener ugc nofollow" target="_blank">user-agent</a></code>。</li></ul><h1 id="0c4d" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">刮掉有机新闻</h1><p id="2ad1" class="pw-post-body-paragraph km kn ht is b it ko kp kq iv kr ks kt ix ku kv kw iz kx ky kz jb la lb lc jd hb bi translated">这个函数抓取<code class="du lw lx ly lm b"><a class="ae ji" href="https://search.brave.com/search" rel="noopener ugc nofollow" target="_blank">https://search.brave.com/search</a></code> URL的所有有机新闻数据，并以JSON格式输出所有结果。</p><p id="2d94" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">您需要发出一个请求，传递创建的请求参数和头部。该请求将HTML返回给BeautifulSoup:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="879d" class="lq jp ht lm b fi lr ls l lt lu">html = requests.get('https://search.brave.com/search', headers=headers, params=params)<br/>soup = BeautifulSoup(html.text, 'lxml')</span></pre><ul class=""><li id="1a48" class="iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh bi translated"><code class="du lw lx ly lm b"><a class="ae ji" href="https://docs.python-requests.org/en/master/user/quickstart/#timeouts" rel="noopener ugc nofollow" target="_blank">timeout=30</a></code>30秒后停止等待响应。</li><li id="b819" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><code class="du lw lx ly lm b">BeautifulSoup()</code>返回的HTML数据将由<code class="du lw lx ly lm b">bs4</code>处理。</li></ul><p id="7142" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">创建<code class="du lw lx ly lm b">brave_organic_news</code>列表来存储所有新闻:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="a50b" class="lq jp ht lm b fi lr ls l lt lu">brave_organic_news = []</span></pre><p id="1b7d" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">要提取必要的数据，您需要找到它们所在的选择器。在我们的例子中，这是包含所有有机新闻的<code class="du lw lx ly lm b">#news-carousel .card</code>选择器。您需要在循环中迭代每条新闻:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="f017" class="lq jp ht lm b fi lr ls l lt lu">for result in soup.select('#news-carousel .card'):<br/>    # data extraction will be here</span></pre><p id="40e4" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">要提取数据，您需要找到匹配的选择器。<a class="ae ji" href="https://serpapi.com/blog/web-scraping-with-css-selectors-using-python/#css_gadget" rel="noopener ugc nofollow" target="_blank"> SelectorGadget </a>用于抓取CSS选择器。我想演示一下选择器选择过程是如何工作的:</p><figure class="lh li lj lk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lg"><img src="../Images/bf5f51597285624f4ee1dc4c4440be01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*exRrIWZX_xPy3cqF.gif"/></div></div></figure><p id="c492" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">找到选择器后，我们需要获得相应的文本或属性值:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="49d1" class="lq jp ht lm b fi lr ls l lt lu">title = result.select_one('.title').get_text().strip()<br/>link = result.get('href')<br/>time_published = result.select_one('.card-footer__timestamp').get_text().strip()<br/>source = result.select_one('.anchor').get_text().strip()<br/>favicon = result.select_one('.favicon').get('src')<br/>thumbnail = result.select_one('.img-bg').get('style').split(', ')[0].replace("background-image: url('", "").replace("')", "")</span></pre><ul class=""><li id="2993" class="iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh bi translated"><code class="du lw lx ly lm b"><a class="ae ji" href="https://beautiful-soup-4.readthedocs.io/en/latest/#css-selectors" rel="noopener ugc nofollow" target="_blank">select_one()</a></code> <a class="ae ji" href="https://beautiful-soup-4.readthedocs.io/en/latest/#css-selectors" rel="noopener ugc nofollow" target="_blank"> / </a> <code class="du lw lx ly lm b"><a class="ae ji" href="https://beautiful-soup-4.readthedocs.io/en/latest/#css-selectors" rel="noopener ugc nofollow" target="_blank">select()</a></code>对解析后的文档运行CSS选择器，返回所有匹配的元素。</li><li id="0190" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><code class="du lw lx ly lm b"><a class="ae ji" href="https://beautiful-soup-4.readthedocs.io/en/latest/#get-text" rel="noopener ugc nofollow" target="_blank">get_text()</a></code>从节点获取文本数据。</li><li id="a94d" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><code class="du lw lx ly lm b"><a class="ae ji" href="https://beautiful-soup-4.readthedocs.io/en/latest/#attributes" rel="noopener ugc nofollow" target="_blank">get(&lt;attribute&gt;)</a></code>从节点获取属性数据。</li><li id="1ced" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><code class="du lw lx ly lm b"><a class="ae ji" href="https://docs.python.org/3/library/stdtypes.html#str.strip" rel="noopener ugc nofollow" target="_blank">strip()</a></code>返回删除了前导字符和尾随字符的字符串的副本。</li><li id="5f86" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><code class="du lw lx ly lm b"><a class="ae ji" href="https://docs.python.org/3/library/stdtypes.html#str.replace" rel="noopener ugc nofollow" target="_blank">replace()</a></code>用没有额外元素的新子串替换所有出现的旧子串。</li><li id="f07a" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><code class="du lw lx ly lm b"><a class="ae ji" href="https://docs.python.org/3/library/stdtypes.html#str.split" rel="noopener ugc nofollow" target="_blank">split()</a></code>返回字符串中的单词列表，用分隔符字符串分隔字符串。</li></ul><p id="6501" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">从项目中检索数据后，该数据被追加到<code class="du lw lx ly lm b">brave_organic_news</code>列表中:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="88dd" class="lq jp ht lm b fi lr ls l lt lu">brave_organic_news.append({<br/>    'title': title,<br/>    'link': link,<br/>    'time_published': time_published,<br/>    'source': source,<br/>    'favicon': favicon,<br/>    'thumbnail': thumbnail<br/>})</span></pre><p id="0eac" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">收集有机新闻的完整函数如下所示:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="3f48" class="lq jp ht lm b fi lr ls l lt lu">def scrape_organic_news():<br/>    html = requests.get('https://search.brave.com/search', headers=headers, params=params)<br/>    soup = BeautifulSoup(html.text, 'lxml')</span><span id="47ec" class="lq jp ht lm b fi lv ls l lt lu">    brave_organic_news = []</span><span id="ad10" class="lq jp ht lm b fi lv ls l lt lu">    for result in soup.select('#news-carousel .card'):<br/>        title = result.select_one('.title').get_text().strip()<br/>        link = result.get('href')<br/>        time_published = result.select_one('.card-footer__timestamp').get_text().strip()<br/>        source = result.select_one('.anchor').get_text().strip()<br/>        favicon = result.select_one('.favicon').get('src')<br/>        thumbnail = result.select_one('.img-bg').get('style').split(', ')[0].replace("background-image: url('", "").replace("')", "")</span><span id="bf1d" class="lq jp ht lm b fi lv ls l lt lu">        brave_organic_news.append({<br/>            'title': title,<br/>            'link': link,<br/>            'time_published': time_published,<br/>            'source': source,<br/>            'favicon': favicon,<br/>            'thumbnail': thumbnail<br/>        })</span><span id="d736" class="lq jp ht lm b fi lv ls l lt lu">    print(json.dumps(brave_organic_news, indent=2, ensure_ascii=False))</span></pre><p id="4354" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">输出:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="b19d" class="lq jp ht lm b fi lr ls l lt lu">[<br/>  {<br/>    "title": "Dune subreddit group bans AI-generated art for being ‘low effort’ ...",<br/>    "link": "https://www.theguardian.com/film/2022/oct/16/dune-subreddit-group-bans-ai-generated-art-for-being-low-effort",<br/>    "time_published": "2 days ago",<br/>    "source": "theguardian.com",<br/>    "favicon": "https://imgs.search.brave.com/9NJ5RrmLraV8oAt2-ItS_A5rM7MNWTBcXog1rbJwni0/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNGRmYTNkMTZl/NmJhYTQwYmQ4NDRj/MzQ4NDZkNGQ0YTgy/ZWRlZDM4YWVkMzM4/NmM0Y2Y2NTgyMTQ5/NzQxOTExYy93d3cu/dGhlZ3VhcmRpYW4u/Y29tLw",<br/>    "thumbnail": "https://imgs.search.brave.com/PO4d1ks7aUaIUG07Aty1tXis_sdCsr9ZUJ-IXB5Hr7U/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9pLmd1/aW0uY28udWsvaW1n/L21lZGlhL2EzOTQy/NWM5N2M0MzlmY2Vi/Yzc3NTFlYzUzMDQ0/MmJmYWFjOWNlZGYv/Njk3XzBfMjk1OF8x/Nzc3L21hc3Rlci8y/OTU4LmpwZz93aWR0/aD0xMjAwJmhlaWdo/dD02MzAmcXVhbGl0/eT04NSZhdXRvPWZv/cm1hdCZmaXQ9Y3Jv/cCZvdmVybGF5LWFs/aWduPWJvdHRvbSUy/Q2xlZnQmb3Zlcmxh/eS13aWR0aD0xMDBw/Jm92ZXJsYXktYmFz/ZTY0PUwybHRaeTl6/ZEdGMGFXTXZiM1ps/Y214aGVYTXZkR2N0/WkdWbVlYVnNkQzV3/Ym1jJmVuYWJsZT11/cHNjYWxlJnM9NTVi/NDY1MzM1ZDcyNWNh/YzAxNDg2Nzk2NTNm/ZGJlMzg"<br/>  },<br/>  {<br/>    "title": "Emily Watson: The Dune: ‘The Sisterhood’, ‘God’s Creatures’ ...",<br/>    "link": "https://deadline.com/2022/10/emily-watson-the-dune-the-sisterhood-and-gods-creatures-star-says-she-loves-being-in-front-of-the-camera-because-it-gives-her-a-level-of-trust-1235145603/",<br/>    "time_published": "3 days ago",<br/>    "source": "deadline.com",<br/>    "favicon": "https://imgs.search.brave.com/hbAJswXoM5V6EWHa7svVfcuTtKDvVN3HaccvtoCfhVo/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvMjk2OWMwMWU5/ZDU0MGJjMDdkZjY1/NTJmZmU3OGEzMDU5/Y2U2MWQ2ODE5Njdj/NTEwYzA2MGY5ODYy/N2NlNTkzYS9kZWFk/bGluZS5jb20v",<br/>    "thumbnail": "https://imgs.search.brave.com/-vqS2wBthAQPSJiCpxSHW_IcG2CFsVw-MWbUykIOIZQ/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9kZWFk/bGluZS5jb20vd3At/Y29udGVudC91cGxv/YWRzLzIwMjIvMTAv/ZW1pbHkuanBnP3c9/MTAyNA"<br/>  },<br/>  {<br/>    "title": "DUNE: THE SISTERHOOD Taps OBI-WAN KENOBI And GAME OF THRONES Star ...",<br/>    "link": "https://comicbookmovie.com/sci-fi/dune/dune-the-sisterhood-taps-obi-wan-kenobi-and-game-of-thrones-star-indira-varma-for-lead-role-a197335",<br/>    "time_published": "2 days ago",<br/>    "source": "comicbookmovie.com",<br/>    "favicon": "https://imgs.search.brave.com/ZqE9eQ5BIk1l3ZH7MOTWEPqScYt79E7VyJ5D46uRTeA/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvYzNlOWQ3NGE2/MzQwYWExZjRhMDEx/Njk1NGE5OTlkYzhj/NjZmZmEwNjVlYmY1/ODM1MzIyMWZjNWQy/M2FjM2JlNi9jb21p/Y2Jvb2ttb3ZpZS5j/b20v",<br/>    "thumbnail": "https://imgs.search.brave.com/-wstGGJXxONeT0Ig7TNrqFw1DLK5kIWLdm9V-_Ne4lU/rs:fit:200:200:1/g:ce/aHR0cHM6Ly9jb21p/Y2Jvb2ttb3ZpZS5j/b20vaW1hZ2VzL2Fy/dGljbGVzL2Jhbm5l/cnMvMTk3MzM1Lmpw/ZWc"<br/>  },<br/>  ... other news<br/>]</span></pre><h1 id="3812" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">抓取标签新闻</h1><p id="8cca" class="pw-post-body-paragraph km kn ht is b it ko kp kq iv kr ks kt ix ku kv kw iz kx ky kz jb la lb lc jd hb bi translated">这个函数抓取<code class="du lw lx ly lm b"><a class="ae ji" href="https://search.brave.com/news" rel="noopener ugc nofollow" target="_blank">https://search.brave.com/news</a></code> URL的所有选项卡新闻数据，并以JSON格式输出所有结果。</p><p id="5b33" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">您需要发出一个请求，传递创建的请求头和不带<code class="du lw lx ly lm b">'source'</code>参数的参数。该请求将HTML返回给BeautifulSoup:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="560e" class="lq jp ht lm b fi lr ls l lt lu">del params['source']<br/>html = requests.get('https://search.brave.com/news', headers=headers, params=params)<br/>soup = BeautifulSoup(html.text, 'lxml')</span></pre><p id="bfa3" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">创建<code class="du lw lx ly lm b">brave_tab_news</code>列表来存储所有新闻:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="cf45" class="lq jp ht lm b fi lr ls l lt lu">brave_tab_news = []</span></pre><p id="f7d8" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">要从页面中的所有新闻中检索数据，您需要找到条目的<code class="du lw lx ly lm b">.snippet</code>选择器。您需要迭代循环中的每一项:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="b6c4" class="lq jp ht lm b fi lr ls l lt lu">for result in soup.select('.snippet'):<br/>    # data extraction will be here</span></pre><p id="2105" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">在这个页面上，匹配的选择器是不同的。所以这个函数也使用了<a class="ae ji" href="https://serpapi.com/blog/web-scraping-with-css-selectors-using-python/#css_gadget" rel="noopener ugc nofollow" target="_blank"> SelectorGadget </a>来抓取CSS选择器。我想演示一下选择器选择过程是如何工作的:</p><figure class="lh li lj lk fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lg"><img src="../Images/f4612d87ba26720624c370d3102ec883.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WYkoJv1AmHQ4Fioi.gif"/></div></div></figure><p id="547a" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">在这个函数中提取数据的区别在于，在这里你可以得到一个<code class="du lw lx ly lm b">snippet</code>:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="7e97" class="lq jp ht lm b fi lr ls l lt lu">title = result.select_one('.snippet-title').get_text()<br/>link = result.select_one('.result-header').get('href')<br/>snippet = result.select_one('.snippet-description').get_text().strip()<br/>time_published = result.select_one('.ml-5+ .text-gray').get_text()<br/>source = result.select_one('.netloc').get_text()<br/>favicon = result.select_one('.favicon').get('src')<br/>thumbnail = result.select_one('.thumb')<br/>thumbnail = thumbnail.get('src') if thumbnail else None</span></pre><p id="bf7e" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">📌注意:当提取<code class="du lw lx ly lm b">thumbnail</code>时，使用一个<a class="ae ji" href="https://docs.python.org/3/reference/expressions.html#conditional-expressions" rel="noopener ugc nofollow" target="_blank">三元表达式</a>来处理这些数据的值，如果有的话。</p><p id="ecfe" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">从项目中检索数据后，它被附加到<code class="du lw lx ly lm b">brave_tab_news</code>列表中:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="f102" class="lq jp ht lm b fi lr ls l lt lu">brave_tab_news.append({<br/>    'title': title,<br/>    'link': link,<br/>    'snippet': snippet,<br/>    'time_published': time_published,<br/>    'source': source,<br/>    'favicon': favicon,<br/>    'thumbnail': thumbnail<br/>})</span></pre><p id="ac65" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">抓取标签新闻的完整函数如下所示:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="d59d" class="lq jp ht lm b fi lr ls l lt lu">def scrape_tab_news():<br/>    del params['source']<br/>    html = requests.get('https://search.brave.com/news', headers=headers, params=params)<br/>    soup = BeautifulSoup(html.text, 'lxml')</span><span id="b3be" class="lq jp ht lm b fi lv ls l lt lu">    brave_tab_news = []</span><span id="af56" class="lq jp ht lm b fi lv ls l lt lu">    for result in soup.select('.snippet'):<br/>        title = result.select_one('.snippet-title').get_text()<br/>        link = result.select_one('.result-header').get('href')<br/>        snippet = result.select_one('.snippet-description').get_text().strip()<br/>        time_published = result.select_one('.ml-5+ .text-gray').get_text()<br/>        source = result.select_one('.netloc').get_text()<br/>        favicon = result.select_one('.favicon').get('src')<br/>        thumbnail = result.select_one('.thumb')<br/>        thumbnail = thumbnail.get('src') if thumbnail else None</span><span id="2e35" class="lq jp ht lm b fi lv ls l lt lu">        brave_tab_news.append({<br/>            'title': title,<br/>            'link': link,<br/>            'snippet': snippet,<br/>            'time_published': time_published,<br/>            'source': source,<br/>            'favicon': favicon,<br/>            'thumbnail': thumbnail<br/>        })</span><span id="c272" class="lq jp ht lm b fi lv ls l lt lu">    print(json.dumps(brave_tab_news, indent=2, ensure_ascii=False))</span></pre><p id="ced2" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">输出:</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="831c" class="lq jp ht lm b fi lr ls l lt lu">[<br/>  {<br/>    "title": "Dune Games All Have The Same Problem",<br/>    "link": "https://www.msn.com/en-us/entertainment/gaming/dune-games-all-have-the-same-problem/ar-AA1364qI",<br/>    "snippet": "Dune video games have managed to reflect the strategy of ruling Arrakis, but they've failed to capture the franchise’s most fascinating quality.",<br/>    "time_published": "1 day ago",<br/>    "source": "ScreenRant on MSN.com",<br/>    "favicon": "https://imgs.search.brave.com/-8C0opPjysKHAWE2H2sJ4d6TC-jhlh7zWo326qw_QK4/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNGJmODdhNGJk/YmYxY2RkMDU4YzNl/ZjY3OTUyMmNmMzlm/YjYyMmM4MDJlYmQ5/Yzg4ZjY2MzJiZDg4/MWEzYThkNi93d3cu/bXNuLmNvbS8",<br/>    "thumbnail": "https://imgs.search.brave.com/JqEcp16LXMD8UqcFusDHrpixgLnI5EBQURQ9b02ox4U/rs:fit:1335:225:1/g:ce/aHR0cHM6Ly93d3cu/YmluZy5jb20vdGg_/aWQ9T1ZGVC4waktv/VGVKV21DY2VtNUhU/anJyb3NDJnBpZD1O/ZXdz"<br/>  },<br/>  {<br/>    "title": "Dune: The Sisterhood to begin shooting in November as Indira Varma joins cast",<br/>    "link": "https://www.flickeringmyth.com/2022/10/dune-the-sisterhood-to-begin-shooting-in-november-as-indira-varma-joins-cast/",<br/>    "snippet": "As HBO Max and Legendary Television prepare to kick off production on Dune: The Sisterhood, Deadline is reporting that Indira Varma (Game of Thrones, Star Wars: Obi-Wan Kenobi) has joined the cast of the Dune spinoff television series.",<br/>    "time_published": "4 hours ago",<br/>    "source": "Flickeringmyth",<br/>    "favicon": "https://imgs.search.brave.com/syftwTbOGwbuYrlw8LiSFZpqkyNYOzcn2zYsu9tP7g4/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNzQzMTViMjdk/ZWUxNTc3MWY3N2Vi/ZDEwZWI1ODgzOTIy/YzMzYjE5ZGYxODdi/YTUzYzZlZTFkOWM1/M2RlNWI3Yi93d3cu/ZmxpY2tlcmluZ215/dGguY29tLw",<br/>    "thumbnail": null<br/>  },<br/>  {<br/>    "title": "Dune subreddit group bans AI-generated art for being ‘low effort’",<br/>    "link": "https://www.theguardian.com/film/2022/oct/16/dune-subreddit-group-bans-ai-generated-art-for-being-low-effort?amp;amp;amp",<br/>    "snippet": "Moderators of community devoted to sci-fi films and novels say they want to prioritise ‘human-made’ art",<br/>    "time_published": "3 days ago",<br/>    "source": "The Guardian",<br/>    "favicon": "https://imgs.search.brave.com/9NJ5RrmLraV8oAt2-ItS_A5rM7MNWTBcXog1rbJwni0/rs:fit:32:32:1/g:ce/aHR0cDovL2Zhdmlj/b25zLnNlYXJjaC5i/cmF2ZS5jb20vaWNv/bnMvNGRmYTNkMTZl/NmJhYTQwYmQ4NDRj/MzQ4NDZkNGQ0YTgy/ZWRlZDM4YWVkMzM4/NmM0Y2Y2NTgyMTQ5/NzQxOTExYy93d3cu/dGhlZ3VhcmRpYW4u/Y29tLw",<br/>    "thumbnail": "https://imgs.search.brave.com/To--PX2Q-ovIhZzDlN07Go1mLvlaZmj7p6Nb3x-4dZU/rs:fit:1335:225:1/g:ce/aHR0cHM6Ly93d3cu/YmluZy5jb20vdGg_/aWQ9T1ZGVC5ZVUVJ/VzhYc1hxdDZmLTlR/OFl6S1NpJnBpZD1O/ZXdz"<br/>  },<br/>  ... other news<br/>]</span></pre><h1 id="1e28" class="jo jp ht bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">链接</h1><ul class=""><li id="d8bc" class="iq ir ht is b it ko iv kr ix lz iz ma jb mb jd je jf jg jh bi translated"><a class="ae ji" href="https://replit.com/@chukhraiartur/blog-brave-search-organic-news#main.py" rel="noopener ugc nofollow" target="_blank">在线IDE中的代码</a></li><li id="6158" class="iq ir ht is b it jj iv jk ix jl iz jm jb jn jd je jf jg jh bi translated"><a class="ae ji" href="https://dev.to/dimitryzub/how-to-reduce-chance-being-blocked-while-web-scraping-search-engines-1o46" rel="noopener ugc nofollow" target="_blank">减少抓取网页时被堵塞的几率</a></li></ul><p id="a0ab" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">加入我们在推特上的讨论</p><p id="13fd" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated">添加一个<a class="ae ji" href="https://github.com/serpapi/public-roadmap/issues" rel="noopener ugc nofollow" target="_blank">特征请求</a>💫还是一个<a class="ae ji" href="https://github.com/serpapi/public-roadmap/issues" rel="noopener ugc nofollow" target="_blank"> Bug </a>🐞</p></div><div class="ab cl mc md gp me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="hb hc hd he hf"><p id="88b4" class="pw-post-body-paragraph km kn ht is b it iu kp kq iv iw ks kt ix ld kv kw iz le ky kz jb lf lb lc jd hb bi translated"><em class="mj">原载于2021年10月27日https://serpapi.com</em><em class="mj">的</em> <a class="ae ji" href="https://serpapi.com/blog/scrape-organic-news-from-brave-search-with-python/" rel="noopener ugc nofollow" target="_blank"> <em class="mj">。</em></a></p></div></div>    
</body>
</html>