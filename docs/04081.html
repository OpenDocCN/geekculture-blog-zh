<html>
<head>
<title>Useful Dataset for Human Pose Estimation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于人体姿态估计的有用数据集</h1>
<blockquote>原文：<a href="https://medium.com/geekculture/useful-dataset-for-human-pose-estimation-b905d8f08ed4?source=collection_archive---------22-----------------------#2021-06-21">https://medium.com/geekculture/useful-dataset-for-human-pose-estimation-b905d8f08ed4?source=collection_archive---------22-----------------------#2021-06-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/1b57585bb192a557823a2f877dd48b83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Gb9bPZU4mS78y9cZ"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Photo by <a class="ae iu" href="https://unsplash.com/@medicadetion?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Cade Prior</a> on <a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="a88b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">人工智能是每个行业中使用最多的技术，因为它便于出色地完成工作。其中，数据集在任何推荐系统中都起着至关重要的作用。因此，我提出了一个基于人体姿态的数据集的概要。人体姿态估计，每个计算机视觉研究员都想在这方面做出贡献。希望你喜欢我的文章！</p><h1 id="6038" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak"> MPII </strong></h1><p id="6750" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">MPII是<strong class="ix hj">M</strong>ax<strong class="ix hj">P</strong>lanck<strong class="ix hj">I</strong>nstitute<strong class="ix hj">I</strong>informatik的缩写。Mykhaylo，Leonid，Peter和Bernt代表MPII人体姿态数据集。这是一个国家的艺术基准评估连贯的人类姿态估计。它包括用于多人的2D姿势估计，其包含大约25K个图像，其中大约有40K个人在其上标注了身体关节。它包含了410项人类活动，这些活动都是以相应的标签定期执行的。所有的图片都是从YouTube视频中提取的，没有标注帧。在三维姿态测试集上取得了很好的效果，特别是在头部和躯干的定位上，在遮挡图像部分也取得了很好的效果。</p><h1 id="d3fd" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">田蜜</strong></h1><p id="fd09" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">COCO是<strong class="ix hj"> Co </strong> ntext中<strong class="ix hj">C</strong>ommon<strong class="ix hj">O</strong>objects的缩写。这个2D姿态估计数据集是由来自谷歌大脑、MSR、加州理工学院、TTI芝加哥分校、WaveOne、康乃尔理工学院、脸书人工智能研究所、佐治亚理工学院和CMU的研究员通过从Flickr收集数据合作准备的。它高度集中于对象检测、字幕和基于分段的数据特征。它有一些诱人的功能，如上下文识别，超像素的东西和对象分割。它由300K图像组成，其中超过200K是标记图像。它有80个物品类别和91个物品类别。更令人兴奋的功能是，每张图片都有5个标题，250，000人的图片都有关键点注释。它在密集姿态、语义分割、全景分割、检测、关键点标注和图像字幕任务上显示了有效的结果。</p><h1 id="8079" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak"> HumanEva </strong></h1><p id="f30f" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">这个数据集是由马克斯·普朗克智能系统感知系统研究所准备的。它由两个数据集组成，分别是</p><h1 id="495b" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">HumanEva-I </h1><p id="b4f8" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">该数据集使用软件同步，一次保存七个摄像机。摄像机有两种类型:3色和4灰度摄像机，其中6个摄像机是运动捕捉摄像机。它有训练、验证和测试数据集。</p><h1 id="450f" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak"> HumanEva-II </strong></h1><p id="ec80" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">通过一次保持四个摄像机，使用硬件来同步该数据集。有4台彩色摄像机，其中8台是动作捕捉摄像机。它只有测试数据集。</p><p id="4b96" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是针对单人的3D姿态估计，其包括在两种类型的数据集中讨论的视频序列。基于标记的运动捕捉相机用于准备3D姿态地面真实图像。它由执行6种常见动作的4个受试者组成。2D和3D姿态中误差度量是可用的。</p><h1 id="5535" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">人类3.6米</strong></h1><p id="997e" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">根据数据集的名称，它有360万个11个被崇拜的专业演员的3D人体姿势图像，其中有6个男性和5个女性在17个不同的活动中。使用高度校准的和基于飞行时间的4个摄像机捕获频率为50Hz和高分辨率的视频帧。测量每个配置和像素级的24个身体部位标签。演员的3D激光扫描被利用。它有适当的背景减法和包围盒的人。</p><h1 id="e180" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">超现实</strong></h1><p id="2af9" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">超现实是<strong class="ix hj">S</strong>ynetic h<strong class="ix hj">U</strong>man for<strong class="ix hj">R REAL</strong>tasks的缩写。它包含了照片般真实的渲染，在纹理、形状、视角和姿势上有巨大的变化。当提供RGB视频输入时，它对于生成身体部位、光流、2D和3D姿态、表面法线和深度具有良好的功效。有600万帧人造人。使用SMPL(带皮肤的多人线性模型)身体模型生成合成身体，该身体模型的参数与由原始3D MoCap标记数据提供的MoSh方法相关。</p><h1 id="35b4" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak"> FLIC </strong></h1><p id="5c38" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">FLIC是<strong class="ix hj">F</strong>rames<strong class="ix hj">L</strong>abelled<strong class="ix hj">I</strong>n<strong class="ix hj">C</strong>inema的缩写。它由5003张取自好莱坞电影场景的图片组成。它是使用canonical person detector在30部电影的每个连续第十帧上收集的。总共有20000人被纳入置信图的考虑范围，这些置信图被发送到人口高度密集的亚马逊土耳其人那里，以获得地面真相标签。在Turkers图像的帮助下，进行上身关节注释，并考虑五个标记点的中值作为离群点注释。测试数据由1016个数据图像组成。不得将FLIC用于培训和测试。因此，如果我们使用它在不同的数据集上测试和训练机器，因为它是训练数据的超集，这可能会导致过拟合。它也有FLIC-full数据集，其中有大量来自mass电影的帧集，这些电影的手部关节注释是由Mechanical Turk制作的。</p><h1 id="fce5" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak"> LSP </strong></h1><p id="2817" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">LSP是<strong class="ix hj">L</strong>EADS<strong class="ix hj">S</strong>ports<strong class="ix hj">P</strong>ose dataset的缩写。<strong class="ix hj"> </strong>它由2000张仅与八种不同体育活动相关的带注释的姿势图像组成。它们是从Flickr上收集的。所有图像都缩小到大约150像素长。所有的运动图像都能够检测14个关键点关节位置。训练和测试数据按50%的比例划分。</p><p id="a4e2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后，我试图总结几个数据集的细节。我希望它会有用。在评论区分享你的观点，这样在下一篇文章中我可以改进它。</p></div></div>    
</body>
</html>